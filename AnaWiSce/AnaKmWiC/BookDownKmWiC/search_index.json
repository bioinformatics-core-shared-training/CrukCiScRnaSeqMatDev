[["index.html", "CRUK Bioinformatics Summer School 2020 - single-cell RNA-seq analysis Heterogeneity in childhood acute lymphoblastic leukemia with droplet-based 10X Chromium assay. Chapter 1 Preamble 1.1 The study 1.2 The plan 1.3 The analyses 1.4 Overall summary 1.5 Conclusion 1.6 Abbreviations", " CRUK Bioinformatics Summer School 2020 - single-cell RNA-seq analysis Heterogeneity in childhood acute lymphoblastic leukemia with droplet-based 10X Chromium assay. Stephane Ballereau, Zeynep Kalender Atak 2021-05-19 Chapter 1 Preamble 1.1 The study “Childhood acute lymphoblastic leukemia (cALL) is the most common pediatric cancer. It is characterized by bone marrow lymphoid precursors that acquire genetic alterations, resulting in disrupted maturation and uncontrollable proliferation.” Caron et al. 2020. Nowaways, up to 85–90% of patients are cured, but others do not respond to treatment or relapse and die. The aim of the study is to characterise the heterogeneity of gene expression at the cell level, within and between patients. Four type of samples are considered: eight patients: six B-ALL two T-ALL three healthy pediatric controls eight healthy adult controls, publicly available As the study aims at identifying cell populations, large numbers of cells were sequenced with the droplet-based 10X Chromium assay. 1.2 The plan We will follow several steps: sequencing quality check alignment of reads to the human genome (GRCh38) with 10X software cellranger quality control (cell calls, cells and genes filtering) count normalisation data set integration feature selection dimensionality reduction clustering marker gene identification cell type annotation cell cycle assignment trajectory analysis 1.3 The analyses This report includes: Sequence Quality is good (see 2) cellranger output suggests the data sets are good quality (see 3) Quality control - a first glance at the RNA data set comprising all droplets deemed to contain at leat one cell, to check the data quality and biological signal (eg. do we observe cell types we expect?) (see 4 for the ‘all-cells’ analysis and 5 for the analysis of the downsampled data set to use in the course) –&gt; 1.4 Overall summary 1.5 Conclusion 1.6 Abbreviations BMMC: Bone Marrow Mononuclear Cell HCA: Human Cell Atlas PCA: Principal Component Analysis UMI: Unique Molecular Identifier "],["SeqQualTop.html", "Chapter 2 Sequence Quality 2.1 Introduction 2.2 CaronBourque2020 - fastqc 2.3 CaronBourque2020 - MultiQC 2.4 HCA adult BMMC - fastqc 2.5 HCA adult BMMC - MultiQC", " Chapter 2 Sequence Quality #projDirOsx &lt;- &quot;/Users/baller01/MyMount/clust1a/20200511_FernandesM_ME_crukBiSs2020&quot; #projDir &lt;- &quot;/mnt/scratcha/bioinformatics/baller01/20200511_FernandesM_ME_crukBiSs2020&quot; #projDir &lt;- &quot;/home/ubuntu/Course_Materials/scRNAseq&quot; projDir &lt;- params$projDir projDirLink &lt;- &quot;/Users/baller01/MyMount/svr008ssd/20200511_FernandesM_ME_crukBiSs2020&quot; inpDirBit &lt;- params$inpDirBit outDirBit &lt;- params$outDirBit library(DT) 2.1 Introduction We will use two sets of Bone Marrow Mononuclear Cells (BMMC): ‘CaronBourque2020’: pediatric samples ‘Hca’: HCA Census of Immune Cells for adult BMMCs Fastq files were retrieved from publicly available archive (SRA and HCA). Sequencing quality was assessed and visualised using fastQC and MultiQC. Library structure reminder: The sample index identifies the library, with one I7 index per sample The 10X cell barcode (or cell index) identifies the droplet in the library The UMI identifies the transcript molecule within a cell and gene The insert is the transcript molecule, ie the cDNA sequence Each sample is described with three sets of fastq files: I1: sample index R1: 10x barcode + UMI R2: insert sequence The sample index is actually a set of four 8-ntd oligo. For example SIGAB8 is ‘AAAGTGCT-GCTACCTG-TGCTGTAA-CTGCAAGC’. All four are used and identified by a digit, eg 1-4. Depending on the processing pipeline, fastq files may be returned for each 8-ntd index, or combined into a single file. For the Caron data set they are combined in a single file, and files for separate lanes were also combined into a single fastq file. Each sample is identified by three fastq files, one per read type: sample _ S0 _ L001 _ I1 _ 001 _ .fastq.gz: contains sample index sample _ S0 _ L001 _ R1 _ 001 _ .fastq.gz: contains 10x barcode + UMI sample _ S0 _ L001 _ R2 _ 001 _ .fastq.gz: contains insert sequence We kept the same names for the fastqc output. With for example sample ‘SRR9264343’: SRR9264343 _ S0 _ L001 _ I1 _ 001 _ fastqc.html SRR9264343 _ S0 _ L001 _ R1 _ 001 _ fastqc.html SRR9264343 _ S0 _ L001 _ R2 _ 001 _ fastqc.html fastqcDir &lt;- sprintf(&quot;%s/Data/%s/fastqc&quot;, projDir, &quot;CaronBourque2020&quot;) fastqcDirLink &lt;- sprintf(&quot;%s/Data/%s/fastqc&quot;, projDirLink, &quot;CaronBourque2020&quot;) 2.2 CaronBourque2020 - fastqc # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) #cb_sampleSheet &lt;- cb_sampleSheet %&gt;% filter(!Run == &quot;SRR9264351&quot;) cb_sampleSheet ## Run Assay.Type AvgSpotLen Bases BioProject BioSample ## 1 SRR9264343 RNA-Seq 132 27850288884 PRJNA548203 SAMN12011162 ## 2 SRR9264344 RNA-Seq 132 43613421192 PRJNA548203 SAMN12011172 ## 3 SRR9264345 RNA-Seq 132 43838527392 PRJNA548203 SAMN12011171 ## 4 SRR9264346 RNA-Seq 132 39752529300 PRJNA548203 SAMN12011170 ## 5 SRR9264347 RNA-Seq 132 41035092252 PRJNA548203 SAMN12011169 ## 6 SRR9264348 RNA-Seq 132 42840756288 PRJNA548203 SAMN12011168 ## 7 SRR9264349 RNA-Seq 132 42953865372 PRJNA548203 SAMN12011167 ## 8 SRR9264350 RNA-Seq 132 42822420960 PRJNA548203 SAMN12011166 ## 9 SRR9264351 RNA-Seq 132 28322630028 PRJNA548203 SAMN12011165 ## 10 SRR9264352 RNA-Seq 132 36199482528 PRJNA548203 SAMN12011165 ## 11 SRR9264353 RNA-Seq 132 41446760124 PRJNA548203 SAMN12011164 ## 12 SRR9264354 RNA-Seq 132 42802129128 PRJNA548203 SAMN12011163 ## Bytes ## 1 18644549905 ## 2 27638885644 ## 3 28054431102 ## 4 25564104997 ## 5 24777477094 ## 6 27432674292 ## 7 27523442193 ## 8 27282064655 ## 9 19040444664 ## 10 22143300246 ## 11 26850120365 ## 12 27774281557 ## Cell_type ## 1 Pre-B t(12;21) [ETV6-RUNX1] acute lymphoblastic leukemia cells ## 2 Pre-B t(12;21) [ETV6-RUNX1] acute lymphoblastic leukemia cells ## 3 Pre-B t(12;21) [ETV6-RUNX1] acute lymphoblastic leukemia cells ## 4 Pre-B t(12;21) [ETV6-RUNX1] acute lymphoblastic leukemia cells ## 5 Pre-B High hyper diploid [HHD] acute lymphoblastic leukemia cells ## 6 Pre-B High hyper diploid [HHD] acute lymphoblastic leukemia cells ## 7 Pre-T acute lymphoblastic leukemia cells ## 8 Pre-T acute lymphoblastic leukemia cells ## 9 Healthy pediatric bone marrow mononuclear cells ## 10 Healthy pediatric bone marrow mononuclear cells ## 11 Healthy pediatric bone marrow mononuclear cells ## 12 Healthy pediatric bone marrow mononuclear cells ## Center.Name Consent DATASTORE.filetype DATASTORE.provider ## 1 GEO public fastq,sra gs,ncbi,s3 ## 2 GEO public fastq,sra gs,ncbi,s3 ## 3 GEO public fastq,sra gs,ncbi,s3 ## 4 GEO public fastq,sra gs,ncbi,s3 ## 5 GEO public fastq,sra gs,ncbi,s3 ## 6 GEO public fastq,sra gs,ncbi,s3 ## 7 GEO public fastq,sra gs,ncbi,s3 ## 8 GEO public fastq,sra gs,ncbi,s3 ## 9 GEO public fastq,sra gs,ncbi,s3 ## 10 GEO public fastq,sra gs,ncbi,s3 ## 11 GEO public fastq,sra gs,ncbi,s3 ## 12 GEO public fastq,sra gs,ncbi,s3 ## DATASTORE.region disease_state ## 1 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 2 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 3 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 4 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 5 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 6 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 7 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 8 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 9 gs.US,ncbi.public,s3.us-east-1 Healthy pediatric control ## 10 gs.US,ncbi.public,s3.us-east-1 Healthy pediatric control ## 11 gs.US,ncbi.public,s3.us-east-1 Healthy pediatric control ## 12 gs.US,ncbi.public,s3.us-east-1 Healthy pediatric control ## Experiment GEO_Accession..exp. Instrument LibraryLayout ## 1 SRX6034681 GSM3872434 Illumina HiSeq 4000 PAIRED ## 2 SRX6034682 GSM3872435 Illumina HiSeq 4000 PAIRED ## 3 SRX6034683 GSM3872436 Illumina HiSeq 4000 PAIRED ## 4 SRX6034684 GSM3872437 Illumina HiSeq 4000 PAIRED ## 5 SRX6034685 GSM3872438 Illumina HiSeq 4000 PAIRED ## 6 SRX6034686 GSM3872439 Illumina HiSeq 4000 PAIRED ## 7 SRX6034687 GSM3872440 Illumina HiSeq 4000 PAIRED ## 8 SRX6034688 GSM3872441 Illumina HiSeq 4000 PAIRED ## 9 SRX6034689 GSM3872442 Illumina HiSeq 4000 PAIRED ## 10 SRX6034689 GSM3872442 Illumina HiSeq 4000 PAIRED ## 11 SRX6034690 GSM3872443 Illumina HiSeq 4000 PAIRED ## 12 SRX6034691 GSM3872444 Illumina HiSeq 4000 PAIRED ## LibrarySelection LibrarySource Organism Platform ReleaseDate ## 1 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 2 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 3 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 4 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 5 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 6 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 7 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 8 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 9 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 10 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 11 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 12 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## Sample.Name source_name SRA.Study ## 1 GSM3872434 ETV6-RUNX1 SRP201012 ## 2 GSM3872435 ETV6-RUNX1 SRP201012 ## 3 GSM3872436 ETV6-RUNX1 SRP201012 ## 4 GSM3872437 ETV6-RUNX1 SRP201012 ## 5 GSM3872438 HHD SRP201012 ## 6 GSM3872439 HHD SRP201012 ## 7 GSM3872440 PRE-T SRP201012 ## 8 GSM3872441 PRE-T SRP201012 ## 9 GSM3872442 PBMMC SRP201012 ## 10 GSM3872442 PBMMC SRP201012 ## 11 GSM3872443 PBMMC SRP201012 ## 12 GSM3872444 PBMMC SRP201012 htmlVec &lt;- list.files(fastqcDir) htmlVec &lt;- grep(&quot;\\\\.html$&quot;, htmlVec, value=TRUE) filesDf &lt;- data.frame( &quot;I1&quot; = sprintf(&quot;%s_S0_L001_%s_001_fastqc.html&quot;, cb_sampleSheet$Run, &quot;I1&quot;), &quot;R1&quot; = sprintf(&quot;%s_S0_L001_%s_001_fastqc.html&quot;, cb_sampleSheet$Run, &quot;R1&quot;), &quot;R2&quot; = sprintf(&quot;%s_S0_L001_%s_001_fastqc.html&quot;, cb_sampleSheet$Run, &quot;R2&quot;) ) rownames(filesDf) &lt;- cb_sampleSheet$Run for (runx in cb_sampleSheet$Run) { cat(&quot;Run &quot;, runx, &quot;:\\n\\n&quot;) for(i in c(&quot;I1&quot;, &quot;R1&quot;, &quot;R2&quot;)) { #filepath &lt;- file.path(fastqcDir, filesDf[runx,i]) filepath &lt;- file.path(fastqcDirLink, filesDf[runx,i]) cat(i, &quot;: [&quot;, filesDf[runx,i], &quot;](&quot;,filepath,&quot;)\\n\\n&quot;) } } Run SRR9264343 : I1 : SRR9264343_S0_L001_I1_001_fastqc.html R1 : SRR9264343_S0_L001_R1_001_fastqc.html R2 : SRR9264343_S0_L001_R2_001_fastqc.html Run SRR9264344 : I1 : SRR9264344_S0_L001_I1_001_fastqc.html R1 : SRR9264344_S0_L001_R1_001_fastqc.html R2 : SRR9264344_S0_L001_R2_001_fastqc.html Run SRR9264345 : I1 : SRR9264345_S0_L001_I1_001_fastqc.html R1 : SRR9264345_S0_L001_R1_001_fastqc.html R2 : SRR9264345_S0_L001_R2_001_fastqc.html Run SRR9264346 : I1 : SRR9264346_S0_L001_I1_001_fastqc.html R1 : SRR9264346_S0_L001_R1_001_fastqc.html R2 : SRR9264346_S0_L001_R2_001_fastqc.html Run SRR9264347 : I1 : SRR9264347_S0_L001_I1_001_fastqc.html R1 : SRR9264347_S0_L001_R1_001_fastqc.html R2 : SRR9264347_S0_L001_R2_001_fastqc.html Run SRR9264348 : I1 : SRR9264348_S0_L001_I1_001_fastqc.html R1 : SRR9264348_S0_L001_R1_001_fastqc.html R2 : SRR9264348_S0_L001_R2_001_fastqc.html Run SRR9264349 : I1 : SRR9264349_S0_L001_I1_001_fastqc.html R1 : SRR9264349_S0_L001_R1_001_fastqc.html R2 : SRR9264349_S0_L001_R2_001_fastqc.html Run SRR9264350 : I1 : SRR9264350_S0_L001_I1_001_fastqc.html R1 : SRR9264350_S0_L001_R1_001_fastqc.html R2 : SRR9264350_S0_L001_R2_001_fastqc.html Run SRR9264351 : I1 : SRR9264351_S0_L001_I1_001_fastqc.html R1 : SRR9264351_S0_L001_R1_001_fastqc.html R2 : SRR9264351_S0_L001_R2_001_fastqc.html Run SRR9264352 : I1 : SRR9264352_S0_L001_I1_001_fastqc.html R1 : SRR9264352_S0_L001_R1_001_fastqc.html R2 : SRR9264352_S0_L001_R2_001_fastqc.html Run SRR9264353 : I1 : SRR9264353_S0_L001_I1_001_fastqc.html R1 : SRR9264353_S0_L001_R1_001_fastqc.html R2 : SRR9264353_S0_L001_R2_001_fastqc.html Run SRR9264354 : I1 : SRR9264354_S0_L001_I1_001_fastqc.html R1 : SRR9264354_S0_L001_R1_001_fastqc.html R2 : SRR9264354_S0_L001_R2_001_fastqc.html 2.3 CaronBourque2020 - MultiQC 2.3.1 sample index: I1 htmlVec &lt;- list.files(paste0(fastqcDir, &quot;/Multiqc/I1&quot;)) htmlVec &lt;- grep(&quot;\\\\.html$&quot;, htmlVec, value=TRUE) for(i in htmlVec){ filename &lt;- file.path(fastqcDirLink, &quot;/Multiqc/I1&quot;, i) cat(&quot;[&quot;, i, &quot;](&quot;,filename,&quot;)\\n\\n&quot;) } multiqc_report.html 2.3.2 cell barcode + UMI: R1 htmlVec &lt;- list.files(paste0(fastqcDir, &quot;/Multiqc/R1&quot;)) htmlVec &lt;- grep(&quot;\\\\.html$&quot;, htmlVec, value=TRUE) for(i in htmlVec){ filename &lt;- file.path(fastqcDirLink, &quot;/Multiqc/R1&quot;, i) cat(&quot;[&quot;, i, &quot;](&quot;,filename,&quot;)\\n\\n&quot;) } multiqc_report.html 2.3.3 insert: R2 htmlVec &lt;- list.files(paste0(fastqcDir, &quot;/Multiqc/R2&quot;)) htmlVec &lt;- grep(&quot;\\\\.html$&quot;, htmlVec, value=TRUE) for(i in htmlVec){ filename &lt;- file.path(fastqcDirLink, &quot;/Multiqc/R2&quot;, i) cat(&quot;[&quot;, i, &quot;](&quot;,filename,&quot;)\\n\\n&quot;) } multiqc_report.html 2.4 HCA adult BMMC - fastqc For the HCA adult BMMC fastq files were provided for each 8-ntd sample index and lane. We ran fastqc on each separately. We are therefore not listing links to the fastqc reports but only to the MultiQC reports. fastqcDir &lt;- sprintf(&quot;%s/Data/%s/fastqc&quot;, projDir, &quot;Hca&quot;) fastqcDirLink &lt;- sprintf(&quot;%s/Data/%s/fastqc&quot;, projDirLink, &quot;Hca&quot;) # HCA hca_sampleSheetFn &lt;- file.path(projDir, &quot;Data/Hca/accList_Hca.txt&quot;) hca_sampleSheet &lt;- read.table(hca_sampleSheetFn, header=F, sep=&quot;,&quot;) colnames(hca_sampleSheet) &lt;- &quot;Run&quot; hca_sampleSheet ## Run ## 1 MantonBM1 ## 2 MantonBM2 ## 3 MantonBM3 ## 4 MantonBM4 ## 5 MantonBM5 ## 6 MantonBM6 ## 7 MantonBM7 ## 8 MantonBM8 htmlVec &lt;- list.files(fastqcDir) htmlVec &lt;- grep(&quot;\\\\.html$&quot;, htmlVec, value=TRUE) 378 fastqc reports were compiled in the multiQC reports below. 2.5 HCA adult BMMC - MultiQC 2.5.1 sample index: I1 htmlVec &lt;- list.files(paste0(fastqcDir, &quot;/Multiqc/I1&quot;)) htmlVec &lt;- grep(&quot;\\\\.html$&quot;, htmlVec, value=TRUE) for(i in htmlVec){ filename &lt;- file.path(fastqcDirLink, &quot;/Multiqc/I1&quot;, i) cat(&quot;[&quot;, i, &quot;](&quot;,filename,&quot;)\\n\\n&quot;) } multiqc_report.html 2.5.2 cell barcode + UMI: R1 htmlVec &lt;- list.files(paste0(fastqcDir, &quot;/Multiqc/R1&quot;)) htmlVec &lt;- grep(&quot;\\\\.html$&quot;, htmlVec, value=TRUE) for(i in htmlVec){ filename &lt;- file.path(fastqcDirLink, &quot;/Multiqc/R1&quot;, i) cat(&quot;[&quot;, i, &quot;](&quot;,filename,&quot;)\\n\\n&quot;) } multiqc_report.html 2.5.3 insert: R2 htmlVec &lt;- list.files(paste0(fastqcDir, &quot;/Multiqc/R2&quot;)) htmlVec &lt;- grep(&quot;\\\\.html$&quot;, htmlVec, value=TRUE) for(i in htmlVec){ filename &lt;- file.path(fastqcDirLink, &quot;/Multiqc/R2&quot;, i) cat(&quot;[&quot;, i, &quot;](&quot;,filename,&quot;)\\n\\n&quot;) } multiqc_report.html WORKING DOCUMENT - IN PROGRESS library(dplyr) "],["AliFeatCountTop.html", "Chapter 3 Alignment and feature counting 3.1 Introduction 3.2 10X cellranger pipeline in brief 3.3 sample sheet 3.4 10X cellranger reports for CaronBourque2020 3.5 10X cellranger reports for HCA’s adult BMMCs", " Chapter 3 Alignment and feature counting 3.1 Introduction We will use two sets of Bone Marrow Mononuclear Cells (BMMC): ‘CaronBourque2020’: pediatric samples ‘Hca’: HCA Census of Immune Cells for adult BMMCs Fastq files were retrieved from publicly available archive (SRA and HCA). Sequencing quality was assessed and visualised using fastQC and MultiQC. Reads were aligned against GRCh38 and features counted using cellranger (v3.1.0). #wrkDir &lt;- &quot;/mnt/scratchb/bioinformatics/baller01/20200511_FernandesM_ME_crukBiSs2020/CaronBourque2020/grch38300&quot; #setwd(wrkDir) projDir &lt;- params$projDir #projDirLink &lt;- &quot;/Users/baller01/MyMount/svr008ssd/20200511_FernandesM_ME_crukBiSs2020&quot; projDirLink &lt;- gsub(&quot;/ssd/personal/baller01&quot;, &quot;/Users/baller01/MyMount/svr008ssd&quot;, projDir) inpDirBit &lt;- params$inpDirBit # &quot;AnaWiSeurat/Attempt1&quot; outDirBit &lt;- params$outDirBit # &quot;AnaWiSeurat/Attempt1&quot; plotDir &lt;- &quot;QcPlots&quot; # eg # cellrangerDirLink &lt;- sprintf(&quot;%s/%s/grch38300&quot;, projDirLink, &quot;CaronBourque2020&quot;) 3.2 10X cellranger pipeline in brief Each sample was analysed separately with cellranger. This pipeline “is a set of analysis pipelines that process Chromium single-cell RNA-seq output to align reads, generate feature-barcode matrices and perform clustering and gene expression analysis.” TODO Add code to call cellranger 3.3 sample sheet # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) # Human Cell Atlas hca_sampleSheetFn &lt;- file.path(projDir, &quot;Data/Hca/accList_Hca.txt&quot;) # read sample sheet in: splShtColToKeep &lt;- c(&quot;Run&quot;, &quot;Sample.Name&quot;, &quot;source_name&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) hca_sampleSheet &lt;- read.table(hca_sampleSheetFn, header=F, sep=&quot;,&quot;) colnames(hca_sampleSheet) &lt;- &quot;Sample.Name&quot; hca_sampleSheet$Run &lt;- hca_sampleSheet$Sample.Name hca_sampleSheet$source_name &lt;- &quot;ABMMC&quot; # adult BMMC sampleSheetCat &lt;- rbind(cb_sampleSheet[,splShtColToKeep], hca_sampleSheet[,splShtColToKeep]) sampleSheetCat %&gt;% #DT::datatable(options = list(dom=&#39;t&#39;)) DT::datatable(options = list(pageLength = 10)) 3.4 10X cellranger reports for CaronBourque2020 #cellrangerDir &lt;- sprintf(&quot;%s/%s/grch38300&quot;, projDir, &quot;CaronBourque2020&quot;) #projDirOsx &lt;- &quot;/Users/baller01/MyMount/clust1b/20200511_FernandesM_ME_crukBiSs2020&quot; # make dir name for each sample of interest # with &#39;Run&#39; column sampleSheet &lt;- sampleSheetCat %&gt;% filter(! source_name == &quot;ABMMC&quot;) cellrangerDirLink &lt;- sprintf(&quot;%s/%s/grch38300&quot;, projDirLink, &quot;CaronBourque2020&quot;) htmlVec &lt;- sprintf(&quot;%s/%s/%s/outs/web_summary.html&quot;, cellrangerDirLink, sampleSheet$Run, sampleSheet$Run) names(htmlVec) &lt;- sampleSheet$Run for(i in 1:length(htmlVec)){ cat(&quot;[&quot;, names(htmlVec)[i], &quot;](&quot;, htmlVec[i],&quot;)\\n\\n&quot;) } SRR9264343 SRR9264344 SRR9264345 SRR9264346 SRR9264347 SRR9264348 SRR9264349 SRR9264350 SRR9264351 SRR9264352 SRR9264353 SRR9264354 # TODO: add links to sample sheet and show with DT::datatable 3.5 10X cellranger reports for HCA’s adult BMMCs #cellrangerDir &lt;- sprintf(&quot;%s/%s/grch38300&quot;, projDir, &quot;CaronBourque2020&quot;) #projDirOsx &lt;- &quot;/Users/baller01/MyMount/clust1b/20200511_FernandesM_ME_crukBiSs2020&quot; # make dir name for each sample of interest # with &#39;Run&#39; column sampleSheet &lt;- sampleSheetCat %&gt;% filter(source_name == &quot;ABMMC&quot;) cellrangerDirLink &lt;- sprintf(&quot;%s/%s/grch38300&quot;, projDirLink, &quot;Hca&quot;) htmlVec &lt;- sprintf(&quot;%s/%s/%s/outs/web_summary.html&quot;, cellrangerDirLink, sampleSheet$Run, sampleSheet$Run) names(htmlVec) &lt;- sampleSheet$Run for(i in 1:length(htmlVec)){ cat(&quot;[&quot;, names(htmlVec)[i], &quot;](&quot;, htmlVec[i],&quot;)\\n\\n&quot;) } MantonBM1 MantonBM2 MantonBM3 MantonBM4 MantonBM5 MantonBM6 MantonBM7 MantonBM8 "],["PreProcAllCellsTop.html", "Chapter 4 Quality Control - with 2-5k cells per sample 4.1 Introduction 4.2 Load packages 4.3 Sample sheet 4.4 Data representation 4.5 Example 4.6 Mapping QC 4.7 Cell calling for droplet data 4.8 Load filtered matrices 4.9 Properties of scRNA-seq data 4.10 Quality control 4.11 Identification of low-quality cells with adaptive thresholds 4.12 Experimental factors 4.13 Novelty 4.14 QC based on sparsity 4.15 Subsample Hca set 4.16 Session information", " Chapter 4 Quality Control - with 2-5k cells per sample 4.1 Introduction We will use two sets of Bone Marrow Mononuclear Cells (BMMC): ‘CaronBourque2020’: pediatric samples ‘Hca’: HCA Census of Immune Cells for adult BMMCs Fastq files were retrieved from publicly available archive (SRA and HCA). Sequencing quality was assessed and visualised using fastQC and MultiQC. Reads were aligned against GRCh38 and features counted using cellranger (v3.1.0). We will now check the quality of the data further: mapping quality and amplification rate cell counts distribution of keys quality metrics We will then: filter genes with very low expression identify low-quality cells filter and/or mark low quality cells 4.2 Load packages SingleCellExperiment - to store the data Matrix - to deal with sparse and/or large matrices DropletUtils - utilities for the analysis of droplet-based, inc. cell counting scater - QC scran - normalisation igraph - graphs biomaRt - for gene annotation ggplot2 - for plotting irlba - for faster PCA #projDir &lt;- &quot;/home/ubuntu/Course_Materials/scRNAseq&quot; projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit setSuf &lt;- params$setSuf # with merge-knit # params are read once only. # but we need to change one param value: dirRel # 3 solutions: # - unlock bindings to edit the global value # - copy params to edit and use the local copy # - simply set dirRel, based on type of merging if need be. # unlock binding # (but should remember to set back to init value if need be) #bindingIsLocked(&quot;params&quot;, env = .GlobalEnv) #unlockBinding(&quot;params&quot;, env = .GlobalEnv) #params$stuff &lt;- &#39;toto&#39; # OR: # global_params &lt;- params; # if merge-knit # have local copy of params to edit and use here #local_params &lt;- params; # if merge-knit #local_params$stuff &lt;- &#39;toto&#39; # OR: # if merge-knit, edit params. if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_allCells&quot; dirRel &lt;- &quot;..&quot; cacheLazyBool &lt;- FALSE } # other variables: wrkDir &lt;- sprintf(&quot;%s/CaronBourque2020/grch38300&quot;, projDir) qcPlotDirBit &lt;- &quot;Plots/Qc&quot; poolBool &lt;- TRUE # FALSE # whether to read each sample in and pool them and write object to file, or just load that file. biomartBool &lt;- TRUE # FALSE # biomaRt sometimes fails, do it once, write to file and use that copy. addQcBool &lt;- TRUE # FALSE runAll &lt;- TRUE dir.create(sprintf(&quot;%s/%s/%s&quot;, projDir, outDirBit, qcPlotDirBit), showWarnings = FALSE, recursive = TRUE) dir.create(sprintf(&quot;%s/%s/Robjects&quot;, projDir, outDirBit), showWarnings = FALSE) 4.3 Sample sheet We will load both the Caron and Hca data sets. # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) # Human Cell Atlas hca_sampleSheetFn &lt;- file.path(projDir, &quot;Data/Hca/accList_Hca.txt&quot;) # read sample sheet in: splShtColToKeep &lt;- c(&quot;Run&quot;, &quot;Sample.Name&quot;, &quot;source_name&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) hca_sampleSheet &lt;- read.table(hca_sampleSheetFn, header=F, sep=&quot;,&quot;) colnames(hca_sampleSheet) &lt;- &quot;Sample.Name&quot; hca_sampleSheet$Run &lt;- hca_sampleSheet$Sample.Name hca_sampleSheet$source_name &lt;- &quot;ABMMC&quot; # adult BMMC sampleSheet &lt;- rbind(cb_sampleSheet[,splShtColToKeep], hca_sampleSheet[,splShtColToKeep]) sampleSheet %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) 4.4 Data representation We will use a SingleCellExperiment object that is described here and stores various data types: the count matrix feature (gene) annotation droplet annotation outcome of downstream analysis such as dimensionality reduction tmpFn &lt;- sprintf(&quot;%s/Images/tenxLibStructureV3.png&quot;, &quot;..&quot;) knitr::include_graphics(tmpFn, auto_pdf = TRUE) 4.5 Example We will load the data for the first sample in the sample sheet: SRR9264343. i &lt;- 1 sample.path &lt;- sprintf(&quot;%s/%s/%s/outs/raw_feature_bc_matrix/&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) sce.raw &lt;- read10xCounts(sample.path, col.names=TRUE) sce.raw ## class: SingleCellExperiment ## dim: 33538 737280 ## metadata(1): Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(3): ID Symbol Type ## colnames(737280): AAACCTGAGAAACCAT-1 AAACCTGAGAAACCGC-1 ... ## TTTGTCATCTTTAGTC-1 TTTGTCATCTTTCCTC-1 ## colData names(2): Sample Barcode ## reducedDimNames(0): ## altExpNames(0): We can access these different types of data with various functions. Number of genes and droplets in the count matrix: dim(counts(sce.raw)) ## [1] 33538 737280 Features, with rowData(): head(rowData(sce.raw)) ## DataFrame with 6 rows and 3 columns ## ID Symbol Type ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000243485 ENSG00000243485 MIR1302-2HG Gene Expression ## ENSG00000237613 ENSG00000237613 FAM138A Gene Expression ## ENSG00000186092 ENSG00000186092 OR4F5 Gene Expression ## ENSG00000238009 ENSG00000238009 AL627309.1 Gene Expression ## ENSG00000239945 ENSG00000239945 AL627309.3 Gene Expression ## ENSG00000239906 ENSG00000239906 AL627309.2 Gene Expression Samples, with colData(): head(colData(sce.raw)) ## DataFrame with 6 rows and 2 columns ## Sample Barcode ## &lt;character&gt; &lt;character&gt; ## AAACCTGAGAAACCAT-1 /ssd/personal/baller.. AAACCTGAGAAACCAT-1 ## AAACCTGAGAAACCGC-1 /ssd/personal/baller.. AAACCTGAGAAACCGC-1 ## AAACCTGAGAAACCTA-1 /ssd/personal/baller.. AAACCTGAGAAACCTA-1 ## AAACCTGAGAAACGAG-1 /ssd/personal/baller.. AAACCTGAGAAACGAG-1 ## AAACCTGAGAAACGCC-1 /ssd/personal/baller.. AAACCTGAGAAACGCC-1 ## AAACCTGAGAAAGTGG-1 /ssd/personal/baller.. AAACCTGAGAAAGTGG-1 Single-cell RNA-seq data compared to bulk RNA-seq is sparse, especially with droplet-based methods such as 10X, mostly because: a given cell does not express each gene the library preparation does not capture all transcript the cell does express the sequencing depth per cell is far lower Counts, with counts(). Given the large number of droplets in a sample, count matrices can be large. They are however very sparse and can be stored in a ‘sparse matrix’ that only stores non-zero values, for example a ‘dgCMatrix’ object (‘DelayedArray’ class). counts(sce.raw) &lt;- as(counts(sce.raw), &quot;dgCMatrix&quot;) #class(counts(sce.raw)) counts(sce.raw)[1:10, 1:10] ## 10 x 10 sparse Matrix of class &quot;dgCMatrix&quot; ## ## ENSG00000243485 . . . . . . . . . . ## ENSG00000237613 . . . . . . . . . . ## ENSG00000186092 . . . . . . . . . . ## ENSG00000238009 . . . . . . . . . . ## ENSG00000239945 . . . . . . . . . . ## ENSG00000239906 . . . . . . . . . . ## ENSG00000241599 . . . . . . . . . . ## ENSG00000236601 . . . . . . . . . . ## ENSG00000284733 . . . . . . . . . . ## ENSG00000235146 . . . . . . . . . . 4.6 Mapping QC 4.6.1 Gene body coverage The plot below show the average coverage (y-axis) along the body of genes (x-axis). tmpFn &lt;- sprintf(&quot;%s/Images/1_AAACCTGAGACTTTCG-1.rseqcGeneBodyCovCheck.txt.geneBodyCoverage.curves.png&quot;, &quot;..&quot;) knitr::include_graphics(tmpFn, auto_pdf = TRUE) 4.6.2 Amplification rate We will use the information stored in the ‘molecule info’ file to count the number of UMI and reads for each gene in each cell. ##mol.info.file &lt;- sprintf(&quot;%s/%s/%s/outs/molecule_info.h5&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) ##mol.info &lt;- read10xMolInfo(mol.info.file) # or mol.info object if issue with H5Fopen mol.info.file &lt;- sprintf(&quot;%s/%s/%s/outs/molecule_info_h5.Rds&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) mol.info &lt;- readRDS(mol.info.file) # slow # &#39;data&#39; slot: mol.info$data ## DataFrame with 18544666 rows and 5 columns ## cell umi gem_group gene reads ## &lt;character&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 1 AAACCTGAGAAACCTA 467082 1 3287 1 ## 2 AAACCTGAGAAACCTA 205888 1 3446 1 ## 3 AAACCTGAGAAACCTA 866252 1 3896 3 ## 4 AAACCTGAGAAACCTA 796027 1 3969 1 ## 5 AAACCTGAGAAACCTA 542561 1 5008 1 ## ... ... ... ... ... ... ## 18544662 TTTGTCATCTTTAGTC 927060 1 23634 1 ## 18544663 TTTGTCATCTTTAGTC 975865 1 27143 1 ## 18544664 TTTGTCATCTTTAGTC 364964 1 27467 4 ## 18544665 TTTGTCATCTTTAGTC 152570 1 30125 7 ## 18544666 TTTGTCATCTTTAGTC 383230 1 30283 5 # &#39;genes&#39; slot head(mol.info$genes) ## [1] &quot;ENSG00000243485&quot; &quot;ENSG00000237613&quot; &quot;ENSG00000186092&quot; &quot;ENSG00000238009&quot; ## [5] &quot;ENSG00000239945&quot; &quot;ENSG00000239906&quot; # for each cell and gene, count UMIs # slow, but needs running, at least once # so write it to file to load later if need be. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_preProc_ampDf1.Rds&quot;, projDir, outDirBit) if(!file.exists(tmpFn)) { ampDf &lt;- mol.info$data %&gt;% data.frame() %&gt;% mutate(umi = as.character(umi)) %&gt;% group_by(cell, gene) %&gt;% summarise(nUmis = n(), totReads=sum(reads)) %&gt;% data.frame() # Write object to file saveRDS(ampDf, tmpFn) } else { ampDf &lt;- readRDS(tmpFn) } rm(tmpFn) # distribution of totReads summary(ampDf$totReads) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.00 2.00 6.00 15.23 12.00 79275.00 # distribution of nUmis summary(ampDf$nUmis) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 1.000 1.000 2.377 1.000 7137.000 # too slow sp &lt;- ggplot(ampDf, aes(x=nUmis, y=totReads)) + geom_point() + scale_x_continuous(trans=&#39;log2&#39;) + scale_y_continuous(trans=&#39;log2&#39;) sp #ggMarginal(sp) sp2 &lt;- ggplot(ampDf, aes(x=nUmis, y=totReads)) + geom_bin2d(bins = 50) + scale_fill_continuous(type = &quot;viridis&quot;) + scale_x_continuous(trans=&#39;log10&#39;) + scale_y_continuous(trans=&#39;log10&#39;) + ggtitle(&quot;totReads vs nUmis&quot;) + theme_bw() sp2 gc(verbose=FALSE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 7789319 416.0 37880625 2023.1 54939086 2934.1 ## Vcells 89103218 679.9 257295792 1963.1 257295792 1963.1 4.7 Cell calling for droplet data For a given sample, amongst the tens of thousands of droplets used in the assay, some will contain a cell while many others will not. The presence of RNA in a droplet will show with non-zero UMI count. This is however not sufficient to infer that the droplet does contain a cell. Indeed, after sample preparation, some cell debris including RNA will still float in the mix. This ambient RNA is unwillignly captured during library preparation and sequenced. Cellranger generates a count matrix that includes all droplets analysed in the assay. We will now load this ‘raw matrix’ for one sample and draw the distribution of UMI counts. Distribution of UMI counts: libSizeDf &lt;- mol.info$data %&gt;% data.frame() %&gt;% mutate(umi = as.character(umi)) %&gt;% group_by(cell) %&gt;% summarise(nUmis = n(), totReads=sum(reads)) %&gt;% data.frame() rm(mol.info) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 7741618 413.5 30304500 1618.5 54939086 2934.1 ## Vcells 33701469 257.2 205836634 1570.5 257295792 1963.1 ggplot(libSizeDf, aes(x=log10(nUmis))) + geom_histogram(bins = 50) Library size varies widely, both amongst empty droplets and droplets carrying cells, mostly due to: variation in droplet size, amplification efficiency, sequencing Most cell counting methods try to identify the library size that best distinguishes empty from cell-carrying droplets. 4.7.1 Mixture model This method by default fits a mixture of two normal distributions to the logged library sizes: one with a small mean for empty droplets the other with a higher mean for cell-carrying droplets set.seed(100) # get package library(&quot;mixtools&quot;) # have library sizes on a log10 scale log10_lib_size &lt;- log10(libSizeDf$nUmis) # fit mixture mix &lt;- normalmixEM(log10_lib_size, mu=c(log10(10), log10(100), log10(10000)), maxrestarts=50, epsilon = 1e-03) ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## number of iterations= 64 # plot p1 &lt;- dnorm(log10_lib_size, mean=mix$mu[1], sd=mix$sigma[1]) p2 &lt;- dnorm(log10_lib_size, mean=mix$mu[2], sd=mix$sigma[2]) p3 &lt;- dnorm(log10_lib_size, mean=mix$mu[3], sd=mix$sigma[3]) pList &lt;- list(p1, p2, p3) if (mix$mu[1] &lt; mix$mu[2]) { split &lt;- min(log10_lib_size[p1 &lt; p2]) } else { split &lt;- min(log10_lib_size[p2 &lt; p1]) } # find densities with the higest means: i1 &lt;- which(order(mix$mu)==2) i2 &lt;- which(order(mix$mu)==3) # find intersection: dd0 &lt;- data.frame(log10_lib_size=log10_lib_size, #p1, p2, p3) pA=pList[[i1]], pB=pList[[i2]]) split &lt;- dd0 %&gt;% filter(pA &lt; pB &amp; mix$mu[i1] &lt; log10_lib_size) %&gt;% arrange(log10_lib_size) %&gt;% head(n=1) %&gt;% pull(log10_lib_size) # show split on plot: plot(mix, which=2, xlab2=&quot;log10(mol per cell)&quot;) # get density for each distribution: #log10_lib_size &lt;- log10(libSizeDf$nUmis) abline(v=split, lwd=2) dd &lt;- data.frame(log10_lib_size=log10_lib_size, p1, p2, p3) %&gt;% arrange(log10_lib_size) %&gt;% tidyr::pivot_longer(!log10_lib_size, names_to = &quot;curve&quot;, values_to = &quot;density&quot;) head(dd) ggplot(dd, aes(x=log10_lib_size, y=density, col=curve)) + geom_line() 4.7.2 Barcode rank plot The barcode rank plot shows the library sizes against their rank in decreasing order, for the first 10000 droplets only. barcode_rank &lt;- rank(-libSizeDf$nUmis) plot(barcode_rank, libSizeDf$nUmis, xlim=c(1,10000), ylab=&quot;library size&quot;) Given the exponential shape of the curve above, library sizes can be shown on the log10 scale: plot(barcode_rank, log10_lib_size, xlim=c(1,10000)) The plot above shows that the majority of droplets have fewer than 100 UMIs, e.g. droplets with rank greater than 4000. We will redraw the plot to focus on droplets with lower ranks, by using the log10 scale for the x-axis. plot(log10(barcode_rank), log10_lib_size, xlim=log10(c(1,10000))) The point on the curve where it drops sharply may be used as the split point. Before that point library sizes are high, because droplets carry a cell. After that point, library sizes are far smaller because droplets do not carry a cell, only ambient RNA (… or do they?). Here, we could ‘visually’ approximate the number of cells to 2500. There are however more robust and convenient methods. 4.7.3 Inflection point We could also compute the inflection point of the curve. o &lt;- order(barcode_rank) log10_lib_size &lt;- log10_lib_size[o] barcode_rank &lt;- barcode_rank[o] rawdiff &lt;- diff(log10_lib_size)/diff(barcode_rank) inflection &lt;- which(rawdiff == min(rawdiff[100:length(rawdiff)], na.rm=TRUE)) plot(x=log10(barcode_rank), y=log10_lib_size, xlim=log10(c(1,10000))) abline(v=log10(inflection), col=&quot;red&quot;, lwd=2) The inflection is at 3279 UMIs (3.5157414 on the log10 scale). 2306 droplets have at least these many UMIs and would thus contain one cell (or more). 4.7.4 Cellranger v1 and v2 Given an expected number of cells, cellranger used to assume a ~10-fold range of library sizes for real cells and estimate this range (cellranger (v1 and v2). The threshold was defined as the 99th quantile of the library size, divided by 10. # approximate number of cells expected: n_cells &lt;- 2500 # CellRanger totals &lt;- sort(libSizeDf$nUmis, decreasing = TRUE) # 99th percentile of top n_cells divided by 10 thresh = totals[round(0.01*n_cells)]/10 plot(x=log10(seq(1,10000)), y=log10(totals)[1:10000] ) abline(h=log10(thresh), col=&quot;red&quot;, lwd=2) The threshold is at 1452 UMIs and 2773 cells are detected. 4.7.5 DropletUtils and EmptyDrops The DropletUtils package offers utilities to analyse droplet-based data, including cell counting using the library size as seen above. These simple approaches may exclude droplets with small or quiet cells with low RNA content. The emptyDrops method calls cells by first computing the expression profile for droplets with RNA content so low they almost certainly do not contain any cell: the ‘background’ or ‘ambient’ profile. The method then tests each non-background droplet for significant difference in expression profile. Let’s first check the knee and inflection methods. br.out &lt;- barcodeRanks(counts(sce.raw)) plot(br.out$rank, br.out$total, log=&quot;xy&quot;, xlab=&quot;Rank&quot;, ylab=&quot;Total UMI count&quot;) o &lt;- order(br.out$rank) lines(br.out$rank[o], br.out$fitted[o], col=&quot;red&quot;) abline(h=metadata(br.out)$knee, col=&quot;dodgerblue&quot;, lty=2) abline(h=metadata(br.out)$inflection, col=&quot;forestgreen&quot;, lty=2) legend(&quot;bottomleft&quot;, lty=2, col=c(&quot;dodgerblue&quot;, &quot;forestgreen&quot;), legend=c(&quot;knee&quot;, &quot;inflection&quot;)) Testing for empty droplets. We will call cells with a false discovery rate (FDR) of 0.1% so that at most 1 in 1000 droplets called may be empty. # a bit slow # significance is computed by simulation so we set a seed for reproducibility set.seed(100) # run analysis: e.out &lt;- emptyDrops(counts(sce.raw)) e.out ## DataFrame with 737280 rows and 5 columns ## Total LogProb PValue Limited FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;logical&gt; &lt;numeric&gt; ## AAACCTGAGAAACCAT-1 0 NA NA NA NA ## AAACCTGAGAAACCGC-1 0 NA NA NA NA ## AAACCTGAGAAACCTA-1 31 NA NA NA NA ## AAACCTGAGAAACGAG-1 0 NA NA NA NA ## AAACCTGAGAAACGCC-1 0 NA NA NA NA ## ... ... ... ... ... ... ## TTTGTCATCTTTACAC-1 0 NA NA NA NA ## TTTGTCATCTTTACGT-1 1 NA NA NA NA ## TTTGTCATCTTTAGGG-1 0 NA NA NA NA ## TTTGTCATCTTTAGTC-1 26 NA NA NA NA ## TTTGTCATCTTTCCTC-1 0 NA NA NA NA NAs are assigned to droplets used to compute the ambient profile. Get numbers of droplets in each class defined by FDR and the cut-off used: summary(e.out$FDR &lt;= 0.001) ## Mode FALSE TRUE NA&#39;s ## logical 487 3075 733718 The test significance is computed by permutation. For each droplet tested, the number of permutations may limit the value of the p-value. This information is available in the ‘Limited’ column. If ‘Limited’ is ‘TRUE’ for any non-significant droplet, the number of permutations was too low, should be increased and the analysis re-run. comment=&quot;emptyDrops() uses Monte Carlo simulations to compute p-values for the multinomial sampling transcripts from the ambient pool. The number of Monte Carlo iterations determines the lower bound for the p-values (Phipson and Smyth 2010). The Limited field in the output indicates whether or not the computed p-value for a particular barcode is bounded by the number of iterations. If any non-significant barcodes are TRUE for Limited, we may need to increase the number of iterations. A larger number of iterations will result in a lower p-value for these barcodes, which may allow them to be detected after correcting for multiple testing.&quot; table(Sig=e.out$FDR &lt;= 0.001, Limited=e.out$Limited) ## Limited ## Sig FALSE TRUE ## FALSE 487 0 ## TRUE 76 2999 Let’s check that the background comprises only empty droplets. If the droplets used to define the background profile are indeed empty, testing them should result in a flat distribution of p-values. Let’s test the ‘ambient’ droplets and draw the p-value distribution. commment=&quot;As mentioned above, emptyDrops() assumes that barcodes with low total UMI counts are empty droplets. Thus, the null hypothesis should be true for all of these barcodes. We can check whether the hypothesis testing procedure holds its size by examining the distribution of p-values for low-total barcodes with test.ambient=TRUE. Ideally, the distribution should be close to uniform (Figure 6.6). Large peaks near zero indicate that barcodes with total counts below lower are not all ambient in origin. This can be resolved by decreasing lower further to ensure that barcodes corresponding to droplets with very small cells are not used to estimate the ambient profile.&quot; set.seed(100) limit &lt;- 100 all.out &lt;- emptyDrops(counts(sce.raw), lower=limit, test.ambient=TRUE) hist(all.out$PValue[all.out$Total &lt;= limit &amp; all.out$Total &gt; 0], xlab=&quot;P-value&quot;, main=&quot;&quot;, col=&quot;grey80&quot;) The distribution of p-values looks uniform with no large peak for small values: no cell in these droplets. To evaluate the outcome of the analysis, we will plot the strength of the evidence against library size. is.cell &lt;- e.out$FDR &lt;= 0.001 Number of cells detected: 3075. The plot plot shows the strength of the evidence against the library size. Each point is a droplet coloured: in black if without cell, in red if with a cell (or more) in green if with a cell (or more) as defined with emptyDrops but not the inflection method. # colour: cellColour &lt;- ifelse(is.cell, &quot;red&quot;, &quot;black&quot;) # rep(&quot;black&quot;, nrow((e.out))) # boolean for presence of cells as defined by the inflection method tmpBoolInflex &lt;- e.out$Total &gt; metadata(br.out)$inflection # boolean for presence of cells as defined by the emptyDrops method tmpBoolSmall &lt;- e.out$FDR &lt;= 0.001 tmpBoolRecov &lt;- !tmpBoolInflex &amp; tmpBoolSmall cellColour[tmpBoolRecov] &lt;- &quot;green&quot; # &#39;recovered&#39; cells # plot strength of significance vs library size plot(log10(e.out$Total), -e.out$LogProb, col=cellColour, xlim=c(2,max(log10(e.out$Total))), xlab=&quot;Total UMI count&quot;, ylab=&quot;-Log Probability&quot;) # add point to show &#39;recovered&#39; cell on top points(log10(e.out$Total)[tmpBoolRecov], -e.out$LogProb[tmpBoolRecov], pch=16, col=&quot;green&quot;) Let’s filter out empty droplets. comment=&quot;Once we are satisfied with the performance of emptyDrops(), we subset our SingleCellExperiment object to retain only the detected cells. Discerning readers will notice the use of which(), which conveniently removes the NAs prior to the subsetting.&quot; sce.ed &lt;- sce.raw[,which(e.out$FDR &lt;= 0.001)] # ed for empty droplet rm(sce.raw); gc(); ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 8907934 475.8 24243600 1294.8 54939086 2934.1 ## Vcells 59096638 450.9 164689296 1256.5 257295792 1963.1 And check the new SCE object: sce.ed ## class: SingleCellExperiment ## dim: 33538 3075 ## metadata(1): Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(3): ID Symbol Type ## colnames(3075): AAACCTGAGACTTTCG-1 AAACCTGGTCTTCAAG-1 ... ## TTTGTCACAGGCTCAC-1 TTTGTCAGTTCGGCAC-1 ## colData names(2): Sample Barcode ## reducedDimNames(0): ## altExpNames(0): rm(sce.ed) Cell calling in cellranger v3 uses a method similar to emptyDrops() and a ‘filtered matrix’ is generated that only keeps droplets deemed to contain a cell. We will load these filtered matrices now. text=&quot;emptyDrops() already removes cells with very low library sizes or (by association) low numbers of expressed genes. Thus, further filtering on these metrics is not strictly necessary. It may still be desirable to filter on both of these metrics to remove non-empty droplets containing cell fragments or stripped nuclei that were not caught by the mitochondrial filter. However, this should be weighed against the risk of losing genuine cell types as discussed in Section 6.3.2.2.&quot; 4.8 Load filtered matrices Each sample was analysed with cellranger separately. We load filtered matrices one sample at a time, showing for each the name and number of features and cells. # a bit slow # load data: sce.list &lt;- vector(&quot;list&quot;, length = nrow(sampleSheet)) for (i in 1:nrow(sampleSheet)) { print(sprintf(&quot;&#39;Run&#39; %s, &#39;Sample.Name&#39; %s&quot;, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Sample.Name&quot;])) sample.path &lt;- sprintf(&quot;%s/%s/%s/outs/filtered_feature_bc_matrix/&quot;, sprintf(&quot;%s/%s/grch38300&quot;, projDir, ifelse(sampleSheet[i,&quot;source_name&quot;] == &quot;ABMMC&quot;, &quot;Hca&quot;, &quot;CaronBourque2020&quot;)), sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) sce.list[[i]] &lt;- read10xCounts(sample.path) print(dim(sce.list[[i]])) } ## [1] &quot;&#39;Run&#39; SRR9264343, &#39;Sample.Name&#39; GSM3872434&quot; ## [1] 33538 3088 ## [1] &quot;&#39;Run&#39; SRR9264344, &#39;Sample.Name&#39; GSM3872435&quot; ## [1] 33538 6678 ## [1] &quot;&#39;Run&#39; SRR9264345, &#39;Sample.Name&#39; GSM3872436&quot; ## [1] 33538 5054 ## [1] &quot;&#39;Run&#39; SRR9264346, &#39;Sample.Name&#39; GSM3872437&quot; ## [1] 33538 6096 ## [1] &quot;&#39;Run&#39; SRR9264347, &#39;Sample.Name&#39; GSM3872438&quot; ## [1] 33538 5442 ## [1] &quot;&#39;Run&#39; SRR9264348, &#39;Sample.Name&#39; GSM3872439&quot; ## [1] 33538 5502 ## [1] &quot;&#39;Run&#39; SRR9264349, &#39;Sample.Name&#39; GSM3872440&quot; ## [1] 33538 4126 ## [1] &quot;&#39;Run&#39; SRR9264350, &#39;Sample.Name&#39; GSM3872441&quot; ## [1] 33538 3741 ## [1] &quot;&#39;Run&#39; SRR9264351, &#39;Sample.Name&#39; GSM3872442&quot; ## [1] 33538 978 ## [1] &quot;&#39;Run&#39; SRR9264352, &#39;Sample.Name&#39; GSM3872442&quot; ## [1] 33538 1150 ## [1] &quot;&#39;Run&#39; SRR9264353, &#39;Sample.Name&#39; GSM3872443&quot; ## [1] 33538 4964 ## [1] &quot;&#39;Run&#39; SRR9264354, &#39;Sample.Name&#39; GSM3872444&quot; ## [1] 33538 4255 ## [1] &quot;&#39;Run&#39; MantonBM1, &#39;Sample.Name&#39; MantonBM1&quot; ## [1] 33538 23283 ## [1] &quot;&#39;Run&#39; MantonBM2, &#39;Sample.Name&#39; MantonBM2&quot; ## [1] 33538 25055 ## [1] &quot;&#39;Run&#39; MantonBM3, &#39;Sample.Name&#39; MantonBM3&quot; ## [1] 33538 24548 ## [1] &quot;&#39;Run&#39; MantonBM4, &#39;Sample.Name&#39; MantonBM4&quot; ## [1] 33538 26478 ## [1] &quot;&#39;Run&#39; MantonBM5, &#39;Sample.Name&#39; MantonBM5&quot; ## [1] 33538 26383 ## [1] &quot;&#39;Run&#39; MantonBM6, &#39;Sample.Name&#39; MantonBM6&quot; ## [1] 33538 22801 ## [1] &quot;&#39;Run&#39; MantonBM7, &#39;Sample.Name&#39; MantonBM7&quot; ## [1] 33538 24372 ## [1] &quot;&#39;Run&#39; MantonBM8, &#39;Sample.Name&#39; MantonBM8&quot; ## [1] 33538 24860 Let’s combine all 20 samples into a single object. We first check the feature lists are identical. # check row names are the same # compare to that for the first sample rowNames1 &lt;- rownames(sce.list[[1]]) for (i in 2:nrow(sampleSheet)) { print(identical(rowNames1, rownames(sce.list[[i]]))) } ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE A cell barcode comprises the actual sequence and a ‘group ID’, e.g. AAACCTGAGAAACCAT-1. The latter helps distinguish cells that share the same sequence but come from different samples. As each sample was analysed separately, the group ID is set to 1 in all data sets. To pool these data sets we first need to change group IDs so cell barcodes are unique across all samples. We will use the position of the sample in the sample sheet. sce &lt;- sce.list[[1]] colData(sce)$Barcode &lt;- gsub(&quot;([0-9])$&quot;, 1, colData(sce)$Barcode) print(head(colData(sce)$Barcode)) ## [1] &quot;AAACCTGAGACTTTCG-1&quot; &quot;AAACCTGGTCTTCAAG-1&quot; &quot;AAACCTGGTGCAACTT-1&quot; ## [4] &quot;AAACCTGGTGTTGAGG-1&quot; &quot;AAACCTGTCCCAAGTA-1&quot; &quot;AAACCTGTCGAATGCT-1&quot; print(tail(colData(sce)$Barcode)) ## [1] &quot;TTTGGTTTCCGAAGAG-1&quot; &quot;TTTGGTTTCTTTAGGG-1&quot; &quot;TTTGTCAAGAAACGAG-1&quot; ## [4] &quot;TTTGTCAAGGACGAAA-1&quot; &quot;TTTGTCACAGGCTCAC-1&quot; &quot;TTTGTCAGTTCGGCAC-1&quot; for (i in 2:nrow(sampleSheet)) { sce.tmp &lt;- sce.list[[i]] colData(sce.tmp)$Barcode &lt;- gsub(&quot;([0-9])$&quot;, i, colData(sce.tmp)$Barcode) sce &lt;- cbind(sce, sce.tmp) #print(head(colData(sce)$Barcode)) print(tail(colData(sce)$Barcode, 2)) } ## [1] &quot;TTTGTCATCTTAACCT-2&quot; &quot;TTTGTCATCTTCTGGC-2&quot; ## [1] &quot;TTTGTCATCCGCGGTA-3&quot; &quot;TTTGTCATCCGGGTGT-3&quot; ## [1] &quot;TTTGTCATCACTCTTA-4&quot; &quot;TTTGTCATCTATCCCG-4&quot; ## [1] &quot;TTTGTCAGTTCCCTTG-5&quot; &quot;TTTGTCATCGACGGAA-5&quot; ## [1] &quot;TTTGTCATCCTTTCGG-6&quot; &quot;TTTGTCATCTATGTGG-6&quot; ## [1] &quot;TTTGTCAGTCATTAGC-7&quot; &quot;TTTGTCAGTTGTGGCC-7&quot; ## [1] &quot;TTTGTCATCTACCAGA-8&quot; &quot;TTTGTCATCTGCAGTA-8&quot; ## [1] &quot;TTTGGTTGTGCATCTA-9&quot; &quot;TTTGTCACAGCTCGAC-9&quot; ## [1] &quot;TTTGTCAGTAAATGTG-10&quot; &quot;TTTGTCAGTACAAGTA-10&quot; ## [1] &quot;TTTGTCATCACCCTCA-11&quot; &quot;TTTGTCATCTTCATGT-11&quot; ## [1] &quot;TTTGTCATCAGTTGAC-12&quot; &quot;TTTGTCATCTCGTTTA-12&quot; ## [1] &quot;TTTGTCATCTTTACAC-13&quot; &quot;TTTGTCATCTTTCCTC-13&quot; ## [1] &quot;TTTGTCATCGACGGAA-14&quot; &quot;TTTGTCATCGCCTGAG-14&quot; ## [1] &quot;TTTGTCATCTTGTACT-15&quot; &quot;TTTGTCATCTTTAGGG-15&quot; ## [1] &quot;TTTGTCATCGGATGGA-16&quot; &quot;TTTGTCATCGTGGACC-16&quot; ## [1] &quot;TTTGTCATCTGCGGCA-17&quot; &quot;TTTGTCATCTGCGTAA-17&quot; ## [1] &quot;TTTGTCATCTAACTGG-18&quot; &quot;TTTGTCATCTGCGGCA-18&quot; ## [1] &quot;TTTGTCATCTGGGCCA-19&quot; &quot;TTTGTCATCTTGTATC-19&quot; ## [1] &quot;TTTGTCATCTTGAGAC-20&quot; &quot;TTTGTCATCTTGTATC-20&quot; rm(sce.list) We now add the sample sheet information to the object metadata. colDataOrig &lt;- colData(sce) # split path: tmpList &lt;- strsplit(colDataOrig$Sample, split=&quot;/&quot;) # get Run ID, to use to match sample in the meta data and sample sheet objects: tmpVec &lt;- unlist(lapply(tmpList, function(x){x[9]})) colData(sce)$Run &lt;- tmpVec # merge: colData(sce) &lt;- colData(sce) %&gt;% data.frame %&gt;% left_join(sampleSheet[,splShtColToKeep], &quot;Run&quot;) %&gt;% relocate() %&gt;% DataFrame Let’s save the object for future reference. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postPool%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postPool%s.Rds&quot;, projDir, outDirBit, setSuf) sce &lt;- readRDS(tmpFn) 4.9 Properties of scRNA-seq data # a bit slow # TODO first remove emtpy droplets the mol.info data mol.info$data head(mol.info$genes) dd &lt;- mol.info$data %&gt;% data.frame() dd$umi &lt;- as.character(dd$umi) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_preProc_ampDf2.Rds&quot;, projDir, outDirBit) if(FALSE) # slow { ampDf &lt;- dd %&gt;% filter(paste(cell,gem_group, sep=&quot;-&quot;) %in% sce$Barcode) %&gt;% group_by(cell, gene) %&gt;% summarise(nUmis = n(), totReads=sum(reads)) %&gt;% data.frame() # Write object to file saveRDS(ampDf, tmpFn) } else { ampDf &lt;- readRDS(tmpFn) } rm(tmpFn) #summary(ampDf$nUmis) #summary(ampDf$totReads) hist(log2(ampDf$nUmis), n=100) hist(log2(ampDf$totReads), n=100) sp2 &lt;- ggplot(ampDf, aes(x=nUmis, y=totReads)) + geom_bin2d(bins = 50) + scale_fill_continuous(type = &quot;viridis&quot;) + scale_x_continuous(trans=&#39;log2&#39;) + scale_y_continuous(trans=&#39;log2&#39;) + theme_bw() sp2 #rm(mol.info) rm(ampDf) gc() The number and identity of genes detected in a cell vary across cells: the total number of genes detected across all cells is far larger than the number of genes per cell. Total number of genes detected across cells: # for each gene, compute total number of UMIs across all cells, # then counts genes with at least one UMI: countsRowSums &lt;- rowSums(counts(sce)) sum(countsRowSums &gt; 0) ## [1] 27795 Summary of the distribution of the number of genes detected per cell: # for each cell count number of genes with at least 1 UMI # then compute distribution moments: summary(colSums(counts(sce) &gt; 0)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 26 724 873 1173 1262 8077 Now let’s plot for each gene, the total number of UMIs and the proportion of cells that express it. Lowly expressed genes tend to be detected in a large proportion of cells. The higher the overall expression the lower the proportion of cells. # very slow; many points # skip in DEV, TODO: write plot to file and embed that. # x-axis: total number of UMIs for the gene across all cells # y-axis: fraction of cells expressing the gene tmpFn &lt;- sprintf(&quot;%s/%s/%s/corelLibSizePropCellExpress%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) CairoPNG(tmpFn) plot( # x-axis: nb UMI per gene across all cells countsRowSums, # y-axis: proportion of cells that do express the cell rowMeans(counts(sce) &gt; 0), log = &quot;x&quot;, xlab=&quot;total number of UMIs&quot;, ylab=&quot;proportion of cells expressing the gene&quot; ) dev.off() dd &lt;- data.frame(&quot;countsRowSums&quot; = countsRowSums, &quot;propCellsExpr&quot; = rowMeans(counts(sce) &gt; 0)) head(dd) ## countsRowSums propCellsExpr ## ENSG00000243485 3 1.205526e-05 ## ENSG00000237613 0 0.000000e+00 ## ENSG00000186092 0 0.000000e+00 ## ENSG00000238009 203 8.157393e-04 ## ENSG00000239945 5 2.009210e-05 ## ENSG00000239906 0 0.000000e+00 sp &lt;- ggplot(dd, aes(x=countsRowSums, y=propCellsExpr)) + geom_point(alpha=0.3) + scale_x_continuous(trans=&#39;log10&#39;) + geom_density_2d() + xlab(&quot;total number of UMIs&quot;) + ylab(&quot;proportion of cells expressing the gene&quot;) sp ggExtra::ggMarginal(sp) tmpFn &lt;- sprintf(&quot;%s/%s/%s/corelLibSizePropCellExpress%s_2.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) tmpFn ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Plots/Qc/corelLibSizePropCellExpress_allCells_2.png&quot; ggsave(ggExtra::ggMarginal(sp), file=tmpFn, type=&quot;cairo-png&quot;) rm(tmpFn) getwd() tmpFn &lt;- sprintf(&quot;%s/%s/corelLibSizePropCellExpress%s_2.png&quot;, dirRel, qcPlotDirBit, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Count genes that are not ‘expressed’ (detected): not.expressed &lt;- rowSums(counts(sce)) == 0 table(not.expressed) ## not.expressed ## FALSE TRUE ## 27795 5743 Plot the percentage of counts per gene and show genes with the highest UMI counts: #Compute the relative expression of each gene per cell # a bit slow rel_expression &lt;- t( t(counts(sce)) / Matrix::colSums(counts(sce))) * 100 rownames(rel_expression) &lt;- rowData(sce)$Symbol most_expressed &lt;- sort(Matrix::rowSums( rel_expression ),T)[20:1] / ncol(sce) boxplot( as.matrix(t(rel_expression[names(most_expressed),])), cex=.1, las=1, xlab=&quot;% total count per cell&quot;, col=scales::hue_pal()(20)[20:1], horizontal=TRUE) Mind that we have combined two data sets here. It may be interesting to count non-expressed genes in each set separately. 4.10 Quality control Cell calling performed above does not inform on the quality of the library in each of the droplets kept. Poor-quality cells, or rather droplets, may be caused by cell damage during dissociation or failed library preparation. They usually have low UMI counts, few genes detected and/or high mitochondrial content. The presence may affect normalisation, assessment of cell population heterogeneity, clustering and trajectory: Normalisation: Contaminating genes, ‘the ambient RNA’, are detected at low levels in all libraires. In low quality libraries with low RNA content, scaling will increase counts for these genes more than for better-quality cells, resulting in their apparent upregulation in these cells and increased variance overall. Cell population heterogeneity: variance estimation and dimensionality reduction with PCA where the first principal component will be correlated with library size, rather than biology. Clustering and trajectory: higher mitochondrial and/or nuclear RNA content may cause low-quality cells to cluster separately or form states or trajectories between distinct cell types. We will now exclude lowly expressed features and identify low-quality cells using the following metrics mostly: library size, i.e. the total number of UMIs per cell number of features detected per cell mitochondrial content, i.e. the proportion of UMIs that map to mitochondrial genes, with higher values consistent with leakage from the cytoplasm of RNA, but not mitochodria We will first annotate genes, to know which lie in the mitochondrial genome, then use scater’s addPerCellQC() to compute various metrics. Annotate genes with biomaRt. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postBiomart%s.Rds&quot;, projDir, outDirBit, setSuf) biomartBool &lt;- ifelse(file.exists(tmpFn), FALSE, TRUE) # retrieve the feature information gene.info &lt;- rowData(sce) # setup the biomaRt connection to Ensembl using the correct species genome (hsapiens_gene_ensembl) #ensembl &lt;- useEnsembl(biomart=&#39;ensembl&#39;, # dataset=&#39;hsapiens_gene_ensembl&#39;, # #mirror = &quot;www&quot;) # #mirror = &quot;useast&quot;) # mirror = &quot;uswest&quot;) # #mirror = &quot;asia&quot;) ensembl = useMart(biomart=&quot;ENSEMBL_MART_ENSEMBL&quot;, dataset=&quot;hsapiens_gene_ensembl&quot;, host=&quot;uswest.ensembl.org&quot;, ensemblRedirect = FALSE) # retrieve the attributes of interest from biomaRt using the Ensembl gene ID as the key # beware that this will only retrieve information for matching IDs gene_symbol &lt;- getBM(attributes=c(&#39;ensembl_gene_id&#39;, &#39;external_gene_name&#39;, &#39;chromosome_name&#39;, &#39;start_position&#39;, &#39;end_position&#39;, &#39;strand&#39;), filters=&#39;ensembl_gene_id&#39;, mart=ensembl, values=gene.info[, 1]) # create a new data frame of the feature information gene.merge &lt;- merge(gene_symbol, gene.info, by.x=c(&#39;ensembl_gene_id&#39;), by.y=c(&#39;ID&#39;), all.y=TRUE) rownames(gene.merge) &lt;- gene.merge$ensembl_gene_id # set the order for the same as the original gene information gene.merge &lt;- gene.merge[gene.info[, 1], ] # reset the rowdata on the SCE object to contain all of this information rowData(sce) &lt;- gene.merge # slow # Write object to file ##tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postBiomart%s.Rds&quot;, ## projDir, outDirBit, setSuf) saveRDS(sce, tmpFn) # Read object in: ##tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postBiomart%s.Rds&quot;, ## projDir, outDirBit, setSuf) sce &lt;- readRDS(tmpFn) table(rowData(sce)$chromosome_name) ## ## 1 10 11 12 13 14 15 ## 3126 1220 1910 1748 661 1380 1121 ## 16 17 18 19 2 20 21 ## 1515 1880 654 1989 2261 888 499 ## 22 3 4 5 6 7 8 ## 831 1704 1344 1646 1616 1526 1302 ## 9 GL000009.2 GL000194.1 GL000195.1 GL000205.2 GL000213.1 GL000218.1 ## 1210 1 2 2 1 1 1 ## GL000219.1 KI270711.1 KI270713.1 KI270721.1 KI270726.1 KI270727.1 KI270728.1 ## 1 1 2 1 2 4 6 ## KI270731.1 KI270734.1 MT X Y ## 1 3 13 1064 97 is.mito &lt;- which(rowData(sce)$chromosome_name==&quot;MT&quot;) Calculate and store QC metrics for genes with addPerFeatureQC() and for cells with addPerCellQC(). # long # for genes sce &lt;- addPerFeatureQC(sce) head(rowData(sce)) %&gt;% as.data.frame() %&gt;% datatable(rownames = FALSE) # ENS ID Three columns of interest for cells: ‘sum’: total UMI count ‘detected’: number of features (genes) detected ‘subsets_Mito_percent’: percentage of reads mapped to mitochondrial transcripts # for cells sce &lt;- addPerCellQC(sce, subsets=list(Mito=is.mito)) head(colData(sce)) %&gt;% as.data.frame() %&gt;% datatable(rownames = FALSE) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postAddQc%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postAddQc%s.Rds&quot;, projDir, outDirBit, setSuf) sce &lt;- readRDS(tmpFn) 4.10.1 QC metric distribution Overall: par(mfrow=c(1, 2)) hist(log10(sce$sum), breaks=20, col=&quot;grey80&quot;, xlab=&quot;Log-total UMI count&quot;, main=&quot;&quot;) hist(sce$subsets_Mito_percent, breaks=20, col=&quot;grey80&quot;, xlab=&quot;Proportion of reads in mitochondrial genes&quot;, main=&quot;&quot;) abline(v=20, lty=2, col=&#39;purple&#39;) Per sample group: sce$source_name &lt;- factor(sce$source_name) sce$block &lt;- sce$source_name sce$setName &lt;- ifelse(grepl(&quot;ABMMC&quot;, sce$source_name), &quot;Hca&quot;, &quot;Caron&quot;) # ok, but little gain in splitting by Caron and Hca, # better set levels to have PBMMC last and use ggplot with colours. tmpFn &lt;- sprintf(&quot;%s/%s/%s/qc_metricDistrib_plotColData2%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) CairoPNG(tmpFn) # violin plots gridExtra::grid.arrange( plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, other_fields=&quot;setName&quot;) + # facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;), ncol=1 ) dev.off() ## pdf ## 2 # eval=FALSE: see chunks below for each of the metrics separately tmpFn &lt;- sprintf(&quot;%s/%s/%s/qc_metricDistrib_plotColData2%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Library size (‘Total count’): plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;) Number of genes (‘detected’): plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) Mitochondrial content (‘subsets_Mito_percent’): plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, other_fields=&quot;setName&quot;) + # facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;) Correlation between the number of genes detected and library size (‘detected’ against ‘sum’): sp &lt;- ggplot(data.frame(colData(sce)), aes(x=sum, y=detected, col=source_name)) + geom_point(alpha=0.3) sp + facet_wrap(~source_name) Correlation between the mitochondrial content and library size (‘subsets_Mito_percent’ against ‘sum’): sp &lt;- ggplot(data.frame(colData(sce)), aes(x=sum, y=detected, col=subsets_Mito_percent)) + geom_point() sp + facet_wrap(~source_name) 4.11 Identification of low-quality cells with adaptive thresholds One can use hard threshold for the library size, number of genes detected and mitochondrial content. These will however vary across runs. It may therefore be preferable to rely on outlier detection to identify cells that markedly differ from most cells. We saw above that the distribution of the QC metrics is close to Normal. Hence, we can detect outlier using the median and the median absolute deviation (MAD) from the median (not the mean and the standard deviation that both are sensitive to outliers). For a given metric, an outlier value is one that lies over some number of MADs away from the median. A cell will be excluded if it is an outlier in the part of the range to avoid, for example low gene counts, or high mitochondrial content. For a normal distribution, a threshold defined with a distance of 3 MADs from the median retains about 99% of values. 4.11.1 Library size For the library size we use the log scale to avoid negative values for lower part of the distribution. qc.lib2 &lt;- isOutlier(sce$sum, log=TRUE, type=&quot;lower&quot;) table(qc.lib2) ## qc.lib2 ## FALSE TRUE ## 245250 3604 Threshold values: attr(qc.lib2, &quot;thresholds&quot;) ## lower higher ## 920.8674 Inf 4.11.2 Number of genes For the number of genes detected we also use the log scale to avoid negative values for lower part of the distribution. qc.nexprs2 &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;) table(qc.nexprs2) ## qc.nexprs2 ## FALSE TRUE ## 246349 2505 Threshold values: attr(qc.nexprs2, &quot;thresholds&quot;) ## lower higher ## 302.3803 Inf 4.11.3 Mitochondrial content For the mitochondrial content the exclusion zone is in the higher part of the distribution. qc.mito2 &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;) table(qc.mito2) ## qc.mito2 ## FALSE TRUE ## 237080 11774 Threshold values: attr(qc.mito2, &quot;thresholds&quot;) ## lower higher ## -Inf 7.613065 4.11.4 Summary discard2 &lt;- qc.lib2 | qc.nexprs2 | qc.mito2 # Summarize the number of cells removed for each reason. DataFrame(LibSize=sum(qc.lib2), NExprs=sum(qc.nexprs2), MitoProp=sum(qc.mito2), Total=sum(discard2)) ## DataFrame with 1 row and 4 columns ## LibSize NExprs MitoProp Total ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 1 3604 2505 11774 15386 4.11.5 All steps at once The steps above may be run at once with quickPerCellQC(): reasons &lt;- quickPerCellQC(colData(sce), percent_subsets=c(&quot;subsets_Mito_percent&quot;)) colSums(as.matrix(reasons)) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) 4.11.6 Assumptions Data quality depends on the tissue analysed, some being difficult to dissociate, e.g. brain, so that one level of QC stringency will not fit all data sets. Filtering based on QC metrics as done here assumes that these QC metrics are not correlated with biology. This may not necessarily be true in highly heterogenous data sets where some cell types represented by good-quality cells may have low RNA content or high mitochondrial content. 4.12 Experimental factors The two data sets analysed here may have been obtained in experiments with different settings, such as cell preparation or sequencing depth. Such differences between these two batches would affect the adaptive thresholds discussed above. We will now perform QC in each batch separately. We will use the quickPerCellQC() ‘batch’ option. batch.reasons &lt;- quickPerCellQC(colData(sce), percent_subsets=c(&quot;subsets_Mito_percent&quot;), batch=sce$setName) colSums(as.matrix(batch.reasons)) ## low_lib_size low_n_features high_subsets_Mito_percent ## 0 1034 11046 ## discard ## 12014 sce$discard &lt;- batch.reasons$discard Fewer cells are discarded, in particular because of small library size and low gene number. But the differences are deeper as the two sets only partially overlap: table(reasons$discard, batch.reasons$discard) ## ## FALSE TRUE ## FALSE 231781 1687 ## TRUE 5059 10327 # see chunks below for each of the metric separately tmpFn &lt;- sprintf(&quot;%s/%s/%s/qc_metricDistrib_plotColDataBatch%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) CairoPNG(tmpFn) gridExtra::grid.arrange( plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;), ncol=1 ) dev.off() ## pdf ## 2 # eval=FALSE; see chunks below for each of the metric separately tmpFn &lt;- sprintf(&quot;%s/%s/qc_metricDistrib_plotColDataBatch%s.png&quot;, dirRel, qcPlotDirBit, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Library size: plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;) Number of genes detected: plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + facet_wrap(~colour_by) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) Mitochondrial content: plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=detected, y=subsets_Mito_percent, col=discard)) + geom_point(size = 0.05, alpha = 0.2) + geom_density_2d(size = 0.5, colour = &quot;blue&quot;) + guides(colour = guide_legend(override.aes = list(size=1, alpha=1))) + theme(legend.position=&quot;bottom&quot;) #sp ggExtra::ggMarginal(sp) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=detected, y=subsets_Mito_percent, col=discard)) + geom_point(size = 0.05, alpha = 0.2) sp + facet_wrap(~source_name) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=detected, y=subsets_Mito_percent)) + geom_point(size = 0.05, alpha = 0.0) sp + #geom_density_2d_filled(alpha = 0.5) + geom_density_2d(size = 0.5, colour = &quot;black&quot;) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=detected, y=subsets_Mito_percent)) + geom_point(size = 0.05, alpha = 0.2) + geom_density_2d(size = 0.5, colour = &quot;blue&quot;) ggExtra::ggMarginal(sp) 4.12.1 Identify poor-quality batches We will now consider the ‘sample’ batch to illustrate how to identify batches with overall low quality or different from other batches. Let’s compare thresholds across sample groups. 4.12.1.1 Number of genes detected # compute discard.nexprs &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;, batch=sce$Sample.Name) nexprs.thresholds &lt;- attr(discard.nexprs, &quot;thresholds&quot;)[&quot;lower&quot;,] nexprs.thresholds %&gt;% round(0) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) Without block: # plots - without blocking discard.nexprs.woBlock &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;) without.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;detected&quot;, colour_by=I(discard.nexprs.woBlock)) without.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) With block: # plots - with blocking with.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;detected&quot;, colour_by=I(discard.nexprs)) with.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) 4.12.1.1.1 Mitochondrial content discard.mito &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;, batch=sce$Sample.Name) mito.thresholds &lt;- attr(discard.mito, &quot;thresholds&quot;)[&quot;higher&quot;,] mito.thresholds %&gt;% round(0) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) Without block: # plots - without blocking discard.mito.woBlock &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;) without.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=I(discard.mito.woBlock)) without.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) With block: # plots - with blocking with.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=I(discard.mito)) with.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) 4.12.1.2 Samples to check Names of samples with a ‘low’ threshold for the number of genes detected: # names names(nexprs.thresholds)[isOutlier(nexprs.thresholds, type=&quot;lower&quot;)] ## character(0) Names of samples with a ‘high’ threshold for mitocondrial content: # names names(mito.thresholds)[isOutlier(mito.thresholds, type=&quot;higher&quot;)] ## [1] &quot;GSM3872434&quot; &quot;GSM3872437&quot; &quot;GSM3872438&quot; &quot;GSM3872443&quot; 4.12.2 QC metrics space A similar approach exists to identify outliers using a set of metrics together. We will the same QC metrics as above: # slow stats &lt;- cbind(log10(sce$sum), log10(sce$detected), sce$subsets_Mito_percent) library(robustbase) outlying &lt;- adjOutlyingness(stats, only.outlyingness = TRUE) multi.outlier &lt;- isOutlier(outlying, type = &quot;higher&quot;) summary(multi.outlier) ## Mode FALSE TRUE ## logical 232401 16453 Compare with previous filtering: table(sce$discard, multi.outlier) ## multi.outlier ## FALSE TRUE ## FALSE 226413 10427 ## TRUE 5988 6026 4.12.3 QC PCA One can also perform a principal components analysis (PCA) on cells, based on the column metadata in a SingleCellExperiment object. Here we will only use the library size, the number of genes detected (which is correlated with library size) and the mitochondrial content. sce &lt;- runColDataPCA(sce, variables=list( &quot;sum&quot;, &quot;detected&quot;, &quot;subsets_Mito_percent&quot;), outliers=TRUE) #reducedDimNames(sce) #head(reducedDim(sce)) #head(colData(sce)) #p &lt;- plotReducedDim(sce, dimred=&quot;PCA_coldata&quot;, colour_by = &quot;Sample.Name&quot;) p &lt;- plotReducedDim(sce, dimred=&quot;PCA_coldata&quot;, colour_by = &quot;outlier&quot;) p + facet_wrap(~sce$discard) Compare with previous filtering: discard and runColDataPCA’s outlier: table(sce$discard, sce$outlier) ## ## FALSE TRUE ## FALSE 227999 8841 ## TRUE 5611 6403 adjOutlyingness’ multi.outlier and runColDataPCA’s outlier: table(multi.outlier, sce$outlier) ## ## multi.outlier FALSE TRUE ## FALSE 226248 6153 ## TRUE 7362 9091 4.12.4 Other diagnostic plots Mitochondrial content against library size: plotColData(sce, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=sum, y=subsets_Mito_percent, col=discard)) + geom_point(size = 0.05, alpha = 0.7) + geom_density_2d(size = 0.5, colour = &quot;blue&quot;) + guides(colour = guide_legend(override.aes = list(size=1, alpha=1))) + theme(legend.position=&quot;bottom&quot;) #sp ggExtra::ggMarginal(sp) Mind distributions: sp + facet_wrap(~source_name) 4.12.5 Filter low-quality cells out We will now exclude poor-quality cells. scePreQc &lt;- sce sce &lt;- scePreQc[,!scePreQc$discard] sce ## class: SingleCellExperiment ## dim: 33538 236840 ## metadata(20): Samples Samples ... Samples Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(10): ensembl_gene_id external_gene_name ... mean detected ## colnames: NULL ## colData names(15): Sample Barcode ... discard outlier ## reducedDimNames(1): PCA_coldata ## altExpNames(0): We also write the R object to file to use later if need be. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postQc%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postQc%s.Rds&quot;, projDir, outDirBit, setSuf) print(&quot;DEV&quot;); print(getwd()); print(tmpFn) #sce &lt;- readRDS(tmpFn) 4.13 Novelty The number of genes per UMI for each cell informs on the level of sequencing saturation achieved ( hbctraining). For a given cell, as sequencing depth increases each extra UMI is less likely to correspnf to a gene not already detected in that cell. Cells with small library size tend to have higher overall ‘novelty’ i.e. they have not reached saturation for any given gene. Outlier cell may have a library with low complexity. This may suggest the some cell types, e.g. red blood cells. The expected novelty is about 0.8. Here we see that some PBMMCs have low novelty, ie overall fewer genes were detected for an equivalent number of UMIs in these cells than in others. p &lt;- colData(sce) %&gt;% data.frame() %&gt;% ggplot(aes(x=sum, y=detected, color=subsets_Mito_percent)) + geom_point() + stat_smooth(method=lm) + scale_x_log10() + scale_y_log10() + geom_vline(xintercept = 800) + facet_wrap(~source_name) p # write plot to file tmpFn &lt;- sprintf(&quot;%s/%s/%s/novelty_scat%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) #print(&quot;DEV&quot;); print(getwd()); print(tmpFn) ggsave(plot=p, file=tmpFn, type=&quot;cairo-png&quot;) # Novelty # the number of genes per UMI for each cell, # https://hbctraining.github.io/In-depth-NGS-Data-Analysis-Course/sessionIV/lessons/SC_quality_control_analysis.html # Add number of UMIs per gene for each cell to metadata colData(sce)$log10GenesPerUMI &lt;- log10(colData(sce)$detected) / log10(colData(sce)$sum) #```{r novelty_dens_allCells, cache.lazy = FALSE} # Visualize the overall novelty of the gene expression by visualizing the genes detected per UMI p &lt;- colData(sce) %&gt;% data.frame() %&gt;% ggplot(aes(x=log10GenesPerUMI, color = source_name, fill = source_name)) + geom_density() p tmpFn &lt;- sprintf(&quot;%s/%s/%s/novelty_dens%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) #print(&quot;DEV&quot;); print(getwd()); print(tmpFn) ggsave(plot=p, file=tmpFn, type=&quot;cairo-png&quot;) rm(sce) 4.14 QC based on sparsity The approach above identified poor-quality using thresholds on the number of genes detected and mitochondrial content. We will here specifically look at the sparsity of the data, both at the gene and cell levels. 4.14.1 Remove genes that are not expressed at all Genes that are not expressed at all are not informative, so we remove them not.expressed &lt;- rowSums(counts(scePreQc)) == 0 # store the cell-wise information cols.meta &lt;- colData(scePreQc) rows.meta &lt;- rowData(scePreQc) nz.counts &lt;- counts(scePreQc)[!not.expressed, ] sce.nz &lt;- SingleCellExperiment(list(counts=nz.counts)) # reset the column data on the new object colData(sce.nz) &lt;- cols.meta rowData(sce.nz) &lt;- rows.meta[!not.expressed, ] sce.nz ## class: SingleCellExperiment ## dim: 27795 248854 ## metadata(0): ## assays(1): counts ## rownames(27795): ENSG00000243485 ENSG00000238009 ... ENSG00000271254 ## ENSG00000268674 ## rowData names(10): ensembl_gene_id external_gene_name ... mean detected ## colnames: NULL ## colData names(15): Sample Barcode ... discard outlier ## reducedDimNames(0): ## altExpNames(0): # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce.nz, tmpFn) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz%s.Rds&quot;, projDir, outDirBit, setSuf) sce.nz &lt;- readRDS(tmpFn) Number of genes 27795. Number of cells 248854. 4.14.2 Sparsity plots We will compute: the cell sparsity: for each cell, the proportion of genes that are not detected the gene sparsity: for each gene, the proportion of cells in which it is not detected # compute - SLOW cell_sparsity &lt;- apply(counts(sce.nz) == 0, 2, sum)/nrow(counts(sce.nz)) gene_sparsity &lt;- apply(counts(sce.nz) == 0, 1, sum)/ncol(counts(sce.nz)) colData(sce.nz)$cell_sparsity &lt;- cell_sparsity rowData(sce.nz)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(list(&quot;colData&quot; = colData(sce.nz), &quot;rowData&quot; = rowData(sce.nz)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setSuf) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity We now plot the distribution of these two metrics. The cell sparsity plot shows that cells have between 85% and 99% 0’s, which is typical. The gene sparsity plot shows that a large number of genes are almost never detected, which is alo regularly observed. # plot tmpFn &lt;- sprintf(&quot;%s/%s/%s/sparsity%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) #print(&quot;DEV&quot;); print(getwd()); print(tmpFn) CairoPNG(tmpFn) par(mfrow=c(1, 2)) hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) abline(v=40, lty=2, col=&#39;purple&#39;) dev.off() ## pdf ## 2 tmpFn &lt;- sprintf(&quot;%s/%s/sparsity%s.png&quot;, dirRel, qcPlotDirBit, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 4.14.3 Filters We also remove cells with sparsity higher than 0.99, and/or mitochondrial content higher than 20%. Genes detected in a few cells only are unlikely to be informative and would hinder normalisation. We will remove genes that are expressed in fewer than 20 cells. # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.nz$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells Number of genes removed: table(sparse.genes) ## sparse.genes ## FALSE TRUE ## 21579 6216 Number of cells removed: table(sparse.cells, mito.cells) ## mito.cells ## sparse.cells FALSE TRUE ## FALSE 244996 1785 ## TRUE 1859 214 # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.nz) rows.meta &lt;- rowData(sce.nz) counts.nz &lt;- counts(sce.nz)[!sparse.genes, !(sparse.cells | mito.cells)] sce.nz &lt;- SingleCellExperiment(assays=list(counts=counts.nz)) colData(sce.nz) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.nz) &lt;- rows.meta[!sparse.genes, ] sce.nz ## class: SingleCellExperiment ## dim: 21579 244996 ## metadata(0): ## assays(1): counts ## rownames(21579): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Sample Barcode ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): rm(counts.nz) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce.nz, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setSuf) print(&quot;DEV&quot;); print(getwd()); print(tmpFn) ##sce.nz &lt;- readRDS(tmpFn) Compare with filter above (mind that the comparison is not fair because we used a less stringent, hard filtering on mitochondrial content): table(scePreQc$discard, (sparse.cells | mito.cells)) ## ## FALSE TRUE ## FALSE 235832 1008 ## TRUE 9164 2850 rm(scePreQc) 4.14.4 Separate Caron and Hca batches We will now check sparsity for each batch separately. sce.nz.caron &lt;- sce.nz[,sce.nz$setName==&quot;Caron&quot;] sce.nz.hca &lt;- sce.nz[,sce.nz$setName==&quot;Hca&quot;] 4.14.5 Caron only setName &lt;- &quot;caron&quot; sce.x &lt;- sce.nz.caron # for code re-use rm(sce.nz.caron) # compute - SLOW cell_sparsity &lt;- apply(counts(sce.x) == 0, 2, sum)/nrow(counts(sce.x)) gene_sparsity &lt;- apply(counts(sce.x) == 0, 1, sum)/ncol(counts(sce.x)) colData(sce.x)$cell_sparsity &lt;- cell_sparsity rowData(sce.x)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(list(&quot;colData&quot; = colData(sce.x), &quot;rowData&quot; = rowData(sce.x)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setName, setSuf) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity # plot tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sparsity%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf) CairoPNG(tmpFn) par(mfrow=c(1, 2)) hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) abline(v=40, lty=2, col=&#39;purple&#39;) dev.off() ## pdf ## 2 tmpFn &lt;- sprintf(&quot;%s/%s/%s_sparsity%s.png&quot;, dirRel, qcPlotDirBit, setName, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.x$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.x) rows.meta &lt;- rowData(sce.x) counts.x &lt;- counts(sce.x)[!sparse.genes, !(sparse.cells | mito.cells)] sce.x &lt;- SingleCellExperiment(assays=list(counts=counts.x)) colData(sce.x) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.x) &lt;- rows.meta[!sparse.genes, ] sce.x ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(1): counts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Sample Barcode ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): We write the R object to caron_sce_nz_postQc_allCells.Rds. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce.x, tmpFn) # rename to sce.nz.caron sce.nz.caron &lt;- sce.x # TODO sce.nz.caron not used rm(sce.x) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce.nz.caron &lt;- readRDS(tmpFn) 4.14.6 Hca only setName &lt;- &quot;hca&quot; sce.x &lt;- sce.nz.hca # for code re-use rm(sce.nz.hca) # compute - SLOW cell_sparsity &lt;- apply(counts(sce.x) == 0, 2, sum)/nrow(counts(sce.x)) gene_sparsity &lt;- apply(counts(sce.x) == 0, 1, sum)/ncol(counts(sce.x)) colData(sce.x)$cell_sparsity &lt;- cell_sparsity rowData(sce.x)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(list(&quot;colData&quot; = colData(sce.x), &quot;rowData&quot; = rowData(sce.x)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setName, setSuf) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity #```{r Hca_sparsity_plot_allCells, eval=runAll} # plot tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sparsity%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf) #print(&quot;DEV&quot;); print(getwd()); print(tmpFn) CairoPNG(tmpFn) par(mfrow=c(1, 2)) hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) abline(v=40, lty=2, col=&#39;purple&#39;) dev.off() ## pdf ## 2 #tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sparsity.png&quot;, projDir, outDirBit, qcPlotDirBit, setName) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sparsity%s.png&quot;, dirRel, qcPlotDirBit, setName, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.x$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.x) rows.meta &lt;- rowData(sce.x) counts.x &lt;- counts(sce.x)[!sparse.genes, !(sparse.cells | mito.cells)] sce.x &lt;- SingleCellExperiment(assays=list(counts=counts.x)) colData(sce.x) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.x) &lt;- rows.meta[!sparse.genes, ] sce.x ## class: SingleCellExperiment ## dim: 20425 197166 ## metadata(0): ## assays(1): counts ## rownames(20425): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Sample Barcode ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): rm(counts.x) We write the R object to hca_sce_nz_postQc_allCells.Rds. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce.x, tmpFn) # rename to sce.nz.hca sce.nz.hca &lt;- sce.x # TODO sce.nz.hca only used for sce.nz.hca.5k rm(sce.x) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce.nz.hca &lt;- readRDS(tmpFn) 4.15 Subsample Hca set The HCA data comprises about 25,000 cells per samples, compared to 5,000 for the Caron study. We will randomly subsample the HCA samples down to 5000 cells. sce.nz.hca ## class: SingleCellExperiment ## dim: 20425 197166 ## metadata(0): ## assays(1): counts ## rownames(20425): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Sample Barcode ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): # have new list of cell barcodes for each sample sce.nz.hca.5k.bc &lt;- colData(sce.nz.hca) %&gt;% data.frame() %&gt;% group_by(Sample.Name) %&gt;% sample_n(5000) %&gt;% pull(Barcode) table(colData(sce.nz.hca)$Barcode %in% sce.nz.hca.5k.bc) ## ## FALSE TRUE ## 157166 40000 tmpInd &lt;- which(colData(sce.nz.hca)$Barcode %in% sce.nz.hca.5k.bc) sce.nz.hca.5k &lt;- sce.nz.hca[,tmpInd] # mind that genes were filtered using all cells, not just those sampled here. We write the R object to ‘hca_sce_nz_postQc_5kCellPerSpl.Rds’. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc_5kCellPerSpl.Rds&quot;, projDir, outDirBit, setName) saveRDS(sce.nz.hca.5k, tmpFn) rm(sce.nz.hca) rm(sce.nz.hca.5k) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 8536994 456.0 13988780 747.1 13988780 747.1 ## Vcells 2685439024 20488.3 4893692944 37336.0 4065286169 31015.7 4.16 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] robustbase_0.93-7 mixtools_1.2.0 ## [3] Cairo_1.5-12.2 dplyr_1.0.5 ## [5] DT_0.18 irlba_2.3.3 ## [7] biomaRt_2.46.3 Matrix_1.3-2 ## [9] igraph_1.2.6 DropletUtils_1.10.3 ## [11] scater_1.18.6 ggplot2_3.3.3 ## [13] scran_1.18.7 SingleCellExperiment_1.12.0 ## [15] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [17] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [19] IRanges_2.24.1 S4Vectors_0.28.1 ## [21] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [23] matrixStats_0.58.0 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] ggbeeswarm_0.6.0 colorspace_2.0-0 ## [3] ellipsis_0.3.2 scuttle_1.0.4 ## [5] bluster_1.0.0 XVector_0.30.0 ## [7] BiocNeighbors_1.8.2 bit64_4.0.5 ## [9] AnnotationDbi_1.52.0 fansi_0.4.2 ## [11] xml2_1.3.2 codetools_0.2-18 ## [13] splines_4.0.3 R.methodsS3_1.8.1 ## [15] sparseMatrixStats_1.2.1 cachem_1.0.4 ## [17] jsonlite_1.7.2 kernlab_0.9-29 ## [19] dbplyr_2.1.1 R.oo_1.24.0 ## [21] HDF5Array_1.18.1 compiler_4.0.3 ## [23] httr_1.4.2 dqrng_0.3.0 ## [25] assertthat_0.2.1 fastmap_1.1.0 ## [27] limma_3.46.0 BiocSingular_1.6.0 ## [29] htmltools_0.5.1.1 prettyunits_1.1.1 ## [31] tools_4.0.3 rsvd_1.0.5 ## [33] gtable_0.3.0 glue_1.4.2 ## [35] GenomeInfoDbData_1.2.4 rappdirs_0.3.3 ## [37] Rcpp_1.0.6 jquerylib_0.1.3 ## [39] vctrs_0.3.7 rhdf5filters_1.2.0 ## [41] DelayedMatrixStats_1.12.3 xfun_0.22 ## [43] stringr_1.4.0 beachmat_2.6.4 ## [45] lifecycle_1.0.0 statmod_1.4.35 ## [47] XML_3.99-0.6 DEoptimR_1.0-8 ## [49] edgeR_3.32.1 MASS_7.3-54 ## [51] zlibbioc_1.36.0 scales_1.1.1 ## [53] hms_1.0.0 rhdf5_2.34.0 ## [55] curl_4.3.1 yaml_2.2.1 ## [57] memoise_2.0.0 gridExtra_2.3 ## [59] sass_0.3.1 segmented_1.3-3 ## [61] stringi_1.5.3 RSQLite_2.2.6 ## [63] BiocParallel_1.24.1 rlang_0.4.10 ## [65] pkgconfig_2.0.3 bitops_1.0-7 ## [67] evaluate_0.14 lattice_0.20-44 ## [69] purrr_0.3.4 Rhdf5lib_1.12.1 ## [71] htmlwidgets_1.5.3 bit_4.0.4 ## [73] tidyselect_1.1.1 magrittr_2.0.1 ## [75] bookdown_0.22 R6_2.5.0 ## [77] generics_0.1.0 DelayedArray_0.16.3 ## [79] DBI_1.1.1 pillar_1.6.0 ## [81] withr_2.4.2 survival_3.2-11 ## [83] RCurl_1.98-1.3 tibble_3.1.1 ## [85] crayon_1.4.1 utf8_1.2.1 ## [87] BiocFileCache_1.14.0 rmarkdown_2.7 ## [89] viridis_0.6.0 progress_1.2.2 ## [91] locfit_1.5-9.4 grid_4.0.3 ## [93] blob_1.2.1 digest_0.6.27 ## [95] R.utils_2.10.1 openssl_1.4.4 ## [97] munsell_0.5.0 beeswarm_0.3.1 ## [99] viridisLite_0.4.0 vipor_0.4.5 ## [101] bslib_0.2.4 askpass_1.1 "],["PreProcTop.html", "Chapter 5 Quality Control - with 500 cells per sample 5.1 Introduction 5.2 Load packages 5.3 Sample sheet 5.4 Data representation 5.5 Example 5.6 Mapping QC 5.7 Cell calling for droplet data 5.8 Load filtered matrices 5.9 Properties of scRNA-seq data 5.10 Quality control 5.11 Identification of low-quality cells with adaptive thresholds 5.12 Experimental factors 5.13 Novelty 5.14 QC based on sparsity 5.15 Session information", " Chapter 5 Quality Control - with 500 cells per sample 5.1 Introduction We will use two sets of Bone Marrow Mononuclear Cells (BMMC): ‘CaronBourque2020’: pediatric samples ‘Hca’: HCA Census of Immune Cells for adult BMMCs Fastq files were retrieved from publicly available archive (SRA and HCA). Sequencing quality was assessed and visualised using fastQC and MultiQC. Reads were aligned against GRCh38 and features counted using cellranger (v3.1.0). We will now check the quality of the data further: mapping quality and amplification rate cell counts distribution of keys quality metrics We will then: filter genes with very low expression identify low-quality cells filter and/or mark low quality cells 5.2 Load packages SingleCellExperiment - to store the data Matrix - to deal with sparse and/or large matrices DropletUtils - utilities for the analysis of droplet-based, inc. cell counting scater - QC scran - normalisation igraph - graphs biomaRt - for gene annotation ggplot2 - for plotting irlba - for faster PCA projDir &lt;- params$projDir wrkDir &lt;- sprintf(&quot;%s/CaronBourque2020/grch38300&quot;, projDir) outDirBit &lt;- params$outDirBit # &quot;AnaWiSeurat/Attempt1&quot; qcPlotDirBit &lt;- &quot;Plots/Qc&quot; poolBool &lt;- TRUE # FALSE # whether to read each sample in and pool them and write object to file, or just load that file. biomartBool &lt;- TRUE # FALSE # biomaRt sometimes fails, do it once, write to file and use that copy. See geneAnnot.Rmd addQcBool &lt;- TRUE runAll &lt;- TRUE saveRds &lt;- TRUE # overwrite existing Rds files dir.create(sprintf(&quot;%s/%s/%s&quot;, projDir, outDirBit, qcPlotDirBit), showWarnings = FALSE, recursive = TRUE) dir.create(sprintf(&quot;%s/%s/Robjects&quot;, projDir, outDirBit), showWarnings = FALSE) 5.3 Sample sheet We will load both the Caron and Hca data sets. # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) # Human Cell Atlas hca_sampleSheetFn &lt;- file.path(projDir, &quot;Data/Hca/accList_Hca.txt&quot;) # read sample sheet in: splShtColToKeep &lt;- c(&quot;Run&quot;, &quot;Sample.Name&quot;, &quot;source_name&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) hca_sampleSheet &lt;- read.table(hca_sampleSheetFn, header=F, sep=&quot;,&quot;) colnames(hca_sampleSheet) &lt;- &quot;Sample.Name&quot; hca_sampleSheet$Run &lt;- hca_sampleSheet$Sample.Name hca_sampleSheet$source_name &lt;- &quot;ABMMC&quot; # adult BMMC sampleSheet &lt;- rbind(cb_sampleSheet[,splShtColToKeep], hca_sampleSheet[,splShtColToKeep]) sampleSheet %&gt;% as.data.frame() %&gt;% datatable(rownames = FALSE) 5.4 Data representation We will use a SingleCellExperiment object that is described here and stores various data types: the count matrix feature (gene) annotation droplet annotation outcome of downstream analysis such as dimensionality reduction tmpFn &lt;- sprintf(&quot;%s/Images/tenxLibStructureV3.png&quot;, &quot;..&quot;) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 5.5 Example We will load the data for the first sample in the sample sheet: SRR9264343. i &lt;- 1 sample.path &lt;- sprintf(&quot;%s/%s/%s/outs/raw_feature_bc_matrix/&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) sce.raw &lt;- read10xCounts(sample.path, col.names=TRUE) sce.raw ## class: SingleCellExperiment ## dim: 33538 737280 ## metadata(1): Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(3): ID Symbol Type ## colnames(737280): AAACCTGAGAAACCAT-1 AAACCTGAGAAACCGC-1 ... ## TTTGTCATCTTTAGTC-1 TTTGTCATCTTTCCTC-1 ## colData names(2): Sample Barcode ## reducedDimNames(0): ## altExpNames(0): We can access these different types of data with various functions. Number of genes and droplets in the count matrix: dim(counts(sce.raw)) ## [1] 33538 737280 Features, with rowData(): head(rowData(sce.raw)) ## DataFrame with 6 rows and 3 columns ## ID Symbol Type ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000243485 ENSG00000243485 MIR1302-2HG Gene Expression ## ENSG00000237613 ENSG00000237613 FAM138A Gene Expression ## ENSG00000186092 ENSG00000186092 OR4F5 Gene Expression ## ENSG00000238009 ENSG00000238009 AL627309.1 Gene Expression ## ENSG00000239945 ENSG00000239945 AL627309.3 Gene Expression ## ENSG00000239906 ENSG00000239906 AL627309.2 Gene Expression Samples, with colData(): head(colData(sce.raw)) ## DataFrame with 6 rows and 2 columns ## Sample Barcode ## &lt;character&gt; &lt;character&gt; ## AAACCTGAGAAACCAT-1 /ssd/personal/baller.. AAACCTGAGAAACCAT-1 ## AAACCTGAGAAACCGC-1 /ssd/personal/baller.. AAACCTGAGAAACCGC-1 ## AAACCTGAGAAACCTA-1 /ssd/personal/baller.. AAACCTGAGAAACCTA-1 ## AAACCTGAGAAACGAG-1 /ssd/personal/baller.. AAACCTGAGAAACGAG-1 ## AAACCTGAGAAACGCC-1 /ssd/personal/baller.. AAACCTGAGAAACGCC-1 ## AAACCTGAGAAAGTGG-1 /ssd/personal/baller.. AAACCTGAGAAAGTGG-1 Single-cell RNA-seq data compared to bulk RNA-seq is sparse, especially with droplet-based methods such as 10X, mostly because: a given cell does not express each gene the library preparation does not capture all transcript the cell does express the sequencing depth per cell is far lower Counts, with counts(). Given the large number of droplets in a sample, count matrices can be large. They are however very sparse and can be stored in a ‘sparse matrix’ that only stores non-zero values, for example a ‘dgCMatrix’ object (‘DelayedArray’ class). counts(sce.raw) &lt;- as(counts(sce.raw), &quot;dgCMatrix&quot;) counts(sce.raw)[1:10, 1:10] ## 10 x 10 sparse Matrix of class &quot;dgCMatrix&quot; ## ## ENSG00000243485 . . . . . . . . . . ## ENSG00000237613 . . . . . . . . . . ## ENSG00000186092 . . . . . . . . . . ## ENSG00000238009 . . . . . . . . . . ## ENSG00000239945 . . . . . . . . . . ## ENSG00000239906 . . . . . . . . . . ## ENSG00000241599 . . . . . . . . . . ## ENSG00000236601 . . . . . . . . . . ## ENSG00000284733 . . . . . . . . . . ## ENSG00000235146 . . . . . . . . . . 5.6 Mapping QC 5.6.1 Gene body coverage The plot below show the average coverage (y-axis) along the body of genes (x-axis). tmpFn &lt;- sprintf(&quot;%s/Images/1_AAACCTGAGACTTTCG-1.rseqcGeneBodyCovCheck.txt.geneBodyCoverage.curves.png&quot;, &quot;..&quot;) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 5.6.2 Amplification rate We will use the information stored in the ‘molecule info’ file to count the number of UMI and reads for each gene in each cell. ##mol.info.file &lt;- sprintf(&quot;%s/%s/%s/outs/molecule_info.h5&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) ##mol.info &lt;- read10xMolInfo(mol.info.file) # or mol.info object if issue with H5Fopen i &lt;- 1 mol.info.file &lt;- sprintf(&quot;%s/%s/%s/outs/molecule_info_h5.Rds&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) mol.info &lt;- readRDS(mol.info.file) rm(mol.info.file) # slow # &#39;data&#39; slot: mol.info$data ## DataFrame with 18544666 rows and 5 columns ## cell umi gem_group gene reads ## &lt;character&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 1 AAACCTGAGAAACCTA 467082 1 3287 1 ## 2 AAACCTGAGAAACCTA 205888 1 3446 1 ## 3 AAACCTGAGAAACCTA 866252 1 3896 3 ## 4 AAACCTGAGAAACCTA 796027 1 3969 1 ## 5 AAACCTGAGAAACCTA 542561 1 5008 1 ## ... ... ... ... ... ... ## 18544662 TTTGTCATCTTTAGTC 927060 1 23634 1 ## 18544663 TTTGTCATCTTTAGTC 975865 1 27143 1 ## 18544664 TTTGTCATCTTTAGTC 364964 1 27467 4 ## 18544665 TTTGTCATCTTTAGTC 152570 1 30125 7 ## 18544666 TTTGTCATCTTTAGTC 383230 1 30283 5 # &#39;genes&#39; slot head(mol.info$genes) ## [1] &quot;ENSG00000243485&quot; &quot;ENSG00000237613&quot; &quot;ENSG00000186092&quot; &quot;ENSG00000238009&quot; ## [5] &quot;ENSG00000239945&quot; &quot;ENSG00000239906&quot; # for each cell and gene, count UMIs # slow, but needs running, at least once # so write it to file to load later if need be. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_preProc_ampDf1.Rds&quot;, projDir, outDirBit) if(!file.exists(tmpFn)) { ampDf &lt;- mol.info$data %&gt;% data.frame() %&gt;% mutate(umi = as.character(umi)) %&gt;% group_by(cell, gene) %&gt;% summarise(nUmis = n(), totReads=sum(reads)) %&gt;% data.frame() # Write object to file saveRDS(ampDf, tmpFn) } else { ampDf &lt;- readRDS(tmpFn) } rm(tmpFn) # distribution of totReads summary(ampDf$totReads) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.00 2.00 6.00 15.23 12.00 79275.00 # distribution of nUmis summary(ampDf$nUmis) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 1.000 1.000 2.377 1.000 7137.000 We now plot the amplification rate. sp2 &lt;- ggplot(ampDf, aes(x=nUmis, y=totReads)) + geom_bin2d(bins = 50) + scale_fill_continuous(type = &quot;viridis&quot;) + scale_x_continuous(trans=&#39;log10&#39;) + scale_y_continuous(trans=&#39;log10&#39;) + ggtitle(&quot;totReads vs nUmis&quot;) + theme_bw() sp2 gc(verbose=FALSE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 8621710 460.5 15837858 845.9 11041355 589.7 ## Vcells 106269424 810.8 335474351 2559.5 335474351 2559.5 5.7 Cell calling for droplet data For a given sample, amongst the tens of thousands of droplets used in the assay, some will contain a cell while many others will not. The presence of RNA in a droplet will show with non-zero UMI count. This is however not sufficient to infer that the droplet does contain a cell. Indeed, after sample preparation, some cell debris including RNA will still float in the mix. This ambient RNA is unwillingly captured during library preparation and sequenced. Cellranger generates a count matrix that includes all droplets analysed in the assay. We will now load this ‘raw matrix’ for one sample and draw the distribution of UMI counts. Distribution of UMI counts: libSizeDf &lt;- mol.info$data %&gt;% data.frame() %&gt;% mutate(umi = as.character(umi)) %&gt;% group_by(cell) %&gt;% summarise(nUmis = n(), totReads=sum(reads)) %&gt;% data.frame() rm(mol.info) ggplot(libSizeDf, aes(x=log10(nUmis))) + geom_histogram(bins = 50) Library size varies widely, both amongst empty droplets and droplets carrying cells, mostly due to: variation in droplet size, amplification efficiency, sequencing Most cell counting methods try to identify the library size that best distinguishes empty from cell-carrying droplets. 5.7.1 Mixture model This method by default fits a mixture of two normal distributions to the logged library sizes: one with a small mean for empty droplets the other with a higher mean for cell-carrying droplets set.seed(100) # get package library(&quot;mixtools&quot;) # have library sizes on a log10 scale log10_lib_size &lt;- log10(libSizeDf$nUmis) # fit mixture mix &lt;- normalmixEM(log10_lib_size, mu=c(log10(100), log10(1000)), maxrestarts=50, epsilon = 1e-03) ## number of iterations= 29 # plot plot(mix, which=2, xlab2=&quot;log(mol per cell)&quot;) # get density for each distribution: p1 &lt;- dnorm(log10_lib_size, mean=mix$mu[1], sd=mix$sigma[1]) p2 &lt;- dnorm(log10_lib_size, mean=mix$mu[2], sd=mix$sigma[2]) # find intersection: if (mix$mu[1] &lt; mix$mu[2]) { split &lt;- min(log10_lib_size[p2 &gt; p1]) } else { split &lt;- min(log10_lib_size[p1 &gt; p2]) } # show split on plot: abline(v=split, lwd=2) 5.7.2 Barcode rank plot The barcode rank plot shows the library sizes against their rank in decreasing order, for the first 10000 droplets only. barcode_rank &lt;- rank(-libSizeDf$nUmis) plot(barcode_rank, libSizeDf$nUmis, xlim=c(1,10000), ylab=&quot;library size&quot;) Given the exponential shape of the curve above, library sizes can be shown on the log10 scale: plot(barcode_rank, log10_lib_size, xlim=c(1,10000)) The plot above shows that the majority of droplets have fewer than 100 UMIs, e.g. droplets with rank greater than 4000. We will redraw the plot to focus on droplets with lower ranks, by using the log10 scale for the x-axis. plot(log10(barcode_rank), log10_lib_size, xlim=log10(c(1,10000))) The point on the curve where it drops sharply may be used as the split point. Before that point library sizes are high, because droplets carry a cell. After that point, library sizes are far smaller because droplets do not carry a cell, only ambient RNA (… or do they?). Here, we could ‘visually’ approximate the number of cells to 2500. There are however more robust and convenient methods. 5.7.3 Inflection point We could also compute the inflection point of the curve. o &lt;- order(barcode_rank) log10_lib_size &lt;- log10_lib_size[o] barcode_rank &lt;- barcode_rank[o] rawdiff &lt;- diff(log10_lib_size)/diff(barcode_rank) inflection &lt;- which(rawdiff == min(rawdiff[100:length(rawdiff)], na.rm=TRUE)) plot(x=log10(barcode_rank), y=log10_lib_size, xlim=log10(c(1,10000))) abline(v=log10(inflection), col=&quot;red&quot;, lwd=2) The inflection is at 3279 UMIs (3.5157414 on the log10 scale). 2306 droplets have at least these many UMIs and would thus contain one cell (or more). 5.7.4 Cellranger v1 and v2 Given an expected number of cells, cellranger used to assume a ~10-fold range of library sizes for real cells and estimate this range (cellranger v1 and v2). The threshold was defined as the 99th quantile of the library size, divided by 10. # approximate number of cells expected: n_cells &lt;- 2500 # CellRanger totals &lt;- sort(libSizeDf$nUmis, decreasing = TRUE) # 99th percentile of top n_cells divided by 10 thresh = totals[round(0.01*n_cells)]/10 #plot(log10(totals), xlim=c(1,10000)) plot(x=log10(seq(1,10000)), y=log10(totals)[1:10000] ) abline(h=log10(thresh), col=&quot;red&quot;, lwd=2) The threshold is at 1452 UMIs and 2773 cells are detected. 5.7.5 DropletUtils and EmptyDrops The DropletUtils package offers utilities to analyse droplet-based data, including cell counting using the library size as seen above. These simple approaches may exclude droplets with small or quiet cells with low RNA content. The emptyDrops method calls cells by first computing the expression profile for droplets with RNA content so low they almost certainly do not contain any cell: the ‘background’ or ‘ambient’ profile. The method then tests each non-background droplet for significant difference in expression profile. Let’s first check the knee and inflection methods. br.out &lt;- barcodeRanks(counts(sce.raw)) plot(br.out$rank, br.out$total, log=&quot;xy&quot;, xlab=&quot;Rank&quot;, ylab=&quot;Total UMI count&quot;) o &lt;- order(br.out$rank) lines(br.out$rank[o], br.out$fitted[o], col=&quot;red&quot;) abline(h=metadata(br.out)$knee, col=&quot;dodgerblue&quot;, lty=2) abline(h=metadata(br.out)$inflection, col=&quot;forestgreen&quot;, lty=2) legend(&quot;bottomleft&quot;, lty=2, col=c(&quot;dodgerblue&quot;, &quot;forestgreen&quot;), legend=c(&quot;knee&quot;, &quot;inflection&quot;)) Testing for empty droplets. We will call cells with a false discovery rate (FDR) of 0.1% so that at most 1 in 1000 droplets called may be empty. # a bit slow # significance is computed by simulation so we set a seed for reproducibility set.seed(100) # run analysis: e.out &lt;- emptyDrops(counts(sce.raw)) e.out ## DataFrame with 737280 rows and 5 columns ## Total LogProb PValue Limited FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;logical&gt; &lt;numeric&gt; ## AAACCTGAGAAACCAT-1 0 NA NA NA NA ## AAACCTGAGAAACCGC-1 0 NA NA NA NA ## AAACCTGAGAAACCTA-1 31 NA NA NA NA ## AAACCTGAGAAACGAG-1 0 NA NA NA NA ## AAACCTGAGAAACGCC-1 0 NA NA NA NA ## ... ... ... ... ... ... ## TTTGTCATCTTTACAC-1 0 NA NA NA NA ## TTTGTCATCTTTACGT-1 1 NA NA NA NA ## TTTGTCATCTTTAGGG-1 0 NA NA NA NA ## TTTGTCATCTTTAGTC-1 26 NA NA NA NA ## TTTGTCATCTTTCCTC-1 0 NA NA NA NA NAs are assigned to droplets used to compute the ambient profile. Get numbers of droplets in each class defined by FDR and the cut-off used: summary(e.out$FDR &lt;= 0.001) ## Mode FALSE TRUE NA&#39;s ## logical 487 3075 733718 The test significance is computed by permutation. For each droplet tested, the number of permutations may limit the value of the p-value. This information is available in the ‘Limited’ column. If ‘Limited’ is ‘TRUE’ for any non-significant droplet, the number of permutations was too low, should be increased and the analysis re-run. table(Sig=e.out$FDR &lt;= 0.001, Limited=e.out$Limited) ## Limited ## Sig FALSE TRUE ## FALSE 487 0 ## TRUE 76 2999 Let’s check that the background comprises only empty droplets. If the droplets used to define the background profile are indeed empty, testing them should result in a flat distribution of p-values. Let’s test the ‘ambient’ droplets and draw the p-value distribution. set.seed(100) limit &lt;- 100 all.out &lt;- emptyDrops(counts(sce.raw), lower=limit, test.ambient=TRUE) hist(all.out$PValue[all.out$Total &lt;= limit &amp; all.out$Total &gt; 0], xlab=&quot;P-value&quot;, main=&quot;&quot;, col=&quot;grey80&quot;) The distribution of p-values looks uniform with no large peak for small values: no cell in these droplets. To evaluate the outcome of the analysis, we will plot the strength of the evidence against library size. is.cell &lt;- e.out$FDR &lt;= 0.001 Number of cells detected: 3075. The plot plot shows the strength of the evidence against the library size. Each point is a droplet coloured: in black if without cell, in red if with a cell (or more) in green if with a cell (or more) as defined with emptyDrops but not the inflection method. # colour: cellColour &lt;- ifelse(is.cell, &quot;red&quot;, &quot;black&quot;) # rep(&quot;black&quot;, nrow((e.out))) # boolean for presence of cells as defined by the inflection method tmpBoolInflex &lt;- e.out$Total &gt; metadata(br.out)$inflection # boolean for presence of cells as defined by the emptyDrops method tmpBoolSmall &lt;- e.out$FDR &lt;= 0.001 tmpBoolRecov &lt;- !tmpBoolInflex &amp; tmpBoolSmall cellColour[tmpBoolRecov] &lt;- &quot;green&quot; # &#39;recovered&#39; cells # plot strength of significance vs library size plot(log10(e.out$Total), -e.out$LogProb, col=cellColour, xlim=c(2,max(log10(e.out$Total))), xlab=&quot;Total UMI count&quot;, ylab=&quot;-Log Probability&quot;) # add point to show &#39;recovered&#39; cell on top points(log10(e.out$Total)[tmpBoolRecov], -e.out$LogProb[tmpBoolRecov], pch=16, col=&quot;green&quot;) Let’s filter out empty droplets. sce.ed &lt;- sce.raw[,which(e.out$FDR &lt;= 0.001)] # &#39;ed&#39; for empty droplet rm(sce.raw); gc(); ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 8977270 479.5 15837858 845.9 15837858 845.9 ## Vcells 58782587 448.5 268379481 2047.6 335474351 2559.5 And check the new SCE object: sce.ed ## class: SingleCellExperiment ## dim: 33538 3075 ## metadata(1): Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(3): ID Symbol Type ## colnames(3075): AAACCTGAGACTTTCG-1 AAACCTGGTCTTCAAG-1 ... ## TTTGTCACAGGCTCAC-1 TTTGTCAGTTCGGCAC-1 ## colData names(2): Sample Barcode ## reducedDimNames(0): ## altExpNames(0): rm(sce.ed) Cell calling in cellranger v3 uses a method similar to emptyDrops() and a ‘filtered matrix’ is generated that only keeps droplets deemed to contain a cell (or more). We will load these filtered matrices now. 5.8 Load filtered matrices Each sample was analysed with cellranger separately. We load filtered matrices one sample at a time, showing for each the name and number of features and cells. # load data: # a bit slow # use &#39;cache.lazy = FALSE&#39; to avoid &#39;long vectors not supported yet&#39; when &#39;cache=TRUE&#39; sce.list &lt;- vector(&quot;list&quot;, length = nrow(sampleSheet)) for (i in 1:nrow(sampleSheet)) { print(sprintf(&quot;&#39;Run&#39; %s, &#39;Sample.Name&#39; %s&quot;, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Sample.Name&quot;])) sample.path &lt;- sprintf(&quot;%s/%s/%s/outs/filtered_feature_bc_matrix/&quot;, sprintf(&quot;%s/%s/grch38300&quot;, projDir, ifelse(sampleSheet[i,&quot;source_name&quot;] == &quot;ABMMC&quot;, &quot;Hca&quot;, &quot;CaronBourque2020&quot;)), sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) sce.list[[i]] &lt;- read10xCounts(sample.path) print(dim(sce.list[[i]])) } ## [1] &quot;&#39;Run&#39; SRR9264343, &#39;Sample.Name&#39; GSM3872434&quot; ## [1] 33538 3088 ## [1] &quot;&#39;Run&#39; SRR9264344, &#39;Sample.Name&#39; GSM3872435&quot; ## [1] 33538 6678 ## [1] &quot;&#39;Run&#39; SRR9264345, &#39;Sample.Name&#39; GSM3872436&quot; ## [1] 33538 5054 ## [1] &quot;&#39;Run&#39; SRR9264346, &#39;Sample.Name&#39; GSM3872437&quot; ## [1] 33538 6096 ## [1] &quot;&#39;Run&#39; SRR9264347, &#39;Sample.Name&#39; GSM3872438&quot; ## [1] 33538 5442 ## [1] &quot;&#39;Run&#39; SRR9264348, &#39;Sample.Name&#39; GSM3872439&quot; ## [1] 33538 5502 ## [1] &quot;&#39;Run&#39; SRR9264349, &#39;Sample.Name&#39; GSM3872440&quot; ## [1] 33538 4126 ## [1] &quot;&#39;Run&#39; SRR9264350, &#39;Sample.Name&#39; GSM3872441&quot; ## [1] 33538 3741 ## [1] &quot;&#39;Run&#39; SRR9264351, &#39;Sample.Name&#39; GSM3872442&quot; ## [1] 33538 978 ## [1] &quot;&#39;Run&#39; SRR9264352, &#39;Sample.Name&#39; GSM3872442&quot; ## [1] 33538 1150 ## [1] &quot;&#39;Run&#39; SRR9264353, &#39;Sample.Name&#39; GSM3872443&quot; ## [1] 33538 4964 ## [1] &quot;&#39;Run&#39; SRR9264354, &#39;Sample.Name&#39; GSM3872444&quot; ## [1] 33538 4255 ## [1] &quot;&#39;Run&#39; MantonBM1, &#39;Sample.Name&#39; MantonBM1&quot; ## [1] 33538 23283 ## [1] &quot;&#39;Run&#39; MantonBM2, &#39;Sample.Name&#39; MantonBM2&quot; ## [1] 33538 25055 ## [1] &quot;&#39;Run&#39; MantonBM3, &#39;Sample.Name&#39; MantonBM3&quot; ## [1] 33538 24548 ## [1] &quot;&#39;Run&#39; MantonBM4, &#39;Sample.Name&#39; MantonBM4&quot; ## [1] 33538 26478 ## [1] &quot;&#39;Run&#39; MantonBM5, &#39;Sample.Name&#39; MantonBM5&quot; ## [1] 33538 26383 ## [1] &quot;&#39;Run&#39; MantonBM6, &#39;Sample.Name&#39; MantonBM6&quot; ## [1] 33538 22801 ## [1] &quot;&#39;Run&#39; MantonBM7, &#39;Sample.Name&#39; MantonBM7&quot; ## [1] 33538 24372 ## [1] &quot;&#39;Run&#39; MantonBM8, &#39;Sample.Name&#39; MantonBM8&quot; ## [1] 33538 24860 Let’s combine all 20 samples into a single object. We first check the feature lists are identical. # check row names are the same # compare to that for the first sample rowNames1 &lt;- rownames(sce.list[[1]]) for (i in 2:nrow(sampleSheet)) { print(identical(rowNames1, rownames(sce.list[[i]]))) } ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE A cell barcode comprises the actual sequence and a ‘group ID’, e.g. AAACCTGAGAAACCAT-1. The latter helps distinguish cells with identical barcode sequence but come from different samples. As each sample was analysed separately, the group ID is set to 1 in all data sets. To pool these data sets we first need to change group IDs so cell barcodes are unique across all samples. We will use the position of the sample in the sample sheet. We also downsample to 2000 cells maximum per sample for faster computation during the course. # subset 2000 cells: # mind that is not mentioned in Rds file names ... if(ncol(sce.list[[1]]) &lt; 2000) { sce &lt;- sce.list[[1]] } else { sce &lt;- sce.list[[1]][, sample(ncol(sce.list[[1]]), 2000)] } colData(sce)$Barcode &lt;- gsub(&quot;([0-9])$&quot;, 1, colData(sce)$Barcode) print(head(colData(sce)$Barcode)) ## [1] &quot;GATGCTAGTATCAGTC-1&quot; &quot;GTCCTCAGTCCAAGTT-1&quot; &quot;CGCGTTTAGGCTAGCA-1&quot; ## [4] &quot;GGATTACGTGCGAAAC-1&quot; &quot;CGTTGGGCAGCCAATT-1&quot; &quot;GTGCGGTGTCATTAGC-1&quot; print(tail(colData(sce)$Barcode)) ## [1] &quot;CGTCCATAGATTACCC-1&quot; &quot;CAGCCGACATCCCATC-1&quot; &quot;GCAGCCACACTTCTGC-1&quot; ## [4] &quot;CAAGATCGTCGGCACT-1&quot; &quot;GTAACGTTCCCATTAT-1&quot; &quot;TTCGGTCAGGGTTCCC-1&quot; for (i in 2:nrow(sampleSheet)) { if(ncol(sce.list[[i]]) &lt; 2000) { sce.tmp &lt;- sce.list[[i]] } else { sce.tmp &lt;- sce.list[[i]][, sample(ncol(sce.list[[i]]), 2000)] } colData(sce.tmp)$Barcode &lt;- gsub(&quot;([0-9])$&quot;, i, colData(sce.tmp)$Barcode) sce &lt;- cbind(sce, sce.tmp) print(tail(colData(sce)$Barcode, 2)) } ## [1] &quot;AGAGTGGCACCAGTTA-2&quot; &quot;AACACGTGTACCTACA-2&quot; ## [1] &quot;CGGCTAGAGCTGAACG-3&quot; &quot;TAGCCGGAGTTAGCGG-3&quot; ## [1] &quot;ACACCAAGTCAGAAGC-4&quot; &quot;AAGGTTCAGGCCGAAT-4&quot; ## [1] &quot;AGGGTGAAGAGTCGGT-5&quot; &quot;CTGCGGAGTGAGTATA-5&quot; ## [1] &quot;GGCGACTGTGTTTGGT-6&quot; &quot;TTGGAACAGTGTACTC-6&quot; ## [1] &quot;TGTGGTACACTTACGA-7&quot; &quot;ACTGAGTTCTATCGCC-7&quot; ## [1] &quot;GTCACAACAATCGGTT-8&quot; &quot;CTACATTGTCTCTCGT-8&quot; ## [1] &quot;TTTGGTTGTGCATCTA-9&quot; &quot;TTTGTCACAGCTCGAC-9&quot; ## [1] &quot;TTTGTCAGTAAATGTG-10&quot; &quot;TTTGTCAGTACAAGTA-10&quot; ## [1] &quot;TGCGGGTAGCGTAGTG-11&quot; &quot;CTAGAGTCAAAGTGCG-11&quot; ## [1] &quot;GCAATCAAGGCTATCT-12&quot; &quot;GGGTCTGCATAAGACA-12&quot; ## [1] &quot;TATCTCAGTCATATCG-13&quot; &quot;TCGTACCTCTGGTATG-13&quot; ## [1] &quot;CGTTCTGCAGCTGTTA-14&quot; &quot;TCGCGAGTCATCTGCC-14&quot; ## [1] &quot;ACTTACTCAGGTTTCA-15&quot; &quot;ACTGCTCTCGGTTAAC-15&quot; ## [1] &quot;AGAGTGGCAAAGGCGT-16&quot; &quot;ACACCCTAGATCCCGC-16&quot; ## [1] &quot;GCTGGGTAGGCTCATT-17&quot; &quot;TGTTCCGCACAGACAG-17&quot; ## [1] &quot;CTACATTGTAGCGATG-18&quot; &quot;TGGGCGTCACACCGCA-18&quot; ## [1] &quot;TTCCCAGCAGGGTACA-19&quot; &quot;GTTCTCGGTCCTCCAT-19&quot; ## [1] &quot;GCTGGGTCATAACCTG-20&quot; &quot;TATGCCCCAGCGTCCA-20&quot; rm(sce.list) We now add the sample sheet information to the object metadata. colDataOrig &lt;- colData(sce) # split path: tmpList &lt;- strsplit(colDataOrig$Sample, split=&quot;/&quot;) # get Run ID, to use to match sample in the meta data and sample sheet objects: tmpVec &lt;- unlist(lapply(tmpList, function(x){x[9]})) colData(sce)$Run &lt;- tmpVec # remove path to filtered matrix files by sample name in &#39;Sample&#39;: colData(sce)$Sample &lt;- NULL # merge: colData(sce) &lt;- colData(sce) %&gt;% data.frame %&gt;% left_join(sampleSheet[,splShtColToKeep], &quot;Run&quot;) %&gt;% relocate() %&gt;% DataFrame rm(tmpVec) Let’s save the object for future reference. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postPool.Rds&quot;, projDir, outDirBit) saveRDS(sce, tmpFn) rm(tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postPool.Rds&quot;, projDir, outDirBit) sce &lt;- readRDS(tmpFn) rm(tmpFn) 5.9 Properties of scRNA-seq data The number and identity of genes detected in a cell vary across cells: the total number of genes detected across all cells is far larger than the number of genes detected in each cell. Total number of genes detected across cells: # for each gene, compute total number of UMIs across all cells, # then counts genes with at least one UMI: sum(rowSums(counts(sce)) &gt; 0) ## [1] 25116 Summary of the distribution of the number of genes detected per cell: # for each cell count number of genes with at least 1 UMI # then compute distribution moments: summary(colSums(counts(sce) &gt; 0)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 26 717 940 1228 1521 6586 Now let’s plot for each gene the total number of UMIs and the proportion of cells that express it. Lowly expressed genes tend to be detected in a large proportion of cells. The higher the overall expression the lower the proportion of cells. # randomly subset 1000 cells. tmpCounts &lt;- counts(sce)[,sample(1000)] plot(rowSums(tmpCounts), rowMeans(tmpCounts &gt; 0), log = &quot;x&quot;, xlab=&quot;total number of UMIs&quot;, ylab=&quot;proportion of cells expressing the gene&quot; ) Count genes that are not ‘expressed’ (detected): not.expressed &lt;- rowSums(counts(sce)) == 0 table(not.expressed) ## not.expressed ## FALSE TRUE ## 25116 8422 Plot the percentage of counts per gene and show genes with the highest UMI counts: #Compute the relative expression of each gene per cell rel_expression &lt;- t( t(counts(sce)) / Matrix::colSums(counts(sce))) * 100 rownames(rel_expression) &lt;- rowData(sce)$Symbol most_expressed &lt;- sort(Matrix::rowSums( rel_expression ),T)[20:1] / ncol(sce) boxplot( as.matrix(t(rel_expression[names(most_expressed),])), cex=.1, las=1, xlab=&quot;% total count per cell&quot;, col=scales::hue_pal()(20)[20:1], horizontal=TRUE) rm(rel_expression, most_expressed) Mind that we have combined two data sets here. It may be interesting to count non-expressed genes in each set separately. 5.10 Quality control Cell calling performed above does not inform on the quality of the library in each of the droplets kept. Poor-quality cells, or rather droplets, may be caused by cell damage during dissociation or failed library preparation. They usually have low UMI counts, few genes detected and/or high mitochondrial content. The presence may affect normalisation, assessment of cell population heterogeneity, clustering and trajectory: Normalisation: Contaminating genes, ‘the ambient RNA’, are detected at low levels in all libraires. In low quality libraries with low RNA content, scaling will increase counts for these genes more than for better-quality cells, resulting in their apparent upregulation in these cells and increased variance overall. Cell population heterogeneity: variance estimation and dimensionality reduction with PCA where the first principal component will be correlated with library size, rather than biology. Clustering and trajectory: higher mitochondrial and/or nuclear RNA content may cause low-quality cells to cluster separately or form states or trajectories between distinct cell types. We will now exclude lowly expressed features and identify low-quality cells using the following metrics mostly: library size, i.e. the total number of UMIs per cell number of features detected per cell mitochondrial content, i.e. the proportion of UMIs that map to mitochondrial genes, with higher values consistent with leakage from the cytoplasm of RNA, but not mitochondria We will first annotate genes, to know which ones are mitochondrial, then use scater’s addPerCellQC() to compute various metrics. Annotate genes with biomaRt. # retrieve the feature information gene.info &lt;- rowData(sce) # setup the biomaRt connection to Ensembl using the correct species genome (hsapiens_gene_ensembl) ensembl &lt;- useEnsembl(biomart=&#39;ensembl&#39;, dataset=&#39;hsapiens_gene_ensembl&#39;, mirror = &quot;www&quot;) #ensembl = useMart(biomart=&quot;ensembl&quot;, # dataset=&#39;hsapiens_gene_ensembl&#39;, # host = &quot;www.ensembl.org&quot;) # ensemblRedirect = FALSE # retrieve the attributes of interest from biomaRt using the Ensembl gene ID as the key # beware that this will only retrieve information for matching IDs gene_symbol &lt;- getBM(attributes=c(&#39;ensembl_gene_id&#39;, &#39;external_gene_name&#39;, &#39;chromosome_name&#39;, &#39;start_position&#39;, &#39;end_position&#39;, &#39;strand&#39;), filters=&#39;ensembl_gene_id&#39;, mart=ensembl, values=gene.info[, 1]) # create a new data frame of the feature information gene.merge &lt;- merge(gene_symbol, gene.info, by.x=c(&#39;ensembl_gene_id&#39;), by.y=c(&#39;ID&#39;), all.y=TRUE) rownames(gene.merge) &lt;- gene.merge$ensembl_gene_id # set the order for the same as the original gene information gene.merge &lt;- gene.merge[gene.info[, 1], ] # reset the rowdata on the SCE object to contain all of this information rowData(sce) &lt;- gene.merge rm(gene_symbol, gene.merge) # slow # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postBiomart.Rds&quot;, projDir, outDirBit) saveRDS(sce, tmpFn) rm(tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postBiomart.Rds&quot;, projDir, outDirBit) sce &lt;- readRDS(tmpFn) rm(tmpFn) Number of genes per chromosome, inc. 13 on the mitochondrial genome: # number of genes per chromosome table(rowData(sce)$chromosome_name) %&gt;% as.data.frame() %&gt;% dplyr::rename(Chromosome=Var1, NbGenes=Freq) %&gt;% datatable(rownames = FALSE) # mitochondrial genes is.mito &lt;- which(rowData(sce)$chromosome_name==&quot;MT&quot;) Calculate and store QC metrics for genes with addPerFeatureQC() and for cells with addPerCellQC(). # long # for genes sce &lt;- addPerFeatureQC(sce) head(rowData(sce)) %&gt;% as.data.frame() %&gt;% datatable(rownames = FALSE) # ENS ID Three columns of interest for cells: ‘sum’: total UMI count ‘detected’: number of features (genes) detected ‘subsets_Mito_percent’: percentage of reads mapped to mitochondrial transcripts # for cells sce &lt;- addPerCellQC(sce, subsets=list(Mito=is.mito)) head(colData(sce)) %&gt;% as.data.frame() %&gt;% datatable(rownames = FALSE) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postAddQc.Rds&quot;, projDir, outDirBit) saveRDS(sce, tmpFn) rm(tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postAddQc.Rds&quot;, projDir, outDirBit) sce &lt;- readRDS(tmpFn) rm(tmpFn) 5.10.1 QC metric distribution Overall: par(mfrow=c(1, 2)) hist(log10(sce$sum), breaks=20, col=&quot;grey80&quot;, xlab=&quot;Log-total UMI count&quot;, main=&quot;&quot;) hist(sce$subsets_Mito_percent, breaks=20, col=&quot;grey80&quot;, xlab=&quot;Proportion of reads in mitochondrial genes&quot;, main=&quot;&quot;) abline(v=20, lty=2, col=&#39;purple&#39;) Per sample group: sce$source_name &lt;- factor(sce$source_name) sce$block &lt;- sce$source_name sce$setName &lt;- ifelse(grepl(&quot;ABMMC&quot;, sce$source_name), &quot;Hca&quot;, &quot;Caron&quot;) Library size (‘Total count’): p &lt;- plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;) p Number of genes (‘detected’): p &lt;- plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) p Mitochondrial content (‘subsets_Mito_percent’): p &lt;- plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, other_fields=&quot;setName&quot;) + # facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;) p tmpFn &lt;- sprintf(&quot;%s/%s/%s/qc_metricDistrib_plotColData2.png&quot;, projDir, outDirBit, qcPlotDirBit) CairoPNG(tmpFn) # violin plots gridExtra::grid.arrange( plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, other_fields=&quot;setName&quot;) + # facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;), ncol=1 ) dev.off() ## pdf ## 2 tmpFn &lt;- sprintf(&quot;../%s/qc_metricDistrib_plotColData2.png&quot;, qcPlotDirBit) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Correlation between the number of genes detected and library size (‘detected’ against ‘sum’): sp &lt;- ggplot(data.frame(colData(sce)), aes(x=sum, y=detected, col=subsets_Mito_percent)) + geom_point() sp + facet_wrap(~source_name) 5.11 Identification of low-quality cells with adaptive thresholds One can use hard threshold for the library size, number of genes detected and mitochondrial content. These will however vary across runs. It may therefore be preferable to rely on outlier detection to identify cells that markerdly differ from most cells. We saw above that the distribution of the QC metrics is close to Normal. Hence, we can detect outlier using the median and the median absolute deviation (MAD) from the median (not the mean and the standard deviation that both are sensitive to outliers). For a given metric, an outlier value is one that lies over some number of MADs away from the median. A cell will be excluded if it is an outlier in the part of the range to avoid, for example low gene counts, or high mitochondrial content. For a normal distribution, a threshold defined with a distance of 3 MADs from the median retains about 99% of values. 5.11.1 Library size For the library size we use the log scale to avoid negative values for lower part of the distribution. qc.lib2 &lt;- isOutlier(sce$sum, log=TRUE, type=&quot;lower&quot;) table(qc.lib2) ## qc.lib2 ## FALSE TRUE ## 37795 333 Threshold values: attr(qc.lib2, &quot;thresholds&quot;) ## lower higher ## 576.4435 Inf 5.11.2 Number of genes For the number of genes detected we also use the log scale to avoid negative values for lower part of the distribution. qc.nexprs2 &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;) table(qc.nexprs2) ## qc.nexprs2 ## FALSE TRUE ## 37723 405 Threshold values: attr(qc.nexprs2, &quot;thresholds&quot;) ## lower higher ## 204.1804 Inf 5.11.3 Mitochondrial content For the mitochondrial content the exclusion zone is in the higher part of the distribution. qc.mito2 &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;) table(qc.mito2) ## qc.mito2 ## FALSE TRUE ## 35755 2373 Threshold values: attr(qc.mito2, &quot;thresholds&quot;) ## lower higher ## -Inf 8.715114 5.11.4 Summary discard2 &lt;- qc.lib2 | qc.nexprs2 | qc.mito2 # Summarize the number of cells removed for each reason. DataFrame(LibSize=sum(qc.lib2), NExprs=sum(qc.nexprs2), MitoProp=sum(qc.mito2), Total=sum(discard2)) ## DataFrame with 1 row and 4 columns ## LibSize NExprs MitoProp Total ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 1 333 405 2373 2900 rm(discard2, qc.lib2, qc.nexprs2, qc.mito2) 5.11.5 All steps at once The steps above may be run at once with quickPerCellQC(): reasons &lt;- quickPerCellQC(colData(sce), percent_subsets=c(&quot;subsets_Mito_percent&quot;)) colSums(as.matrix(reasons)) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) 5.11.6 Assumptions Data quality depends on the tissue analysed, some being difficult to dissociate, e.g. brain, so that one level of QC stringency will not fit all data sets. Filtering based on QC metrics as done here assumes that these QC metrics are not correlated with biology. This may not necessarily be true in highly heterogenous data sets where some cell types represented by good-quality cells may have low RNA content or high mitochondrial content. 5.12 Experimental factors The two data sets analysed here may have been obtained in experiments with different settings, such as cell preparation or sequencing depth. Such differences between these two batches would affect the adaptive thesholds discussed above. We will now perform QC in each batch separately. We will use the quickPerCellQC() ‘batch’ option. batch.reasons &lt;- quickPerCellQC(colData(sce), percent_subsets=c(&quot;subsets_Mito_percent&quot;), batch=sce$setName) colSums(as.matrix(batch.reasons)) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) sce$discard &lt;- batch.reasons$discard Fewer cells are discarded, in particular because of small library size and low gene number. But the differences are deeper as the two sets only partially overlap: table(reasons$discard, batch.reasons$discard) ## ## FALSE TRUE ## FALSE 34880 348 ## TRUE 805 2095 rm(reasons, batch.reasons) Library size: plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + scale_y_log10() + ggtitle(&quot;Total count&quot;) Number of genes detected: plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + facet_wrap(~colour_by) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) Mitochondrial content: plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + ggtitle(&quot;Mito percent&quot;) 5.12.1 Identify poor-quality batches We will now consider the ‘sample’ batch to illustrate how to identify batches with overall low quality or different from other batches. Let’s compare thresholds across sample groups. 5.12.1.1 Number of genes detected # compute discard.nexprs &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;, batch=sce$Sample.Name) nexprs.thresholds &lt;- attr(discard.nexprs, &quot;thresholds&quot;)[&quot;lower&quot;,] nexprs.thresholds %&gt;% round(0) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) Without block: # plots - without blocking discard.nexprs.woBlock &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;) without.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;detected&quot;, colour_by=I(discard.nexprs.woBlock)) without.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) With block: # plots - with blocking with.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;detected&quot;, colour_by=I(discard.nexprs)) with.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) 5.12.1.1.1 Mitochondrial content discard.mito &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;, batch=sce$Sample.Name) mito.thresholds &lt;- attr(discard.mito, &quot;thresholds&quot;)[&quot;higher&quot;,] mito.thresholds %&gt;% round(0) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) Without block: # plots - without blocking discard.mito.woBlock &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;) without.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=I(discard.mito.woBlock)) without.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) With block: # plots - with blocking with.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=I(discard.mito)) with.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) 5.12.1.2 Samples to check Names of samples with a ‘low’ threshold for the number of genes detected: # names names(nexprs.thresholds)[isOutlier(nexprs.thresholds, type=&quot;lower&quot;)] ## character(0) Names of samples with a ‘high’ threshold for mitocondrial content: # names names(mito.thresholds)[isOutlier(mito.thresholds, type=&quot;higher&quot;)] ## [1] &quot;GSM3872434&quot; &quot;GSM3872437&quot; &quot;GSM3872438&quot; &quot;GSM3872443&quot; 5.12.2 QC metrics space A similar approach exists to identify outliers using a set of metrics together. We will the same QC metrics as above. # slow stats &lt;- cbind(log10(sce$sum), log10(sce$detected), sce$subsets_Mito_percent) library(robustbase) outlying &lt;- adjOutlyingness(stats, only.outlyingness = TRUE) multi.outlier &lt;- isOutlier(outlying, type = &quot;higher&quot;) summary(multi.outlier) ## Mode FALSE TRUE ## logical 34254 3874 Compare with previous filtering: table(sce$discard, multi.outlier) ## multi.outlier ## FALSE TRUE ## FALSE 33416 2269 ## TRUE 838 1605 5.12.3 QC PCA One can also perform a principal components analysis (PCA) on cells, based on the column metadata in a SingleCellExperiment object. Here we will only use the library size, the number of genes detected (which is correlated with library size) and the mitochondrial content. sce &lt;- runColDataPCA(sce, variables=list( &quot;sum&quot;, &quot;detected&quot;, &quot;subsets_Mito_percent&quot;), outliers=TRUE) #reducedDimNames(sce) #head(reducedDim(sce)) #head(colData(sce)) #p &lt;- plotReducedDim(sce, dimred=&quot;PCA_coldata&quot;, colour_by = &quot;Sample.Name&quot;) p &lt;- plotReducedDim(sce, dimred=&quot;PCA_coldata&quot;, colour_by = &quot;outlier&quot;) p + facet_wrap(~sce$discard) Compare with previous filtering: table(sce$discard, sce$outlier) ## ## FALSE TRUE ## FALSE 34997 688 ## TRUE 768 1675 table(multi.outlier, sce$outlier) ## ## multi.outlier FALSE TRUE ## FALSE 33631 623 ## TRUE 2134 1740 5.12.4 Other diagnostic plots Mitochondrial content against library size: plotColData(sce, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=sum, y=subsets_Mito_percent, col=discard)) + geom_point(size = 0.05, alpha = 0.7) + geom_density_2d(size = 0.5, colour = &quot;blue&quot;) + guides(colour = guide_legend(override.aes = list(size=1, alpha=1))) + theme(legend.position=&quot;bottom&quot;) #sp ggExtra::ggMarginal(sp) Mind distributions: sp + facet_wrap(~source_name) 5.12.5 Filter low-quality cells out We will now exclude poor-quality cells. scePreQc &lt;- sce sce &lt;- scePreQc[,!scePreQc$discard] sce ## class: SingleCellExperiment ## dim: 33538 35685 ## metadata(20): Samples Samples ... Samples Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(10): ensembl_gene_id external_gene_name ... mean detected ## colnames: NULL ## colData names(14): Barcode Run ... discard outlier ## reducedDimNames(1): PCA_coldata ## altExpNames(0): We also write the R object to file to use later if need be. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postQc.Rds&quot;, projDir, outDirBit) saveRDS(sce, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postQc.Rds&quot;, projDir, outDirBit) sce &lt;- readRDS(tmpFn) 5.13 Novelty The number of genes per UMI for each cell informs on the level of sequencing saturation achieved ( hbctraining). For a given cell, as sequencing depth increases each extra UMI is less likely to correspnf to a gene not already detected in that cell. Cells with small library size tend to have higher overall ‘novelty’ i.e. they have not reached saturation for any given gene. Outlier cell may have a library with low complexity. This may suggest the some cell types, e.g. red blood cells. The expected novelty is about 0.8. Here we see that some PBMMCs have low novelty, ie overall fewer genes were detected for an equivalent number of UMIs in these cells than in others. p &lt;- colData(sce) %&gt;% data.frame() %&gt;% ggplot(aes(x=sum, y=detected, color=subsets_Mito_percent)) + geom_point() + stat_smooth(method=lm) + scale_x_log10() + scale_y_log10() + geom_vline(xintercept = 800) + facet_wrap(~source_name) p # write plot to file tmpFn &lt;- sprintf(&quot;%s/%s/%s/novelty_scat.png&quot;, projDir, outDirBit, qcPlotDirBit) ggsave(plot=p, file=tmpFn, type = &quot;cairo-png&quot;) # Novelty # the number of genes per UMI for each cell, # https://hbctraining.github.io/In-depth-NGS-Data-Analysis-Course/sessionIV/lessons/SC_quality_control_analysis.html # Add number of UMIs per gene for each cell to metadata colData(sce)$log10GenesPerUMI &lt;- log10(colData(sce)$detected) / log10(colData(sce)$sum) # Visualize the overall novelty of the gene expression by visualizing the genes detected per UMI p &lt;- colData(sce) %&gt;% data.frame() %&gt;% ggplot(aes(x=log10GenesPerUMI, color = source_name, fill = source_name)) + geom_density() p tmpFn &lt;- sprintf(&quot;%s/%s/%s/novelty_dens.png&quot;, projDir, outDirBit, qcPlotDirBit) ggsave(plot=p, file=tmpFn, type=&#39;cairo-png&#39;) rm(sce) 5.14 QC based on sparsity The approach above identified poor-quality using thresholds on the number of genes detected and mitochondrial content. We will here specifically look at the sparsity of the data, both at the gene and cell levels. 5.14.1 Remove genes that are not expressed at all Genes that are not expressed at all are not informative, so we remove them: not.expressed &lt;- rowSums(counts(scePreQc)) == 0 # store the cell-wise information cols.meta &lt;- colData(scePreQc) rows.meta &lt;- rowData(scePreQc) nz.counts &lt;- counts(scePreQc)[!not.expressed, ] sce.nz &lt;- SingleCellExperiment(list(counts=nz.counts)) # reset the column data on the new object colData(sce.nz) &lt;- cols.meta rowData(sce.nz) &lt;- rows.meta[!not.expressed, ] sce.nz ## class: SingleCellExperiment ## dim: 25116 38128 ## metadata(0): ## assays(1): counts ## rownames(25116): ENSG00000238009 ENSG00000239945 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(10): ensembl_gene_id external_gene_name ... mean detected ## colnames: NULL ## colData names(14): Barcode Run ... discard outlier ## reducedDimNames(0): ## altExpNames(0): # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz.Rds&quot;, projDir, outDirBit) saveRDS(sce.nz, tmpFn) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz.Rds&quot;, projDir, outDirBit) sce.nz &lt;- readRDS(tmpFn) 5.14.2 Sparsity plots We will compute: the cell sparsity: for each cell, the proportion of genes that are not detected the gene sparsity: for each gene, the proportion of cells in which it is not detected # compute - SLOW cell_sparsity &lt;- apply(counts(sce.nz) == 0, 2, sum)/nrow(counts(sce.nz)) gene_sparsity &lt;- apply(counts(sce.nz) == 0, 1, sum)/ncol(counts(sce.nz)) colData(sce.nz)$cell_sparsity &lt;- cell_sparsity rowData(sce.nz)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_sparsityCellGene.Rds&quot;, projDir, outDirBit) saveRDS(list(&quot;colData&quot; = colData(sce.nz), &quot;rowData&quot; = rowData(sce.nz)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_sparsityCellGene.Rds&quot;, projDir, outDirBit) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity We now plot the distribution of these two metrics. The cell sparsity plot shows that cells have between 85% and 99% 0’s, which is typical. hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) The gene sparsity plot shows that a large number of genes are almost never detected, which is also regularly observed. hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) 5.14.3 Filters We also remove cells with sparsity higher than 0.99, and/or mitochondrial content higher than 20%. Genes detected in a few cells only are unlikely to be informative and would hinder normalisation. We will remove genes that are expressed in fewer than 20 cells. # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.nz$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells Number of genes removed: table(sparse.genes) ## sparse.genes ## FALSE TRUE ## 17854 7262 Number of cells removed: table(sparse.cells, mito.cells) ## mito.cells ## sparse.cells FALSE TRUE ## FALSE 36871 671 ## TRUE 525 61 # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.nz) rows.meta &lt;- rowData(sce.nz) counts.nz &lt;- counts(sce.nz)[!sparse.genes, !(sparse.cells | mito.cells)] sce.nz &lt;- SingleCellExperiment(assays=list(counts=counts.nz)) colData(sce.nz) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.nz) &lt;- rows.meta[!sparse.genes, ] sce.nz ## class: SingleCellExperiment ## dim: 17854 36871 ## metadata(0): ## assays(1): counts ## rownames(17854): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(15): Barcode Run ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_postQc.Rds&quot;, projDir, outDirBit) saveRDS(sce.nz, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_postQc.Rds&quot;, projDir, outDirBit) sce.nz &lt;- readRDS(tmpFn) Compare with filter above (mind that the comparison is not fair because we used a less stringent, hard filtering on mitochondrial content): table(scePreQc$discard, (sparse.cells | mito.cells)) ## ## FALSE TRUE ## FALSE 35351 334 ## TRUE 1520 923 rm(scePreQc) 5.14.4 Separate Caron and Hca batches We will now check sparsity for each batch separately. sce.nz.caron &lt;- sce.nz[,sce.nz$setName==&quot;Caron&quot;] sce.nz.hca &lt;- sce.nz[,sce.nz$setName==&quot;Hca&quot;] 5.14.5 Caron only setName &lt;- &quot;caron&quot; sce.x &lt;- sce.nz.caron rm(sce.nz.caron) # compute - SLOW cell_sparsity &lt;- apply(counts(sce.x) == 0, 2, sum)/nrow(counts(sce.x)) gene_sparsity &lt;- apply(counts(sce.x) == 0, 1, sum)/ncol(counts(sce.x)) colData(sce.x)$cell_sparsity &lt;- cell_sparsity rowData(sce.x)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene.Rds&quot;, projDir, outDirBit, setName) saveRDS(list(&quot;colData&quot; = colData(sce.x), &quot;rowData&quot; = rowData(sce.x)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene.Rds&quot;, projDir, outDirBit, setName) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity # plot tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sparsity.png&quot;, projDir, outDirBit, qcPlotDirBit, setName) CairoPNG(tmpFn) par(mfrow=c(1, 2)) hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) abline(v=40, lty=2, col=&#39;purple&#39;) dev.off() ## pdf ## 2 tmpFn &lt;- sprintf(&quot;../%s/%s_sparsity.png&quot;, qcPlotDirBit, setName) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.x$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells We write the R object to ‘caron_sce_nz_postQc.Rds’. # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.x) rows.meta &lt;- rowData(sce.x) counts.x &lt;- counts(sce.x)[!sparse.genes, !(sparse.cells | mito.cells)] sce.x &lt;- SingleCellExperiment(assays=list(counts=counts.x)) colData(sce.x) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.x) &lt;- rows.meta[!sparse.genes, ] sce.x ## class: SingleCellExperiment ## dim: 16629 20908 ## metadata(0): ## assays(1): counts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(15): Barcode Run ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc.Rds&quot;, projDir, outDirBit, setName) saveRDS(sce.x, tmpFn) # update sce.nz.caron sce.nz.caron &lt;- sce.x # TODO not used rm(sce.x) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc.Rds&quot;, dirRel, outDirBit, setName) sce.nz.caron &lt;- readRDS(tmpFn) 5.14.6 Hca only setName &lt;- &quot;hca&quot; sce.x &lt;- sce.nz.hca rm(sce.nz.hca) # compute - SLOW cell_sparsity &lt;- apply(counts(sce.x) == 0, 2, sum)/nrow(counts(sce.x)) gene_sparsity &lt;- apply(counts(sce.x) == 0, 1, sum)/ncol(counts(sce.x)) colData(sce.x)$cell_sparsity &lt;- cell_sparsity rowData(sce.x)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene.Rds&quot;, projDir, outDirBit, setName) saveRDS(list(&quot;colData&quot; = colData(sce.x), &quot;rowData&quot; = rowData(sce.x)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene.Rds&quot;, projDir, outDirBit, setName) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity # plot tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sparsity.png&quot;, projDir, outDirBit, qcPlotDirBit, setName) CairoPNG(tmpFn) par(mfrow=c(1, 2)) hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) abline(v=40, lty=2, col=&#39;purple&#39;) dev.off() ## pdf ## 2 tmpFn &lt;- sprintf(&quot;../%s/%s_sparsity.png&quot;, qcPlotDirBit, setName) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.x$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells We write the R object to ‘hca_sce_nz_postQc.Rds’. # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.x) rows.meta &lt;- rowData(sce.x) counts.x &lt;- counts(sce.x)[!sparse.genes, !(sparse.cells | mito.cells)] sce.x &lt;- SingleCellExperiment(assays=list(counts=counts.x)) colData(sce.x) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.x) &lt;- rows.meta[!sparse.genes, ] sce.x ## class: SingleCellExperiment ## dim: 14994 15963 ## metadata(0): ## assays(1): counts ## rownames(14994): ENSG00000237491 ENSG00000225880 ... ENSG00000276345 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(15): Barcode Run ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc.Rds&quot;, projDir, outDirBit, setName) saveRDS(sce.x, tmpFn) # update sce.nz.hca sce.nz.hca &lt;- sce.x # TODO not used rm(sce.x) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc.Rds&quot;, projDir, outDirBit, setName) sce.nz.hca &lt;- readRDS(tmpFn) # TODO not used 5.15 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] robustbase_0.93-7 mixtools_1.2.0 ## [3] Cairo_1.5-12.2 dplyr_1.0.5 ## [5] DT_0.18 irlba_2.3.3 ## [7] biomaRt_2.46.3 Matrix_1.3-2 ## [9] igraph_1.2.6 DropletUtils_1.10.3 ## [11] scater_1.18.6 ggplot2_3.3.3 ## [13] scran_1.18.7 SingleCellExperiment_1.12.0 ## [15] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [17] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [19] IRanges_2.24.1 S4Vectors_0.28.1 ## [21] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [23] matrixStats_0.58.0 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] BiocFileCache_1.14.0 splines_4.0.3 ## [3] BiocParallel_1.24.1 crosstalk_1.1.1 ## [5] digest_0.6.27 htmltools_0.5.1.1 ## [7] viridis_0.6.0 fansi_0.4.2 ## [9] magrittr_2.0.1 memoise_2.0.0 ## [11] limma_3.46.0 R.utils_2.10.1 ## [13] askpass_1.1 prettyunits_1.1.1 ## [15] colorspace_2.0-0 blob_1.2.1 ## [17] rappdirs_0.3.3 xfun_0.22 ## [19] crayon_1.4.1 RCurl_1.98-1.3 ## [21] jsonlite_1.7.2 survival_3.2-11 ## [23] glue_1.4.2 gtable_0.3.0 ## [25] zlibbioc_1.36.0 XVector_0.30.0 ## [27] DelayedArray_0.16.3 BiocSingular_1.6.0 ## [29] kernlab_0.9-29 Rhdf5lib_1.12.1 ## [31] DEoptimR_1.0-8 HDF5Array_1.18.1 ## [33] scales_1.1.1 DBI_1.1.1 ## [35] edgeR_3.32.1 miniUI_0.1.1.1 ## [37] Rcpp_1.0.6 isoband_0.2.4 ## [39] viridisLite_0.4.0 xtable_1.8-4 ## [41] progress_1.2.2 dqrng_0.3.0 ## [43] bit_4.0.4 rsvd_1.0.5 ## [45] htmlwidgets_1.5.3 httr_1.4.2 ## [47] ellipsis_0.3.2 pkgconfig_2.0.3 ## [49] XML_3.99-0.6 R.methodsS3_1.8.1 ## [51] farver_2.1.0 scuttle_1.0.4 ## [53] sass_0.3.1 dbplyr_2.1.1 ## [55] locfit_1.5-9.4 utf8_1.2.1 ## [57] labeling_0.4.2 tidyselect_1.1.1 ## [59] rlang_0.4.10 later_1.2.0 ## [61] AnnotationDbi_1.52.0 munsell_0.5.0 ## [63] tools_4.0.3 cachem_1.0.4 ## [65] generics_0.1.0 RSQLite_2.2.6 ## [67] evaluate_0.14 stringr_1.4.0 ## [69] fastmap_1.1.0 yaml_2.2.1 ## [71] bit64_4.0.5 purrr_0.3.4 ## [73] nlme_3.1-152 sparseMatrixStats_1.2.1 ## [75] mime_0.10 R.oo_1.24.0 ## [77] ggExtra_0.9 xml2_1.3.2 ## [79] compiler_4.0.3 beeswarm_0.3.1 ## [81] curl_4.3.1 tibble_3.1.1 ## [83] statmod_1.4.35 bslib_0.2.4 ## [85] stringi_1.5.3 highr_0.9 ## [87] lattice_0.20-44 bluster_1.0.0 ## [89] vctrs_0.3.7 pillar_1.6.0 ## [91] lifecycle_1.0.0 rhdf5filters_1.2.0 ## [93] jquerylib_0.1.3 BiocNeighbors_1.8.2 ## [95] cowplot_1.1.1 bitops_1.0-7 ## [97] httpuv_1.5.5 R6_2.5.0 ## [99] bookdown_0.22 promises_1.2.0.1 ## [101] gridExtra_2.3 vipor_0.4.5 ## [103] codetools_0.2-18 MASS_7.3-54 ## [105] assertthat_0.2.1 rhdf5_2.34.0 ## [107] openssl_1.4.4 withr_2.4.2 ## [109] GenomeInfoDbData_1.2.4 mgcv_1.8-35 ## [111] hms_1.0.0 grid_4.0.3 ## [113] beachmat_2.6.4 rmarkdown_2.7 ## [115] DelayedMatrixStats_1.12.3 segmented_1.3-3 ## [117] shiny_1.6.0 ggbeeswarm_0.6.0 "],["NormalisationAllCellsTop.html", "Chapter 6 Normalisation - with 2-5k cells per sample 6.1 Caron 6.2 Hca 6.3 SCTransform 6.4 Session information", " Chapter 6 Normalisation - with 2-5k cells per sample Why normalise? Systematic differences in sequencing coverage between libraries caused by low input material, differences in cDNA capture and PCR amplification. Normalisation removes such differences so that differences between cells are not technical but biological, allowing meaningful comparison of expression profiles between cells. TODO difference between normalisation and batch correction. norm: technical differences only. batch correction: technical and biological. different assumptions and methods. In scaling normalization, the “normalization factor” is an estimate of the library size relative to the other cells. steps: compute a cell-specific ‘scaling’ or ‘size’ factor that represents the relative bias in that cell and divide all counts for the cell by that factor to remove that bias. Assumption: any cell specific bias will affect genes the same way. Scaling methods typically generate normalised counts-per-million (CPM) or transcripts-per-million (TPM_ values. projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit compuBool &lt;- TRUE # whether to run computation again (dev) #qcPlotDirBit &lt;- &quot;Plots/Norm&quot; library(scuttle) library(scran) library(ggplot2) library(dplyr) library(Cairo) 6.1 Caron Load object. setName &lt;- &quot;caron&quot; setSuf = &quot;_allCells&quot; # suffix to add to file name to say all cells are used, with no downsampling # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce &lt;- readRDS(tmpFn) 6.1.1 Library size normalization For each cell, the library size factor is proportional to the library size such that the average size factor across cell is one. Advantage: normalised counts are on the same scale as the initial counts. Compute size factors: lib.sf &lt;- librarySizeFactors(sce) summary(lib.sf) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1205 0.4432 0.7308 1.0000 1.2859 14.4562 Size factor distribution: wide range, typical of scRNA-seq data. hist(log10(lib.sf), xlab=&quot;Log10[Size factor]&quot;, col=&#39;grey80&#39;) Assumption: absence of compositional bias; differential expression two cells is balanced: upregulation in some genes is accompanied by downregulation of other genes. Not observed. Inaccurate normalisation due to unaccounted-for composition bias affects the size of the log fold change measured between clusters, but less so the clustering itself. It is thus sufficient to identify clusters and top marker genes. 6.1.2 Deconvolution Composition bias occurs when differential expression beteween two samples or here cells is not balanced. For a fixed library size, identical in both cells, upregulation of one gene in the a cell will means fewer UMIs can be assigned to other genes, which would then appear down regulated. Even if library sizes are allowed to differ in size, with that for the cell with upregulation being higher, scaling normalisation will reduce noralised counts. Non-upregulated would therefore also appear downregulated. For bulk RNA-seq, composition bias is removed by assuming that most genes are not differentially expressed between samples, so that differences in non-DE genes would amount to the bias, and used to compute size factors. Given the sparsity of scRNA-seq data, the methods are not appropriate. The method below increases read counts by pooling cells into groups, computing size factors within each of these groups and scaling them so they are comparable across clusters. This process is repeated many times, changing pools each time to collect several size factors for each cell, frome which is derived a single value for that cell. Cluster cells, normalise : set.seed(100) # clusters with PCA from irlba with approximation clust &lt;- quickCluster(sce) # slow with all cells. # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(clust, tmpFn) # read from file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds&quot;, projDir, outDirBit, setName, setSuf) clust &lt;- readRDS(tmpFn) table(clust) ## clust ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## 1557 5519 3149 602 2106 374 2389 1788 1378 4815 923 1846 5575 1989 108 1657 ## 17 18 19 20 21 22 23 24 25 ## 701 1882 5053 1420 278 714 802 1049 156 6.1.3 Compute size factors deconv.sf &lt;- calculateSumFactors(sce, cluster=clust) # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(deconv.sf, tmpFn) # read from file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds&quot;, projDir, outDirBit, setName, setSuf) deconv.sf &lt;- readRDS(tmpFn) summary(deconv.sf) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.03169 0.41551 0.73178 1.00000 1.30221 15.27223 Plot size factors: plot(lib.sf, deconv.sf, xlab=&quot;Library size factor&quot;, ylab=&quot;Deconvolution size factor&quot;, log=&#39;xy&#39;, pch=16, col=as.integer(factor(sce$source_name))) abline(a=0, b=1, col=&quot;red&quot;) deconvDf &lt;- data.frame(lib.sf, deconv.sf, &quot;source_name&quot; = sce$source_name, &quot;sum&quot; = sce$sum, &quot;mito_content&quot; = sce$subsets_Mito_percent, &quot;cell_sparsity&quot; = sce$cell_sparsity) # colour by sample type sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=source_name)) + geom_point() sp + facet_wrap(~source_name) # colour by library size sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=sum)) + geom_point() sp # colour by mito. content sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=mito_content)) + geom_point() sp # colour by cell sparsity sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=cell_sparsity)) + geom_point() sp #ggMarginal(sp) 6.1.3.1 Apply size factors For each cell, raw counts for genes are divided by the size factor for that cell and log-transformed so downstream analyses focus on genes with strong relative differences. We use scater::logNormCounts(). sce &lt;- logNormCounts(sce) assayNames(sce) ## [1] &quot;counts&quot; &quot;logcounts&quot; 6.1.3.2 Save object sce_caron &lt;- sce # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce_caron, tmpFn) 6.2 Hca Load object. # the 5kCellPerSpl subset setName &lt;- &quot;hca&quot; setSuf &lt;- &quot;_5kCellPerSpl&quot; # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce &lt;- readRDS(tmpFn) 6.2.1 Library size normalization For each cell, the library size factor is proportioanl to the library size such that the average size factor across cell is one. Advantage: normalised counts are on the same scale as the initial counts. Compute size factors: lib.sf &lt;- librarySizeFactors(sce) summary(lib.sf) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.3252 0.4931 0.6028 1.0000 0.8227 17.8270 Size factor distribution: wide range, typical of scRNA-seq data. hist(log10(lib.sf), xlab=&quot;Log10[Size factor]&quot;, col=&#39;grey80&#39;) Assumption: absence of compositional bias; differential expression two cells is balanced: upregulation in some genes is accompanied by downregulation of other genes. Not observed. Inaccurate normalisation due to unaccounted-for composition bias affects the size of the log fold change measured between clusters, but less so the clusterisation itself. It is thus sufficient to identify clustrs and top arker genes. 6.2.2 Deconvolution Composition bias occurs when differential expression beteween two samples or here cells is not balanced. For a fixed library size, identical in both cells, upregulation of one gene in the a cell will means fewer UMIs can be assigned to other genes, which would then appear down regulated. Even if library sizes are allowed to differ in size, with that for the cell with upregulation being higher, scaling normalisation will reduce noralised counts. Non-upregulated would therefore also appear downregulated. For bulk RNA-seq, composition bias is removed by assuming that most genes are not differentially expressed between samples, so that differences in non-DE genes would amount to the bias, and used to compute size factors. Given the sparsity of scRNA-seq data, the methods are not appropriate. The method below increases read counts by pooling cells into groups, computing size factors within each of these groups and scaling them so they are comparable across clusters. This process is repeated many times, changing pools each time to collect several size factors for each cell, frome which is derived a single value for that cell. Cluster cells then normalise : #library(scran) set.seed(100) # clusters with PCA from irlba with approximation clust &lt;- quickCluster(sce) # slow with all cells. # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(clust, tmpFn) # read from file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds&quot;, projDir, outDirBit, setName, setSuf) clust &lt;- readRDS(tmpFn) table(clust) ## clust ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## 1130 1072 346 2163 4848 7186 690 637 497 565 3975 826 3567 6756 918 157 ## 17 18 19 20 21 22 23 ## 535 2030 793 509 241 311 248 6.2.3 Compute size factors deconv.sf &lt;- calculateSumFactors(sce, cluster=clust) # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(deconv.sf, tmpFn) # read from file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds&quot;, projDir, outDirBit, setName, setSuf) deconv.sf &lt;- readRDS(tmpFn) summary(deconv.sf) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.07409 0.40967 0.50765 1.00000 0.75926 25.05274 Plot size factors: plot(lib.sf, deconv.sf, xlab=&quot;Library size factor&quot;, ylab=&quot;Deconvolution size factor&quot;, log=&#39;xy&#39;, pch=16, col=as.integer(factor(sce$source_name))) abline(a=0, b=1, col=&quot;red&quot;) deconvDf &lt;- data.frame(lib.sf, deconv.sf, &quot;source_name&quot; = sce$source_name, &quot;sum&quot; = sce$sum, &quot;mito_content&quot; = sce$subsets_Mito_percent, &quot;cell_sparsity&quot; = sce$cell_sparsity) # colour by sample type sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=source_name)) + geom_point() sp + facet_wrap(~source_name) # colour by library size sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=sum)) + geom_point() sp # colour by mito. content sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=mito_content)) + geom_point() sp # colour by cell sparsity sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=cell_sparsity)) + geom_point() sp #ggMarginal(sp) 6.2.3.1 Apply size factors For each cell, raw counts for genes are divided by the size factor for that cell and log-transformed so downstream analyses focus on genes with strong relative differences. We use scater::logNormCounts(). sce &lt;- logNormCounts(sce) assayNames(sce) ## [1] &quot;counts&quot; &quot;logcounts&quot; 6.2.3.2 Save object sce_hca &lt;- sce # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce_hca, tmpFn) 6.3 SCTransform With scaling normalisation a correlation remains between the mean and variation of expression (heteroskedasticity). This affects downstream dimensionality reduction as the few main new dimensions are usually correlated with library size. SCTransform addresses the issue by regressing library size out of raw counts and providing residuals to use as normalized and variance-stabilized expression values in downstream analysis. 6.3.1 Caron setName &lt;- &quot;caron&quot; setSuf = &quot;_allCells&quot; # suffix to add to file name to say which cells are used, eg downsampling sce &lt;- sce_caron counts &lt;- counts(sce) class(counts) ## [1] &quot;dgCMatrix&quot; ## attr(,&quot;package&quot;) ## [1] &quot;Matrix&quot; colnames(counts) &lt;- colData(sce)$Barcode Inspect data We will now calculate some properties and visually inspect the data. Our main interest is in the general trends not in individual outliers. Neither genes nor cells that stand out are important at this step, but we focus on the global trends. Derive gene and cell attributes from the UMI matrix. gene_attr &lt;- data.frame(mean = rowMeans(counts), detection_rate = rowMeans(counts &gt; 0), var = apply(counts, 1, var)) gene_attr$log_mean &lt;- log10(gene_attr$mean) gene_attr$log_var &lt;- log10(gene_attr$var) rownames(gene_attr) &lt;- rownames(counts) cell_attr &lt;- data.frame(n_umi = colSums(counts), n_gene = colSums(counts &gt; 0)) rownames(cell_attr) &lt;- colnames(counts) ggplot(gene_attr, aes(log_mean, log_var)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) + geom_abline(intercept = 0, slope = 1, color=&#39;red&#39;) Mean-variance relationship For the genes, we can see that up to a mean UMI count of ca. 0.1 the variance follows the line through the origin with slop one, i.e. variance and mean are roughly equal as expected under a Poisson model. However, genes with a higher average UMI count show overdispersion compared to Poisson. # add the expected detection rate under Poisson model x = seq(from = -3, to = 2, length.out = 1000) poisson_model &lt;- data.frame(log_mean = x, detection_rate = 1 - dpois(0, lambda = 10^x)) ggplot(gene_attr, aes(log_mean, detection_rate)) + geom_point(alpha=0.3, shape=16) + geom_line(data=poisson_model, color=&#39;red&#39;) + theme_gray(base_size = 8) Mean-detection-rate relationship In line with the previous plot, we see a lower than expected detection rate in the medium expression range. However, for the highly expressed genes, the rate is at or very close to 1.0 suggesting that there is no zero-inflation in the counts for those genes and that zero-inflation is a result of overdispersion, rather than an independent systematic bias. ggplot(cell_attr, aes(n_umi, n_gene)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) General idea of transformation Based on the observations above, which are not unique to this particular data set, we propose to model the expression of each gene as a negative binomial random variable with a mean that depends on other variables. Here the other variables can be used to model the differences in sequencing depth between cells and are used as independent variables in a regression model. In order to avoid overfitting, we will first fit model parameters per gene, and then use the relationship between gene mean and parameter values to fit parameters, thereby combining information across genes. Given the fitted model parameters, we transform each observed UMI count into a Pearson residual which can be interpreted as the number of standard deviations an observed count was away from the expected mean. If the model accurately describes the mean-variance relationship and the dependency of mean and latent factors, then the result should have mean zero and a stable variance across the range of expression. Estimate model parameters and transform data The vst function estimates model parameters and performs the variance stabilizing transformation. Here we use the log10 of the total UMI counts of a cell as variable for sequencing depth for each cell. After data transformation we plot the model parameters as a function of gene mean (geometric mean). # We use the Future API for parallel processing; set parameters here future::plan(strategy = &#39;multicore&#39;, workers = 4) options(future.globals.maxSize = 10 * 1024 ^ 3) set.seed(44) vst_out &lt;- sctransform::vst(counts, latent_var = c(&#39;log_umi&#39;), return_gene_attr = TRUE, return_cell_attr = TRUE, show_progress = FALSE) sctransform::plot_model_pars(vst_out) Inspect model We will look at several genes in more detail. rowData(sce) %&gt;% as.data.frame %&gt;% filter(Symbol %in% c(&#39;MALAT1&#39;, &#39;RPL10&#39;, &#39;FTL&#39;)) ## ensembl_gene_id external_gene_name chromosome_name ## ENSG00000147403 ENSG00000147403 RPL10 X ## ENSG00000251562 ENSG00000251562 MALAT1 11 ## ENSG00000087086 ENSG00000087086 FTL 19 ## start_position end_position strand Symbol Type ## ENSG00000147403 154389955 154409168 1 RPL10 Gene Expression ## ENSG00000251562 65497688 65506516 1 MALAT1 Gene Expression ## ENSG00000087086 48965309 48966879 1 FTL Gene Expression ## mean detected gene_sparsity ## ENSG00000147403 48.85548 99.28030 0.011540874 ## ENSG00000251562 193.05529 99.09786 0.005352289 ## ENSG00000087086 15.48621 96.42481 0.085532093 sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000251562&#39;, &#39;ENSG00000147403&#39;, &#39;ENSG00000087086&#39;), plot_residual = TRUE) sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000087086&#39;), plot_residual = TRUE, show_nr = TRUE, arrange_vertical = FALSE) # Error in seq_len(n) : argument must be coercible to non-negative integer rowData(sce) %&gt;% as.data.frame %&gt;% filter(Symbol %in% c(&#39;GNLY&#39;, &#39;S100A9&#39;)) #sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000115523&#39;, &#39;ENSG00000163220&#39;), plot_residual = TRUE, show_nr = TRUE) sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000115523&#39;), plot_residual = TRUE, show_nr = TRUE) # ok # sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000087086&#39;), plot_residual = TRUE, show_nr = TRUE) ggplot(vst_out$gene_attr, aes(residual_mean)) + geom_histogram(binwidth=0.01) ggplot(vst_out$gene_attr, aes(residual_variance)) + geom_histogram(binwidth=0.1) + geom_vline(xintercept=1, color=&#39;red&#39;) + xlim(0, 10) ggplot(vst_out$gene_attr, aes(x=residual_mean, y=residual_variance)) + geom_point(alpha=0.3, shape=16) + xlim(0, 2.5) + ylim(0, 10) + geom_density_2d() ggplot(vst_out$gene_attr, aes(log10(gmean), residual_variance)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) dd &lt;- vst_out$gene_attr %&gt;% arrange(-residual_variance) %&gt;% slice_head(n = 22) %&gt;% mutate(across(where(is.numeric), round, 2)) dd %&gt;% tibble::rownames_to_column(&quot;ensembl_gene_id&quot;) %&gt;% left_join(as.data.frame(rowData(sce))[,c(&quot;ensembl_gene_id&quot;, &quot;Symbol&quot;)], by = &quot;ensembl_gene_id&quot;) %&gt;% DT::datatable(rownames = FALSE) # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_vst_out%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(vst_out, tmpFn) 6.3.2 Hca Load object. setName &lt;- &quot;hca&quot; setSuf &lt;- &quot;_5kCellPerSpl&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce_hca &lt;- readRDS(tmpFn) sce &lt;- sce_hca counts &lt;- counts(sce) class(counts) ## [1] &quot;dgCMatrix&quot; ## attr(,&quot;package&quot;) ## [1] &quot;Matrix&quot; colnames(counts) &lt;- colData(sce)$Barcode Inspect data gene_attr &lt;- data.frame(mean = rowMeans(counts), detection_rate = rowMeans(counts &gt; 0), var = apply(counts, 1, var)) gene_attr$log_mean &lt;- log10(gene_attr$mean) gene_attr$log_var &lt;- log10(gene_attr$var) rownames(gene_attr) &lt;- rownames(counts) cell_attr &lt;- data.frame(n_umi = colSums(counts), n_gene = colSums(counts &gt; 0)) rownames(cell_attr) &lt;- colnames(counts) Mean-variance relationship # add the expected detection rate under Poisson model x = seq(from = -3, to = 2, length.out = 1000) poisson_model &lt;- data.frame(log_mean = x, detection_rate = 1 - dpois(0, lambda = 10^x)) ggplot(gene_attr, aes(log_mean, detection_rate)) + geom_point(alpha=0.3, shape=16) + geom_line(data=poisson_model, color=&#39;red&#39;) + theme_gray(base_size = 8) Mean-detection-rate relationship ggplot(cell_attr, aes(n_umi, n_gene)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) # We use the Future API for parallel processing; set parameters here future::plan(strategy = &#39;multicore&#39;, workers = 4) options(future.globals.maxSize = 10 * 1024 ^ 3) set.seed(44) vst_out &lt;- sctransform::vst(counts, latent_var = c(&#39;log_umi&#39;), return_gene_attr = TRUE, return_cell_attr = TRUE, show_progress = FALSE) sctransform::plot_model_pars(vst_out) Inspect model We will look at several genes in more detail. rowData(sce) %&gt;% as.data.frame %&gt;% filter(Symbol %in% c(&#39;MALAT1&#39;, &#39;RPL10&#39;, &#39;FTL&#39;)) ## ensembl_gene_id external_gene_name chromosome_name ## ENSG00000147403 ENSG00000147403 RPL10 X ## ENSG00000251562 ENSG00000251562 MALAT1 11 ## ENSG00000087086 ENSG00000087086 FTL 19 ## start_position end_position strand Symbol Type ## ENSG00000147403 154389955 154409168 1 RPL10 Gene Expression ## ENSG00000251562 65497688 65506516 1 MALAT1 Gene Expression ## ENSG00000087086 48965309 48966879 1 FTL Gene Expression ## mean detected gene_sparsity ## ENSG00000147403 48.85548 99.28030 0.0007912115 ## ENSG00000251562 193.05529 99.09786 0.0063449073 ## ENSG00000087086 15.48621 96.42481 0.0170262621 sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000251562&#39;, &#39;ENSG00000147403&#39;, &#39;ENSG00000087086&#39;), plot_residual = TRUE) sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000087086&#39;), plot_residual = TRUE, show_nr = TRUE, arrange_vertical = FALSE) ggplot(vst_out$gene_attr, aes(residual_mean)) + geom_histogram(binwidth=0.01) ggplot(vst_out$gene_attr, aes(residual_variance)) + geom_histogram(binwidth=0.1) + geom_vline(xintercept=1, color=&#39;red&#39;) + xlim(0, 10) ggplot(vst_out$gene_attr, aes(x=residual_mean, y=residual_variance)) + geom_point(alpha=0.3, shape=16) + xlim(0, 2.5) + ylim(0, 10) + geom_density_2d() ggplot(vst_out$gene_attr, aes(log10(gmean), residual_variance)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) #dd &lt;- head(round(vst_out$gene_attr[order(-vst_out$gene_attr$residual_variance), ], 2), 22) dd &lt;- vst_out$gene_attr %&gt;% arrange(-residual_variance) %&gt;% slice_head(n = 22) %&gt;% mutate(across(where(is.numeric), round, 2)) dd %&gt;% tibble::rownames_to_column(&quot;ensembl_gene_id&quot;) %&gt;% left_join(as.data.frame(rowData(sce))[,c(&quot;ensembl_gene_id&quot;, &quot;Symbol&quot;)], &quot;ensembl_gene_id&quot;) %&gt;% DT::datatable(rownames = FALSE) # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_vst_out%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(vst_out, tmpFn) 6.4 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] Cairo_1.5-12.2 dplyr_1.0.5 ## [3] ggplot2_3.3.3 scran_1.18.7 ## [5] scuttle_1.0.4 SingleCellExperiment_1.12.0 ## [7] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [9] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [11] IRanges_2.24.1 S4Vectors_0.28.1 ## [13] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [15] matrixStats_0.58.0 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 sctransform_0.3.2.9005 ## [3] tools_4.0.3 bslib_0.2.4 ## [5] DT_0.18 utf8_1.2.1 ## [7] R6_2.5.0 irlba_2.3.3 ## [9] DBI_1.1.1 colorspace_2.0-0 ## [11] withr_2.4.2 gridExtra_2.3 ## [13] tidyselect_1.1.1 compiler_4.0.3 ## [15] BiocNeighbors_1.8.2 isoband_0.2.4 ## [17] DelayedArray_0.16.3 labeling_0.4.2 ## [19] bookdown_0.22 sass_0.3.1 ## [21] scales_1.1.1 stringr_1.4.0 ## [23] digest_0.6.27 rmarkdown_2.7 ## [25] XVector_0.30.0 pkgconfig_2.0.3 ## [27] htmltools_0.5.1.1 parallelly_1.24.0 ## [29] sparseMatrixStats_1.2.1 fastmap_1.1.0 ## [31] limma_3.46.0 highr_0.9 ## [33] htmlwidgets_1.5.3 rlang_0.4.10 ## [35] shiny_1.6.0 DelayedMatrixStats_1.12.3 ## [37] jquerylib_0.1.3 generics_0.1.0 ## [39] farver_2.1.0 jsonlite_1.7.2 ## [41] crosstalk_1.1.1 BiocParallel_1.24.1 ## [43] RCurl_1.98-1.3 magrittr_2.0.1 ## [45] BiocSingular_1.6.0 GenomeInfoDbData_1.2.4 ## [47] Matrix_1.3-2 Rcpp_1.0.6 ## [49] munsell_0.5.0 fansi_0.4.2 ## [51] lifecycle_1.0.0 stringi_1.5.3 ## [53] yaml_2.2.1 edgeR_3.32.1 ## [55] MASS_7.3-54 zlibbioc_1.36.0 ## [57] plyr_1.8.6 grid_4.0.3 ## [59] promises_1.2.0.1 listenv_0.8.0 ## [61] dqrng_0.3.0 crayon_1.4.1 ## [63] lattice_0.20-44 beachmat_2.6.4 ## [65] locfit_1.5-9.4 pillar_1.6.0 ## [67] igraph_1.2.6 future.apply_1.7.0 ## [69] reshape2_1.4.4 codetools_0.2-18 ## [71] glue_1.4.2 evaluate_0.14 ## [73] httpuv_1.5.5 vctrs_0.3.7 ## [75] gtable_0.3.0 purrr_0.3.4 ## [77] future_1.21.0 assertthat_0.2.1 ## [79] xfun_0.22 mime_0.10 ## [81] rsvd_1.0.5 xtable_1.8-4 ## [83] later_1.2.0 tibble_3.1.1 ## [85] bluster_1.0.0 globals_0.14.0 ## [87] statmod_1.4.35 ellipsis_0.3.2 #qcPlotDirBit &lt;- &quot;NormPlots&quot; #setNameUpp &lt;- &quot;Caron&quot; projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool library(knitr) #src &lt;- lapply(c(&quot;Caron&quot;, &quot;Hca&quot;), function(setNameUpp) knit_expand(file = &quot;test.Rmd&quot;)) src &lt;- lapply(c(&quot;Caron&quot;), function(setNameUpp) knit_expand(file = &quot;normalisation_5hCellPerSpl.Rmd&quot;)) ## src &lt;- lapply(c(&quot;Caron&quot;), function(setNameUpp) knit_expand(file = &quot;normalisation_GSM3872434.Rmd&quot;)) "],["normalisation-caron-set.html", "Chapter 7 Normalisation - Caron set 7.1 Scaling normalization 7.2 SCTransform 7.3 Visualisation 7.4 Session information", " Chapter 7 Normalisation - Caron set Sources: chapters on Normalisation in the OSCA book and the ’Hemberg group material. Why normalise? Systematic differences in sequencing coverage between libraries occur because of low input material, differences in cDNA capture and PCR amplification. Normalisation removes such differences so that differences between cells are not technical but biological, allowing meaningful comparison of expression profiles between cells. Normalisation and batch correction have different aims. Normalisation addresses technical differences only, while batch correction considers both technical and biological differences. qcPlotDirBit &lt;- &quot;Plots/Norm&quot; setName &lt;- tolower(&quot;Caron&quot;) projDir &lt;- params$projDir dirRel &lt;- params$dirRel if(params$bookType == &quot;mk&quot;){dirRel &lt;- &quot;..&quot;} outDirBit &lt;- params$outDirBit writeRds &lt;- TRUE # FALSE dir.create(sprintf(&quot;%s/%s/%s&quot;, projDir, outDirBit, qcPlotDirBit), showWarnings = FALSE, recursive = TRUE) Load object. setSuf &lt;- &quot;&quot; if(setName == &quot;hca&quot;) {setSuf &lt;- &quot;_5kCellPerSpl&quot;} # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postQc.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 16629 20908 ## metadata(0): ## assays(1): counts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(15): Barcode Run ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): Subsample cells down to 500 per sample setSuf &lt;- &quot;_5hCellPerSpl&quot; nbCells &lt;- 500 #setSuf &lt;- &quot;_1kCellPerSpl&quot; #nbCells &lt;- 1000 #setSuf &lt;- &quot;_GSM3872434&quot; ##nbCells &lt;- 500 # have new list of cell barcodes for each sample sce.nz.master &lt;- sce vec.bc &lt;- colData(sce.nz.master) %&gt;% data.frame() %&gt;% filter(!Run == &quot;SRR9264351&quot;) %&gt;% group_by(Sample.Name) %&gt;% sample_n(nbCells) %&gt;% pull(Barcode) table(colData(sce.nz.master)$Barcode %in% vec.bc) ## ## FALSE TRUE ## 15408 5500 tmpInd &lt;- which(colData(sce.nz.master)$Barcode %in% vec.bc) sce &lt;- sce.nz.master[,tmpInd] We write the R object to ‘caron_sce_nz_postQc_5hCellPerSpl.Rds’. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce, tmpFn) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce &lt;- readRDS(tmpFn) 7.1 Scaling normalization In scaling normalization, the “normalization factor” is an estimate of the library size relative to the other cells. Steps usually include: computation of a cell-specific ‘scaling’ or ‘size’ factor that represents the relative bias in that cell and division of all counts for the cell by that factor to remove that bias. Assumption: any cell specific bias will affect genes the same way. Scaling methods typically generate normalised counts-per-million (CPM) or transcripts-per-million (TPM) values that address the effect of sequencing depth. These values however typically have a variance that increases with their mean (heteroscedasticity) while most statistical methods assume a stable variance, which does not vary with the mean (homoscedasticity). A widely used ‘variance stabilising transformation’ is the log transformation (often log2). This works fine for highly expressed genes (as in bulk RNA-seq) but less so for sparse scRNA-seq data. 7.1.1 CPM Convert raw counts to counts-per-million (CPM) for each cell by dividing counts by the library size then multiplying by 1.000.000. Mind that this does not adress compositional bias caused by highly expressed genes that are also differentially expressed betwenn cells. In scater CPMs are computed with the following code: calc_cpm &lt;- function (expr_mat, spikes = NULL) { norm_factor &lt;- colSums(expr_mat[-spikes, ]) return(t(t(expr_mat)/norm_factor)) * 10^6 } We will use scater’s calculateCPM() 7.1.2 DESeq’s size factor For each gene, compute geometric mean across cells. for each cell compute for each gene the ratio of its expression to its geometric mean, and derive the cell’s size factor as the median ratio across genes. Not suitable for sparse scRNA-seq data as the geometric is computed on non-zero values only. This method is also known as ‘Relative Log Expression’ (RLE) in edgeR and scater. Example code: calc_sf &lt;- function (expr_mat, spikes = NULL) { geomeans &lt;- exp(rowMeans(log(expr_mat[-spikes, ]))) SF &lt;- function(cnts) { median((cnts/geomeans)[(is.finite(geomeans) &amp; geomeans &gt; 0)]) } norm_factor &lt;- apply(expr_mat[-spikes, ], 2, SF) return(t(t(expr_mat)/norm_factor)) } 7.1.3 Weighted Trimmed mean of M-values To compute weighted Trimmed mean of M-values (TMM), a given cell is chosen as a reference to use in computation for other cells. The M-values are gene-wise log2-fold changes between cells. Trimming entails the removal of the top and bottom 30% of values. The size factor is computed as the average for the remaining cells with a weight according to inverse variances. This method assumes that most genes are not differentially expressed, and the 40% lof genes left after trimming may include many zero counts. sizeFactors(sce) &lt;- edgeR::calcNormFactors(counts(sce), method = &quot;TMM&quot;) 7.1.4 Library size normalization For each cell, the library size factor is proportional to the library size such that the average size factor across cell is one. Advantage: normalised counts are on the same scale as the initial counts. Compute size factors: lib.sf &lt;- librarySizeFactors(sce) summary(lib.sf) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1222 0.4196 0.7350 1.0000 1.3192 8.8420 Size factor distribution: wide range, typical of scRNA-seq data. hist(log10(lib.sf), xlab=&quot;Log10[Size factor]&quot;, col=&#39;grey80&#39;) Assumption: absence of compositional bias; differential expression two cells is balanced: upregulation in some genes is accompanied by downregulation of other genes. Not observed. Inaccurate normalisation due to unaccounted-for composition bias affects the size of the log fold change measured between clusters, but less so the clustering itself. It is thus sufficient to identify clusters and top marker genes. 7.1.5 Deconvolution Composition bias occurs when differential expression beteween two samples or here cells is not balanced. For a fixed library size, identical in both cells, upregulation of one gene in the a cell will means fewer UMIs can be assigned to other genes, which would then appear down regulated. Even if library sizes are allowed to differ in size, with that for the cell with upregulation being higher, scaling normalisation will reduce noralised counts. Non-upregulated would therefore also appear downregulated. For bulk RNA-seq, composition bias is removed by assuming that most genes are not differentially expressed between samples, so that differences in non-DE genes would amount to the bias, and used to compute size factors. Given the sparsity of scRNA-seq data, the methods are not appropriate. The method below increases read counts by pooling cells into groups, computing size factors within each of these groups and scaling them so they are comparable across clusters. This process is repeated many times, changing pools each time to collect several size factors for each cell, frome which is derived a single value for that cell. Cluster cells then normalise. 7.1.5.1 Cluster cells set.seed(100) # clusters with PCA from irlba with approximation clust &lt;- quickCluster(sce) # slow with all cells. # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(clust, tmpFn) # read from file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds&quot;, projDir, outDirBit, setName, setSuf) clust &lt;- readRDS(tmpFn) table(clust) ## clust ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## 222 175 141 427 638 521 313 120 226 179 234 369 428 167 187 162 314 104 150 134 ## 21 22 ## 134 155 7.1.5.2 Compute size factors #deconv.sf &lt;- calculateSumFactors(sce, cluster=clust) sce &lt;- computeSumFactors(sce, cluster=clust, min.mean=0.1) deconv.sf &lt;- sizeFactors(sce) # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(deconv.sf, tmpFn) # read from file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds&quot;, projDir, outDirBit, setName, setSuf) deconv.sf &lt;- readRDS(tmpFn) summary(deconv.sf) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.03427 0.37755 0.72301 1.00000 1.35926 8.16947 Plot size factors: plot(lib.sf, deconv.sf, xlab=&quot;Library size factor&quot;, ylab=&quot;Deconvolution size factor&quot;, log=&#39;xy&#39;, pch=16, col=as.integer(factor(sce$source_name))) abline(a=0, b=1, col=&quot;red&quot;) deconvDf &lt;- data.frame(lib.sf, deconv.sf, &quot;source_name&quot; = sce$source_name, &quot;sum&quot; = sce$sum, &quot;mito_content&quot; = sce$subsets_Mito_percent, &quot;cell_sparsity&quot; = sce$cell_sparsity) # colour by sample type sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=source_name)) + geom_point() sp + facet_wrap(~source_name) # colour by library size sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=sum)) + geom_point() sp # colour by mito. content sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=mito_content)) + geom_point() sp # colour by cell sparsity sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=cell_sparsity)) + geom_point() sp 7.1.5.3 Apply size factors For each cell, raw counts for genes are divided by the size factor for that cell and log-transformed so downstream analyses focus on genes with strong relative differences. We use scater::logNormCounts(). sce &lt;- logNormCounts(sce) # adds logcounts print(assayNames(sce)) ## [1] &quot;counts&quot; &quot;logcounts&quot; 7.1.5.4 Save object sceDeconv &lt;- sce # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sceDeconv, tmpFn) 7.2 SCTransform With scaling normalisation a correlation remains between the mean and variation of expression (heteroskedasticity). This affects downstream dimensionality reduction as the few main new dimensions are usually correlated with library size. SCTransform addresses the issue by regressing library size out of raw counts and providing residuals to use as normalized and variance-stabilized expression values in downstream analysis. counts &lt;- counts(sce) print(class(counts)) ## [1] &quot;dgCMatrix&quot; ## attr(,&quot;package&quot;) ## [1] &quot;Matrix&quot; print(dim(counts)) ## [1] 16629 5500 colnames(counts) &lt;- colData(sce)$Barcode 7.2.1 Inspect data We will now calculate some properties and visually inspect the data. Our main interest is in the general trends not in individual outliers. Neither genes nor cells that stand out are important at this step, but we focus on the global trends. Derive gene and cell attributes from the UMI matrix. gene_attr &lt;- data.frame(mean = rowMeans(counts), detection_rate = rowMeans(counts &gt; 0), var = apply(counts, 1, var)) gene_attr$log_mean &lt;- log10(gene_attr$mean) gene_attr$log_var &lt;- log10(gene_attr$var) rownames(gene_attr) &lt;- rownames(counts) cell_attr &lt;- data.frame(n_umi = colSums(counts), n_gene = colSums(counts &gt; 0)) rownames(cell_attr) &lt;- colnames(counts) dim(gene_attr) ## [1] 16629 5 head(gene_attr) ## mean detection_rate var log_mean log_var ## ENSG00000237491 0.023636364 0.023636364 0.023081883 -1.6264193 -1.6367288 ## ENSG00000225880 0.012545455 0.011818182 0.013845129 -1.9015136 -1.8587030 ## ENSG00000230368 0.018363636 0.018000000 0.018757096 -1.7360413 -1.7268344 ## ENSG00000230699 0.002545455 0.002545455 0.002539437 -2.5942347 -2.5952626 ## ENSG00000188976 0.183636364 0.156363636 0.213952950 -0.7360413 -0.6696817 ## ENSG00000187961 0.005272727 0.004909091 0.005973284 -2.2779647 -2.2237868 dim(cell_attr) ## [1] 5500 2 head(cell_attr) ## n_umi n_gene ## GTGCGGTGTCATTAGC-1 4104 1575 ## TGAGCATCATGCTAGT-1 2603 1185 ## TGTTCCGTCCGTTGCT-1 5742 1835 ## TTTGTCAAGAAACGAG-1 7569 2337 ## ACTTGTTTCAGCTTAG-1 4882 1723 ## CGTTCTGGTCTAGGTT-1 4909 1874 Mean-variance relationship For the genes, we can see that up to a mean UMI count of ca. 0.1 the variance follows the line through the origin with slop one, i.e. variance and mean are roughly equal as expected under a Poisson model. However, genes with a higher average UMI count show overdispersion compared to Poisson. ggplot(gene_attr, aes(log_mean, log_var)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) + geom_abline(intercept = 0, slope = 1, color=&#39;red&#39;) Mean-detection-rate relationship In line with the previous plot, we see a lower than expected detection rate in the medium expression range. However, for the highly expressed genes, the rate is at or very close to 1.0 suggesting that there is no zero-inflation in the counts for those genes and that zero-inflation is a result of overdispersion, rather than an independent systematic bias. # add the expected detection rate under Poisson model x = seq(from = -3, to = 2, length.out = 1000) poisson_model &lt;- data.frame(log_mean = x, detection_rate = 1 - dpois(0, lambda = 10^x)) ggplot(gene_attr, aes(log_mean, detection_rate)) + geom_point(alpha=0.3, shape=16) + geom_line(data=poisson_model, color=&#39;red&#39;) + theme_gray(base_size = 8) ggplot(cell_attr, aes(n_umi, n_gene)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) 7.2.2 Transformation Based on the observations above, which are not unique to this particular data set, we propose to model the expression of each gene as a negative binomial random variable with a mean that depends on other variables. Here the other variables can be used to model the differences in sequencing depth between cells and are used as independent variables in a regression model. In order to avoid overfitting, we will first fit model parameters per gene, and then use the relationship between gene mean and parameter values to fit parameters, thereby combining information across genes. Given the fitted model parameters, we transform each observed UMI count into a Pearson residual which can be interpreted as the number of standard deviations an observed count was away from the expected mean. If the model accurately describes the mean-variance relationship and the dependency of mean and latent factors, then the result should have mean zero and a stable variance across the range of expression. Estimate model parameters and transform data The vst function estimates model parameters and performs the variance stabilizing transformation. Here we use the log10 of the total UMI counts of a cell as variable for sequencing depth for each cell. After data transformation we plot the model parameters as a function of gene mean (geometric mean). print(dim(counts)) ## [1] 16629 5500 # We use the Future API for parallel processing; set parameters here future::plan(strategy = &#39;multicore&#39;, workers = 4) options(future.globals.maxSize = 10 * 1024 ^ 3) set.seed(44) vst_out &lt;- sctransform::vst(counts, latent_var = c(&#39;log_umi&#39;), return_gene_attr = TRUE, return_cell_attr = TRUE, show_progress = FALSE) sctransform::plot_model_pars(vst_out) Inspect model print(vst_out$model_str) ## [1] &quot;y ~ log_umi&quot; We will look at several genes in more detail. rowData(sce) %&gt;% as.data.frame %&gt;% filter(Symbol %in% c(&#39;MALAT1&#39;, &#39;RPL10&#39;, &#39;FTL&#39;)) ## ensembl_gene_id external_gene_name chromosome_name ## ENSG00000147403 ENSG00000147403 RPL10 X ## ENSG00000251562 ENSG00000251562 MALAT1 11 ## ENSG00000087086 ENSG00000087086 FTL 19 ## start_position end_position strand Symbol Type ## ENSG00000147403 154389955 154409168 1 RPL10 Gene Expression ## ENSG00000251562 65497688 65506516 1 MALAT1 Gene Expression ## ENSG00000087086 48965309 48966879 1 FTL Gene Expression ## mean detected gene_sparsity ## ENSG00000147403 44.29776 98.41586 0.01085709 ## ENSG00000251562 168.70211 98.86173 0.00607423 ## ENSG00000087086 11.38505 92.88974 0.09063516 sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000251562&#39;, &#39;ENSG00000147403&#39;, &#39;ENSG00000087086&#39;), plot_residual = TRUE) sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000087086&#39;), plot_residual = TRUE, show_nr = TRUE, arrange_vertical = FALSE) Distribution of residual mean: ggplot(vst_out$gene_attr, aes(residual_mean)) + geom_histogram(binwidth=0.01) Distribution of residual variance: ggplot(vst_out$gene_attr, aes(residual_variance)) + geom_histogram(binwidth=0.1) + geom_vline(xintercept=1, color=&#39;red&#39;) + xlim(0, 10) Variance against mean (residuals): ggplot(vst_out$gene_attr, aes(x=residual_mean, y=residual_variance)) + geom_point(alpha=0.3, shape=16) + xlim(0, 2.5) + ylim(0, 10) + geom_density_2d() Variance against mean (genes): ggplot(vst_out$gene_attr, aes(log10(gmean), residual_variance)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) Variance against mean (residuals): dd &lt;- vst_out$gene_attr %&gt;% arrange(-residual_variance) %&gt;% slice_head(n = 22) %&gt;% mutate(across(where(is.numeric), round, 2)) dd %&gt;% tibble::rownames_to_column(&quot;ensembl_gene_id&quot;) %&gt;% left_join(as.data.frame(rowData(sce))[,c(&quot;ensembl_gene_id&quot;, &quot;Symbol&quot;)], &quot;ensembl_gene_id&quot;) %&gt;% DT::datatable(rownames = FALSE) Write outcome to file. # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_vst_out%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(vst_out, tmpFn) Check transformed values: print(dim(vst_out$y)) ## [1] 16365 5500 vst_out$y[1:10,1:5] ## GTGCGGTGTCATTAGC-1 TGAGCATCATGCTAGT-1 TGTTCCGTCCGTTGCT-1 ## ENSG00000237491 -0.15111304 -0.12479475 -0.17353904 ## ENSG00000225880 -0.10700472 -0.08947667 -0.12181808 ## ENSG00000230368 -0.13153649 -0.10900447 -0.15070410 ## ENSG00000230699 -0.04999663 -0.04248972 -0.05629298 ## ENSG00000188976 1.74243506 -0.33462980 -0.46403541 ## ENSG00000187961 -0.07049556 -0.05993033 -0.07930258 ## ENSG00000272512 -0.04626533 -0.03936378 -0.05205822 ## ENSG00000188290 -0.36559547 -0.30160916 -0.41896733 ## ENSG00000187608 -0.63522969 -0.52989583 -0.71764842 ## ENSG00000188157 -0.06849471 -0.05823428 -0.07704895 ## TTTGTCAAGAAACGAG-1 ACTTGTTTCAGCTTAG-1 ## ENSG00000237491 4.46490500 -0.16237299 ## ENSG00000225880 -0.13527205 -0.11445399 ## ENSG00000230368 -0.16818836 -0.14116301 ## ENSG00000230699 -0.06199242 -0.05316684 ## ENSG00000188976 -0.51584024 -0.43507321 ## ENSG00000187961 -0.08722259 -0.07493685 ## ENSG00000272512 -0.05730784 -0.04918135 ## ENSG00000188290 -0.46651259 -0.39254587 ## ENSG00000187608 0.01929706 -0.67751046 ## ENSG00000188157 -0.08474310 -0.07280835 sce ## class: SingleCellExperiment ## dim: 16629 5500 ## metadata(0): ## assays(2): counts logcounts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Barcode Run ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): print(assayNames(sce)) ## [1] &quot;counts&quot; &quot;logcounts&quot; # assay(sce, &quot;sctrans_norm&quot;) &lt;- vst_out$y Genes that are expressed in fewer than 5 cells are not used and not returned, so to add vst_out$y as an assay we need to remove the missing genes. # genes that are expressed in fewer than 5 cells are not used and not returned # so to add vst_out$y as an assay we need to ditch the missing genes completely. # https://github.com/ChristophH/sctransform/issues/27 #rownames(vst_out$y) sceOrig &lt;- sce sceOrig ## class: SingleCellExperiment ## dim: 16629 5500 ## metadata(0): ## assays(2): counts logcounts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Barcode Run ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): tmpInd &lt;- which(rownames(sce) %in% rownames(vst_out$y)) cols.meta &lt;- colData(sceOrig) rows.meta &lt;- rowData(sceOrig) new.counts &lt;- counts(sceOrig)[tmpInd, ] sce &lt;- SingleCellExperiment(list(counts=new.counts)) # reset the column data on the new object colData(sce) &lt;- cols.meta rowData(sce) &lt;- rows.meta[tmpInd, ] if(FALSE) # dev { # logcounts_raw assayX &lt;- &quot;logcounts_raw&quot; tmpAssay &lt;- assay(sceOrig, assayX) assay(sce, assayX) &lt;- tmpAssay[tmpInd, ] # logCpm # logcounts for (assayX in c(&quot;logCpm&quot;, &quot;logcounts&quot;)) { tmpAssay &lt;- assay(sceOrig, assayX) assay(sce, assayX) &lt;- tmpAssay[tmpInd, ] } rm(assayX, tmpAssay) } assayNames(sce) ## [1] &quot;counts&quot; sce ## class: SingleCellExperiment ## dim: 16365 5500 ## metadata(0): ## assays(1): counts ## rownames(16365): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Barcode Run ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): vstMat &lt;- as(vst_out$y[rownames(sce),], &quot;dgCMatrix&quot;) all(colnames(vstMat) == sce$Barcode) ## [1] TRUE colnames(vstMat) &lt;- NULL assay(sce, &quot;sctrans_norm&quot;) &lt;- vstMat # as(vst_out$y[rownames(sce),], &quot;dgCMatrix&quot;) assayNames(sce) ## [1] &quot;counts&quot; &quot;sctrans_norm&quot; 7.2.3 Save SCE object # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postSct%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce, tmpFn) 7.3 Visualisation 7.3.1 log raw counts typeNorm &lt;- &quot;logRaw&quot; #setSuf &lt;- &quot;_5kCellPerSpl&quot; options(BiocSingularParam.default=IrlbaParam()) assay(sce, &quot;logcounts_raw&quot;) &lt;- log2(counts(sce) + 1) tmp &lt;- runPCA( sce[,], exprs_values = &quot;logcounts_raw&quot; ) PCA plot for the ‘logRaw’ counts in the caron set. p &lt;- plotPCA( tmp, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;PCA plot for log raw counts: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Cell-wise RLE for the ‘logRaw’ counts in the caron set. Each cell is represented by a box plot showing the inter-quartile range in grey, wiskers colour-coded by Sample.Name and the median as a black circle. p &lt;- plotRLE( #tmp[,1:10], tmp, exprs_values = &quot;logcounts_raw&quot;, colour_by = &quot;Sample.Name&quot; ) + ggtitle(sprintf(&quot;RLE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 7.3.2 log CPM typeNorm &lt;- &quot;logCpm&quot; assay(sce, &quot;logCpm&quot;) &lt;- log2(calculateCPM(sce, size_factors = NULL) + 1) logCpmPca &lt;- runPCA( sce[,], exprs_values = &quot;logCpm&quot; ) PCA plot for the ‘logCpm’ counts in the caron set. p &lt;- plotPCA( logCpmPca, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;PCA plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Cell-wise RLE for the ‘logCpm’ counts in the caron set. p &lt;- plotRLE( sce, exprs_values = &quot;logCpm&quot;, colour_by = &quot;Sample.Name&quot; ) + ggtitle(sprintf(&quot;RLE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 7.3.3 scran Normalised counts are stored in ‘logcounts’ assay typeNorm &lt;- &quot;scran&quot; # assay(sce, &quot;logcounts&quot;) scranPca &lt;- runPCA( sceDeconv[,], exprs_values = &quot;logcounts&quot; ) PCA plot for the ‘scran’ counts in the caron set. p &lt;- plotPCA( scranPca, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;PCA plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) TSNE plot for the ‘scran’ counts in the caron set. typeNorm &lt;- &quot;scran&quot; reducedDim(sceDeconv, &quot;TSNE_scran&quot;) &lt;- reducedDim( runTSNE(sceDeconv, exprs_values = &quot;logcounts&quot;), &quot;TSNE&quot; ) p &lt;- plotReducedDim( sceDeconv, dimred = &quot;TSNE_scran&quot;, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;TSNE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sTsne.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sTsne.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) UMAP plot for the ‘scran’ counts in the caron set. typeNorm &lt;- &quot;scran&quot; reducedDim(sceDeconv, &quot;UMAP_scran&quot;) &lt;- reducedDim( runUMAP(sceDeconv, exprs_values = &quot;logcounts&quot;), &quot;UMAP&quot; ) p &lt;- plotReducedDim( sceDeconv, dimred = &quot;UMAP_scran&quot;, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;UMAP plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sUmap.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sUmap.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Cell-wise RLE for the ‘scran’ counts in the caron set. p &lt;- plotRLE( scranPca, exprs_values = &quot;logcounts&quot;, colour_by = &quot;Sample.Name&quot; ) + ggtitle(sprintf(&quot;RLE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 7.3.4 SCTransform typeNorm &lt;- &quot;sctrans&quot; reducedDim(sce, &quot;PCA_sctrans_norm&quot;) &lt;- reducedDim( runPCA(sce, exprs_values = &quot;sctrans_norm&quot;), &quot;PCA&quot; ) PCA plot for the ‘sctrans’ counts in the caron set. p &lt;- plotReducedDim( sce, dimred = &quot;PCA_sctrans_norm&quot;, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;PCA plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) TSNE plot for the ‘sctrans’ counts in the caron set. typeNorm &lt;- &quot;sctrans&quot; reducedDim(sce, &quot;TSNE_sctrans_norm&quot;) &lt;- reducedDim( runTSNE(sce, exprs_values = &quot;sctrans_norm&quot;), &quot;TSNE&quot; ) p &lt;- plotReducedDim( sce, dimred = &quot;TSNE_sctrans_norm&quot;, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;TSNE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sTsne.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sTsne.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) UMAP plot for the ‘sctrans’ counts in the caron set. typeNorm &lt;- &quot;sctrans&quot; reducedDim(sce, &quot;UMAP_sctrans_norm&quot;) &lt;- reducedDim( runUMAP(sce, exprs_values = &quot;sctrans_norm&quot;), &quot;UMAP&quot; ) p &lt;- plotReducedDim( sce, dimred = &quot;UMAP_sctrans_norm&quot;, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;UMAP plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sUmap.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sUmap.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Cell-wise RLE for the ‘sctrans’ counts in the caron set. p &lt;- plotRLE( sce, exprs_values = &quot;sctrans_norm&quot;, colour_by = &quot;Sample.Name&quot; ) + ggtitle(sprintf(&quot;RLE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, dirRel, qcPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 7.4 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] Cairo_1.5-12.2 BiocSingular_1.6.0 ## [3] dplyr_1.0.5 scran_1.18.7 ## [5] scater_1.18.6 ggplot2_3.3.3 ## [7] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [9] Biobase_2.50.0 GenomicRanges_1.42.0 ## [11] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [13] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [15] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [17] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 RcppAnnoy_0.0.18 ## [3] tools_4.0.3 bslib_0.2.4 ## [5] utf8_1.2.1 R6_2.5.0 ## [7] irlba_2.3.3 vipor_0.4.5 ## [9] uwot_0.1.10 DBI_1.1.1 ## [11] colorspace_2.0-0 withr_2.4.2 ## [13] tidyselect_1.1.1 gridExtra_2.3 ## [15] compiler_4.0.3 BiocNeighbors_1.8.2 ## [17] DelayedArray_0.16.3 labeling_0.4.2 ## [19] bookdown_0.22 sass_0.3.1 ## [21] scales_1.1.1 stringr_1.4.0 ## [23] digest_0.6.27 rmarkdown_2.7 ## [25] XVector_0.30.0 pkgconfig_2.0.3 ## [27] htmltools_0.5.1.1 sparseMatrixStats_1.2.1 ## [29] limma_3.46.0 highr_0.9 ## [31] rlang_0.4.10 DelayedMatrixStats_1.12.3 ## [33] jquerylib_0.1.3 generics_0.1.0 ## [35] farver_2.1.0 jsonlite_1.7.2 ## [37] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [39] magrittr_2.0.1 GenomeInfoDbData_1.2.4 ## [41] scuttle_1.0.4 Matrix_1.3-2 ## [43] Rcpp_1.0.6 ggbeeswarm_0.6.0 ## [45] munsell_0.5.0 fansi_0.4.2 ## [47] viridis_0.6.0 lifecycle_1.0.0 ## [49] stringi_1.5.3 yaml_2.2.1 ## [51] edgeR_3.32.1 zlibbioc_1.36.0 ## [53] Rtsne_0.15 grid_4.0.3 ## [55] dqrng_0.3.0 crayon_1.4.1 ## [57] lattice_0.20-44 cowplot_1.1.1 ## [59] beachmat_2.6.4 locfit_1.5-9.4 ## [61] pillar_1.6.0 igraph_1.2.6 ## [63] codetools_0.2-18 glue_1.4.2 ## [65] evaluate_0.14 vctrs_0.3.7 ## [67] png_0.1-7 gtable_0.3.0 ## [69] purrr_0.3.4 assertthat_0.2.1 ## [71] xfun_0.22 rsvd_1.0.5 ## [73] RSpectra_0.16-0 viridisLite_0.4.0 ## [75] tibble_3.1.1 beeswarm_0.3.1 ## [77] bluster_1.0.0 statmod_1.4.35 ## [79] ellipsis_0.3.2 "],["NormalisationGSM3872434Top.html", "Chapter 8 Normalisation - GSM3872434 set 8.1 Scaling normalization 8.2 SCTransform 8.3 Visualisation 8.4 Session information", " Chapter 8 Normalisation - GSM3872434 set Sources: chapters on normalisation in the OSCA book and the ‘Hemberg group material’. Why normalise? Systematic differences in sequencing coverage between libraries occur because of low input material, differences in cDNA capture and PCR amplification. Normalisation removes such differences so that differences between cells are not technical but biological, allowing meaningful comparison of expression profiles between cells. Normalisation and batch correction have different aims. Normalisation addresses technical differences only, while batch correction considers both technical and biological differences. normPlotDirBit &lt;- &quot;Plots/Norm&quot; projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit setName &lt;- params$setName setSuf &lt;- params$setSuf if(params$bookType == &quot;mk&quot;) { setName &lt;- &quot;GSM3872434&quot; setSuf &lt;- &quot;_allCells&quot; dirRel &lt;- &quot;..&quot; } dir.create(sprintf(&quot;%s/%s/%s&quot;, projDir, outDirBit, normPlotDirBit), showWarnings = FALSE) Load object # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, &quot;caron&quot;, setSuf) if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(1): counts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Sample Barcode ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): Select cells for GSM3872434: ##setSuf &lt;- &quot;_5hCellPerSpl&quot; ##nbCells &lt;- 500 #setSuf &lt;- &quot;_1kCellPerSpl&quot; #nbCells &lt;- 1000 setSuf &lt;- &quot;_GSM3872434&quot; ##nbCells &lt;- 500 # have new list of cell barcodes for each sample sce.nz.master &lt;- sce vec.bc &lt;- colData(sce.nz.master) %&gt;% data.frame() %&gt;% filter(Sample.Name == &quot;GSM3872434&quot;) %&gt;% group_by(Sample.Name) %&gt;% ##sample_n(nbCells) %&gt;% pull(Barcode) Number of cells in the sample: table(colData(sce.nz.master)$Barcode %in% vec.bc) ## ## FALSE TRUE ## 44977 2853 Subset cells from the SCE object: tmpInd &lt;- which(colData(sce.nz.master)$Barcode %in% vec.bc) sce &lt;- sce.nz.master[,tmpInd] sce ## class: SingleCellExperiment ## dim: 18431 2853 ## metadata(0): ## assays(1): counts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Sample Barcode ... outlier cell_sparsity ## reducedDimNames(0): ## altExpNames(0): Check columns data: head(colData(sce)) ## DataFrame with 6 rows and 16 columns ## Sample Barcode Run Sample.Name source_name ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;factor&gt; ## 1 /ssd/personal/baller.. AAACCTGAGACTTTCG-1 SRR9264343 GSM3872434 ETV6-RUNX1 ## 2 /ssd/personal/baller.. AAACCTGGTCTTCAAG-1 SRR9264343 GSM3872434 ETV6-RUNX1 ## 3 /ssd/personal/baller.. AAACCTGGTGTTGAGG-1 SRR9264343 GSM3872434 ETV6-RUNX1 ## 4 /ssd/personal/baller.. AAACCTGTCCCAAGTA-1 SRR9264343 GSM3872434 ETV6-RUNX1 ## 5 /ssd/personal/baller.. AAACCTGTCGAATGCT-1 SRR9264343 GSM3872434 ETV6-RUNX1 ## 6 /ssd/personal/baller.. AAACGGGCACCATCCT-1 SRR9264343 GSM3872434 ETV6-RUNX1 ## sum detected subsets_Mito_sum subsets_Mito_detected ## &lt;numeric&gt; &lt;integer&gt; &lt;numeric&gt; &lt;integer&gt; ## 1 6462 1996 290 12 ## 2 11706 3079 567 12 ## 3 7981 2511 423 12 ## 4 8354 2307 519 13 ## 5 1373 701 91 11 ## 6 2142 985 102 10 ## subsets_Mito_percent total block setName discard outlier ## &lt;numeric&gt; &lt;numeric&gt; &lt;factor&gt; &lt;character&gt; &lt;logical&gt; &lt;logical&gt; ## 1 4.48777 6462 ETV6-RUNX1 Caron FALSE FALSE ## 2 4.84367 11706 ETV6-RUNX1 Caron FALSE FALSE ## 3 5.30009 7981 ETV6-RUNX1 Caron FALSE FALSE ## 4 6.21259 8354 ETV6-RUNX1 Caron FALSE FALSE ## 5 6.62782 1373 ETV6-RUNX1 Caron FALSE FALSE ## 6 4.76190 2142 ETV6-RUNX1 Caron FALSE FALSE ## cell_sparsity ## &lt;numeric&gt; ## 1 0.907503 ## 2 0.857361 ## 3 0.883637 ## 4 0.893091 ## 5 0.967515 ## 6 0.954400 table(colData(sce)$Sample.Name) ## ## GSM3872434 ## 2853 We write the R object to GSM3872434_sce_nz_postQc_GSM3872434.Rds. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce, tmpFn) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce &lt;- readRDS(tmpFn) 8.1 Scaling normalization In scaling normalization, the “normalization factor” is an estimate of the library size relative to the other cells. Steps usually include: computation of a cell-specific ‘scaling’ or ‘size’ factor that represents the relative bias in that cell and division of all counts for the cell by that factor to remove that bias. Assumption: any cell specific bias will affect genes the same way. Scaling methods typically generate normalised counts-per-million (CPM) or transcripts-per-million (TPM) values that address the effect of sequencing depth. These values however typically have a variance that changes with their mean (heteroscedasticity) while most statistical methods assume a stable variance, which does not vary with the mean (homoscedasticity). A widely used ‘variance stabilising transformation’ is the log transformation (often log2). This works fine for highly expressed genes (as in bulk RNA-seq) but less so for sparse scRNA-seq data. 8.1.1 CPM Convert raw counts to counts-per-million (CPM) for each cell by dividing counts by the library size then multiplying by 1.000.000. Mind that this does not adress compositional bias caused by highly expressed genes that are also differentially expressed between cells. In scater CPMs are computed with the following code: calc_cpm &lt;- function (expr_mat, spikes = NULL) { norm_factor &lt;- colSums(expr_mat[-spikes, ]) return(t(t(expr_mat)/norm_factor)) * 10^6 } We will use scater’s calculateCPM(). 8.1.2 DESeq’s size factor For each gene, compute geometric mean across cells. For each cell compute for each gene the ratio of its expression to its geometric mean, and derive the cell’s size factor as the median ratio across genes. Not suitable for sparse scRNA-seq data as the geometric is computed on non-zero values only. This method is also known as ‘Relative Log Expression’ (RLE) in edgeR and scater. Example code: calc_sf &lt;- function (expr_mat, spikes = NULL) { geomeans &lt;- exp(rowMeans(log(expr_mat[-spikes, ]))) SF &lt;- function(cnts) { median((cnts/geomeans)[(is.finite(geomeans) &amp; geomeans &gt; 0)]) } norm_factor &lt;- apply(expr_mat[-spikes, ], 2, SF) return(t(t(expr_mat)/norm_factor)) } 8.1.3 Weighted Trimmed mean of M-values To compute weighted Trimmed mean of M-values (TMM), a given cell is chosen as a reference to use in computation for other cells. The M-values are gene-wise log2-fold changes between cells. Trimming entails the removal of the top and bottom 30% of values. The size factor is computed as the average for the remaining cells with a weight according to inverse variances. This method assumes that most genes are not differentially expressed, and the 40% of genes left after trimming may include many zero counts. sizeFactors(sce) &lt;- edgeR::calcNormFactors(counts(sce), method = &quot;TMM&quot;) 8.1.4 Library size factor distribution For each cell, the library size factor is proportional to the library size such that the average size factor across cells is one. Advantage: normalised counts are on the same scale as the initial counts. Compute size factors: lib.sf &lt;- librarySizeFactors(sce) summary(lib.sf) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.09666 0.66197 0.92591 1.00000 1.23957 5.49973 Size factor distribution: wide range, typical of scRNA-seq data. hist(log10(lib.sf), xlab=&quot;Log10[Size factor]&quot;, col=&#39;grey80&#39;) Assumption: absence of compositional bias; differential expression between two cells is balanced: upregulation in some genes is accompanied by downregulation of other genes. Not observed. Inaccurate normalisation due to unaccounted-for composition bias affects the size of the log fold change measured between clusters, but less so the clustering itself. It is thus sufficient to identify clusters and top marker genes. 8.1.5 Deconvolution Composition bias occurs when differential expression beteween two samples or here cells is not balanced. For a fixed library size, identical in both cells, upregulation of one gene in a cell will means fewer UMIs can be assigned to other genes, which would then appear down regulated. Even if library sizes are allowed to differ, with that for the cell with upregulation being higher, scaling normalisation will reduce normalised counts. Non-upregulated would therefore also appear downregulated. For bulk RNA-seq, composition bias is removed by assuming that most genes are not differentially expressed between samples, so that differences in non-DE genes would amount to the bias, and used to compute size factors. Given the sparsity of scRNA-seq data, the methods are not appropriate. The method below increases read counts by pooling cells into groups, computing size factors within each of these groups and scaling them so they are comparable across clusters. This process is repeated many times, changing pools each time to collect several size factors for each cell, from which is derived a single value for that cell. tmpFn &lt;- sprintf(&quot;%s/Images/scran_Fig3.png&quot;, &quot;..&quot;) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Cluster cells then normalise. 8.1.5.1 Cluster cells set.seed(100) # clusters with PCA from irlba with approximation clust &lt;- quickCluster(sce) # slow with all cells. # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(clust, tmpFn) # read from file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds&quot;, projDir, outDirBit, setName, setSuf) clust &lt;- readRDS(tmpFn) table(clust) ## clust ## 1 2 3 4 5 6 7 8 9 ## 232 193 617 315 407 380 398 189 122 8.1.5.2 Compute size factors #deconv.sf &lt;- calculateSumFactors(sce, cluster=clust) sce &lt;- computeSumFactors(sce, cluster=clust, min.mean=0.1) deconv.sf &lt;- sizeFactors(sce) # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(deconv.sf, tmpFn) # read from file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds&quot;, projDir, outDirBit, setName, setSuf) deconv.sf &lt;- readRDS(tmpFn) summary(deconv.sf) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.08207 0.67672 0.91982 1.00000 1.22628 4.06014 Plot deconvolution size factors against library size factors: deconvDf &lt;- data.frame(lib.sf, deconv.sf, &quot;source_name&quot; = sce$source_name, &quot;sum&quot; = sce$sum, &quot;mito_content&quot; = sce$subsets_Mito_percent, &quot;cell_sparsity&quot; = sce$cell_sparsity) sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=source_name)) + geom_point() # Split by sample type: #sp + facet_wrap(~source_name) sp &lt;- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=cell_sparsity)) + geom_point() sp 8.1.5.3 Apply size factors For each cell, raw counts for genes are divided by the size factor for that cell and log-transformed so downstream analyses focus on genes with strong relative differences. We use scater::logNormCounts(). sce &lt;- logNormCounts(sce) # adds logcounts print(assayNames(sce)) ## [1] &quot;counts&quot; &quot;logcounts&quot; 8.1.5.4 Save object # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce, tmpFn) sceDeconv &lt;- sce 8.2 SCTransform With scaling normalisation a correlation remains between the mean and variation of expression (heteroskedasticity). This affects downstream dimensionality reduction as the few main new dimensions are usually correlated with library size. SCTransform addresses the issue by regressing library size out of raw counts and providing residuals to use as normalized and variance-stabilized expression values in downstream analysis. We will use the sctransform vignette. counts &lt;- counts(sce) print(class(counts)) ## [1] &quot;dgCMatrix&quot; ## attr(,&quot;package&quot;) ## [1] &quot;Matrix&quot; print(dim(counts)) ## [1] 18431 2853 colnames(counts) &lt;- colData(sce)$Barcode 8.2.1 Inspect data We will now calculate some properties and visually inspect the data. Our main interest is in the general trends not in individual outliers. Neither genes nor cells that stand out are important at this step, but we focus on the global trends. Derive gene and cell attributes from the UMI matrix. gene_attr &lt;- data.frame(mean = rowMeans(counts), detection_rate = rowMeans(counts &gt; 0), var = apply(counts, 1, var)) gene_attr$log_mean &lt;- log10(gene_attr$mean) gene_attr$log_var &lt;- log10(gene_attr$var) rownames(gene_attr) &lt;- rownames(counts) cell_attr &lt;- data.frame(n_umi = colSums(counts), n_gene = colSums(counts &gt; 0)) rownames(cell_attr) &lt;- colnames(counts) dim(gene_attr) ## [1] 18431 5 head(gene_attr) ## mean detection_rate var log_mean log_var ## ENSG00000238009 0.0007010165 0.0007010165 0.0007007707 -3.1542718 -3.1544241 ## ENSG00000237491 0.0364528566 0.0357518402 0.0365388860 -1.4382684 -1.4372447 ## ENSG00000225880 0.0318962496 0.0304942166 0.0336947550 -1.4962604 -1.4724377 ## ENSG00000230368 0.0140203295 0.0136698212 0.0145298692 -1.8532418 -1.8377383 ## ENSG00000230699 0.0021030494 0.0021030494 0.0020993624 -2.6771505 -2.6779126 ## ENSG00000188976 0.2958289520 0.2509638977 0.3065639427 -0.5289593 -0.5134789 dim(cell_attr) ## [1] 2853 2 head(cell_attr) ## n_umi n_gene ## AAACCTGAGACTTTCG-1 6462 1996 ## AAACCTGGTCTTCAAG-1 11705 3078 ## AAACCTGGTGTTGAGG-1 7981 2511 ## AAACCTGTCCCAAGTA-1 8354 2307 ## AAACCTGTCGAATGCT-1 1373 701 ## AAACGGGCACCATCCT-1 2141 984 Mean-variance relationship For the genes, we can see that up to a mean UMI count of 0 the variance follows the line through the origin with slop one, i.e. variance and mean are roughly equal as expected under a Poisson model. However, genes with a higher average UMI count show overdispersion compared to Poisson. ggplot(gene_attr, aes(log_mean, log_var)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) + geom_abline(intercept = 0, slope = 1, color=&#39;red&#39;) Mean-detection-rate relationship In line with the previous plot, we see a lower than expected detection rate in the medium expression range. However, for the highly expressed genes, the rate is at or very close to 1.0 suggesting that there is no zero-inflation in the counts for those genes and that zero-inflation is a result of overdispersion, rather than an independent systematic bias. # add the expected detection rate under Poisson model x = seq(from = -3, to = 2, length.out = 1000) poisson_model &lt;- data.frame(log_mean = x, detection_rate = 1 - dpois(0, lambda = 10^x)) ggplot(gene_attr, aes(log_mean, detection_rate)) + geom_point(alpha=0.3, shape=16) + geom_line(data=poisson_model, color=&#39;red&#39;) + theme_gray(base_size = 8) 8.2.2 Transformation “Based on the observations above, which are not unique to this particular data set, we propose to model the expression of each gene as a negative binomial random variable with a mean that depends on other variables. Here the other variables can be used to model the differences in sequencing depth between cells and are used as independent variables in a regression model. In order to avoid overfitting, we will first fit model parameters per gene, and then use the relationship between gene mean and parameter values to fit parameters, thereby combining information across genes. Given the fitted model parameters, we transform each observed UMI count into a Pearson residual which can be interpreted as the number of standard deviations an observed count was away from the expected mean. If the model accurately describes the mean-variance relationship and the dependency of mean and latent factors, then the result should have mean zero and a stable variance across the range of expression.” sctransform vignette. Estimate model parameters and transform data The vst function estimates model parameters and performs the variance stabilizing transformation. Here we use the log10 of the total UMI counts of a cell as variable for sequencing depth for each cell. After data transformation we plot the model parameters as a function of gene mean (geometric mean). print(dim(counts)) ## [1] 18431 2853 # We use the Future API for parallel processing; set parameters here future::plan(strategy = &#39;multicore&#39;, workers = 4) options(future.globals.maxSize = 10 * 1024 ^ 3) set.seed(44) vst_out &lt;- sctransform::vst(counts, latent_var = c(&#39;log_umi&#39;), return_gene_attr = TRUE, return_cell_attr = TRUE, show_progress = FALSE) sctransform::plot_model_pars(vst_out) Inspect model: print(vst_out$model_str) ## [1] &quot;y ~ log_umi&quot; We will look at several genes in more detail. #sctransform::plot_model(vst_out, counts, c(&#39;MALAT1&#39;, &#39;RPL10&#39;, &#39;FTL&#39;), plot_residual = TRUE) rowData(sce) %&gt;% as.data.frame %&gt;% filter(Symbol %in% c(&#39;MALAT1&#39;, &#39;RPL10&#39;, &#39;FTL&#39;)) ## ensembl_gene_id external_gene_name chromosome_name ## ENSG00000147403 ENSG00000147403 RPL10 X ## ENSG00000251562 ENSG00000251562 MALAT1 11 ## ENSG00000087086 ENSG00000087086 FTL 19 ## start_position end_position strand Symbol Type ## ENSG00000147403 154389955 154409168 1 RPL10 Gene Expression ## ENSG00000251562 65497688 65506516 1 MALAT1 Gene Expression ## ENSG00000087086 48965309 48966879 1 FTL Gene Expression ## mean detected gene_sparsity ## ENSG00000147403 48.85548 99.28030 0.011540874 ## ENSG00000251562 193.05529 99.09786 0.005352289 ## ENSG00000087086 15.48621 96.42481 0.085532093 sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000251562&#39;, &#39;ENSG00000147403&#39;, &#39;ENSG00000087086&#39;), plot_residual = TRUE) sctransform::plot_model(vst_out, counts, c(&#39;ENSG00000087086&#39;), plot_residual = TRUE, show_nr = TRUE, arrange_vertical = FALSE) Distribution of residual mean: ggplot(vst_out$gene_attr, aes(residual_mean)) + geom_histogram(binwidth=0.01) Distribution of residual variance: ggplot(vst_out$gene_attr, aes(residual_variance)) + geom_histogram(binwidth=0.1) + geom_vline(xintercept=1, color=&#39;red&#39;) + xlim(0, 10) Variance against mean (residuals): ggplot(vst_out$gene_attr, aes(x=residual_mean, y=residual_variance)) + geom_point(alpha=0.3, shape=16) + xlim(0, 2.5) + ylim(0, 10) + geom_density_2d() Variance against mean (genes): ggplot(vst_out$gene_attr, aes(log10(gmean), residual_variance)) + geom_point(alpha=0.3, shape=16) + geom_density_2d(size = 0.3) Check genes with large residual variance: dd &lt;- vst_out$gene_attr %&gt;% arrange(-residual_variance) %&gt;% slice_head(n = 22) %&gt;% mutate(across(where(is.numeric), round, 2)) dd %&gt;% tibble::rownames_to_column(&quot;ensembl_gene_id&quot;) %&gt;% left_join(as.data.frame(rowData(sce))[,c(&quot;ensembl_gene_id&quot;, &quot;Symbol&quot;)], &quot;ensembl_gene_id&quot;) ## ensembl_gene_id detection_rate gmean variance residual_mean ## 1 ENSG00000197061 0.72 2.04 534.32 1.90 ## 2 ENSG00000175063 0.21 0.36 26.18 0.68 ## 3 ENSG00000164104 0.66 1.74 120.31 1.06 ## 4 ENSG00000100097 0.06 0.07 3.85 0.31 ## 5 ENSG00000008517 0.01 0.02 0.87 0.20 ## 6 ENSG00000123416 0.91 5.22 447.36 1.07 ## 7 ENSG00000211679 0.08 0.09 1.46 0.30 ## 8 ENSG00000102970 0.03 0.03 2.22 0.15 ## 9 ENSG00000170540 0.54 0.86 38.67 0.47 ## 10 ENSG00000164611 0.21 0.31 12.05 0.41 ## 11 ENSG00000128322 0.33 0.61 11.86 0.69 ## 12 ENSG00000244734 0.45 0.49 85356.97 0.15 ## 13 ENSG00000188536 0.16 0.15 8088.98 0.11 ## 14 ENSG00000206172 0.12 0.11 4995.50 0.09 ## 15 ENSG00000271503 0.02 0.02 0.41 0.12 ## 16 ENSG00000131747 0.16 0.27 7.92 0.34 ## 17 ENSG00000187837 0.67 1.53 21.13 0.78 ## 18 ENSG00000026025 0.69 1.92 58.23 0.73 ## 19 ENSG00000115523 0.00 0.01 0.24 0.06 ## 20 ENSG00000145649 0.00 0.01 0.06 0.08 ## 21 ENSG00000158578 0.01 0.01 1.67 0.06 ## 22 ENSG00000117399 0.11 0.16 4.07 0.25 ## residual_variance Symbol ## 1 65.39 HIST1H4C ## 2 20.67 UBE2C ## 3 16.78 HMGB2 ## 4 16.15 LGALS1 ## 5 15.36 IL32 ## 6 13.55 TUBA1B ## 7 12.64 IGLC3 ## 8 10.97 CCL17 ## 9 10.80 ARL6IP1 ## 10 10.77 PTTG1 ## 11 10.17 IGLL1 ## 12 9.95 HBB ## 13 9.83 HBA2 ## 14 9.75 HBA1 ## 15 9.02 CCL5 ## 16 8.63 TOP2A ## 17 8.44 HIST1H1C ## 18 8.42 VIM ## 19 7.85 GNLY ## 20 7.79 GZMA ## 21 7.78 ALAS2 ## 22 7.53 CDC20 Write outcome to file: # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_vst_out%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(vst_out, tmpFn) Check transformed values. print(dim(vst_out$y)) ## [1] 14214 2853 vst_out$y[1:10,1:5] ## AAACCTGAGACTTTCG-1 AAACCTGGTCTTCAAG-1 AAACCTGGTGTTGAGG-1 ## ENSG00000237491 -0.20121617 -0.25944999 -0.22046915 ## ENSG00000225880 -0.18668543 -0.24052717 -0.20448848 ## ENSG00000230368 -0.12439501 -0.16164785 -0.13667117 ## ENSG00000230699 -0.04842402 -0.06042004 -0.05240396 ## ENSG00000188976 1.03374030 1.56177764 0.80159808 ## ENSG00000187961 -0.05363629 -0.06698983 -0.05806420 ## ENSG00000188290 -0.09174430 -0.12027862 -0.10110587 ## ENSG00000187608 2.45936165 -0.77304781 -0.65435652 ## ENSG00000188157 -0.07078407 -0.09039073 -0.07724886 ## ENSG00000131591 -0.16874897 -0.21715523 -0.18475767 ## AAACCTGTCCCAAGTA-1 AAACCTGTCGAATGCT-1 ## ENSG00000237491 -0.22484005 -0.10084504 ## ENSG00000225880 -0.20852982 -0.09378858 ## ENSG00000230368 -0.13946384 -0.06115474 ## ENSG00000230699 -0.05330481 -0.02694137 ## ENSG00000188976 0.75303608 -0.27198451 ## ENSG00000187961 -0.05906678 -0.02977692 ## ENSG00000188290 -0.10324123 -0.04420393 ## ENSG00000187608 -0.66778017 -0.28420778 ## ENSG00000188157 -0.07871818 -0.03690960 ## ENSG00000131591 -0.18839118 -0.08509713 Genes that are expressed in fewer than 5 cells are not used and not returned, so to add vst_out$y as an assay we need to remove the missing genes. # https://github.com/ChristophH/sctransform/issues/27 sceOrig &lt;- sce sceOrig ## class: SingleCellExperiment ## dim: 18431 2853 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): tmpInd &lt;- which(rownames(sce) %in% rownames(vst_out$y)) cols.meta &lt;- colData(sceOrig) rows.meta &lt;- rowData(sceOrig) new.counts &lt;- counts(sceOrig)[tmpInd, ] sce &lt;- SingleCellExperiment(list(counts=new.counts)) # reset the column data on the new object colData(sce) &lt;- cols.meta rowData(sce) &lt;- rows.meta[tmpInd, ] assayNames(sce) ## [1] &quot;counts&quot; sce ## class: SingleCellExperiment ## dim: 14214 2853 ## metadata(0): ## assays(1): counts ## rownames(14214): ENSG00000237491 ENSG00000225880 ... ENSG00000278817 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): vstMat &lt;- as(vst_out$y[rownames(sce),], &quot;dgCMatrix&quot;) all(colnames(vstMat) == sce$Barcode) ## [1] TRUE colnames(vstMat) &lt;- NULL assay(sce, &quot;sctrans_norm&quot;) &lt;- vstMat # as(vst_out$y[rownames(sce),], &quot;dgCMatrix&quot;) #assayNames(sce) 8.2.3 Save SCE object # write to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postSct%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce, tmpFn) 8.3 Visualisation 8.3.1 log raw counts typeNorm &lt;- &quot;logRaw&quot; #setSuf &lt;- &quot;_5kCellPerSpl&quot; options(BiocSingularParam.default=IrlbaParam()) assay(sce, &quot;logcounts_raw&quot;) &lt;- log2(counts(sce) + 1) tmp &lt;- runPCA( sce[,], exprs_values = &quot;logcounts_raw&quot; ) PCA plot for the logRaw counts in the GSM3872434 set. p &lt;- plotPCA( tmp, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;PCA plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, projDir, outDirBit, normPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, dirRel, normPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 8.3.2 log CPM typeNorm &lt;- &quot;logCpm&quot; assay(sce, &quot;logCpm&quot;) &lt;- log2(calculateCPM(sce, size_factors = NULL) + 1) logCpmPca &lt;- runPCA( sce[,], exprs_values = &quot;logCpm&quot; ) PCA plot for the logCpm counts in the GSM3872434 set. p &lt;- plotPCA( logCpmPca, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;PCA plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, projDir, outDirBit, normPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, dirRel, normPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 8.3.3 scran Normalised counts are stored in the ‘logcounts’ assay typeNorm &lt;- &quot;scran&quot; # assay(sce, &quot;logcounts&quot;) scranPca &lt;- runPCA( sceDeconv[,], exprs_values = &quot;logcounts&quot; ) PCA plot for the ‘scran’ counts in the GSM3872434 set. p &lt;- plotPCA( scranPca, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;PCA plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, projDir, outDirBit, normPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, dirRel, normPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) TSNE plot for the ‘scran’ counts in the GSM3872434 set. typeNorm &lt;- &quot;scran&quot; reducedDim(sceDeconv, &quot;TSNE_scran&quot;) &lt;- reducedDim( runTSNE(sceDeconv, exprs_values = &quot;logcounts&quot;), &quot;TSNE&quot; ) p &lt;- plotReducedDim( sceDeconv, dimred = &quot;TSNE_scran&quot;, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;TSNE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sTsne.png&quot;, projDir, outDirBit, normPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sTsne.png&quot;, dirRel, normPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 8.3.4 SCTransform typeNorm &lt;- &quot;sctrans&quot; reducedDim(sce, &quot;PCA_sctrans_norm&quot;) &lt;- reducedDim( runPCA(sce, exprs_values = &quot;sctrans_norm&quot;), &quot;PCA&quot; ) PCA plot for the ‘sctrans’ counts in the GSM3872434 set. p &lt;- plotReducedDim( sce, dimred = &quot;PCA_sctrans_norm&quot;, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;PCA plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, projDir, outDirBit, normPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, dirRel, normPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) TSNE plot for the sctrans counts in the GSM3872434 set. typeNorm &lt;- &quot;sctrans&quot; reducedDim(sce, &quot;TSNE_sctrans_norm&quot;) &lt;- reducedDim( runTSNE(sce, exprs_values = &quot;sctrans_norm&quot;), &quot;TSNE&quot; ) p &lt;- plotReducedDim( sce, dimred = &quot;TSNE_sctrans_norm&quot;, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) + ggtitle(sprintf(&quot;TSNE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sTsne.png&quot;, projDir, outDirBit, normPlotDirBit, setName, setSuf, typeNorm) ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sTsne.png&quot;, dirRel, normPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Cell-wise RLE for the sctrans counts in the GSM3872434 set. p &lt;- plotRLE( sce, exprs_values = &quot;sctrans_norm&quot;, colour_by = &quot;Sample.Name&quot; ) + ggtitle(sprintf(&quot;RLE plot: %s&quot;, typeNorm)) # write plot to file: tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, projDir, outDirBit, normPlotDirBit, setName, setSuf, typeNorm) print(&quot;DEV&quot;); print(getwd()); print(tmpFn) ## [1] &quot;DEV&quot; ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/ScriptsKmWiC&quot; ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Plots/Norm/GSM3872434_sce_nz_postQc_GSM3872434_sctransRle.png&quot; ggsave(filename=tmpFn, plot=p, type=&quot;cairo-png&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sce_nz_postQc%s_%sRle.png&quot;, dirRel, normPlotDirBit, setName, setSuf, typeNorm) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 8.4 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] Cairo_1.5-12.2 BiocSingular_1.6.0 ## [3] dplyr_1.0.5 scran_1.18.7 ## [5] scater_1.18.6 ggplot2_3.3.3 ## [7] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [9] Biobase_2.50.0 GenomicRanges_1.42.0 ## [11] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [13] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [15] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [17] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 sctransform_0.3.2.9005 ## [3] tools_4.0.3 bslib_0.2.4 ## [5] utf8_1.2.1 R6_2.5.0 ## [7] irlba_2.3.3 vipor_0.4.5 ## [9] DBI_1.1.1 colorspace_2.0-0 ## [11] withr_2.4.2 tidyselect_1.1.1 ## [13] gridExtra_2.3 compiler_4.0.3 ## [15] BiocNeighbors_1.8.2 isoband_0.2.4 ## [17] DelayedArray_0.16.3 labeling_0.4.2 ## [19] bookdown_0.22 sass_0.3.1 ## [21] scales_1.1.1 stringr_1.4.0 ## [23] digest_0.6.27 rmarkdown_2.7 ## [25] XVector_0.30.0 pkgconfig_2.0.3 ## [27] htmltools_0.5.1.1 parallelly_1.24.0 ## [29] sparseMatrixStats_1.2.1 limma_3.46.0 ## [31] highr_0.9 rlang_0.4.10 ## [33] DelayedMatrixStats_1.12.3 jquerylib_0.1.3 ## [35] generics_0.1.0 farver_2.1.0 ## [37] jsonlite_1.7.2 BiocParallel_1.24.1 ## [39] RCurl_1.98-1.3 magrittr_2.0.1 ## [41] GenomeInfoDbData_1.2.4 scuttle_1.0.4 ## [43] Matrix_1.3-2 Rcpp_1.0.6 ## [45] ggbeeswarm_0.6.0 munsell_0.5.0 ## [47] fansi_0.4.2 viridis_0.6.0 ## [49] lifecycle_1.0.0 stringi_1.5.3 ## [51] yaml_2.2.1 edgeR_3.32.1 ## [53] MASS_7.3-54 zlibbioc_1.36.0 ## [55] Rtsne_0.15 plyr_1.8.6 ## [57] grid_4.0.3 listenv_0.8.0 ## [59] dqrng_0.3.0 crayon_1.4.1 ## [61] lattice_0.20-44 cowplot_1.1.1 ## [63] beachmat_2.6.4 locfit_1.5-9.4 ## [65] pillar_1.6.0 igraph_1.2.6 ## [67] future.apply_1.7.0 reshape2_1.4.4 ## [69] codetools_0.2-18 glue_1.4.2 ## [71] evaluate_0.14 vctrs_0.3.7 ## [73] png_0.1-7 gtable_0.3.0 ## [75] purrr_0.3.4 future_1.21.0 ## [77] assertthat_0.2.1 xfun_0.22 ## [79] rsvd_1.0.5 viridisLite_0.4.0 ## [81] tibble_3.1.1 beeswarm_0.3.1 ## [83] globals_0.14.0 bluster_1.0.0 ## [85] statmod_1.4.35 ellipsis_0.3.2 "],["dimRedForVizTop.html", "Chapter 9 Dimensionality reduction for visualisation 9.1 Principal Component Analysis 9.2 Load packages 9.3 Load data 9.4 PCA 9.5 t-SNE: t-Distributed Stochastic Neighbor Embedding 9.6 UMAP 9.7 Session information", " Chapter 9 Dimensionality reduction for visualisation projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit library(Cairo) In part 1 we gathered the data, aligned reads, checked quality, and normalised read counts. We will now identify genes to focus on, use visualisation to explore the data, collapse the data set, cluster cells by their expression profile and identify genes that best characterise these cell populations. These main steps are shown below (???). We’ll first explain dimensionality reduction for visualisation, using Principal Component Analysis, t-SNE and UMAP. 9.1 Principal Component Analysis In a single cell RNA-seq (scRNASeq) data set, each cell is described by the expression level of thoushands of genes. The total number of genes measured is referred to as dimensionality. Each gene measured is one dimension in the space characterising the data set. Many genes will little vary across cells and thus be uninformative when comparing cells. Also, because some genes will have correlated expression patterns, some information is redundant. Moreover, we can represent data in three dimensions, not more. So reducing the number of useful dimensions is necessary. 9.1.1 Description The data set: a matrix with one row per sample and one variable per column. Here samples are cells and each variable is the normalised read count for a given gene. The space: each cell is associated to a point in a multi-dimensional space where each gene is a dimension. The aim: to find a new set of variables defining a space with fewer dimensions while losing as little information as possible. Out of a set of variables (read counts), PCA defines new variables called Principal Components (PCs) that best capture the variability observed amongst samples (cells), see (???) for example. The number of variables does not change. Only the fraction of variance captured by each variable differs. The first PC explains the highest proportion of variance possible (bound by prperties of PCA). The second PC explains the highest proportion of variance not explained by the first PC. PCs each explain a decreasing amount of variance not explained by the previous ones. Each PC is a dimension in the new space. The total amount of variance explained by the first few PCs is usually such that excluding remaining PCs, ie dimensions, loses little information. The stronger the correlation between the initial variables, the stronger the reduction in dimensionality. PCs to keep can be chosen as those capturing at least as much as the average variance per initial variable or using a scree plot, see below. PCs are linear combinations of the initial variables. PCs represent the same amount of information as the initial set and enable its restoration. The data is not altered. We only look at it in a different way. About the mapping function from the old to the new space: it is linear it is inverse, to restore the original space it relies on orthogonal PCs so that the total variance remains the same. Two transformations of the data are necessary: center the data so that the sample mean for each column is 0 so the covariance matrix of the intial matrix takes a simple form scale variance to 1, ie standardize, to avoid PCA loading on variables with large variance. 9.1.2 Example Here we will make a simple data set of 100 samples and 2 variables, perform PCA and visualise on the initial plane the data set and PCs (???). library(ggplot2) fontsize &lt;- theme(axis.text=element_text(size=12), axis.title=element_text(size=16)) Let’s make and plot a data set. set.seed(123) #sets the seed for random number generation. x &lt;- 1:100 #creates a vector x with numbers from 1 to 100 ex &lt;- rnorm(100, 0, 30) #100 normally distributed rand. nos. w/ mean=0, s.d.=30 ey &lt;- rnorm(100, 0, 30) # &quot; &quot; y &lt;- 30 + 2 * x #sets y to be a vector that is a linear function of x x_obs &lt;- x + ex #adds &quot;noise&quot; to x y_obs &lt;- y + ey #adds &quot;noise&quot; to y P &lt;- cbind(x_obs,y_obs) #places points in matrix plot(P,asp=1,col=1) #plot points points(mean(x_obs),mean(y_obs),col=3, pch=19) #show center Center the data and compute covariance matrix. M &lt;- cbind(x_obs - mean(x_obs), y_obs - mean(y_obs)) #centered matrix MCov &lt;- cov(M) #creates covariance matrix Compute the principal axes, ie eigenvectors and corresponding eigenvalues. An eigenvector is a direction and an eigenvalue is a number measuring the spread of the data in that direction. The eigenvector with the highest eigenvalue is the first principal component. The eigenvectors of the covariance matrix provide the principal axes, and the eigenvalues quantify the fraction of variance explained in each component. eigenValues &lt;- eigen(MCov)$values #compute eigenvalues eigenVectors &lt;- eigen(MCov)$vectors #compute eigenvectors # or use &#39;singular value decomposition&#39; of the matrix d &lt;- svd(M)$d #the singular values v &lt;- svd(M)$v #the right singular vectors Let’s plot the principal axes. First PC: # PC 1: plot(P,asp=1,col=1) #plot points points(mean(x_obs),mean(y_obs),col=3, pch=19) #show center lines(x_obs,eigenVectors[2,1]/eigenVectors[1,1]*M[x]+mean(y_obs),col=8) Second PC: plot(P,asp=1,col=1) #plot points points(mean(x_obs),mean(y_obs),col=3, pch=19) #show center # PC 1: lines(x_obs,eigenVectors[2,1]/eigenVectors[1,1]*M[x]+mean(y_obs),col=8) # PC 2: lines(x_obs,eigenVectors[2,2]/eigenVectors[1,2]*M[x]+mean(y_obs),col=8) Add the projections of the points onto the first PC: plot(P,asp=1,col=1) #plot points points(mean(x_obs),mean(y_obs),col=3, pch=19) #show center # PC 1: lines(x_obs,eigenVectors[2,1]/eigenVectors[1,1]*M[x]+mean(y_obs),col=8) # PC 2: lines(x_obs,eigenVectors[2,2]/eigenVectors[1,2]*M[x]+mean(y_obs),col=8) # add projecions: trans &lt;- (M%*%v[,1])%*%v[,1] #compute projections of points P_proj &lt;- scale(trans, center=-cbind(mean(x_obs),mean(y_obs)), scale=FALSE) points(P_proj, col=4,pch=19,cex=0.5) #plot projections segments(x_obs,y_obs,P_proj[,1],P_proj[,2],col=4,lty=2) #connect to points Compute PCs with prcomp(). pca_res &lt;- prcomp(M) summary(pca_res) ## Importance of components: ## PC1 PC2 ## Standard deviation 73.827 28.279 ## Proportion of Variance 0.872 0.128 ## Cumulative Proportion 0.872 1.000 var_explained &lt;- pca_res$sdev^2/sum(pca_res$sdev^2) var_explained ## [1] 0.8720537 0.1279463 Check amount of variance captured by PCs on a scree plot. # Show scree plot: plot(pca_res) Plot with ggplot. df_pc &lt;- data.frame(pca_res$x) g &lt;- ggplot(df_pc, aes(PC1, PC2)) + geom_point(size=2) + # draw points labs(title=&quot;PCA&quot;, subtitle=&quot;With principal components PC1 and PC2 as X and Y axis&quot;) + coord_cartesian(xlim = 1.2 * c(min(df_pc$PC1), max(df_pc$PC1)), ylim = 1.2 * c(min(df_pc$PC2), max(df_pc$PC2))) g &lt;- g + geom_hline(yintercept=0) g &lt;- g + geom_vline(xintercept=0) g Or use ggfortify autoplot(). # ggfortify library(ggfortify) g &lt;- autoplot(pca_res) g &lt;- g + geom_hline(yintercept=0) g &lt;- g + geom_vline(xintercept=0) g Going from 2D to 3D (figure from (???)): 9.2 Load packages library(scater) # for QC and plots 9.3 Load data We will load the R file keeping the SCE object with the normalised counts for 500 cells per sample. setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_5hCellPerSpl&quot; # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 16629 5500 ## metadata(0): ## assays(2): counts logcounts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Barcode Run ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): head(rowData(sce)) ## DataFrame with 6 rows and 11 columns ## ensembl_gene_id external_gene_name chromosome_name ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000237491 ENSG00000237491 LINC01409 1 ## ENSG00000225880 ENSG00000225880 LINC00115 1 ## ENSG00000230368 ENSG00000230368 FAM41C 1 ## ENSG00000230699 ENSG00000230699 1 ## ENSG00000188976 ENSG00000188976 NOC2L 1 ## ENSG00000187961 ENSG00000187961 KLHL17 1 ## start_position end_position strand Symbol ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;character&gt; ## ENSG00000237491 778747 810065 1 AL669831.5 ## ENSG00000225880 826206 827522 -1 LINC00115 ## ENSG00000230368 868071 876903 -1 FAM41C ## ENSG00000230699 911435 914948 1 AL645608.3 ## ENSG00000188976 944203 959309 -1 NOC2L ## ENSG00000187961 960584 965719 1 KLHL17 ## Type mean detected gene_sparsity ## &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000237491 Gene Expression 0.02785355 2.706672 0.977951 ## ENSG00000225880 Gene Expression 0.01376941 1.340222 0.985699 ## ENSG00000230368 Gene Expression 0.02027381 1.946076 0.980821 ## ENSG00000230699 Gene Expression 0.00144251 0.144251 0.997704 ## ENSG00000188976 Gene Expression 0.17711393 14.511645 0.835565 ## ENSG00000187961 Gene Expression 0.00354070 0.348825 0.995935 #any(duplicated(rowData(nz.sce)$ensembl_gene_id)) # some function(s) used below complain about &#39;strand&#39; already being used in row data, # so rename that column now: colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; 9.4 PCA Perform PCA, keep outcome in same object. nbPcToComp &lt;- 50 # compute PCA: #sce &lt;- runPCA(sce, ncomponents = nbPcToComp, method = &quot;irlba&quot;) sce &lt;- runPCA(sce, ncomponents = nbPcToComp) Display scree plot. # with reducedDim sce.pca &lt;- reducedDim(sce, &quot;PCA&quot;) attributes(sce.pca)$percentVar ## [1] 16.5531107 10.0199888 4.3629600 3.7422222 1.9514046 1.7700235 ## [7] 1.6280021 1.2600210 1.1413238 0.8701746 0.7881998 0.6933591 ## [13] 0.6465512 0.5898302 0.5307767 0.4365192 0.3893798 0.3791947 ## [19] 0.3639489 0.3434668 0.3324412 0.2924477 0.2857375 0.2708208 ## [25] 0.2674348 0.2620022 0.2529266 0.2422967 0.2388725 0.2374630 ## [31] 0.2339333 0.2312881 0.2296763 0.2261449 0.2229721 0.2218208 ## [37] 0.2215260 0.2195930 0.2168220 0.2151280 0.2129703 0.2114219 ## [43] 0.2099425 0.2091484 0.2073056 0.2054996 0.2046071 0.2042045 ## [49] 0.2038521 0.2028053 barplot(attributes(sce.pca)$percentVar, main=sprintf(&quot;Scree plot for the %s first PCs&quot;, nbPcToComp), names.arg=1:nbPcToComp, cex.names = 0.8) Display cells on a plot for the first 2 PCs, colouring by ‘Sample’ and setting size to match ‘total_features’. The proximity of cells reflects the similarity of their expression profiles. g &lt;- plotPCA(sce, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot; ) g One can also split the plot by sample. g &lt;- g + facet_wrap(sce$source_name ~ .) g Or plot several PCs at once, using plotReducedDim(): plotReducedDim(sce, dimred=&quot;PCA&quot;, ncomponents=3, colour_by = &quot;Sample.Name&quot;) + fontsize 9.4.1 Correlation between PCs and the total number of features detected The PCA plot above shows cells as symbols whose size depends on the total number of features or library size. It suggests there may be a correlation between PCs and these variables. Let’s check: colData(sce)$source_name &lt;- factor(colData(sce)$source_name) colData(sce)$block &lt;- factor(colData(sce)$block) r2mat &lt;- getExplanatoryPCs(sce) #r2mat &lt;- getExplanatoryPCs(sce, # variables = c(&quot;Run&quot;, &quot;source_name&quot;)) # #variables = c(&quot;Run&quot;, &quot;Sample.Name&quot;)) # #variables = c(&quot;Run&quot;, &quot;Sample.Name&quot;, &quot;source_name&quot;)) r2mat ## Barcode Run Sample.Name source_name sum detected ## PC1 NaN 31.19206 31.19206 6.832312 0.78375254 6.27337092 ## PC2 NaN 39.34643 39.34643 25.662855 5.25084021 0.09729984 ## PC3 NaN 26.52168 26.52168 15.602707 37.70434045 46.35383380 ## PC4 NaN 60.16877 60.16877 46.786763 4.07129265 4.76770624 ## PC5 NaN 29.51006 29.51006 11.510990 4.47573115 7.04988227 ## PC6 NaN 45.52405 45.52405 15.277803 0.51188492 0.02608563 ## PC7 NaN 37.88650 37.88650 30.240815 0.05544668 0.94875299 ## PC8 NaN 56.10658 56.10658 45.833901 0.40672700 0.19891021 ## PC9 NaN 22.89370 22.89370 11.311513 3.38048004 3.34248462 ## PC10 NaN 36.83412 36.83412 2.715106 0.08205300 0.58453373 ## subsets_Mito_sum subsets_Mito_detected subsets_Mito_percent total ## PC1 5.997587644 18.4166606 4.54957617 0.78375254 ## PC2 0.004462683 1.5357613 16.48789805 5.25084021 ## PC3 24.652807031 9.3220632 3.22468580 37.70434045 ## PC4 0.580352132 0.7908534 0.09236766 4.07129265 ## PC5 9.434101761 17.9512413 7.94959368 4.47573115 ## PC6 11.954946849 14.0284466 38.80948618 0.51188492 ## PC7 0.082920314 1.7025755 0.36780972 0.05544668 ## PC8 0.480586751 3.5317294 6.68352338 0.40672700 ## PC9 4.050632836 4.7046742 1.55733687 3.38048004 ## PC10 0.025858060 0.1133214 0.68597039 0.08205300 ## block setName discard outlier cell_sparsity sizeFactor ## PC1 6.832312 NA 0.04444383 0.2296869 6.27289382 5.197542e+00 ## PC2 25.662855 NA 8.43564022 9.2039749 0.09799246 1.941465e-02 ## PC3 15.602707 NA 5.93493152 9.1094043 46.37551341 3.707371e+01 ## PC4 46.786763 NA 2.77398719 4.3293501 4.75796689 5.966918e+00 ## PC5 11.510990 NA 0.85156882 0.3470523 7.04816034 4.575358e+00 ## PC6 15.277803 NA 19.45181700 16.1908399 0.02593408 5.747692e-06 ## PC7 30.240815 NA 0.76305157 1.3702499 0.94864939 1.979993e-01 ## PC8 45.833901 NA 0.99037548 1.0249066 0.19815769 2.156675e-01 ## PC9 11.311513 NA 0.28760449 0.1623147 3.34504092 3.569516e+00 ## PC10 2.715106 NA 0.24819364 0.0366594 0.58349267 3.839716e-01 dat &lt;- cbind(colData(sce)[,c(&quot;Sample.Name&quot;, &quot;source_name&quot;, &quot;sum&quot;, &quot;detected&quot;, #&quot;percent_top_200&quot;, &quot;subsets_Mito_percent&quot;)], reducedDim(sce,&quot;PCA&quot;)) dat &lt;- data.frame(dat) dat$sum &lt;- log2(dat$sum) ggplot(dat, aes(x=sum, y=PC1, shape=source_name, col=Sample.Name)) + geom_point() + geom_smooth(method=lm, inherit.aes = FALSE, aes(x=sum, y=PC1)) #ggplot(dat, aes(x=percent_top_200, y=PC2, shape=source_name, col=Sample.Name)) + # geom_point() + # geom_smooth(method=lm, inherit.aes = FALSE, aes(x=percent_top_200, y=PC2)) ggplot(dat, aes(x=detected, y=PC3, shape=source_name, col=Sample.Name)) + geom_point() + geom_smooth(method=lm, inherit.aes = FALSE, aes(x=detected, y=PC3)) ggplot(dat, aes(x=subsets_Mito_percent, y=PC2, shape=source_name, col=Sample.Name)) + geom_point() + geom_smooth(method=lm, inherit.aes = FALSE, aes(x=subsets_Mito_percent, y=PC2)) ggplot(dat, aes(x=source_name, y=PC7, shape=source_name, col=Sample.Name)) + geom_boxplot() 9.5 t-SNE: t-Distributed Stochastic Neighbor Embedding The Stochastic Neighbor Embedding (SNE) approach address two shortcomings of PCA that captures the global covariance structure with a linear combination of initial variables: by preserving the local structure allowing for non-linear projections. It uses two distributions of the pairwise similarities between data points: in the input data set and in the low-dimensional space. SNE aims at preserving neighbourhoods. For each points, it computes probabilities of chosing each other point as its neighbour based on a Normal distribution depending on 1) the distance matrix and 2) the size of the neighbourhood (perplexity). SNE aims at finding a low-dimension space (eg 2D-plane) such that the similarity matrix deriving from it is as similar as possible as that from the high-dimension space. To address the fact that in low dimension, points are brought together, the similarity matrix in the low-dimension is allowed to follow a t-distribution. Two characteristics matter: perplexity, to indicate the relative importance of the local and global patterns in structure of the data set, usually use a value of 50, stochasticity; running the analysis will produce a different map every time, unless the seed is set. See misread-tsne. 9.5.1 Perplexity Compute t-SNE with default perplexity, ie 50. # runTSNE default perpexity if min(50, floor(ncol(object)/5)) sce &lt;- runTSNE(sce, dimred=&quot;PCA&quot;, perplexity=50, rand_seed=123) Plot t-SNE: tsne50 &lt;- plotTSNE(sce, colour_by=&quot;Sample.Name&quot;, size_by=&quot;sum&quot;) + fontsize + ggtitle(&quot;Perplexity = 50&quot;) tsne50 Compute t-SNE for several perplexity values: tsne5.run &lt;- runTSNE(sce, use_dimred=&quot;PCA&quot;, perplexity=5, rand_seed=123) tsne5 &lt;- plotTSNE(tsne5.run, colour_by=&quot;Sample.Name&quot;) + fontsize + ggtitle(&quot;Perplexity = 5&quot;) #tsne200.run &lt;- runTSNE(sce, use_dimred=&quot;PCA&quot;, perplexity=200, rand_seed=123) #tsne200 &lt;- plotTSNE(tsne200.run, colour_by=&quot;Sample.Name&quot;) + fontsize + ggtitle(&quot;Perplexity = 200&quot;) tsne500.run &lt;- runTSNE(sce, use_dimred=&quot;PCA&quot;, perplexity=500, rand_seed=123) tsne500 &lt;- plotTSNE(tsne500.run, colour_by=&quot;Sample.Name&quot;) + fontsize + ggtitle(&quot;Perplexity = 500&quot;) #tsne1000.run &lt;- runTSNE(sce, use_dimred=&quot;PCA&quot;, perplexity=1000, rand_seed=123) #tsne1000 &lt;- plotTSNE(tsne1000.run, colour_by=&quot;Sample.Name&quot;) + fontsize + ggtitle(&quot;Perplexity = 1000&quot;) tsne5 #tsne50 #tsne200 tsne500 9.5.2 Stochasticity Use a different seed with the same perplexity 50. tsne50.b &lt;- runTSNE(sce, use_dimred=&quot;PCA&quot;, perplexity=50, rand_seed=456) tsne50.b &lt;- plotTSNE(tsne50.b, colour_by=&quot;Sample.Name&quot;, size_by=&quot;sum&quot;) + fontsize + ggtitle(&quot;Perplexity = 50, seed 456&quot;) tsne50.b 9.6 UMAP Another neighbour graph method. Similar to t-SNE, but that is determistic, faster and claims to preserve both local and global structures. Compute UMAP. set.seed(123) sce &lt;- runUMAP(sce, dimred=&quot;PCA&quot;) Plot UMAP: sce.umap &lt;- plotUMAP(sce, colour_by=&quot;Sample.Name&quot;, size_by=&quot;sum&quot;) + fontsize + ggtitle(&quot;UMAP&quot;) sce.umap Save SCE object: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dimRed.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce, tmpFn) 9.7 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] scater_1.18.6 SingleCellExperiment_1.12.0 ## [3] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [5] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [7] IRanges_2.24.1 S4Vectors_0.28.1 ## [9] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [11] matrixStats_0.58.0 ggfortify_0.4.11 ## [13] ggplot2_3.3.3 Cairo_1.5-12.2 ## [15] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] nlme_3.1-152 bitops_1.0-7 ## [3] RcppAnnoy_0.0.18 tools_4.0.3 ## [5] bslib_0.2.4 utf8_1.2.1 ## [7] R6_2.5.0 irlba_2.3.3 ## [9] vipor_0.4.5 uwot_0.1.10 ## [11] DBI_1.1.1 mgcv_1.8-35 ## [13] colorspace_2.0-0 withr_2.4.2 ## [15] tidyselect_1.1.1 gridExtra_2.3 ## [17] compiler_4.0.3 BiocNeighbors_1.8.2 ## [19] DelayedArray_0.16.3 labeling_0.4.2 ## [21] bookdown_0.22 sass_0.3.1 ## [23] scales_1.1.1 stringr_1.4.0 ## [25] digest_0.6.27 rmarkdown_2.7 ## [27] XVector_0.30.0 pkgconfig_2.0.3 ## [29] htmltools_0.5.1.1 sparseMatrixStats_1.2.1 ## [31] highr_0.9 rlang_0.4.10 ## [33] DelayedMatrixStats_1.12.3 jquerylib_0.1.3 ## [35] farver_2.1.0 generics_0.1.0 ## [37] jsonlite_1.7.2 BiocParallel_1.24.1 ## [39] dplyr_1.0.5 RCurl_1.98-1.3 ## [41] magrittr_2.0.1 BiocSingular_1.6.0 ## [43] GenomeInfoDbData_1.2.4 scuttle_1.0.4 ## [45] Matrix_1.3-2 Rcpp_1.0.6 ## [47] ggbeeswarm_0.6.0 munsell_0.5.0 ## [49] fansi_0.4.2 viridis_0.6.0 ## [51] lifecycle_1.0.0 stringi_1.5.3 ## [53] yaml_2.2.1 zlibbioc_1.36.0 ## [55] Rtsne_0.15 grid_4.0.3 ## [57] crayon_1.4.1 lattice_0.20-44 ## [59] cowplot_1.1.1 beachmat_2.6.4 ## [61] splines_4.0.3 pillar_1.6.0 ## [63] codetools_0.2-18 glue_1.4.2 ## [65] evaluate_0.14 vctrs_0.3.7 ## [67] gtable_0.3.0 purrr_0.3.4 ## [69] tidyr_1.1.3 assertthat_0.2.1 ## [71] xfun_0.22 rsvd_1.0.5 ## [73] RSpectra_0.16-0 viridisLite_0.4.0 ## [75] tibble_3.1.1 beeswarm_0.3.1 ## [77] ellipsis_0.3.2 projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool library(knitr) "],["identifying-confounding-factors-caron-set.html", "Chapter 10 Identifying confounding factors - Caron set 10.1 Load object 10.2 PCA 10.3 Normalised counts 10.4 Session information", " Chapter 10 Identifying confounding factors - Caron set knitr::opts_chunk$set(dev=&quot;CairoPNG&quot;) normPlotDirBit &lt;- &quot;Plots/Norm&quot; # &quot;ConfoundPlots&quot; #setNameUpp &lt;- &quot;Caron&quot; #setNameLow &lt;- &quot;caron&quot; setName &lt;- tolower(&quot;Caron&quot;) setSuf &lt;- &quot;_5hCellPerSpl&quot; typeNorm &lt;- &quot;scran&quot; projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit caron 10.1 Load object # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) tmpFn ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl.Rds&quot; #getwd() #file.exists(tmpFn) sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 16629 5500 ## metadata(0): ## assays(2): counts logcounts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Barcode Run ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): 10.2 PCA Remember scran PCA: Normalised counts are stored in ‘logcounts’ assay # scranPca &lt;- runPCA( sce, exprs_values = &quot;logcounts&quot; ) PCA plot for the ‘scran’ counts in the caron set. tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sce_nz_postQc%s_%sPca.png&quot;, #projDir, outDirBit, normPlotDirBit, setName, setSuf, typeNorm) dirRel, normPlotDirBit, setName, setSuf, typeNorm) tmpFn knitr::include_graphics(tmpFn, auto_pdf = TRUE) #options(BiocSingularParam.default=IrlbaParam()) options(BiocSingularParam.default=ExactParam()) qclust &lt;- quickCluster(sce, min.size = 30, use.ranks = FALSE) sce &lt;- computeSumFactors(sce, sizes = 15, clusters = qclust) sce &lt;- logNormCounts(sce) Perform PCA: reducedDim(sce, &quot;PCA&quot;) &lt;- reducedDim( runPCA(sce, exprs_values = &quot;logcounts&quot;, ncomponents = 10), &quot;PCA&quot;) plotPCA( sce, colour_by = &quot;Sample.Name&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) assay(sce, &quot;logcounts_raw&quot;) &lt;- log2(counts(sce)+1) # on norm count https://biocellgen-public.svi.edu.au/mig_2019_scrnaseq-workshop/public/normalization-confounders-and-batch-correction.html#identifying-confounding-factors # on logcounts_raw https://scrnaseq-course.cog.sanger.ac.uk/website/cleaning-the-expression-matrix.html#correlations-with-pcs # a bit long # issue with scale, trying with explanPc/100 # see next chunk too explanPc &lt;- getExplanatoryPCs( sce, exprs_values = &quot;logcounts_raw&quot;, variables = c( &quot;sum&quot;, &quot;detected&quot;, &quot;source_name&quot;, &quot;Sample.Name&quot;, &quot;subsets_Mito_percent&quot; ) ) plotExplanatoryPCs(explanPc/100) # on logcounts_raw # https://biocellgen-public.svi.edu.au/mig_2019_scrnaseq-workshop/public/normalization-confounders-and-batch-correction.html#identifying-confounding-factors plotExplanatoryVariables( sce, exprs_values = &quot;logcounts_raw&quot;, #exprs_values = &quot;counts&quot;, #exprs_values = &quot;logcounts&quot;, variables = c( &quot;sum&quot;, &quot;detected&quot;, &quot;source_name&quot;, &quot;Sample.Name&quot;, &quot;subsets_Mito_percent&quot; ) ) 10.3 Normalised counts Correlation with PCs: logcounts (normalised): # on norm count https://biocellgen-public.svi.edu.au/mig_2019_scrnaseq-workshop/public/normalization-confounders-and-batch-correction.html#identifying-confounding-factors # on logcounts_raw https://scrnaseq-course.cog.sanger.ac.uk/website/cleaning-the-expression-matrix.html#correlations-with-pcs # a bit long colData(sce)$source_name &lt;- factor(colData(sce)$source_name) explanPc &lt;- getExplanatoryPCs(sce, #exprs_values = &quot;logcounts&quot;, # default variables = c( &quot;sum&quot;, &quot;detected&quot;, &quot;source_name&quot;, &quot;Sample.Name&quot;, &quot;subsets_Mito_percent&quot; ) ) plotExplanatoryPCs(explanPc/100) Explanatory variables: logcounts (normalised): # on logcounts_raw # https://biocellgen-public.svi.edu.au/mig_2019_scrnaseq-workshop/public/normalization-confounders-and-batch-correction.html#identifying-confounding-factors plotExplanatoryVariables( sce, # exprs_values = &quot;logcounts&quot;, # default variables = c( &quot;sum&quot;, &quot;detected&quot;, &quot;source_name&quot;, &quot;Sample.Name&quot;, &quot;subsets_Mito_percent&quot; ) ) rm(sce) 10.4 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] Cairo_1.5-12.2 BiocSingular_1.6.0 ## [3] dplyr_1.0.5 scran_1.18.7 ## [5] scater_1.18.6 ggplot2_3.3.3 ## [7] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [9] Biobase_2.50.0 GenomicRanges_1.42.0 ## [11] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [13] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [15] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [17] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] viridis_0.6.0 edgeR_3.32.1 ## [3] sass_0.3.1 jsonlite_1.7.2 ## [5] viridisLite_0.4.0 DelayedMatrixStats_1.12.3 ## [7] scuttle_1.0.4 bslib_0.2.4 ## [9] assertthat_0.2.1 statmod_1.4.35 ## [11] highr_0.9 dqrng_0.3.0 ## [13] GenomeInfoDbData_1.2.4 vipor_0.4.5 ## [15] yaml_2.2.1 pillar_1.6.0 ## [17] lattice_0.20-44 limma_3.46.0 ## [19] glue_1.4.2 beachmat_2.6.4 ## [21] digest_0.6.27 XVector_0.30.0 ## [23] colorspace_2.0-0 cowplot_1.1.1 ## [25] htmltools_0.5.1.1 Matrix_1.3-2 ## [27] pkgconfig_2.0.3 bookdown_0.22 ## [29] zlibbioc_1.36.0 purrr_0.3.4 ## [31] scales_1.1.1 BiocParallel_1.24.1 ## [33] tibble_3.1.1 farver_2.1.0 ## [35] generics_0.1.0 ellipsis_0.3.2 ## [37] withr_2.4.2 magrittr_2.0.1 ## [39] crayon_1.4.1 evaluate_0.14 ## [41] fansi_0.4.2 bluster_1.0.0 ## [43] beeswarm_0.3.1 tools_4.0.3 ## [45] lifecycle_1.0.0 stringr_1.4.0 ## [47] locfit_1.5-9.4 munsell_0.5.0 ## [49] DelayedArray_0.16.3 irlba_2.3.3 ## [51] compiler_4.0.3 jquerylib_0.1.3 ## [53] rsvd_1.0.5 rlang_0.4.10 ## [55] grid_4.0.3 RCurl_1.98-1.3 ## [57] BiocNeighbors_1.8.2 igraph_1.2.6 ## [59] labeling_0.4.2 bitops_1.0-7 ## [61] rmarkdown_2.7 codetools_0.2-18 ## [63] gtable_0.3.0 DBI_1.1.1 ## [65] R6_2.5.0 gridExtra_2.3 ## [67] utf8_1.2.1 stringi_1.5.3 ## [69] ggbeeswarm_0.6.0 Rcpp_1.0.6 ## [71] vctrs_0.3.7 tidyselect_1.1.1 ## [73] xfun_0.22 sparseMatrixStats_1.2.1 "],["featSelecTop.html", "Chapter 11 Feature selection 11.1 Load data 11.2 Feature selection with scran 11.3 Session information", " Chapter 11 Feature selection library(ggplot2) library(scater) library(scran) library(Cairo) projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool setName &lt;- params$setName setSuf &lt;- params$setSuf if(params$bookType == &quot;mk&quot;){ dirRel &lt;- &quot;..&quot; setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_5hCellPerSpl&quot; } fontsize &lt;- theme(axis.text=element_text(size=12), axis.title=element_text(size=16)) 11.1 Load data We will load the R file keeping the SCE object with the normalised counts for 500 cells per sample. # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dimRed.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dimRed.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 16629 5500 ## metadata(0): ## assays(2): counts logcounts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Barcode Run ... cell_sparsity sizeFactor ## reducedDimNames(3): PCA TSNE UMAP ## altExpNames(0): head(rowData(sce)) ## DataFrame with 6 rows and 11 columns ## ensembl_gene_id external_gene_name chromosome_name ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000237491 ENSG00000237491 LINC01409 1 ## ENSG00000225880 ENSG00000225880 LINC00115 1 ## ENSG00000230368 ENSG00000230368 FAM41C 1 ## ENSG00000230699 ENSG00000230699 1 ## ENSG00000188976 ENSG00000188976 NOC2L 1 ## ENSG00000187961 ENSG00000187961 KLHL17 1 ## start_position end_position strandNum Symbol ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;character&gt; ## ENSG00000237491 778747 810065 1 AL669831.5 ## ENSG00000225880 826206 827522 -1 LINC00115 ## ENSG00000230368 868071 876903 -1 FAM41C ## ENSG00000230699 911435 914948 1 AL645608.3 ## ENSG00000188976 944203 959309 -1 NOC2L ## ENSG00000187961 960584 965719 1 KLHL17 ## Type mean detected gene_sparsity ## &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000237491 Gene Expression 0.02785355 2.706672 0.977951 ## ENSG00000225880 Gene Expression 0.01376941 1.340222 0.985699 ## ENSG00000230368 Gene Expression 0.02027381 1.946076 0.980821 ## ENSG00000230699 Gene Expression 0.00144251 0.144251 0.997704 ## ENSG00000188976 Gene Expression 0.17711393 14.511645 0.835565 ## ENSG00000187961 Gene Expression 0.00354070 0.348825 0.995935 #any(duplicated(rowData(sce)$ensembl_gene_id)) # some function(s) used below complain about &#39;strand&#39; already being used in row data, # so rename that column now: colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; assayNames(sce) ## [1] &quot;counts&quot; &quot;logcounts&quot; 11.2 Feature selection with scran scRNASeq measures the expression of thousands of genes in each cell. The biological question asked in a study will most often relate to a fraction of these genes only, linked for example to differences between cell types, drivers of differentiation, or response to perturbation. Most high-throughput molecular data include variation created by the assay itself, not biology, i.e. technical noise, for example caused by sampling during RNA capture and library preparation. In scRNASeq, this technical noise will result in most genes being detected at different levels. This noise may hinder the detection of the biological signal. Let’s identify Highly Variables Genes (HVGs) with the aim to find those underlying the heterogeneity observed across cells. 11.2.1 Modelling and removing technical noise Some assays allow the inclusion of known molecules in a known amount covering a wide range, from low to high abundance: spike-ins. The technical noise is assessed based on the amount of spike-ins used, the corresponding read counts obtained and their variation across cells. The variance in expression can then be decomposed into the biolgical and technical components. UMI-based assays do not (yet?) allow spike-ins. But one can still identify HVGs, that is genes with the highest biological component. Assuming that expression does not vary across cells for most genes, the total variance for these genes mainly reflects technical noise. The latter can thus be assessed by fitting a trend to the variance in expression. The fitted value will be the estimate of the technical component. Let’s fit a trend to the variance, using modelGeneVar(). dec.sce &lt;- modelGeneVar(sce) Let’s plot variance against mean of expression (log scale) and the mean-dependent trend fitted to the variance: # Visualizing the fit: var.fit &lt;- metadata(dec.sce) plot(var.fit$mean, var.fit$var, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curve(var.fit$trend(x), col=&quot;dodgerblue&quot;, add=TRUE, lwd=2) In the absence of spike-in data, one can attempt to create a trend by making some distributional assumptions about the noise. For example, UMI counts typically exhibit near-Poisson variation if we only consider technical noise from library preparation and sequencing. This can be used to construct a mean-variance trend in the log-counts with the modelGeneVarByPoisson() function. Note the increased residuals of the high-abundance genes, which can be interpreted as the amount of biological variation that was assumed to be “uninteresting” when fitting the gene-based trend above. set.seed(0010101) dec.pois.sce &lt;- modelGeneVarByPoisson(sce) dec.pois.sce &lt;- dec.pois.sce[order(dec.pois.sce$bio, decreasing=TRUE),] head(dec.pois.sce) ## DataFrame with 6 rows and 6 columns ## mean total tech bio p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000244734 2.575807 12.54130 0.957640 11.58366 0 0 ## ENSG00000188536 1.914380 10.19250 1.067743 9.12476 0 0 ## ENSG00000206172 1.667508 9.33088 1.056235 8.27465 0 0 ## ENSG00000223609 0.826927 4.70420 0.739370 3.96483 0 0 ## ENSG00000019582 2.844653 4.33650 0.880604 3.45590 0 0 ## ENSG00000206177 0.613229 3.53194 0.593093 2.93885 0 0 Plot: plot(dec.pois.sce$mean, dec.pois.sce$total, pch=16, xlab=&quot;Mean of log-expression&quot;, ylab=&quot;Variance of log-expression&quot;) curve(metadata(dec.pois.sce)$trend(x), col=&quot;dodgerblue&quot;, add=TRUE) Interestingly, trends based purely on technical noise tend to yield large biological components for highly-expressed genes. This often includes so-called “house-keeping” genes coding for essential cellular components such as ribosomal proteins, which are considered uninteresting for characterizing cellular heterogeneity. These observations suggest that a more accurate noise model does not necessarily yield a better ranking of HVGs, though one should keep an open mind - house-keeping genes are regularly DE in a variety of conditions (Glare et al. 2002; Nazari, Parham, and Maleki 2015; Guimaraes and Zavolan 2016), and the fact that they have large biological components indicates that there is strong variation across cells that may not be completely irrelevant. 11.2.2 Choosing some HVGs Identify the top 20 HVGs by sorting genes in decreasing order of biological component. # order genes by decreasing order of biological component o &lt;- order(dec.sce$bio, decreasing=TRUE) # check top and bottom of sorted table head(dec.sce[o,]) ## DataFrame with 6 rows and 6 columns ## mean total tech bio p.value ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000244734 2.575807 12.54130 1.571475 10.96983 0.00000e+00 ## ENSG00000188536 1.914380 10.19250 1.470369 8.72213 0.00000e+00 ## ENSG00000206172 1.667508 9.33088 1.383903 7.94698 0.00000e+00 ## ENSG00000223609 0.826927 4.70420 0.866452 3.83775 1.01388e-200 ## ENSG00000206177 0.613229 3.53194 0.676622 2.85532 2.03444e-182 ## ENSG00000019582 2.844653 4.33650 1.562464 2.77404 4.82497e-34 ## FDR ## &lt;numeric&gt; ## ENSG00000244734 0.00000e+00 ## ENSG00000188536 0.00000e+00 ## ENSG00000206172 0.00000e+00 ## ENSG00000223609 4.21472e-197 ## ENSG00000206177 6.76573e-179 ## ENSG00000019582 1.33716e-31 tail(dec.sce[o,]) ## DataFrame with 6 rows and 6 columns ## mean total tech bio p.value FDR ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000063177 3.03243 1.25207 1.54591 -0.293832 0.902543 0.963192 ## ENSG00000173812 3.07081 1.23210 1.54264 -0.310539 0.915089 0.968993 ## ENSG00000108654 2.36375 1.25412 1.57345 -0.319334 0.916823 0.970088 ## ENSG00000115268 3.84069 1.14533 1.47476 -0.329431 0.936161 0.981326 ## ENSG00000149806 2.86602 1.23055 1.56085 -0.330302 0.925504 0.974980 ## ENSG00000174748 3.78383 1.14424 1.48200 -0.337760 0.939933 0.983367 # choose the top 20 genes with the highest biological component chosen.genes.index &lt;- o[1:20] Show the top 20 HVGs on the plot displaying the variance against the mean expression: plot(var.fit$mean, var.fit$var) curve(var.fit$trend(x), col=&quot;red&quot;, lwd=2, add=TRUE) points(var.fit$mean[chosen.genes.index], var.fit$var[chosen.genes.index], col=&quot;orange&quot;) Rather than choosing a fixed number of top genes, one may define ‘HVGs’ as genes with a positive biological component, ie whose variance is higher than the fitted value for the corresponding mean expression. Select and show these ‘HVGs’ on the plot displaying the variance against the mean expression: hvgBool &lt;- dec.sce$bio &gt; 0 table(hvgBool) ## hvgBool ## FALSE TRUE ## 7333 9296 hvg.index &lt;- which(hvgBool) plot(var.fit$mean, var.fit$var) curve(var.fit$trend(x), col=&quot;red&quot;, lwd=2, add=TRUE) points(var.fit$mean[hvg.index], var.fit$var[hvg.index], col=&quot;orange&quot;) Save objects to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_featSel.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(list(&quot;dec.sce&quot;=dec.sce,&quot;hvg.index&quot;=hvg.index), tmpFn) rm(var.fit, hvgBool, hvg.index) HVGs may be driven by outlier cells. So let’s plot the distribution of expression values for the genes with the largest biological components. First, get gene names to replace ensembl IDs on plot. # the count matrix rows are named with ensembl gene IDs. Let&#39;s label gene with their name instead: # row indices of genes in rowData(sce) tmpInd &lt;- which(rowData(sce)$ensembl_gene_id %in% rownames(dec.sce)[chosen.genes.index]) # check: rowData(sce)[tmpInd,c(&quot;ensembl_gene_id&quot;,&quot;external_gene_name&quot;)] ## DataFrame with 20 rows and 2 columns ## ensembl_gene_id external_gene_name ## &lt;character&gt; &lt;character&gt; ## ENSG00000211592 ENSG00000211592 IGKC ## ENSG00000145335 ENSG00000145335 SNCA ## ENSG00000170180 ENSG00000170180 GYPA ## ENSG00000019582 ENSG00000019582 CD74 ## ENSG00000204287 ENSG00000204287 HLA-DRA ## ... ... ... ## ENSG00000188536 ENSG00000188536 HBA2 ## ENSG00000206172 ENSG00000206172 HBA1 ## ENSG00000169877 ENSG00000169877 AHSP ## ENSG00000004939 ENSG00000004939 SLC4A1 ## ENSG00000090013 ENSG00000090013 BLVRB # store names: tmpName &lt;- rowData(sce)[tmpInd,&quot;external_gene_name&quot;] # the gene name may not be known, so keep the ensembl gene ID in that case: tmpName[tmpName==&quot;&quot;] &lt;- rowData(sce)[tmpInd,&quot;ensembl_gene_id&quot;][tmpName==&quot;&quot;] tmpName[is.na(tmpName)] &lt;- rowData(sce)[tmpInd,&quot;ensembl_gene_id&quot;][is.na(tmpName)] rm(tmpInd) Now show a violin plot for each gene, using plotExpression() and label genes with their name: g &lt;- plotExpression(sce, rownames(dec.sce)[chosen.genes.index], point_alpha=0.05, jitter=&quot;jitter&quot;) + fontsize g &lt;- g + scale_x_discrete(breaks=rownames(dec.sce)[chosen.genes.index], labels=tmpName) g rm(tmpName) Another few genes: chosen.genes.index &lt;- o[21:40] tmpInd &lt;- which(rowData(sce)$ensembl_gene_id %in% rownames(dec.sce)[chosen.genes.index]) # check: rowData(sce)[tmpInd,c(&quot;ensembl_gene_id&quot;,&quot;external_gene_name&quot;)] ## DataFrame with 20 rows and 2 columns ## ensembl_gene_id external_gene_name ## &lt;character&gt; &lt;character&gt; ## ENSG00000163220 ENSG00000163220 S100A9 ## ENSG00000143546 ENSG00000143546 S100A8 ## ENSG00000196154 ENSG00000196154 S100A4 ## ENSG00000136732 ENSG00000136732 GYPC ## ENSG00000008952 ENSG00000008952 SEC62 ## ... ... ... ## ENSG00000170315 ENSG00000170315 UBB ## ENSG00000013306 ENSG00000013306 SLC25A39 ## ENSG00000171223 ENSG00000171223 JUNB ## ENSG00000167815 ENSG00000167815 PRDX2 ## ENSG00000169575 ENSG00000169575 VPREB1 # store names: tmpName &lt;- rowData(sce)[tmpInd,&quot;external_gene_name&quot;] # the gene name may not be known, so keep the ensembl gene ID in that case: tmpName[tmpName==&quot;&quot;] &lt;- rowData(sce)[tmpInd,&quot;ensembl_gene_id&quot;][tmpName==&quot;&quot;] tmpName[is.na(tmpName)] &lt;- rowData(sce)[tmpInd,&quot;ensembl_gene_id&quot;][is.na(tmpName)] rm(tmpInd) g &lt;- plotExpression(sce, rownames(dec.sce)[chosen.genes.index], point_alpha=0.05, jitter=&quot;jitter&quot;) + fontsize g &lt;- g + scale_x_discrete(breaks=rownames(dec.sce)[chosen.genes.index], labels=tmpName) g rm(tmpName) Challenge: Show violin plots for the 20 genes with the lowest biological component. How do they compare to the those for HVGs chosen above? chosen.genes.index.tmp &lt;- order(dec.sce$bio, decreasing=FALSE)[1:20] tmpInd &lt;- (which(rowData(sce)$ensembl_gene_id %in% rownames(dec.sce)[chosen.genes.index.tmp])) # check: rowData(sce)[tmpInd,c(&quot;ensembl_gene_id&quot;,&quot;external_gene_name&quot;)] ## DataFrame with 20 rows and 2 columns ## ensembl_gene_id external_gene_name ## &lt;character&gt; &lt;character&gt; ## ENSG00000171863 ENSG00000171863 RPS7 ## ENSG00000187514 ENSG00000187514 PTMA ## ENSG00000174748 ENSG00000174748 RPL15 ## ENSG00000232112 ENSG00000232112 TMA7 ## ENSG00000104529 ENSG00000104529 EEF1D ## ... ... ... ## ENSG00000105640 ENSG00000105640 RPL18A ## ENSG00000221983 ENSG00000221983 UBA52 ## ENSG00000063177 ENSG00000063177 RPL18 ## ENSG00000142534 ENSG00000142534 RPS11 ## ENSG00000170889 ENSG00000170889 RPS9 # store names: tmpName &lt;- rowData(sce)[tmpInd,&quot;external_gene_name&quot;] # the gene name may not be known, so keep the ensembl gene ID in that case: tmpName[tmpName==&quot;&quot;] &lt;- rowData(sce)[tmpInd,&quot;ensembl_gene_id&quot;][tmpName==&quot;&quot;] tmpName[is.na(tmpName)] &lt;- rowData(sce)[tmpInd,&quot;ensembl_gene_id&quot;][is.na(tmpName)] rm(tmpInd) g &lt;- plotExpression(sce, rownames(dec.sce)[chosen.genes.index.tmp], point_alpha=0.05, jitter=&quot;jitter&quot;) + fontsize g &lt;- g + scale_x_discrete(breaks=rownames(dec.sce)[chosen.genes.index.tmp], labels=tmpName) g rm(chosen.genes.index.tmp, tmpName) rm(dec.sce) rm(dec.pois.sce) rm(sce) 11.3 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] knitr_1.32 Cairo_1.5-12.2 ## [3] scran_1.18.7 scater_1.18.6 ## [5] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [7] Biobase_2.50.0 GenomicRanges_1.42.0 ## [9] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [11] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [13] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [15] ggplot2_3.3.3 ## ## loaded via a namespace (and not attached): ## [1] viridis_0.6.0 sass_0.3.1 ## [3] edgeR_3.32.1 BiocSingular_1.6.0 ## [5] jsonlite_1.7.2 viridisLite_0.4.0 ## [7] DelayedMatrixStats_1.12.3 scuttle_1.0.4 ## [9] bslib_0.2.4 assertthat_0.2.1 ## [11] statmod_1.4.35 highr_0.9 ## [13] dqrng_0.3.0 GenomeInfoDbData_1.2.4 ## [15] vipor_0.4.5 yaml_2.2.1 ## [17] pillar_1.6.0 lattice_0.20-44 ## [19] limma_3.46.0 glue_1.4.2 ## [21] beachmat_2.6.4 digest_0.6.27 ## [23] XVector_0.30.0 colorspace_2.0-0 ## [25] cowplot_1.1.1 htmltools_0.5.1.1 ## [27] Matrix_1.3-2 pkgconfig_2.0.3 ## [29] bookdown_0.22 zlibbioc_1.36.0 ## [31] purrr_0.3.4 scales_1.1.1 ## [33] BiocParallel_1.24.1 tibble_3.1.1 ## [35] farver_2.1.0 generics_0.1.0 ## [37] ellipsis_0.3.2 withr_2.4.2 ## [39] magrittr_2.0.1 crayon_1.4.1 ## [41] evaluate_0.14 fansi_0.4.2 ## [43] bluster_1.0.0 beeswarm_0.3.1 ## [45] tools_4.0.3 lifecycle_1.0.0 ## [47] stringr_1.4.0 locfit_1.5-9.4 ## [49] munsell_0.5.0 DelayedArray_0.16.3 ## [51] irlba_2.3.3 compiler_4.0.3 ## [53] jquerylib_0.1.3 rsvd_1.0.5 ## [55] rlang_0.4.10 grid_4.0.3 ## [57] RCurl_1.98-1.3 BiocNeighbors_1.8.2 ## [59] igraph_1.2.6 labeling_0.4.2 ## [61] bitops_1.0-7 rmarkdown_2.7 ## [63] codetools_0.2-18 gtable_0.3.0 ## [65] DBI_1.1.1 R6_2.5.0 ## [67] gridExtra_2.3 dplyr_1.0.5 ## [69] utf8_1.2.1 stringi_1.5.3 ## [71] ggbeeswarm_0.6.0 Rcpp_1.0.6 ## [73] vctrs_0.3.7 tidyselect_1.1.1 ## [75] xfun_0.22 sparseMatrixStats_1.2.1 "],["batch-correction-gsm3872442-set.html", "Chapter 12 batch correction - GSM3872442 set 12.1 Prepare data 12.2 Normalise each separately and re-pool 12.3 Normalise batches together 12.4 Batch correction 12.5 SCTransform 12.6 mnnCorrect 12.7 fastMNN 12.8 Harmony 12.9 Session information", " Chapter 12 batch correction - GSM3872442 set TODO remove libSize+batch section and keep batch regress only. GSM3872442 is a single PBMMC sample sequenced as a pool of two libraries: SRR9264351 and SRR9264352. We will use this sample to illustrate batch correction. qcPlotDirBit &lt;- &quot;Plots/Norm&quot; # not used TODO projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool setName &lt;- params$setName setSuf &lt;- params$setSuf if(params$bookType == &quot;mk&quot;) { setName &lt;- &quot;GSM3872442&quot; setSuf &lt;- &quot;_allCells&quot; dirRel &lt;- &quot;..&quot; } 12.1 Prepare data Load object setSuf &lt;- &quot;&quot; # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, &quot;caron&quot;, setSuf) sce &lt;- readRDS(tmpFn) Select the GSM3872442 cells: sample1.nz.sce &lt;- SingleCellExperiment(list(counts=counts(sce[, sce$Run %in% c(&quot;SRR9264351&quot;)])), colData=colData(sce[, sce$Run %in% c(&quot;SRR9264351&quot;)])) sample2.nz.sce &lt;- SingleCellExperiment(list(counts=counts(sce[, sce$Run %in% c(&quot;SRR9264352&quot;)])), colData=colData(sce[, sce$Run %in% c(&quot;SRR9264352&quot;)])) 12.2 Normalise each separately and re-pool sample1.clusters &lt;- quickCluster(sample1.nz.sce, method=&quot;igraph&quot;) sample1.nz.sce &lt;- computeSumFactors(sample1.nz.sce, min.mean=0.1, cluster=sample1.clusters) sample1.nz.sce &lt;- logNormCounts(sample1.nz.sce) sample2.clusters &lt;- quickCluster(sample2.nz.sce, method=&quot;igraph&quot;) sample2.nz.sce &lt;- computeSumFactors(sample2.nz.sce, min.mean=0.1, cluster=sample2.clusters) sample2.nz.sce &lt;- logNormCounts(sample2.nz.sce) rm(sample1.clusters, sample2.clusters) Re-pool: # recombine the normalized samples together all.samp.exprs &lt;- do.call(cbind, list(&quot;SRR9264351&quot;=exprs(sample1.nz.sce), &quot;SRR9264352&quot;=exprs(sample2.nz.sce))) colnames(all.samp.exprs) &lt;- c(as.character(colData(sample1.nz.sce)$Barcode), as.character(colData(sample2.nz.sce)$Barcode)) For the PCA we want to quickly select the genes that are most informative. We will use the top 2000 genes with the highest variance. gene.variances &lt;- apply(all.samp.exprs, 1, var) names(gene.variances) &lt;- rownames(all.samp.exprs) highly.variable.genes &lt;- names(gene.variances[order(gene.variances, decreasing=TRUE)])[1:2000] rm(gene.variances) Perform PCA: # we need to use a fast approximate algorithm for PCA on large data sets # this algorithm has a stochastic component, # so we need to fix the seed number to get the same result each time set.seed(42) separate.hvg.pca &lt;- irlba::prcomp_irlba(t(all.samp.exprs[highly.variable.genes, ]), n=5) # we only need a few components separate.hvg.pcs &lt;- as.data.frame(separate.hvg.pca$x) # extract the principal components separate.hvg.pcs$Cell &lt;- colnames(all.samp.exprs) # set the sample column as the cell IDs # combine the PCs with the sample information into a single data frame for plotting samples.info &lt;- data.frame(&quot;Cell&quot;=colnames(all.samp.exprs), &quot;Run&quot;=c(rep(&quot;SRR9264351&quot;, ncol(sample1.nz.sce)), rep(&quot;SRR9264352&quot;, ncol(sample2.nz.sce)))) # merge the two data frames together separate.pca.merge &lt;- merge(separate.hvg.pcs, samples.info, by=&#39;Cell&#39;) # tidy rm(all.samp.exprs, separate.hvg.pca, separate.hvg.pcs, samples.info) Plot PC1-PC2 plane, with cells colored by ‘Run’ (and sized according to library size): sce.sep &lt;- cbind(sample1.nz.sce, sample2.nz.sce) rm(sample1.nz.sce, sample2.nz.sce) sce.sep &lt;- runPCA(sce.sep) plotPCA(sce.sep, colour_by=&quot;Run&quot;, size_by = &quot;sum&quot;) sce.sep &lt;- runTSNE(sce.sep, dimred=&quot;PCA&quot;) plotTSNE(sce.sep, colour_by=&quot;Run&quot;, size_by = &quot;sum&quot;) sce.sep &lt;- runUMAP(sce.sep, dimred=&quot;PCA&quot;) plotUMAP(sce.sep, colour_by=&quot;Run&quot;, size_by = &quot;sum&quot;) rm(sce.sep) 12.3 Normalise batches together sample3.nz.sce &lt;- SingleCellExperiment(list(counts=counts(sce[, sce$Run %in% c(&quot;SRR9264351&quot;, &quot;SRR9264352&quot;)])), colData=colData(sce[, sce$Run %in% c(&quot;SRR9264351&quot;, &quot;SRR9264352&quot;)])) sample3.clusters &lt;- quickCluster(sample3.nz.sce, method=&quot;igraph&quot;) sample3.nz.sce &lt;- computeSumFactors(sample3.nz.sce, min.mean=0.1, cluster=sample3.clusters) sample3.nz.sce &lt;- logNormCounts(sample3.nz.sce) pool.exprs &lt;- exprs(sample3.nz.sce) colnames(pool.exprs) &lt;- gsub(colData(sample3.nz.sce)$Barcode, pattern=&quot;-&quot;, replacement=&quot;.&quot;) rm(sample3.clusters, sce) Find the 2000 genes with the highest variance: gene.variances &lt;- apply(pool.exprs, 1, var) names(gene.variances) &lt;- rownames(pool.exprs) highly.variable.genes &lt;- names(gene.variances[order(gene.variances, decreasing=TRUE)])[1:2000] rm(gene.variances) Perform PCA: # we need to use a fast approximate algorithm for PCA on large data sets # this algorithm has a stochastic component, so we need to fix the seed number to get the same result each time set.seed(42) combined.hvg.pca &lt;- irlba::prcomp_irlba(t(pool.exprs[highly.variable.genes, ]), n=5) # we only need a few components combined.hvg.pcs &lt;- as.data.frame(combined.hvg.pca$x) # extract the principal components combined.hvg.pcs$Cell &lt;- colnames(pool.exprs) # set the sample column as the cell IDs # combine the PCs with the sample information into a single data frame for plotting samples.info &lt;- data.frame(&quot;Cell&quot;=colnames(pool.exprs), &quot;Run&quot;=colData(sample3.nz.sce)$Run) # merge the two data frames together combined.pca.merge &lt;- merge(combined.hvg.pcs, samples.info, by=&#39;Cell&#39;) rm(all.samp.exprs, combined.hvg.pca, combined.hvg.pcs, samples.info) Plot PC1-PC2 plane, with cells colored by ‘Run’ (and sized according to library size): sample3.nz.sce &lt;- runPCA(sample3.nz.sce) plotPCA(sample3.nz.sce, colour_by=&quot;Run&quot;, size_by = &quot;sum&quot;) sample3.nz.sce &lt;- runTSNE(sample3.nz.sce, dimred=&quot;PCA&quot;) plotTSNE(sample3.nz.sce, colour_by=&quot;Run&quot;, size_by = &quot;sum&quot;) sample3.nz.sce &lt;- runUMAP(sample3.nz.sce, dimred=&quot;PCA&quot;) plotUMAP(sample3.nz.sce, colour_by=&quot;Run&quot;, size_by = &quot;sum&quot;) 12.4 Batch correction sample3.nz.sce$Run &lt;- factor(sample3.nz.sce$Run) sample3.nz.sce$batch &lt;- sample3.nz.sce$Run sce &lt;- sample3.nz.sce 12.4.1 Gaussian (normal) linear models Limma suppressMessages(require(limma)) lm_design_batch &lt;- model.matrix(~0 + batch, data = colData(sce)) fit_lm_batch &lt;- lmFit(logcounts(sce), lm_design_batch) resids_lm_batch &lt;- residuals(fit_lm_batch, logcounts(sce)) assay(sce, &quot;lm_batch&quot;) &lt;- resids_lm_batch reducedDim(sce, &quot;PCA_lm_batch&quot;) &lt;- reducedDim( runPCA(sce, exprs_values = &quot;lm_batch&quot;), &quot;PCA&quot;) plotReducedDim(sce, dimred = &quot;PCA_lm_batch&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;LM - regress out batch&quot;) #scePreSct &lt;- sce # not used TODO delete 12.5 SCTransform 12.5.1 Batch only First make a copy of the SCE object (we will need one later). # have log lib size sce$log10sum &lt;- log10(sce$sum) # keep copy of SCE to draw from after SCTransform, # which discard some genes TODO check-again/mention slow &#39;return all&#39; option sceOrig &lt;- sce counts &lt;- counts(sce) class(counts) ## [1] &quot;dgCMatrix&quot; ## attr(,&quot;package&quot;) ## [1] &quot;Matrix&quot; if(FALSE) # dev { # https://rawgit.com/ChristophH/sctransform/supp_html/supplement/variance_stabilizing_transformation.html # https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz setwd(&quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/Scripts/BookDownDevSrv008&quot;) getwd() dir() counts &lt;- Read10X(data.dir = &quot;filtered_gene_bc_matrices/hg19/&quot;) # Seurat function to read in 10x count data getwd() } # inspect data gene_attr &lt;- data.frame(mean = rowMeans(counts), detection_rate = rowMeans(counts &gt; 0), var = apply(counts, 1, var)) gene_attr$log_mean &lt;- log10(gene_attr$mean) gene_attr$log_var &lt;- log10(gene_attr$var) rownames(gene_attr) &lt;- rownames(counts) cell_attr &lt;- data.frame(n_umi = colSums(counts), n_gene = colSums(counts &gt; 0)) rownames(cell_attr) &lt;- colnames(counts) # plot ggplot(gene_attr, aes(log_mean, log_var)) + geom_point(alpha = 0.3, shape = 16) + geom_density_2d(size = 0.3) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) Mean-variance relationship # Mean-variance relationship # add the expected detection rate under Poisson model x = seq(from = -3, to = 2, length.out = 1000) poisson_model &lt;- data.frame(log_mean = x, detection_rate = 1 - dpois(0, lambda = 10^x)) ggplot(gene_attr, aes(log_mean, detection_rate)) + geom_point(alpha = 0.3, shape = 16) + geom_line(data = poisson_model, color = &quot;red&quot;) + theme_gray(base_size = 8) rm(gene_attr) Mean-detection-rate relationship # Mean-detection-rate relationship ggplot(cell_attr, aes(n_umi, n_gene)) + geom_point(alpha = 0.3, shape = 16) + geom_density_2d(size = 0.3) rm(cell_attr) counts &lt;- counts(sce) colnames(counts) &lt;- colData(sce)$Barcode cellAttr &lt;- as.data.frame(colData(sce))[,c(&quot;log10sum&quot;, &quot;batch&quot;)] rownames(cellAttr) &lt;- colData(sce)$Barcode #https://github.com/satijalab/seurat/issues/3925 # remotes::install_github(&quot;ChristophH/sctransform@develop&quot;) ### Genes expressed in at least 5 cells will be kept sctnorm_data &lt;- sctransform::vst(umi = counts, min_cells = 5, #min_cells = 10, #method = &quot;nb_fast&quot;, #n_genes = 3000, #bw_adjust = 2, # 3 cell_attr = cellAttr, latent_var = c(&quot;batch&quot;), #latent_var = c(&quot;log10sum&quot;, &quot;batch&quot;), return_gene_attr = TRUE, return_cell_attr = TRUE, verbosity = 0) Check model used: # model: print(sctnorm_data$model_str) ## [1] &quot;y ~ batch&quot; Check new values (here 3 rows and 3 columns only): sctnorm_data$y[1:3,1:3] ## AAACCTGCACTTCGAA-9 AAACCTGCAGACGCAA-9 AAACCTGTCATCACCC-9 ## ENSG00000237491 -0.1805847 -0.1805847 -0.1805847 ## ENSG00000225880 -0.1052960 -0.1052960 -0.1052960 ## ENSG00000230368 -0.1977572 -0.1977572 -0.1977572 Check object: sce ## class: SingleCellExperiment ## dim: 16629 2099 ## metadata(0): ## assays(3): counts logcounts lm_batch ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(0): ## colnames: NULL ## colData names(18): Barcode Run ... batch log10sum ## reducedDimNames(4): PCA TSNE UMAP PCA_lm_batch ## altExpNames(0): Some genes were not included in the transformation and excluded from the output, so we will remove them from the SCE object too. # exclude genes that were not used in the transformation: tmpInd &lt;- which(rownames(sce) %in% rownames(sctnorm_data$y)) cols.meta &lt;- colData(sceOrig) rows.meta &lt;- rowData(sceOrig) new.counts &lt;- counts(sceOrig)[tmpInd, ] sce &lt;- SingleCellExperiment(list(counts=new.counts)) # reset the column data on the new object colData(sce) &lt;- cols.meta rowData(sce) &lt;- rows.meta[tmpInd, ] We now copy the transformation output to the SCE object: vstMat &lt;- as(sctnorm_data$y[rownames(sce),], &quot;dgCMatrix&quot;) all(colnames(vstMat) == sce$Barcode) ## [1] TRUE dim(vstMat) ## [1] 13784 2099 colnames(vstMat) &lt;- NULL assay(sce, &quot;sctrans_norm_batchOnly&quot;) &lt;- vstMat # as(vst_out$y[rownames(sce),], &quot;dgCMatrix&quot;) Also copy ‘logcounts’: assayX &lt;- &quot;logcounts&quot; tmpAssay &lt;- assay(sceOrig, assayX) assay(sce, assayX) &lt;- tmpAssay[tmpInd, ] Diagnostic plots are shown below: sctransform::plot_model_pars(sctnorm_data) The reduced dimension plots below show improved mixing of cells from the two sets: reducedDim(sce, &quot;PCA_sctrans_norm_batchOnly&quot;) &lt;- reducedDim( runPCA(sce, exprs_values = &quot;sctrans_norm_batchOnly&quot;), &quot;PCA&quot; ) plotReducedDim( sce, dimred = &quot;PCA_sctrans_norm_batchOnly&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;PCA plot: sctransform normalization - batch only&quot;) sce &lt;- runTSNE(sce, dimred=&quot;PCA_sctrans_norm_batchOnly&quot;, name=&quot;TSNE_sctrans_norm_batchOnly&quot;) plotReducedDim( sce, dimred = &quot;TSNE_sctrans_norm_batchOnly&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;TSNE plot: sctransform normalization - batch only&quot;) sce &lt;- runUMAP(sce, dimred=&quot;PCA_sctrans_norm_batchOnly&quot;, name=&quot;UMAP_sctrans_norm_batchOnly&quot;) plotReducedDim( sce, dimred = &quot;UMAP_sctrans_norm_batchOnly&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;UMAP plot: sctransform normalization - batch only&quot;) Keep copy of SCE object for later: sce_batchOnly &lt;- sce 12.5.2 Both library size and batch Use the copy of the SCE object made earlier. sce &lt;- sceOrig Some cells are very different from the rest. counts &lt;- counts(sce) colnames(counts) &lt;- colData(sce)$Barcode #cellAttr &lt;- as.data.frame(colData(sce))[,c(&quot;log10sum&quot;, &quot;batch&quot;)] cellAttr &lt;- as.data.frame(colData(sce)) rownames(cellAttr) &lt;- colData(sce)$Barcode sctnorm_data &lt;- sctransform::vst(umi = counts, min_cells = 5, #min_cells = 10, #method = &quot;nb_fast&quot;, #n_genes = 3000, #bw_adjust = 2, # 3 cell_attr = cellAttr, latent_var = c(&quot;log10sum&quot;, &quot;batch&quot;), #latent_var = c(&quot;batch&quot;), return_gene_attr = TRUE, return_cell_attr = TRUE, verbosity = 0) sctransform::plot_model_pars(sctnorm_data) # exclude genes that were not used in the transformation: tmpInd &lt;- which(rownames(sce) %in% rownames(sctnorm_data$y)) cols.meta &lt;- colData(sceOrig) rows.meta &lt;- rowData(sceOrig) new.counts &lt;- counts(sceOrig)[tmpInd, ] sce &lt;- SingleCellExperiment(list(counts=new.counts)) # reset the column data on the new object colData(sce) &lt;- cols.meta rowData(sce) &lt;- rows.meta[tmpInd, ] # We now copy the transformation output to the SCE object: vstMat &lt;- as(sctnorm_data$y[rownames(sce),], &quot;dgCMatrix&quot;) all(colnames(vstMat) == sce$Barcode) ## [1] TRUE dim(vstMat) ## [1] 13784 2099 colnames(vstMat) &lt;- NULL assay(sce, &quot;sctrans_norm_libSizeBatch0&quot;) &lt;- vstMat # as(vst_out$y[rownames(sce),], &quot;dgCMatrix&quot;) #Also copy &#39;logcounts&#39;: assayX &lt;- &quot;logcounts&quot; tmpAssay &lt;- assay(sceOrig, assayX) assay(sce, assayX) &lt;- tmpAssay[tmpInd, ] reducedDim(sce, &quot;PCA_sctrans_norm_libSizeBatch0&quot;) &lt;- reducedDim( runPCA(sce, exprs_values = &quot;sctrans_norm_libSizeBatch0&quot;), &quot;PCA&quot; ) plotReducedDim( sce, dimred = &quot;PCA_sctrans_norm_libSizeBatch0&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;PCA plot: sctransform normalization - libSizeBatch0&quot;) sce &lt;- sceOrig require(Seurat) # use Seurat&#39;s SCTransform sce.srt &lt;- as.Seurat(sce) sce.srt &lt;- SCTransform(sce.srt, min_cells = 5, vars.to.regress = c(&quot;log10sum&quot;, &quot;batch&quot;), #vars.to.regress = c(&quot;batch&quot;), # Variables to regress out in a second non-regularized linear regression # so log10sum is redundant here ... return_gene_attr = TRUE, return_cell_attr = TRUE, #show_progress = FALSE, verbose = FALSE, verbosity = 0 ) str(sce.srt[[&quot;SCT&quot;]]) ## Formal class &#39;SCTAssay&#39; [package &quot;Seurat&quot;] with 9 slots ## ..@ SCTModel.list:List of 1 ## .. ..$ model1:Formal class &#39;SCTModel&#39; [package &quot;Seurat&quot;] with 6 slots ## .. .. .. ..@ feature.attributes:&#39;data.frame&#39;: 13784 obs. of 12 variables: ## .. .. .. .. ..$ detection_rate : num [1:13784] 0.0243 0.0081 0.02906 0.00333 0.10195 ... ## .. .. .. .. ..$ gmean : num [1:13784] 0.01718 0.00596 0.02074 0.00231 0.08436 ... ## .. .. .. .. ..$ variance : num [1:13784] 0.02512 0.01183 0.03103 0.00333 0.22363 ... ## .. .. .. .. ..$ residual_mean : num [1:13784] 0.02914 0.01863 -0.01525 0.00311 0.01306 ... ## .. .. .. .. ..$ residual_variance : num [1:13784] 1.341 1.403 0.759 0.922 1.081 ... ## .. .. .. .. ..$ theta : num [1:13784] 0.461 0.2 0.536 0.128 1.284 ... ## .. .. .. .. ..$ (Intercept) : num [1:13784] -11.7 -12.2 -11.5 -12.5 -10.3 ... ## .. .. .. .. ..$ log_umi : num [1:13784] 2.27 2.11 2.28 1.91 2.33 ... ## .. .. .. .. ..$ genes_log_gmean_step1: logi [1:13784] FALSE FALSE TRUE FALSE FALSE FALSE ... ## .. .. .. .. ..$ step1_theta : num [1:13784] NA NA 0.933 NA NA ... ## .. .. .. .. ..$ step1_(Intercept) : num [1:13784] NA NA -13 NA NA ... ## .. .. .. .. ..$ step1_log_umi : num [1:13784] NA NA 2.67 NA NA ... ## .. .. .. ..@ cell.attributes :&#39;data.frame&#39;: 2099 obs. of 3 variables: ## .. .. .. .. ..$ umi : num [1:2099] 2160 2291 3349 3728 596 ... ## .. .. .. .. ..$ log_umi : num [1:2099] 3.33 3.36 3.52 3.57 2.78 ... ## .. .. .. .. ..$ cells_step1: logi [1:2099] TRUE TRUE TRUE TRUE TRUE TRUE ... ## .. .. .. ..@ clips :List of 2 ## .. .. .. .. ..$ vst: num [1:2] -45.8 45.8 ## .. .. .. .. ..$ sct: num [1:2] -8.36 8.36 ## .. .. .. ..@ umi.assay : chr &quot;RNA&quot; ## .. .. .. ..@ model : chr &quot;y ~ log_umi&quot; ## .. .. .. ..@ arguments :List of 25 ## .. .. .. .. ..$ latent_var : chr &quot;log_umi&quot; ## .. .. .. .. ..$ batch_var : NULL ## .. .. .. .. ..$ latent_var_nonreg : NULL ## .. .. .. .. ..$ n_genes : num 2000 ## .. .. .. .. ..$ n_cells : num 2099 ## .. .. .. .. ..$ method : chr &quot;poisson&quot; ## .. .. .. .. ..$ do_regularize : logi TRUE ## .. .. .. .. ..$ theta_regularization: chr &quot;od_factor&quot; ## .. .. .. .. ..$ res_clip_range : num [1:2] -45.8 45.8 ## .. .. .. .. ..$ bin_size : num 500 ## .. .. .. .. ..$ min_cells : num 5 ## .. .. .. .. ..$ residual_type : chr &quot;pearson&quot; ## .. .. .. .. ..$ return_cell_attr : logi TRUE ## .. .. .. .. ..$ return_gene_attr : logi TRUE ## .. .. .. .. ..$ return_corrected_umi: logi TRUE ## .. .. .. .. ..$ min_variance : num -Inf ## .. .. .. .. ..$ bw_adjust : num 3 ## .. .. .. .. ..$ gmean_eps : num 1 ## .. .. .. .. ..$ theta_estimation_fun: chr &quot;theta.ml&quot; ## .. .. .. .. ..$ theta_given : NULL ## .. .. .. .. ..$ verbosity : num 0 ## .. .. .. .. ..$ verbose : NULL ## .. .. .. .. ..$ show_progress : NULL ## .. .. .. .. ..$ sct.clip.range : num [1:2] -8.36 8.36 ## .. .. .. .. ..$ sct.method : chr &quot;default&quot; ## ..@ counts :Formal class &#39;dgCMatrix&#39; [package &quot;Matrix&quot;] with 6 slots ## .. .. ..@ i : int [1:1465665] 20 58 67 86 157 177 199 201 210 211 ... ## .. .. ..@ p : int [1:2100] 0 834 1702 2384 3476 3853 4657 5325 6049 6551 ... ## .. .. ..@ Dim : int [1:2] 13784 2099 ## .. .. ..@ Dimnames:List of 2 ## .. .. .. ..$ : chr [1:13784] &quot;ENSG00000237491&quot; &quot;ENSG00000225880&quot; &quot;ENSG00000230368&quot; &quot;ENSG00000230699&quot; ... ## .. .. .. ..$ : chr [1:2099] &quot;cell_1&quot; &quot;cell_2&quot; &quot;cell_3&quot; &quot;cell_4&quot; ... ## .. .. ..@ x : num [1:1465665] 1 1 4 1 1 1 1 14 2 1 ... ## .. .. ..@ factors : list() ## ..@ data :Formal class &#39;dgCMatrix&#39; [package &quot;Matrix&quot;] with 6 slots ## .. .. ..@ i : int [1:1465665] 20 58 67 86 157 177 199 201 210 211 ... ## .. .. ..@ p : int [1:2100] 0 834 1702 2384 3476 3853 4657 5325 6049 6551 ... ## .. .. ..@ Dim : int [1:2] 13784 2099 ## .. .. ..@ Dimnames:List of 2 ## .. .. .. ..$ : chr [1:13784] &quot;ENSG00000237491&quot; &quot;ENSG00000225880&quot; &quot;ENSG00000230368&quot; &quot;ENSG00000230699&quot; ... ## .. .. .. ..$ : chr [1:2099] &quot;cell_1&quot; &quot;cell_2&quot; &quot;cell_3&quot; &quot;cell_4&quot; ... ## .. .. ..@ x : num [1:1465665] 0.693 0.693 1.609 0.693 0.693 ... ## .. .. ..@ factors : list() ## ..@ scale.data : num [1:3000, 1:2099] -0.1647 -0.06593 -0.02594 -0.00907 -0.13346 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : chr [1:3000] &quot;ENSG00000237491&quot; &quot;ENSG00000225880&quot; &quot;ENSG00000188290&quot; &quot;ENSG00000131591&quot; ... ## .. .. ..$ : chr [1:2099] &quot;cell_1&quot; &quot;cell_2&quot; &quot;cell_3&quot; &quot;cell_4&quot; ... ## ..@ key : chr &quot;sct_&quot; ## ..@ assay.orig : chr &quot;RNA&quot; ## ..@ var.features : chr [1:3000] &quot;ENSG00000090382&quot; &quot;ENSG00000143546&quot; &quot;ENSG00000163220&quot; &quot;ENSG00000257764&quot; ... ## ..@ meta.features:&#39;data.frame&#39;: 13784 obs. of 0 variables ## ..@ misc : Named list() ##sce.srt[[&quot;SCT&quot;]]@misc # https://hbctraining.github.io/scRNA-seq/lessons/06_SC_SCT_and_integration.html #GetAssay(sce.srt, assay = &quot;SCT&quot;)@misc$vst.out ##sce.srt[[&quot;SCT&quot;]]@scale.data %&gt;% head() Check model used: #print(sce.srt[[&quot;SCT&quot;]]@misc$vst.out$model_str) # sctransform::vst print(sce.srt[[&quot;SCT&quot;]]@SCTModel.list$model1@model) # Seurat::SCTransform ## [1] &quot;y ~ log_umi&quot; Discard genes that were not used in the transformation. # exclude genes that were not used in the transformation: tmpInd &lt;- which(rownames(sce) %in% rownames(sce.srt[[&quot;SCT&quot;]]@scale.data)) cols.meta &lt;- colData(sceOrig) rows.meta &lt;- rowData(sceOrig) new.counts &lt;- counts(sceOrig)[tmpInd, ] sce &lt;- SingleCellExperiment(list(counts=new.counts)) # reset the column data on the new object colData(sce) &lt;- cols.meta rowData(sce) &lt;- rows.meta[tmpInd, ] # tidy rm(sceOrig) Copy the transformation output to the SCE object. vstMat &lt;- as(sce.srt[[&quot;SCT&quot;]]@scale.data[rownames(sce),], &quot;dgCMatrix&quot;) #all(colnames(vstMat) == sce$Barcode) dd &lt;- sce.srt@meta.data %&gt;% dplyr::select(Barcode) # check order of cells are identical all(dd[colnames(vstMat), &quot;Barcode&quot;] == sce$Barcode) ## [1] TRUE colnames(vstMat) &lt;- NULL assay(sce, &quot;sctrans_norm&quot;) &lt;- vstMat Show diagnostic plots: #sctransform::plot_model_pars(sce.srt[[&quot;SCT&quot;]]@misc$vst.out) # sctransform::vst # not with Seurat::SCTransform ... empty sce.srt[[&quot;SCT&quot;]]@misc 20200422 rm(sce.srt) Show reduced dimension plots and check for improved mixing of cells from the two sets: reducedDim(sce, &quot;PCA_sctrans_norm&quot;) &lt;- reducedDim( runPCA(sce, exprs_values = &quot;sctrans_norm&quot;) ) plotReducedDim( sce, dimred = &quot;PCA_sctrans_norm&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;PCA plot: sctransform normalization&quot;) sce &lt;- runTSNE(sce, dimred=&quot;PCA_sctrans_norm&quot;, name=&quot;TSNE_sctrans_norm&quot;) plotReducedDim( sce, dimred = &quot;TSNE_sctrans_norm&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;TSNE plot: sctransform normalization&quot;) sce &lt;- runUMAP(sce, dimred=&quot;PCA_sctrans_norm&quot;, name=&quot;UMAP_sctrans_norm&quot;) plotReducedDim( sce, dimred = &quot;UMAP_sctrans_norm&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;UMAP plot: sctransform normalization&quot;) Add PCA_sctrans_norm_batchOnly (same cells, only genes may differ) reducedDim(sce, &quot;PCA_sctrans_norm_batchOnly&quot;) &lt;- reducedDim(sce_batchOnly, &quot;PCA_sctrans_norm_batchOnly&quot;) reducedDim(sce, &quot;TSNE_sctrans_norm_batchOnly&quot;) &lt;- reducedDim(sce_batchOnly, &quot;TSNE_sctrans_norm_batchOnly&quot;) reducedDim(sce, &quot;UMAP_sctrans_norm_batchOnly&quot;) &lt;- reducedDim(sce_batchOnly, &quot;UMAP_sctrans_norm_batchOnly&quot;) #scePostSct &lt;- sce # not used TODO remove 12.6 mnnCorrect 12.6.1 Check presence of batch effect Same as above but with batchelor commands to make the two batches and identify highly variable genes for faster dimensionality reduction. sce &lt;- sample3.nz.sce rm(sample3.nz.sce) library(batchelor) # Mind assayNames() sce1 &lt;- sce[, sce$Run == &quot;SRR9264351&quot;] sce2 &lt;- sce[, sce$Run == &quot;SRR9264352&quot;] library(scran) dec1 &lt;- modelGeneVar(sce1) dec2 &lt;- modelGeneVar(sce2) combined.dec &lt;- combineVar(dec1, dec2) chosen.hvgs &lt;- combined.dec$bio &gt; 0 summary(chosen.hvgs) ## Mode FALSE TRUE ## logical 7655 8974 rm(dec1, dec2) As a diagnostic, we check that there actually is a batch effect across these datasets by checking that they cluster separately. Here, we combine the two SingleCellExperiment objects without any correction using the NoCorrectParam() flag, and we informally verify that cells from different batches are separated using a t-SNE plot. There is a moderate batch effect. library(scater) combined &lt;- correctExperiments(A=sce1, B=sce2, PARAM=NoCorrectParam()) combined &lt;- runPCA(combined, subset_row=chosen.hvgs) combined &lt;- runTSNE(combined, dimred=&quot;PCA&quot;) combined &lt;- runUMAP(combined, dimred=&quot;PCA&quot;) plotPCA(combined, colour_by=&quot;batch&quot;) plotTSNE(combined, colour_by=&quot;batch&quot;) plotUMAP(combined, colour_by=&quot;batch&quot;) reducedDim(sce, &quot;PCA_noCor&quot;) &lt;- reducedDim(combined, &quot;PCA&quot;) reducedDim(sce, &quot;TSNE_noCor&quot;) &lt;- reducedDim(combined, &quot;TSNE&quot;) reducedDim(sce, &quot;UMAP_noCor&quot;) &lt;- reducedDim(combined, &quot;UMAP&quot;) rm(combined) 12.6.2 Correct batch effect with mnnCorrect This is the initial method. It uses gene expression values to identify cells with similar expression patterns in both batches. Let us get the normalised counts: batch1 &lt;- logcounts(sce1) batch2 &lt;- logcounts(sce2) rm(sce1, sce2) y &lt;- batchelor::mnnCorrect( batch1, batch2, #subset.row = fewer.hvgs, correct.all = TRUE, k = 20, sigma = 0.1, cos.norm.in = TRUE, svd.dim = 2 ) Copy the corrected values to the SCE object: assay(sce, &quot;mnn&quot;) &lt;- assay(y, &quot;corrected&quot;) Show reduced dimension plots and check for improved mixing of cells from the two sets: sce &lt;- runPCA(sce, exprs_values = &quot;mnn&quot;) plotPCA(sce, colour_by=&quot;batch&quot;) reducedDim(sce, &quot;PCA_mnn&quot;) &lt;- reducedDim(sce, &quot;PCA&quot;) sce &lt;- runTSNE(sce, dimred=&quot;PCA_mnn&quot;) plotTSNE(sce, colour_by=&quot;batch&quot;) reducedDim(sce, &quot;TSNE_mnn&quot;) &lt;- reducedDim(sce, &quot;TSNE&quot;) sce &lt;- runUMAP(sce, dimred=&quot;PCA_mnn&quot;) plotUMAP(sce, colour_by=&quot;batch&quot;) reducedDim(sce, &quot;UMAP_mnn&quot;) &lt;- reducedDim(sce, &quot;UMAP&quot;) rm(combined.dec, chosen.hvgs) 12.7 fastMNN This method is faster than mnnCorrect as it identifies nearest neighbours after dimensionality reduction. fx &lt;- batchelor::fastMNN( sce, #correct.all = TRUE, batch = sce$Run ) class(fx) ## [1] &quot;SingleCellExperiment&quot; ## attr(,&quot;package&quot;) ## [1] &quot;SingleCellExperiment&quot; Copy the corrected values to the SCE object: # fastMNN may drop some genes # so we may not be able to keep the outcome in &#39;assay&#39; assay(sce, &quot;fastmnn&quot;) &lt;- assay(fx, &quot;reconstructed&quot;) Show reduced dimension plots and check for improved mixing of cells from the two sets: fastmnn_pca &lt;- runPCA(assay(sce, &quot;fastmnn&quot;), rank=2) # slow reducedDim(sce, &quot;PCA_fastmnn&quot;) &lt;- fastmnn_pca$rotation rm(fastmnn_pca) plotReducedDim( sce, dimred = &quot;PCA_fastmnn&quot;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) + ggtitle(&quot;PCA plot: fastMNN&quot;) sce &lt;- runTSNE(sce, dimred=&quot;PCA_fastmnn&quot;) plotTSNE(sce, colour_by=&quot;batch&quot;) reducedDim(sce, &quot;TSNE_fastmnn&quot;) &lt;- reducedDim(sce, &quot;TSNE&quot;) sce &lt;- runUMAP(sce, dimred=&quot;PCA_fastmnn&quot;) plotUMAP(sce, colour_by=&quot;batch&quot;) reducedDim(sce, &quot;UMAP_fastmnn&quot;) &lt;- reducedDim(sce, &quot;UMAP&quot;) 12.8 Harmony Harmony [Korsunsky2018fast] is a newer batch correction method, which is designed to operate on PC space. The algorithm proceeds to iteratively cluster the cells, with the objective function formulated to promote cells from multiple datasets within each cluster. Once a clustering is obtained, the positions of the centroids of each dataset are obtained on a per-cluster basis and the coordinates are corrected. This procedure is iterated until convergence. Harmony comes with a theta parameter that controls the degree of batch correction (higher values lead to more dataset integration), and can account for multiple experimental and biological factors on input (see variant of the ‘Hemberg course’). library(harmony) reducedDim(sce, &quot;PCA_logcounts&quot;) &lt;- reducedDim( runPCA(sce, exprs_values = &quot;logcounts&quot;) ) #Seeing how the end result of Harmony is an altered dimensional reduction space created on the basis of PCA, we plot the obtained manifold here and exclude it from the rest of the follow-ups in the section. pca &lt;- as.matrix(reducedDim(sce, &quot;PCA_logcounts&quot;)) harmony_emb &lt;- HarmonyMatrix(pca, sce$batch, theta=2, do_pca=FALSE) reducedDim(sce, &quot;harmony&quot;) &lt;- harmony_emb plotReducedDim( sce, dimred = &#39;harmony&#39;, colour_by = &quot;batch&quot;, size_by = &quot;sum&quot;, shape_by = &quot;Sample.Name&quot; ) 12.9 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] harmony_1.0 Rcpp_1.0.6 ## [3] batchelor_1.6.3 SeuratObject_4.0.0 ## [5] Seurat_4.0.1 limma_3.46.0 ## [7] Cairo_1.5-12.2 BiocSingular_1.6.0 ## [9] dplyr_1.0.5 scran_1.18.7 ## [11] scater_1.18.6 ggplot2_3.3.3 ## [13] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [15] Biobase_2.50.0 GenomicRanges_1.42.0 ## [17] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [19] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [21] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [23] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] plyr_1.8.6 igraph_1.2.6 ## [3] lazyeval_0.2.2 splines_4.0.3 ## [5] BiocParallel_1.24.1 listenv_0.8.0 ## [7] scattermore_0.7 digest_0.6.27 ## [9] htmltools_0.5.1.1 viridis_0.6.0 ## [11] fansi_0.4.2 magrittr_2.0.1 ## [13] tensor_1.5 cluster_2.1.2 ## [15] ROCR_1.0-11 globals_0.14.0 ## [17] spatstat.sparse_2.0-0 colorspace_2.0-0 ## [19] ggrepel_0.9.1 xfun_0.22 ## [21] crayon_1.4.1 RCurl_1.98-1.3 ## [23] jsonlite_1.7.2 spatstat.data_2.1-0 ## [25] survival_3.2-11 zoo_1.8-9 ## [27] glue_1.4.2 polyclip_1.10-0 ## [29] gtable_0.3.0 zlibbioc_1.36.0 ## [31] XVector_0.30.0 leiden_0.3.7 ## [33] DelayedArray_0.16.3 future.apply_1.7.0 ## [35] abind_1.4-5 scales_1.1.1 ## [37] DBI_1.1.1 edgeR_3.32.1 ## [39] miniUI_0.1.1.1 isoband_0.2.4 ## [41] viridisLite_0.4.0 xtable_1.8-4 ## [43] spatstat.core_2.1-2 reticulate_1.18 ## [45] dqrng_0.3.0 rsvd_1.0.5 ## [47] ResidualMatrix_1.0.0 htmlwidgets_1.5.3 ## [49] httr_1.4.2 FNN_1.1.3 ## [51] RColorBrewer_1.1-2 ellipsis_0.3.2 ## [53] ica_1.0-2 pkgconfig_2.0.3 ## [55] farver_2.1.0 scuttle_1.0.4 ## [57] deldir_0.2-10 sass_0.3.1 ## [59] uwot_0.1.10 locfit_1.5-9.4 ## [61] utf8_1.2.1 tidyselect_1.1.1 ## [63] labeling_0.4.2 rlang_0.4.10 ## [65] reshape2_1.4.4 later_1.2.0 ## [67] munsell_0.5.0 tools_4.0.3 ## [69] generics_0.1.0 ggridges_0.5.3 ## [71] evaluate_0.14 stringr_1.4.0 ## [73] fastmap_1.1.0 goftest_1.2-2 ## [75] yaml_2.2.1 fitdistrplus_1.1-3 ## [77] purrr_0.3.4 RANN_2.6.1 ## [79] nlme_3.1-152 pbapply_1.4-3 ## [81] future_1.21.0 sparseMatrixStats_1.2.1 ## [83] mime_0.10 compiler_4.0.3 ## [85] png_0.1-7 plotly_4.9.3 ## [87] beeswarm_0.3.1 spatstat.utils_2.1-0 ## [89] tibble_3.1.1 statmod_1.4.35 ## [91] bslib_0.2.4 stringi_1.5.3 ## [93] highr_0.9 RSpectra_0.16-0 ## [95] lattice_0.20-44 bluster_1.0.0 ## [97] Matrix_1.3-2 vctrs_0.3.7 ## [99] pillar_1.6.0 lifecycle_1.0.0 ## [101] spatstat.geom_2.1-0 lmtest_0.9-38 ## [103] jquerylib_0.1.3 RcppAnnoy_0.0.18 ## [105] BiocNeighbors_1.8.2 data.table_1.14.0 ## [107] cowplot_1.1.1 bitops_1.0-7 ## [109] irlba_2.3.3 httpuv_1.5.5 ## [111] patchwork_1.1.1 R6_2.5.0 ## [113] bookdown_0.22 promises_1.2.0.1 ## [115] KernSmooth_2.23-20 gridExtra_2.3 ## [117] vipor_0.4.5 parallelly_1.24.0 ## [119] codetools_0.2-18 MASS_7.3-54 ## [121] assertthat_0.2.1 withr_2.4.2 ## [123] sctransform_0.3.2.9005 GenomeInfoDbData_1.2.4 ## [125] mgcv_1.8-35 rpart_4.1-15 ## [127] grid_4.0.3 beachmat_2.6.4 ## [129] tidyr_1.1.3 rmarkdown_2.7 ## [131] DelayedMatrixStats_1.12.3 Rtsne_0.15 ## [133] shiny_1.6.0 ggbeeswarm_0.6.0 "],["dimensionality-reduction-for-analysis.html", "Chapter 13 Dimensionality reduction for analysis 13.1 Load data 13.2 Denoising expression values using PCA 13.3 Visualise expression patterns of some HVGs 13.4 Session information", " Chapter 13 Dimensionality reduction for analysis TODO add text and fix fig size. projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool cacheBool &lt;- params$cacheBool setName &lt;- params$setName setSuf &lt;- params$setSuf if(params$bookType == &quot;mk&quot;) { setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_5hCellPerSpl&quot; dirRel &lt;- &quot;..&quot; } nbPcToComp &lt;- 50 library(ggplot2) library(scater) library(scran) library(dplyr) library(Cairo) fontsize &lt;- theme(axis.text=element_text(size=12), axis.title=element_text(size=16)) 13.1 Load data We will load the R file keeping the SCE object with the normalised counts for 500 cells per sample. # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dimRed.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dimRed.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 16629 5500 ## metadata(0): ## assays(2): counts logcounts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Barcode Run ... cell_sparsity sizeFactor ## reducedDimNames(3): PCA TSNE UMAP ## altExpNames(0): #any(duplicated(rowData(sce)$ensembl_gene_id)) # some function(s) used below complain about &#39;strand&#39; already being used in row data, # so rename that column now: colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; # also get feature selection outcome tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_featSel.Rds&quot;, projDir, outDirBit, setName, setSuf) tmpList &lt;- readRDS(tmpFn) dec.sce &lt;- tmpList$dec.sce hvg.index &lt;- tmpList$hvg.index rm(tmpList) 13.2 Denoising expression values using PCA Aim: use the trend fitted above to identify PCs linked to biology. Assumption: biology drives most of the variance hence should be captured by the first PCs, while technical noise affects each gene independently, hence is captured by later PCs. Logic: Compute the sum of the technical component across genes used in the PCA, use it as the amount of variance not related to biology and that we should therefore remove. Later PCs are excluded until the amount of variance they account for matches that corresponding to the technical component. var.fit &lt;- metadata(dec.sce) # remove uninteresting PCs: #options(BiocSingularParam.default=IrlbaParam()) sce &lt;- denoisePCA(sce, technical=var.fit$trend, assay.type=&quot;logcounts&quot;) rm(var.fit) # check assay names, should see &#39;PCA&#39;: ##assayNames(sce) # check dimension of the PC table: ##dim(reducedDim(sce, &quot;PCA&quot;)) sce.pca &lt;- reducedDim(sce, &quot;PCA&quot;) # get copy of PCA matrix tmpCol &lt;- rep(&quot;grey&quot;, nbPcToComp) # set colours to show selected PCs in green tmpCol[1:dim(sce.pca)[2]] &lt;- &quot;green&quot; barplot(attributes(sce.pca)$percentVar[1:nbPcToComp], main=sprintf(&quot;Scree plot for the %s first PCs&quot;, nbPcToComp), names.arg=1:nbPcToComp, col=tmpCol, cex.names = 0.8) # cumulative proportion of variance explained by selected PCs cumsum(attributes(sce.pca)$percentVar)[1:dim(sce.pca)[2]] ## [1] 10.24611 14.47335 16.85835 18.71418 20.10582 21.25363 22.19929 # plot on PC1 and PC2 plane: plotPCA(sce, colour_by = &quot;Sample.Name&quot;) #require(knitr); knit_exit() rm(sce.pca, tmpCol) Show cells on plane for PC1 and PC2: plotReducedDim(sce, dimred = &quot;PCA&quot;, ncomponents = 3, colour_by = &quot;Sample.Name&quot;) + fontsize 13.3 Visualise expression patterns of some HVGs o &lt;- order(dec.sce$bio, decreasing=TRUE) chosen.genes.index &lt;- o[1:20] dec.sce %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;ensembl_gene_id&quot;) %&gt;% right_join(data.frame(rowData(sce)[chosen.genes.index,]), by=&quot;ensembl_gene_id&quot;) %&gt;% dplyr::select(ensembl_gene_id, Symbol, bio, FDR) %&gt;% arrange(-bio) ## ensembl_gene_id Symbol bio FDR ## 1 ENSG00000244734 HBB 10.969829 0.000000e+00 ## 2 ENSG00000188536 HBA2 8.722135 0.000000e+00 ## 3 ENSG00000206172 HBA1 7.946979 0.000000e+00 ## 4 ENSG00000223609 HBD 3.837750 4.214717e-197 ## 5 ENSG00000206177 HBM 2.855318 6.765734e-179 ## 6 ENSG00000019582 CD74 2.774036 1.337160e-31 ## 7 ENSG00000169877 AHSP 2.744183 1.728602e-158 ## 8 ENSG00000204287 HLA-DRA 2.099098 5.828412e-18 ## 9 ENSG00000133742 CA1 2.053374 3.228594e-118 ## 10 ENSG00000147454 SLC25A37 1.706164 7.448037e-64 ## 11 ENSG00000158578 ALAS2 1.683638 5.951544e-120 ## 12 ENSG00000165949 IFI27 1.584846 9.437875e-130 ## 13 ENSG00000090013 BLVRB 1.520814 1.198306e-73 ## 14 ENSG00000100721 TCL1A 1.360332 5.085333e-11 ## 15 ENSG00000211592 IGKC 1.250479 4.764279e-30 ## 16 ENSG00000170180 GYPA 1.221654 1.852283e-88 ## 17 ENSG00000145335 SNCA 1.218528 1.198306e-73 ## 18 ENSG00000170345 FOS 1.203750 2.080415e-06 ## 19 ENSG00000004939 SLC4A1 1.118489 1.112527e-73 ## 20 ENSG00000090382 LYZ 1.114020 4.912100e-90 rm(dec.sce) On PCA plot: # make and store PCA plot for top HVG 1: pca1 &lt;- plotReducedDim(sce, dimred=&quot;PCA&quot;, colour_by=rowData(sce)[chosen.genes.index[1],&quot;ensembl_gene_id&quot;]) + fontsize # + coord_fixed() # make and store PCA plot for top HVG 2: pca2 &lt;- plotReducedDim(sce, dimred=&quot;PCA&quot;, colour_by=rowData(sce)[chosen.genes.index[2],&quot;ensembl_gene_id&quot;]) + fontsize # + coord_fixed() pca1 pca2 # display plots next to each other: # multiplot(pca1, pca2, cols=2) pca1 + facet_wrap(. ~ sce$source_name) + coord_fixed() pca2 + facet_wrap(. ~ sce$source_name) + coord_fixed() rm(pca1, pca2) On t-SNE plot: # plot TSNE, accessing counts for the gene of interest with the ID used to name rows in the count matrix: # make and store TSNE plot for top HVG 1: tsne1 &lt;- plotTSNE(sce, colour_by=rowData(sce)[chosen.genes.index[1],&quot;ensembl_gene_id&quot;]) + fontsize # make and store TSNE plot for top HVG 2: tsne2 &lt;- plotTSNE(sce, colour_by=rowData(sce)[chosen.genes.index[2],&quot;ensembl_gene_id&quot;]) + fontsize tsne1 tsne2 # display plots next to each other: #multiplot(tsne1, tsne2, cols=2) tsne1 + facet_wrap(. ~ sce$source_name) tsne2 + facet_wrap(. ~ sce$source_name) # display plots next to each other, splitting each by sample: #multiplot(tsne1 + facet_grid(. ~ sce$Sample2), tsne2 + facet_grid(. ~ sce$Sample2), cols=2) rm(tsne1, tsne2) Write R object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_denoised.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_denoised.Rds&quot; saveRDS(sce, file=tmpFn) Genes correlated with PC1: sce &lt;- readRDS(tmpFn) rownames(sce) &lt;- uniquifyFeatureNames(rowData(sce)$ensembl_gene_id, rowData(sce)$Symbol) pc1 &lt;- reducedDim(sce, &quot;PCA&quot;)[,1] design &lt;- model.matrix(~pc1) library(limma) fit &lt;- lmFit(logcounts(sce), design) fit &lt;- eBayes(fit, trend=TRUE, robust=TRUE) topTab &lt;- topTable(fit) head(topTab) ## logFC AveExpr t P.Value adj.P.Val B ## ALAS2 -0.1305501 0.4248282 -253.8128 0 0 6988.979 ## HBD -0.1918066 0.8269274 -247.7593 0 0 6866.706 ## AHSP -0.1626882 0.6283138 -227.8409 0 0 6446.080 ## HBM -0.1642649 0.6132294 -218.3411 0 0 6234.849 ## HBA1 -0.2662693 1.6675081 -212.9019 0 0 6110.599 ## HBA2 -0.2748459 1.9143801 -191.7632 0 0 5603.082 rm(topTab) library(pheatmap) de.genes &lt;- rownames(topTable(fit, coef=2, n=50)) heat.vals &lt;- logcounts(sce)[de.genes,] heat.vals &lt;- heat.vals - rowMeans(heat.vals) heat.vals[heat.vals &gt; 2] &lt;- 2 heat.vals[heat.vals &lt; -2] &lt;- -2 p &lt;- pheatmap(heat.vals[,order(pc1)], cluster_cols=FALSE) #plot(p$gtable) rm(pc1, design, fit, de.genes, heat.vals) rm(sce) 13.4 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] pheatmap_1.0.12 limma_3.46.0 ## [3] Cairo_1.5-12.2 dplyr_1.0.5 ## [5] scran_1.18.7 scater_1.18.6 ## [7] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [9] Biobase_2.50.0 GenomicRanges_1.42.0 ## [11] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [13] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [15] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [17] ggplot2_3.3.3 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 RColorBrewer_1.1-2 ## [3] tools_4.0.3 bslib_0.2.4 ## [5] utf8_1.2.1 R6_2.5.0 ## [7] irlba_2.3.3 vipor_0.4.5 ## [9] DBI_1.1.1 colorspace_2.0-0 ## [11] withr_2.4.2 tidyselect_1.1.1 ## [13] gridExtra_2.3 compiler_4.0.3 ## [15] BiocNeighbors_1.8.2 DelayedArray_0.16.3 ## [17] labeling_0.4.2 bookdown_0.22 ## [19] sass_0.3.1 scales_1.1.1 ## [21] stringr_1.4.0 digest_0.6.27 ## [23] rmarkdown_2.7 XVector_0.30.0 ## [25] pkgconfig_2.0.3 htmltools_0.5.1.1 ## [27] sparseMatrixStats_1.2.1 highr_0.9 ## [29] rlang_0.4.10 DelayedMatrixStats_1.12.3 ## [31] jquerylib_0.1.3 generics_0.1.0 ## [33] farver_2.1.0 jsonlite_1.7.2 ## [35] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [37] magrittr_2.0.1 BiocSingular_1.6.0 ## [39] GenomeInfoDbData_1.2.4 scuttle_1.0.4 ## [41] Matrix_1.3-2 Rcpp_1.0.6 ## [43] ggbeeswarm_0.6.0 munsell_0.5.0 ## [45] fansi_0.4.2 viridis_0.6.0 ## [47] lifecycle_1.0.0 stringi_1.5.3 ## [49] yaml_2.2.1 edgeR_3.32.1 ## [51] zlibbioc_1.36.0 grid_4.0.3 ## [53] dqrng_0.3.0 crayon_1.4.1 ## [55] lattice_0.20-44 cowplot_1.1.1 ## [57] beachmat_2.6.4 splines_4.0.3 ## [59] locfit_1.5-9.4 pillar_1.6.0 ## [61] igraph_1.2.6 codetools_0.2-18 ## [63] glue_1.4.2 evaluate_0.14 ## [65] vctrs_0.3.7 gtable_0.3.0 ## [67] purrr_0.3.4 assertthat_0.2.1 ## [69] xfun_0.22 rsvd_1.0.5 ## [71] viridisLite_0.4.0 tibble_3.1.1 ## [73] beeswarm_0.3.1 bluster_1.0.0 ## [75] statmod_1.4.35 ellipsis_0.3.2 "],["DataIntegration-PBMMCTop.html", "Chapter 14 Data integration - PBMMC 14.1 Abbreviations 14.2 Motivation 14.3 Loading the data 14.4 Diagnosing batch effects 14.5 Linear regression 14.6 Performing MNN correction 14.7 Correction diagnostics 14.8 Preserving biological heterogeneity 14.9 Session information", " Chapter 14 Data integration - PBMMC projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool setName &lt;- params$setName splSetToGet &lt;- params$splSetToGet setSuf &lt;- params$setSuf dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;PBMMC&quot; setSuf &lt;- &quot;_allCells&quot; } nbPcToComp &lt;- 50 figSize &lt;- 7 Source: ‘Integrating Datasets’ chapter in the OSCA book. Its text is reproduced below with few modifications to adapt it to the data set under scrutiny here. 14.1 Abbreviations HVG: highly variable genes MNN: mutual nearest neighbors PBMMC: peripheral blood mononuclear cell SCE: SingleCellExperiment 14.2 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 14.3 Loading the data We will load the R file keeping the SCE object with the normalised counts, and subset 1000 cells per sample. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; We next subset the data for the PBMMC sample group: # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) splVec &lt;- cb_sampleSheet %&gt;% filter(source_name == splSetToGet) %&gt;% pull(Sample.Name) %&gt;% unique() sourceNames &lt;- unique(colData(sce)$source_name) sceOrig &lt;- sce sce &lt;- sceOrig[,sce$source_name == splSetToGet ] nbCells &lt;- 1000 all.sce &lt;- list() for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% sample_n(nbCells) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } nbSpl &lt;- length(all.sce) We then apply the standard workflow to each sample separately: * normalisation, * variance modelling * dimensionality reduction * clustering #--- normalization ---# # use logNormCounts() all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# # model varaince with modelGeneVar() # find highly variable genes (HVGs) with getTopHVGs() #library(scran) all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# # use runPCA() # then compute embeddings with runTSNE() and runUMAP() library(BiocSingular) set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) set.seed(100000) all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) set.seed(1000000) all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# # cluster each sample separately for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership colLabels(all.sce[[n]]) &lt;- factor(clust) } To prepare for the batch correction: We subset all batches to the common “universe” of features. In this case, it is straightforward as both batches use Ensembl gene annotation. allNames &lt;- unlist(lapply(all.sce, function(x){rownames(x)})) allNamesNb &lt;- table(allNames) universe &lt;- names(allNamesNb)[allNamesNb==nbSpl] #length(universe) The size of this common “universe” of features here is the number of features shared by all 3 samples is: 18431. # Subsetting the SingleCellExperiment object. uni.sce &lt;- lapply(all.sce, function(x){x[universe,]}) # Also subsetting the variance modelling results, for convenience. uni.dec &lt;- lapply(all.dec, function(x){x[universe,]}) We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment (SCE) objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. # rescale each batch to adjust for differences in sequencing depth between batches #library(batchelor) rescaled &lt;- multiBatchNorm(uni.sce, batch = &quot;Sample.Name&quot;) We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific highly-variable genes (HVGs) while still preserving the within-batch ranking of genes. library(scran) # compute average variance components across samples combined.dec &lt;- combineVar(uni.dec[[1]], uni.dec[[2]], uni.dec[[3]]) # identify highly variables genes # here as those with a positive biological component chosen.hvgs &lt;- combined.dec$bio &gt; 0 # sum(chosen.hvgs) Number of HVGs: 8604. When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons. 14.4 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the three SCE objects and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. # before concatenating matrices, # check that features are identical in all matrices: identical(rowData(rescaled[[1]]), rowData(rescaled[[2]])) ## [1] TRUE identical(rowData(rescaled[[1]]), rowData(rescaled[[3]])) ## [1] TRUE # have a &#39;batch&#39; entry in cell meta data: # (not strikly necessary as any column can be used) rescaled2 &lt;- lapply(rescaled, function(x){x$batch &lt;- x$Sample.Name; x}) rescaled &lt;- rescaled2 rm(rescaled2) # concat matrices: uncorrected &lt;- cbind(rescaled[[1]], rescaled[[2]], rescaled[[3]]) # Perform PCA # Using RandomParam() as it is more efficient for file-backed matrices. #library(scater) set.seed(0010101010) uncorrected &lt;- runPCA(uncorrected, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) We use graph-based clustering on the components to obtain a summary of the population structure. As the samples should be replicates, each cluster should ideally consist of cells from each batch. However, we instead see clusters that are comprised of cells from a single batch. This indicates that cells of the same type are artificially separated due to technical differences between batches. #library(scran) # build shared nearest-neighbour graph snn.gr &lt;- buildSNNGraph(uncorrected, use.dimred=&quot;PCA&quot;) # identify cluster with the walk trap method clusters &lt;- igraph::cluster_walktrap(snn.gr)$membership # get number of cells for each {cluster, batch} pair tab &lt;- table(Cluster=clusters, Batch=uncorrected$batch) #tab tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) Cluster size and cell contribution by sample: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() + ggtitle(&quot;uncorrected, cell numbers&quot;) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) + ggtitle(&quot;uncorrected, proportions&quot;) gridExtra::grid.arrange(p1, p2) We can also visualize the uncorrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results. set.seed(1111001) uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;) plotTSNE(uncorrected, colour_by=&quot;batch&quot;) Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations (which is not a consideration in the PBMMC dataset, but the same cannot be said in general). If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. 14.5 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. #library(batchelor) rescaled2 &lt;- rescaleBatches(rescaled) rescaled2 ## class: SingleCellExperiment ## dim: 18431 3000 ## metadata(0): ## assays(1): corrected ## rownames(18431): ENSG00000000003 ENSG00000000419 ... ENSG00000285486 ## ENSG00000285492 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## altExpNames(0): After clustering, we should observe that most clusters consist of mixtures of cells from the replicate batches, consistent with the removal of the batch effect. set.seed(1010101010) # To ensure reproducibility of IRLBA. rescaled2 &lt;- runPCA(rescaled2, subset_row=chosen.hvgs, exprs_values=&quot;corrected&quot;) snn.gr &lt;- buildSNNGraph(rescaled2, use.dimred=&quot;PCA&quot;) clusters.resc &lt;- igraph::cluster_walktrap(snn.gr)$membership #tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled2$batch) #tab.resc tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.resc, &quot;batch&quot;=rescaled2$batch) Cluster size and cell contribution by sample, with clusters sorted by size: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) Compute and plot t-SNE: rescaled2 &lt;- runTSNE(rescaled2, dimred=&quot;PCA&quot;) rescaled2$batch &lt;- factor(rescaled2$batch) plotTSNE(rescaled2, colour_by=&quot;batch&quot;) 14.6 Performing MNN correction 14.6.1 Algorithm overview Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors (MNN) are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space. 14.6.2 Application to the data The batchelor package provides an implementation of the MNN approach via the fastMNN() function. (Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps.) We apply it to our batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN(rescaled, auto.merge=TRUE, d=50, k=20, subset.row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out ## class: SingleCellExperiment ## dim: 8604 3000 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(8604): ENSG00000000003 ENSG00000000457 ... ENSG00000285458 ## ENSG00000285476 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out.corre.dim &lt;- dim(reducedDim(mnn.out, &quot;corrected&quot;)) mnn.out.corre.dim ## [1] 3000 50 mnn.out.recon.dim &lt;- dim(assay(mnn.out, &quot;reconstructed&quot;)) mnn.out.recon.dim ## [1] 8604 3000 The function returns a SCE object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. print(head(mnn.out$batch)) ## [1] &quot;GSM3872442&quot; &quot;GSM3872442&quot; &quot;GSM3872442&quot; &quot;GSM3872442&quot; &quot;GSM3872442&quot; ## [6] &quot;GSM3872442&quot; The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the principal components (PCs) in our downstream analyses (3000 cells and 50 PCs). A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space (8604 genes and 3000 cells). We do not recommend using this for anything other than visualization. print(assay(mnn.out, &quot;reconstructed&quot;)) ## &lt;8604 x 3000&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ... [,2999] ## ENSG00000000003 -9.693175e-05 1.177007e-04 -1.673004e-04 . 2.055355e-04 ## ENSG00000000457 3.065863e-04 2.538019e-04 9.322986e-04 . -1.994157e-04 ## ENSG00000000938 -9.292932e-04 -2.415617e-03 1.404325e-03 . -2.982403e-03 ## ENSG00000001167 1.860307e-04 -3.200527e-04 3.171867e-04 . -3.775970e-04 ## ENSG00000001461 -5.302109e-04 9.167783e-04 -9.285246e-04 . -2.790526e-04 ## ... . . . . . ## ENSG00000285437 -1.471949e-03 -2.137265e-03 -3.891309e-03 . -2.256149e-03 ## ENSG00000285444 7.318343e-05 -1.387095e-04 -3.779627e-04 . -3.413362e-04 ## ENSG00000285447 -1.167881e-04 -5.224395e-05 -2.945133e-04 . 1.850214e-04 ## ENSG00000285458 -2.076950e-05 1.076314e-05 1.810845e-04 . 9.591474e-05 ## ENSG00000285476 -5.965583e-05 6.250964e-05 -1.062484e-04 . 7.862604e-05 ## [,3000] ## ENSG00000000003 -2.514390e-04 ## ENSG00000000457 1.265962e-04 ## ENSG00000000938 -1.385492e-03 ## ENSG00000001167 -5.522563e-05 ## ENSG00000001461 3.146520e-04 ## ... . ## ENSG00000285437 1.192830e-03 ## ENSG00000285444 1.041148e-04 ## ENSG00000285447 2.203375e-04 ## ENSG00000285458 1.915324e-04 ## ENSG00000285476 -7.949445e-05 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. 14.7 Correction diagnostics 14.7.1 Mixing between batches We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that most clusters contain contributions from each batch after correction, consistent with our expectation that the batches are replicates of each other. #library(scran) snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;) clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster GSM3872442 GSM3872443 GSM3872444 ## 1 16 46 11 ## 2 176 38 96 ## 3 54 48 144 ## 4 77 23 36 ## 5 68 32 48 ## 6 1 62 14 ## 7 3 89 7 ## 8 0 139 2 ## 9 37 86 65 ## 10 9 6 3 ## 11 297 267 230 ## 12 191 35 185 ## 13 11 7 9 ## 14 25 7 39 ## 15 6 33 9 ## 16 29 82 102 Cluster size and cell contribution by sample, with clusters sorted by size: tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$batch) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) We can also compute the variation in the log-abundances to rank the clusters with the greatest variability in their proportional abundances across batches. We can then focus on batch-specific clusters that may be indicative of incomplete batch correction. Obviously, though, this diagnostic is subject to interpretation as the same outcome can be caused by batch-specific populations; some prior knowledge about the biological context is necessary to distinguish between these two possibilities. # Avoid minor difficulties with the &#39;table&#39; class. tab.mnn &lt;- unclass(tab.mnn) # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) # Ranking clusters by the largest variances. rv &lt;- rowVars(norm) %&gt;% round(2) # show DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),] ## DataFrame with 16 rows and 4 columns ## Batch.GSM3872442 Batch.GSM3872443 Batch.GSM3872444 var ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; ## 8 0 139 2 4.74 ## 7 3 89 7 2.53 ## 6 1 62 14 1.85 ## 12 191 35 185 1.52 ## 2 176 38 96 0.96 ## ... ... ... ... ... ## 9 37 86 65 0.27 ## 5 68 32 48 0.20 ## 10 9 6 3 0.08 ## 11 297 267 230 0.03 ## 13 11 7 9 0.02 We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from all batches provides a comforting illusion that the correction was successful. #library(scater) set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;) mnn.out$batch &lt;- factor(mnn.out$batch) plotTSNE(mnn.out, colour_by=&quot;batch&quot;) #mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) #p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, shape_by=&quot;type&quot;) #p + facet_wrap(. ~ mnn.out$type) For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). round(metadata(mnn.out)$merge.info$lost.var,2) ## GSM3872442 GSM3872443 GSM3872444 ## [1,] 0.03 0.00 0.04 ## [2,] 0.02 0.17 0.03 Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. The following t-SNE shows the clusters identified: mnn.out$cluster &lt;- paste0(&quot;c&quot;, clusters.mnn) plotTSNE(mnn.out, colour_by=&quot;cluster&quot;) The following t-SNE plots show expression levels of known cell type marker genes. genesToShow &lt;- c( &quot;CD79A&quot;, # CD79A B *** &quot;CST3&quot;, # CST3 monocytes *** &quot;CD3D&quot;, # CD3D T cells *** &quot;HBA1&quot; # HBA1 erythrocytes *** ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] B cells: genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) monocytes: genex &lt;- ensToShow[2] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Other genes (exercise) genesToShow2 &lt;- c( &quot;IL7R&quot;, # IL7R, CCR7 Naive CD4+ T &quot;CCR7&quot;, # IL7R, CCR7 Naive CD4+ T &quot;S100A4&quot;, # IL7R, S100A4 Memory CD4+ &quot;CD14&quot;, # CD14, LYZ CD14+ Mono &quot;LYZ&quot;, # CD14, LYZ CD14+ Mono &quot;MS4A1&quot;, # MS4A1 B &quot;CD8A&quot;, # CD8A CD8+ T &quot;FCGR3A&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;MS4A7&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;GNLY&quot;, # GNLY, NKG7 NK &quot;NKG7&quot;, # GNLY, NKG7 NK &quot;FCER1A&quot;, # DC &quot;CST3&quot;, # DC &quot;PPBP&quot; # Platelet ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow2) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] for (genex in ensToShow) { p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;])) print(p) } 14.8 Preserving biological heterogeneity 14.8.1 Comparison to within-batch clusters Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries are zero, though this may depend on whether specific clusters of interest are gained or lost. One heatmap is generated for each dataset, where each entry is colored according to the number of cells with each pair of labels (before and after correction), on the log10 scale with a pseudocounts +10 for a smoother color transition (so a minimum value of log10(0+10) == 1). #library(pheatmap) # have common color scale: # for the number of cells on the log10 scale breakVec = seq(0, 3, by = 0.2) colPal &lt;- colorRampPalette(rev(RColorBrewer::brewer.pal(n = 7, name = &quot;RdYlBu&quot;)))(length(breakVec)) # Defines the vector of colors for the legend (it has to be of the same length as breakVec) # For the first batch (adding +10 for a smoother color transition # from zero to non-zero counts for any given matrix entry). splIdx &lt;- 1 tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[rescaled2$batch==splVec[splIdx]]), paste(&quot;before&quot;, colLabels(rescaled[[splIdx]]))) heat1 &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison (number of cells, log10 scale)&quot;, splVec[splIdx]), silent=TRUE, col=colPal) library(clustree) combined &lt;- cbind(cl.1=colLabels(rescaled[[splIdx]]), cl.2=clusters.mnn[rescaled2$batch==splVec[splIdx]]) clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) # For the second batch. splIdx &lt;- 2 tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[rescaled2$batch==splVec[splIdx]]), paste(&quot;before&quot;, colLabels(rescaled[[splIdx]]))) heat2 &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison (number of cells, log10 scale)&quot;, splVec[splIdx]), silent=TRUE) #library(clustree) combined &lt;- cbind(cl.1=colLabels(rescaled[[splIdx]]), cl.2=clusters.mnn[rescaled2$batch==splVec[splIdx]]) clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) gridExtra::grid.arrange(heat1[[4]], heat2[[4]]) Another evaluation approach is to compute the coassignment probabilities, i.e. the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place. Coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each sample, where each entry is colored according to the coassignment probability between each pair of within-batch clusters: # For the first batch. splIdx &lt;- 1 tab &lt;- coassignProb(colLabels(rescaled[[splIdx]]), clusters.mnn[rescaled2$batch==splVec[splIdx]]) heat1 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) # For the second batch. splIdx &lt;- 2 tab &lt;- coassignProb(colLabels(rescaled[[splIdx]]), clusters.mnn[rescaled2$batch==splVec[splIdx]]) heat2 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) gridExtra::grid.arrange(heat1[[4]], heat2[[4]]) Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. suppressMessages(library(fossil)) ri1 &lt;- rand.index(as.integer(clusters.mnn[rescaled2$batch==&quot;GSM3872443&quot;]), as.integer(colLabels(rescaled[[1]]))) #ri1 # same as above but with `bluster` splIdx &lt;- 1 #library(bluster) ri1 &lt;- pairwiseRand(as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]), as.integer(colLabels(rescaled[[splIdx]])), mode=&quot;index&quot;) Rand index for GSM3872442: 0.64. splIdx &lt;- 2 ri2 &lt;- pairwiseRand(as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]), as.integer(colLabels(rescaled[[splIdx]])), mode=&quot;index&quot;) #ri2 Rand index for GSM3872443: 0.91 We can also break down the adjusted Rand index (ARI) into per-cluster ratios for more detailed diagnostics. For example, we could see low ratios off the diagonal if distinct clusters in the within-batch clustering were incorrectly aggregated in the merged clustering. Conversely, we might see low ratios on the diagonal if the correction inflated or introduced spurious heterogeneity inside a within-batch cluster. # For the first batch. splIdx &lt;- 1 tab &lt;- pairwiseRand( as.integer(colLabels(rescaled[[splIdx]])), as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) heat1 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s adjusted Rand index&quot;, splVec[splIdx]), silent=TRUE) # For the second batch. splIdx &lt;- 2 tab &lt;- pairwiseRand( as.integer(colLabels(rescaled[[splIdx]])), as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) heat2 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s adjusted Rand index&quot;, splVec[splIdx]), silent=TRUE) gridExtra::grid.arrange(heat1[[4]], heat2[[4]]) # For the first batch. splIdx &lt;- 1 tab &lt;- pairwiseRand( as.integer(colLabels(rescaled[[splIdx]])), as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) tab1 &lt;- tab #heat1 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, # col=rev(viridis::magma(100)), # main=sprintf(&quot;%s adjusted Rand index&quot;, splVec[splIdx]), # silent=TRUE) # For the second batch. splIdx &lt;- 2 tab &lt;- pairwiseRand( as.integer(colLabels(rescaled[[splIdx]])), as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) tab2 &lt;- tab rm(tab) #heat2 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, # col=rev(viridis::magma(100)), # main=sprintf(&quot;%s adjusted Rand index&quot;, splVec[splIdx]), # silent=TRUE) #gridExtra::grid.arrange(heat1[[4]], heat2[[4]]) ## make breaks from combined range Breaks &lt;- seq(min(c(tab1, tab2), na.rm = TRUE), max(c(tab1, tab2), na.rm = TRUE), length = 100) splIdx &lt;- 1 heat1 &lt;- pheatmap(tab1, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s adjusted Rand index&quot;, splVec[splIdx]), silent=TRUE) splIdx &lt;- 2 heat2 &lt;- pheatmap(tab2, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s adjusted Rand index&quot;, splVec[splIdx]), silent=TRUE) gridExtra::grid.arrange(heat1[[4]], heat2[[4]]) 14.8.2 Encouraging consistency with marker genes In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach. To illustrate, we apply this strategy to our datasets. We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by [SingleR](https://www.bioconductor.org/packages/release/bioc/html/SingleR.html). In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN(). # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. stats1 &lt;- pairwiseWilcox(rescaled[[1]], direction=&quot;up&quot;) markers1 &lt;- getTopMarkers(stats1[[1]], stats1[[2]], n=10) stats2 &lt;- pairwiseWilcox(rescaled[[2]], direction=&quot;up&quot;) markers2 &lt;- getTopMarkers(stats2[[1]], stats2[[2]], n=10) stats3 &lt;- pairwiseWilcox(rescaled[[3]], direction=&quot;up&quot;) markers3 &lt;- getTopMarkers(stats3[[1]], stats3[[2]], n=10) marker.set &lt;- unique(unlist(c(unlist(markers1), unlist(markers2), unlist(markers3)))) length(marker.set) # getting the total number of genes selected in this manner. ## [1] 435 Total number of genes selected in this manner: 435. set.seed(1000110) mnn.out2 &lt;- fastMNN(rescaled, subset.row=marker.set, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) # compute t-SNE: mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;) We can also visualize the corrected coordinates using a t-SNE plot: plotTSNE(mnn.out2, colour_by=&quot;batch&quot;) A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context. gridExtra::grid.arrange( plotTSNE(mnn.out2[,mnn.out2$batch==&quot;GSM3872442&quot;], colour_by=I(colLabels(rescaled[[1]]))), plotTSNE(mnn.out2[,mnn.out2$batch==&quot;GSM3872443&quot;], colour_by=I(colLabels(rescaled[[2]]))), plotTSNE(mnn.out2[,mnn.out2$batch==&quot;GSM3872444&quot;], colour_by=I(colLabels(rescaled[[3]]))), ncol=2 ) # B cells genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) # cannot find &#39;ENSG00000115523&#39; # TODO: use another gene? # erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) We suggest limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. B cells: m.out &lt;- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;), drop=FALSE]) Erythrocytes: demo &lt;- m.out[[&quot;11&quot;]] %&gt;% data.frame %&gt;% arrange(FDR) demo[ensToShow[4],] ## ensembl_gene_id Symbol Top p.value FDR summary.logFC logFC.1 ## ENSG00000206172 ENSG00000206172 HBA1 160 1 1 0.1461401 -2.638346 ## logFC.2 logFC.3 logFC.4 logFC.5 logFC.6 logFC.7 ## ENSG00000206172 0.1126643 -0.3672066 0.0768022 -0.04321104 -5.561042 -5.754414 ## logFC.8 logFC.9 logFC.10 logFC.12 logFC.13 logFC.14 ## ENSG00000206172 -5.734749 -0.2643027 0.1461401 -0.1729262 -0.3015218 0.04455094 ## logFC.15 logFC.16 ## ENSG00000206172 -5.313446 -0.1326186 as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;)]) ## Symbol Top p.value FDR ## ENSG00000161970 RPL26 1 1.381128e-154 2.545558e-150 ## ENSG00000105193 RPS16 2 2.109919e-146 1.944396e-142 ## ENSG00000171858 RPS21 3 1.151263e-143 7.072978e-140 ## ENSG00000071082 RPL31 4 4.726090e-142 2.177664e-138 ## ENSG00000100316 RPL3 5 1.558616e-138 5.745372e-135 ## ENSG00000166441 RPL27A 6 7.723015e-136 2.372381e-132 ## ENSG00000145425 RPS3A 4 1.365755e-135 3.596032e-132 ## ENSG00000142937 RPS8 1 3.979392e-135 9.168022e-132 ## ENSG00000140988 RPS2 9 1.793490e-134 3.672868e-131 ## ENSG00000198755 RPL10A 9 6.611618e-134 1.196538e-130 ## ENSG00000131469 RPL27 11 7.141185e-134 1.196538e-130 ## ENSG00000110700 RPS13 6 1.027873e-133 1.578727e-130 ## ENSG00000197958 RPL12 3 3.133807e-133 4.443015e-130 ## ENSG00000143947 RPS27A 9 8.860447e-133 1.166478e-129 ## ENSG00000156508 EEF1A1 15 4.768881e-129 5.859684e-126 ## ENSG00000198242 RPL23A 7 1.515175e-128 1.745387e-125 ## ENSG00000198918 RPL39 16 1.104657e-126 1.197643e-123 ## ENSG00000231500 RPS18 9 1.350047e-126 1.382373e-123 ## ENSG00000109475 RPL34 5 5.450229e-126 5.287009e-123 ## ENSG00000167526 RPL13 4 8.175809e-126 7.534417e-123 Expression level for the top gene, ENSG00000161970: geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) 14.9 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] bluster_1.0.0 fossil_0.4.0 ## [3] shapefiles_0.7 foreign_0.8-81 ## [5] maps_3.3.0 sp_1.4-5 ## [7] clustree_0.4.3 ggraph_2.0.5 ## [9] pheatmap_1.0.12 batchelor_1.6.3 ## [11] BiocSingular_1.6.0 Cairo_1.5-12.2 ## [13] dplyr_1.0.5 scran_1.18.7 ## [15] scater_1.18.6 SingleCellExperiment_1.12.0 ## [17] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [19] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [21] IRanges_2.24.1 S4Vectors_0.28.1 ## [23] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [25] matrixStats_0.58.0 ggplot2_3.3.3 ## [27] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] Rtsne_0.15 ggbeeswarm_0.6.0 ## [3] colorspace_2.0-0 ellipsis_0.3.2 ## [5] scuttle_1.0.4 XVector_0.30.0 ## [7] BiocNeighbors_1.8.2 farver_2.1.0 ## [9] graphlayouts_0.7.1 ggrepel_0.9.1 ## [11] RSpectra_0.16-0 fansi_0.4.2 ## [13] codetools_0.2-18 sparseMatrixStats_1.2.1 ## [15] polyclip_1.10-0 jsonlite_1.7.2 ## [17] ResidualMatrix_1.0.0 uwot_0.1.10 ## [19] ggforce_0.3.3 compiler_4.0.3 ## [21] dqrng_0.3.0 backports_1.2.1 ## [23] assertthat_0.2.1 Matrix_1.3-2 ## [25] limma_3.46.0 tweenr_1.0.2 ## [27] htmltools_0.5.1.1 tools_4.0.3 ## [29] rsvd_1.0.5 igraph_1.2.6 ## [31] gtable_0.3.0 glue_1.4.2 ## [33] GenomeInfoDbData_1.2.4 Rcpp_1.0.6 ## [35] jquerylib_0.1.3 vctrs_0.3.7 ## [37] DelayedMatrixStats_1.12.3 xfun_0.22 ## [39] stringr_1.4.0 beachmat_2.6.4 ## [41] lifecycle_1.0.0 irlba_2.3.3 ## [43] statmod_1.4.35 edgeR_3.32.1 ## [45] zlibbioc_1.36.0 MASS_7.3-54 ## [47] scales_1.1.1 tidygraph_1.2.0 ## [49] RColorBrewer_1.1-2 yaml_2.2.1 ## [51] gridExtra_2.3 sass_0.3.1 ## [53] stringi_1.5.3 highr_0.9 ## [55] checkmate_2.0.0 BiocParallel_1.24.1 ## [57] rlang_0.4.10 pkgconfig_2.0.3 ## [59] bitops_1.0-7 evaluate_0.14 ## [61] lattice_0.20-44 purrr_0.3.4 ## [63] labeling_0.4.2 cowplot_1.1.1 ## [65] tidyselect_1.1.1 magrittr_2.0.1 ## [67] bookdown_0.22 R6_2.5.0 ## [69] generics_0.1.0 DelayedArray_0.16.3 ## [71] DBI_1.1.1 pillar_1.6.0 ## [73] withr_2.4.2 RCurl_1.98-1.3 ## [75] tibble_3.1.1 crayon_1.4.1 ## [77] utf8_1.2.1 rmarkdown_2.7 ## [79] viridis_0.6.0 locfit_1.5-9.4 ## [81] grid_4.0.3 FNN_1.1.3 ## [83] digest_0.6.27 tidyr_1.1.3 ## [85] munsell_0.5.0 beeswarm_0.3.1 ## [87] viridisLite_0.4.0 vipor_0.4.5 ## [89] bslib_0.2.4 "],["dataSetIntegration-ETV6-RUNX1Top.html", "Chapter 15 Data integration - ETV6-RUNX1 15.1 Abbreviations 15.2 Motivation 15.3 Loading the data 15.4 Diagnosing batch effects 15.5 Linear regression 15.6 Performing MNN correction 15.7 Correction diagnostics 15.8 Encouraging consistency with marker genes 15.9 Session information", " Chapter 15 Data integration - ETV6-RUNX1 projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool setName &lt;- params$setName splSetToGet &lt;- params$splSetToGet setSuf &lt;- params$setSuf dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;ETV6-RUNX1&quot; setSuf &lt;- &quot;_allCells&quot; } nbPcToComp &lt;- 50 figSize &lt;- 7 Source: ‘Integrating Datasets’ chapter in the OSCA book. Its text is reproduced below with few modifications to adapt it to the data set under scrutiny here. 15.1 Abbreviations HVG: highly variable genes MNN: mutual nearest neighbors PBMMC: peripheral blood mononuclear cell SCE: SingleCellExperiment 15.2 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 15.3 Loading the data We will load the R file keeping the SCE object with the normalised counts, and subset 1000 cells per sample. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; We next subset the data for the ETV6-RUNX1 sample group: # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) splVec &lt;- cb_sampleSheet %&gt;% filter(source_name == splSetToGet) %&gt;% pull(Sample.Name) %&gt;% unique() sourceNames &lt;- unique(colData(sce)$source_name) sceOrig &lt;- sce sce &lt;- sceOrig[,sce$source_name == splSetToGet ] nbCells &lt;- 1000 all.sce &lt;- list() for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% sample_n(nbCells) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } nbSpl &lt;- length(all.sce) We then apply the standard workflow to each sample separately: * normalisation, * variance modelling * dimensionality reduction * clustering #--- normalization ---# # use logNormCounts() all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# # model varaince with modelGeneVar() # find highly variable genes (HVGs) with getTopHVGs() all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# # use runPCA() # then compute embeddings with runTSNE() and runUMAP() library(BiocSingular) set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) set.seed(100000) all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) set.seed(1000000) all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# # cluster each sample separately for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership #colLabels(all.sce[[n]]) &lt;- factor(clust) all.sce[[n]]$label &lt;- factor(clust) } To prepare for the batch correction: We subset all batches to the common “universe” of features. In this case, it is straightforward as both batches use Ensembl gene annotation. allNames &lt;- unlist(lapply(all.sce, function(x){rownames(x)})) allNamesNb &lt;- table(allNames) universe &lt;- names(allNamesNb)[allNamesNb==nbSpl] #length(universe) The size of this common “universe” of features here is the number of features shared by all 4 samples is: 18431. # Subsetting the SingleCellExperiment object. uni.sce &lt;- lapply(all.sce, function(x){x[universe,]}) # Also subsetting the variance modelling results, for convenience. uni.dec &lt;- lapply(all.dec, function(x){x[universe,]}) We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment (SCE) objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. # rescale each batch to adjust for differences in sequencing depth between batches rescaled &lt;- multiBatchNorm(uni.sce, batch = &quot;Sample.Name&quot;) We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. # compute average variance components across samples #combined.dec &lt;- combineVar(uni.dec[[1]], uni.dec[[2]], uni.dec[[3]], uni.dec[[4]]) combined.dec &lt;- combineVar(uni.dec) # identify highly variables genes # here as those with a positive biological component chosen.hvgs &lt;- combined.dec$bio &gt; 0 #sum(chosen.hvgs) Number of HVGs: 10953. When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons. 15.4 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the SCE objects and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. identical(rowData(rescaled[[1]]), rowData(rescaled[[2]])) ## [1] TRUE identical(rowData(rescaled[[1]]), rowData(rescaled[[3]])) ## [1] TRUE identical(rowData(rescaled[[1]]), rowData(rescaled[[4]])) ## [1] TRUE rescaled[[1]]$batch &lt;- rescaled[[1]]$Sample.Name rescaled2 &lt;- lapply(rescaled, function(x){x$batch &lt;- x$Sample.Name; x}) rescaled &lt;- rescaled2 rm(rescaled2) # concat matrices: uncorrected &lt;- do.call(cbind, rescaled) # Perform PCA # Using RandomParam() as it is more efficient for file-backed matrices. set.seed(0010101010) uncorrected &lt;- runPCA(uncorrected, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) We use graph-based clustering on the components to obtain a summary of the population structure. As the samples should be replicates, each cluster should ideally consist of cells from each batch. However, we instead see clusters that are comprised of cells from a single batch. This indicates that cells of the same type are artificially separated due to technical differences between batches. # build shared nearest-neighbour graph snn.gr &lt;- buildSNNGraph(uncorrected, use.dimred=&quot;PCA&quot;) # identify cluster with the walk trap method clusters &lt;- igraph::cluster_walktrap(snn.gr)$membership # get number of cells for each {cluster, batch} pair tab &lt;- table(Cluster=clusters, Batch=uncorrected$batch) #tab tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) Cluster size and cell contribution by sample: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() + ggtitle(&quot;uncorrected, cell numbers&quot;) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) + ggtitle(&quot;uncorrected, proportions&quot;) gridExtra::grid.arrange(p1, p2) We can also visualize the uncorrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results. set.seed(1111001) uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;) plotTSNE(uncorrected, colour_by=&quot;batch&quot;) Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations. If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. 15.5 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. rescaled2 &lt;- rescaleBatches(rescaled) rescaled2 ## class: SingleCellExperiment ## dim: 18431 4000 ## metadata(0): ## assays(1): corrected ## rownames(18431): ENSG00000000003 ENSG00000000419 ... ENSG00000285486 ## ENSG00000285492 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## altExpNames(0): After clustering, we observe that most clusters consist of mixtures of cells from the two replicate batches, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches. set.seed(1010101010) # To ensure reproducibility of IRLBA. rescaled2 &lt;- runPCA(rescaled2, subset_row=chosen.hvgs, exprs_values=&quot;corrected&quot;) snn.gr &lt;- buildSNNGraph(rescaled2, use.dimred=&quot;PCA&quot;) clusters.resc &lt;- igraph::cluster_walktrap(snn.gr)$membership #tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled2$batch) #tab.resc tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.resc, &quot;batch&quot;=rescaled2$batch) Cluster size and cell contribution by sample, with clusters sorted by size: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) Compute and plot t-SNE: rescaled2 &lt;- runTSNE(rescaled2, dimred=&quot;PCA&quot;) rescaled2$batch &lt;- factor(rescaled2$batch) plotTSNE(rescaled2, colour_by=&quot;batch&quot;) 15.6 Performing MNN correction 15.6.1 Algorithm overview Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space. 15.6.2 Application to the data The batchelor package provides an implementation of the MNN approach via the fastMNN() function. (Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps.) We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN(rescaled, auto.merge=TRUE, d=50, k=20, subset.row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out ## class: SingleCellExperiment ## dim: 10953 4000 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(10953): ENSG00000000457 ENSG00000000938 ... ENSG00000285292 ## ENSG00000285437 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out.corre.dim &lt;- dim(reducedDim(mnn.out, &quot;corrected&quot;)) mnn.out.corre.dim ## [1] 4000 50 mnn.out.recon.dim &lt;- dim(assay(mnn.out, &quot;reconstructed&quot;)) mnn.out.recon.dim ## [1] 10953 4000 The function returns a SCE object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses (4000 cells and 50 PCs). A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space (10953 genes and 4000 cells). We do not recommend using this for anything other than visualization. print(assay(mnn.out, &quot;reconstructed&quot;)) ## &lt;10953 x 4000&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ... [,3999] ## ENSG00000000457 0.0005836813 0.0006244532 0.0004057674 . 8.543043e-04 ## ENSG00000000938 -0.0011512163 -0.0002567277 -0.0003360513 . -7.241426e-04 ## ENSG00000001167 0.0009362013 0.0015060732 0.0015091582 . 6.712224e-04 ## ENSG00000001460 -0.0001912602 0.0002205073 0.0001764304 . 2.030422e-05 ## ENSG00000001461 -0.0007160136 -0.0002709601 0.0001893310 . 1.933687e-03 ## ... . . . . . ## ENSG00000285165 -3.317488e-06 1.712392e-05 -4.779076e-05 . 9.918968e-05 ## ENSG00000285230 -1.231077e-04 2.336536e-05 1.846989e-04 . -2.490030e-04 ## ENSG00000285278 3.902154e-05 8.325881e-06 -9.229071e-05 . 9.857251e-05 ## ENSG00000285292 -2.597556e-05 -1.117245e-04 -1.833121e-04 . 2.300101e-04 ## ENSG00000285437 -9.814801e-03 -4.484067e-03 -5.647511e-03 . -8.654930e-03 ## [,4000] ## ENSG00000000457 9.593162e-04 ## ENSG00000000938 -1.423729e-04 ## ENSG00000001167 7.862265e-04 ## ENSG00000001460 9.722642e-05 ## ENSG00000001461 -1.973582e-03 ## ... . ## ENSG00000285165 -1.189782e-05 ## ENSG00000285230 2.116166e-04 ## ENSG00000285278 -1.097212e-04 ## ENSG00000285292 1.304183e-05 ## ENSG00000285437 4.627146e-03 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. 15.7 Correction diagnostics 15.7.1 Mixing between batches We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the batches are replicates of each other. snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, k=20) clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster GSM3872434 GSM3872435 GSM3872436 GSM3872437 ## 1 0 0 17 62 ## 2 592 210 95 282 ## 3 1 0 11 22 ## 4 65 46 10 51 ## 5 1 0 5 51 ## 6 149 92 39 141 ## 7 106 516 284 184 ## 8 33 50 23 14 ## 9 0 1 7 27 ## 10 4 4 40 10 ## 11 0 0 7 8 ## 12 33 31 8 35 ## 13 4 4 22 8 ## 14 2 3 21 14 ## 15 1 0 18 26 ## 16 6 31 294 40 ## 17 3 12 99 25 Cluster size and cell contribution by sample, with clusters sorted by size: tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$batch) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) We can also compute the variation in the log-abundances to rank the clusters with the greatest variability in their proportional abundances across batches. We can then focus on batch-specific clusters that may be indicative of incomplete batch correction. Obviously, though, this diagnostic is subject to interpretation as the same outcome can be caused by batch-specific populations; some prior knowledge about the biological context is necessary to distinguish between these two possibilities. The table below shows the number of cells for each cluster (row) and sample (column) together with the variance in cell number across these samples (‘var’ column). # Avoid minor difficulties with the &#39;table&#39; class. tab.mnn &lt;- unclass(tab.mnn) # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) # Ranking clusters by the largest variances. rv &lt;- rowVars(norm) %&gt;% round(2) # show #DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),] DataFrame(tab.mnn, var=rv)[order(rv, decreasing=TRUE),] ## DataFrame with 17 rows and 5 columns ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 var ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; ## 16 6 31 294 40 3.15 ## 1 0 0 17 62 1.86 ## 17 3 12 99 25 1.71 ## 5 1 0 5 51 1.46 ## 2 592 210 95 282 1.09 ## ... ... ... ... ... ... ## 14 2 3 21 14 0.45 ## 12 33 31 8 35 0.40 ## 8 33 50 23 14 0.32 ## 13 4 4 22 8 0.32 ## 11 0 0 7 8 0.22 We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from batches provides a comforting illusion that the correction was successful. set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;) mnn.out$batch &lt;- factor(mnn.out$batch) plotTSNE(mnn.out, colour_by=&quot;batch&quot;) #mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) #p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, shape_by=&quot;type&quot;) #p + facet_wrap(. ~ mnn.out$type) For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). round(metadata(mnn.out)$merge.info$lost.var,2) ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 ## [1,] 0.00 0.00 0.08 0.09 ## [2,] 0.00 0.04 0.01 0.02 ## [3,] 0.04 0.01 0.00 0.00 Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. The following t-SNE shows the clusters identified: mnn.out$cluster &lt;- paste0(&quot;c&quot;, clusters.mnn) p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;) p p + facet_wrap(~colData(mnn.out)$batch) The following t-SNE plots show expression levels of known cell type marker genes. genesToShow &lt;- c( &quot;CD79A&quot;, # CD79A B *** &quot;CST3&quot;, # CST3 monocytes *** &quot;CD3D&quot;, # CD3D T cells *** &quot;HBA1&quot; # HBA1 erythrocytes *** ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] B cells: genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) monocytes: genex &lt;- ensToShow[2] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Compare to the uncorrected values, T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Compare to the uncorrected values, erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Other genes (exercise) genesToShow2 &lt;- c( &quot;IL7R&quot;, # IL7R, CCR7 Naive CD4+ T &quot;CCR7&quot;, # IL7R, CCR7 Naive CD4+ T &quot;S100A4&quot;, # IL7R, S100A4 Memory CD4+ &quot;CD14&quot;, # CD14, LYZ CD14+ Mono &quot;LYZ&quot;, # CD14, LYZ CD14+ Mono &quot;MS4A1&quot;, # MS4A1 B &quot;CD8A&quot;, # CD8A CD8+ T &quot;FCGR3A&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;MS4A7&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;GNLY&quot;, # GNLY, NKG7 NK &quot;NKG7&quot;, # GNLY, NKG7 NK &quot;FCER1A&quot;, # DC &quot;CST3&quot;, # DC &quot;PPBP&quot; # Platelet ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow2) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] table(ensToShow %in% rownames(rowData(mnn.out))) ensToShow &lt;- ensToShow[ensToShow %in% rownames(rowData(mnn.out))] for (genex in ensToShow) { p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;])) print(p) } 15.7.2 Preserving biological heterogeneity 15.7.2.1 Comparison between within-batch clusters and across-batch clusters obtained after MNN correction Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries are zero, though this may depend on whether specific clusters of interest are gained or lost. One heatmap is generated for each dataset, where each entry is colored according to the number of cells with each pair of labels (before and after correction), on the log10 scale with pseudocounts (+10) for a smoother color transition (so a minimum value of log10(0+10) == 1). plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled2$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled[[splIdx]]), cl.2=clusters.mnn[rescaled2$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) #gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, nrow=2, ncol=1, heights=c(unit(.8, &quot;npc&quot;), unit(.2, &quot;npc&quot;))) if(FALSE) { grobx &lt;- gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, nrow=3, ncol=2, heights=c(unit(.8, &quot;npc&quot;), unit(.1, &quot;npc&quot;), unit(.1, &quot;npc&quot;)), widths=c(unit(.3, &quot;npc&quot;), unit(.7, &quot;npc&quot;)), layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE) ) } if(FALSE) { grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, #nrow=3, ncol=2, #layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE), nrow=2, ncol=3, layout_matrix=matrix(c(1,1,2,5,4,3), ncol=3, byrow=FALSE), widths=c(unit(.70, &quot;npc&quot;), unit(.15, &quot;npc&quot;), unit(.15, &quot;npc&quot;)), heights=c(unit(.7, &quot;npc&quot;), unit(.3, &quot;npc&quot;)) ) } grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##gridExtra::marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’, ‘after’) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. figSize &lt;- 7 #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} #gridExtra::grid.arrange(grobs = treeList, gridExtra::grid.arrange(grobs = gxList, ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) gridExtra::grid.arrange(grobs = treeList, ncol=2 ) knitr::knit_exit() 15.7.2.2 Coassignment probabilities Another evaluation approach is to compute the coassignment probabilities, i.e. the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place. The plots below display the coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each sample, where each entry is colored according to the coassignment probability between each pair of within-batch clusters: # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled[[splIdx]]), clusters.mnn[rescaled2$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair (in pairwiseRand() with mode=“ratio” and adjusted=FALSE). The Rand index is introduced below. 15.7.2.3 Rand index Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled[[splIdx]])), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 ## 0.26 0.37 0.74 0.51 A sample may show a low Rand index value if cells grouped together in a small cluster before correction are split into distinct clusters after correction because the latter comprise cell populations not observed in that sample but present in other samples. This would be the case of GSM3872434 and GSM3872435 with far fewer erythrocytes (group in a single cluster) than the other two samples, in which subtypes can be distinguished. We can also break down the adjusted Rand index (ARI) into per-cluster ratios for more detailed diagnostics. For example, we could see low ratios off the diagonal if distinct clusters in the within-batch clustering were incorrectly aggregated in the merged clustering. Conversely, we might see low ratios on the diagonal if the correction inflated or introduced spurious heterogeneity inside a within-batch cluster. # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled[[splIdx]])), alt=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) 15.8 Encouraging consistency with marker genes In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach that is a natural extension of the strategy described in Section 8.4. We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by SingleR. In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN(). # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. markerList &lt;- lapply(rescaled, function(x){ y &lt;- pairwiseWilcox(x, direction=&quot;up&quot;) getTopMarkers(y[[1]], y[[2]], n=10) %&gt;% unlist %&gt;% unlist }) marker.set &lt;- unique(unlist(markerList)) #length(marker.set) # getting the total number of genes selected in this manner. The total number of genes selected in this manner is: 481. set.seed(1000110) mnn.out2 &lt;- fastMNN(rescaled, subset.row=marker.set, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) # compute t-SNE: mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;) We can also visualize the corrected coordinates using a t-SNE plot: plotTSNE(mnn.out2, colour_by=&quot;batch&quot;) plotTSNE(mnn.out2, colour_by=&quot;batch&quot;) + facet_wrap(~colData(mnn.out2)$batch) A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (x in 1:length(splVec)) { plotList[[x]] &lt;- plotTSNE(mnn.out2[,mnn.out2$batch==splVec[x]], colour_by=I(colLabels(rescaled[[x]]))) + ggtitle(splVec[x]) } gridExtra::grid.arrange(grobs = plotList, ncol=2 ) # by_exprs_values, : cannot find &#39;ENSG00000090382&#39; for ETV6-RUNX1 # B cells genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) ensToShowPostCor &lt;- ensToShow[ensToShow %in% rownames(mnn.out2)] rowData(uncorrected)[ensToShowPostCor,c(&quot;ensembl_gene_id&quot;, &quot;external_gene_name&quot;)] genex &lt;- &quot;ENSG00000156738&quot; # MS4A1 # ensToShowPostCor[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) # ENSG00000203747 is FCGR3A genex &lt;- &quot;ENSG00000203747&quot; # FCGR3A # ensToShowPostCor[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) m.out &lt;- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE]) #lapply(m.out, function(x){head(x[,2:6])}) # A (probably activated?) T cell subtype of some sort: tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) Expression level for the top gene, on violin plots: geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, ENSG00000008517 on t-SNE plot: genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) p + facet_wrap(~colData(mnn.out)$batch) We suggest limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. # save object? #fn &lt;- sprintf(&quot;dataSetIntegration_%s.Rdata&quot;, splSetToGet) fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s.Rdata&quot;, projDir, outDirBit, setName, setSuf, splSetToGet) # &#39;dsi&#39; for data set integration saveRDS(mnn.out, file=fn) 15.9 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] BiocSingular_1.6.0 Cairo_1.5-12.2 ## [3] clustree_0.4.3 ggraph_2.0.5 ## [5] pheatmap_1.0.12 dplyr_1.0.5 ## [7] bluster_1.0.0 batchelor_1.6.3 ## [9] scran_1.18.7 scater_1.18.6 ## [11] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [13] Biobase_2.50.0 GenomicRanges_1.42.0 ## [15] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [17] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [19] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [21] ggplot2_3.3.3 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 RColorBrewer_1.1-2 ## [3] backports_1.2.1 tools_4.0.3 ## [5] bslib_0.2.4 utf8_1.2.1 ## [7] R6_2.5.0 irlba_2.3.3 ## [9] ResidualMatrix_1.0.0 vipor_0.4.5 ## [11] uwot_0.1.10 DBI_1.1.1 ## [13] colorspace_2.0-0 withr_2.4.2 ## [15] tidyselect_1.1.1 gridExtra_2.3 ## [17] compiler_4.0.3 BiocNeighbors_1.8.2 ## [19] DelayedArray_0.16.3 labeling_0.4.2 ## [21] bookdown_0.22 sass_0.3.1 ## [23] checkmate_2.0.0 scales_1.1.1 ## [25] stringr_1.4.0 digest_0.6.27 ## [27] rmarkdown_2.7 XVector_0.30.0 ## [29] pkgconfig_2.0.3 htmltools_0.5.1.1 ## [31] sparseMatrixStats_1.2.1 highr_0.9 ## [33] limma_3.46.0 rlang_0.4.10 ## [35] FNN_1.1.3 DelayedMatrixStats_1.12.3 ## [37] farver_2.1.0 jquerylib_0.1.3 ## [39] generics_0.1.0 jsonlite_1.7.2 ## [41] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [43] magrittr_2.0.1 GenomeInfoDbData_1.2.4 ## [45] scuttle_1.0.4 Matrix_1.3-2 ## [47] Rcpp_1.0.6 ggbeeswarm_0.6.0 ## [49] munsell_0.5.0 fansi_0.4.2 ## [51] viridis_0.6.0 lifecycle_1.0.0 ## [53] stringi_1.5.3 yaml_2.2.1 ## [55] edgeR_3.32.1 MASS_7.3-54 ## [57] zlibbioc_1.36.0 Rtsne_0.15 ## [59] grid_4.0.3 ggrepel_0.9.1 ## [61] dqrng_0.3.0 crayon_1.4.1 ## [63] lattice_0.20-44 cowplot_1.1.1 ## [65] graphlayouts_0.7.1 beachmat_2.6.4 ## [67] locfit_1.5-9.4 pillar_1.6.0 ## [69] igraph_1.2.6 codetools_0.2-18 ## [71] glue_1.4.2 evaluate_0.14 ## [73] tweenr_1.0.2 vctrs_0.3.7 ## [75] polyclip_1.10-0 gtable_0.3.0 ## [77] purrr_0.3.4 tidyr_1.1.3 ## [79] assertthat_0.2.1 ggforce_0.3.3 ## [81] xfun_0.22 rsvd_1.0.5 ## [83] tidygraph_1.2.0 RSpectra_0.16-0 ## [85] viridisLite_0.4.0 tibble_3.1.1 ## [87] beeswarm_0.3.1 statmod_1.4.35 ## [89] ellipsis_0.3.2 "],["dataSetIntegration-HHDTop.html", "Chapter 16 Data integration - HDD 16.1 Abbreviations 16.2 Motivation 16.3 Load data 16.4 Loading the data 16.5 Diagnosing batch effects 16.6 Linear regression 16.7 Performing MNN correction 16.8 Correction diagnostics 16.9 Encouraging consistency with marker genes 16.10 Session information", " Chapter 16 Data integration - HDD projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool setName &lt;- params$setName splSetToGet &lt;- params$splSetToGet setSuf &lt;- params$setSuf dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;HHD&quot; setSuf &lt;- &quot;_allCells&quot; } nbPcToComp &lt;- 50 figSize &lt;- 7 Source: ‘Integrating Datasets’ chapter in the OSCA book. Its text is reproduced below with few modifications to adapt it to the data set under scrutiny here. 16.1 Abbreviations HVG: highly variable genes MNN: mutual nearest neighbors PBMMC: peripheral blood mononuclear cell SCE: SingleCellExperiment 16.2 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. 16.3 Load data Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 16.4 Loading the data We will load the R file keeping the SCE object with the normalised counts, and subset 1000 cells per sample. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; We next subset the data for the HHD sample group: # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) splVec &lt;- cb_sampleSheet %&gt;% filter(source_name == splSetToGet) %&gt;% pull(Sample.Name) %&gt;% unique sourceNames &lt;- unique(colData(sce)$source_name) sceOrig &lt;- sce sce &lt;- sceOrig[,sce$source_name == splSetToGet ] nbCells &lt;- 1000 all.sce &lt;- list() for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% sample_n(nbCells) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } nbSpl &lt;- length(all.sce) We then apply the standard workflow to each sample separately: * normalisation, * variance modelling * dimensionality reduction * clustering #--- normalization ---# # use logNormCounts() all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# # model varaince with modelGeneVar() # find highly variable genes (HVGs) with getTopHVGs() all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# # use runPCA() # then compute embeddings with runTSNE() and runUMAP() library(BiocSingular) set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) set.seed(100000) all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) set.seed(1000000) all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# # cluster each sample separately for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership #colLabels(all.sce[[n]]) &lt;- factor(clust) all.sce[[n]]$label &lt;- factor(clust) } To prepare for the batch correction: We subset all batches to the common “universe” of features. In this case, it is straightforward as both batches use Ensembl gene annotation. allNames &lt;- unlist(lapply(all.sce, function(x){rownames(x)})) allNamesNb &lt;- table(allNames) universe &lt;- names(allNamesNb)[allNamesNb==nbSpl] #length(universe) The size of this common “universe” of features here is the number of features shared by all 2 samples is: 18431. # Subsetting the SingleCellExperiment object. uni.sce &lt;- lapply(all.sce, function(x){x[universe,]}) # Also subsetting the variance modelling results, for convenience. uni.dec &lt;- lapply(all.dec, function(x){x[universe,]}) We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment (SCE) objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. # rescale each batch to adjust for differences in sequencing depth between batches rescaled &lt;- multiBatchNorm(uni.sce, batch = &quot;Sample.Name&quot;) We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. # compute average variance components across samples #combined.dec &lt;- combineVar(uni.dec[[1]], uni.dec[[2]], uni.dec[[3]], uni.dec[[4]]) combined.dec &lt;- combineVar(uni.dec) # identify highly variables genes # here as those with a positive biological component chosen.hvgs &lt;- combined.dec$bio &gt; 0 #sum(chosen.hvgs) Number of HVGs: 11167. When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons. 16.5 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the SCE objects and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. for (i in 2:nbSpl) { identical(rowData(rescaled[[1]]), rowData(rescaled[[i]])) } rescaled[[1]]$batch &lt;- rescaled[[1]]$Sample.Name rescaled2 &lt;- lapply(rescaled, function(x){x$batch &lt;- x$Sample.Name; x}) rescaled &lt;- rescaled2 # concat matrices: uncorrected &lt;- do.call(cbind, rescaled) # Perform PCA # Using RandomParam() as it is more efficient for file-backed matrices. set.seed(0010101010) uncorrected &lt;- runPCA(uncorrected, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) We use graph-based clustering on the components to obtain a summary of the population structure. As the samples should be replicates, each cluster should ideally consist of cells from each batch. However, we instead see clusters that are comprised of cells from a single batch. This indicates that cells of the same type are artificially separated due to technical differences between batches. # build shared nearest-neighbour graph snn.gr &lt;- buildSNNGraph(uncorrected, use.dimred=&quot;PCA&quot;) # identify cluster with the walk trap method clusters &lt;- igraph::cluster_walktrap(snn.gr)$membership # get number of cells for each {cluster, batch} pair tab &lt;- table(Cluster=clusters, Batch=uncorrected$batch) #tab tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) Cluster size and cell contribution by sample: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() + ggtitle(&quot;uncorrected, cell numbers&quot;) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) + ggtitle(&quot;uncorrected, proportions&quot;) gridExtra::grid.arrange(p1, p2) We can also visualize the uncorrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results. set.seed(1111001) uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;) plotTSNE(uncorrected, colour_by=&quot;batch&quot;) Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations. If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. 16.6 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. rescaled2 &lt;- rescaleBatches(rescaled) rescaled2 ## class: SingleCellExperiment ## dim: 18431 2000 ## metadata(0): ## assays(1): corrected ## rownames(18431): ENSG00000000003 ENSG00000000419 ... ENSG00000285486 ## ENSG00000285492 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## altExpNames(0): After clustering, we observe that most clusters consist of mixtures of cells from the two replicate batches, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches. set.seed(1010101010) # To ensure reproducibility of IRLBA. rescaled2 &lt;- runPCA(rescaled2, subset_row=chosen.hvgs, exprs_values=&quot;corrected&quot;) snn.gr &lt;- buildSNNGraph(rescaled2, use.dimred=&quot;PCA&quot;) clusters.resc &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled2$batch) #tab.resc tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.resc, &quot;batch&quot;=rescaled2$batch) Cluster size and cell contribution by sample, with clusters sorted by size: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) Compute and plot t-SNE: rescaled2 &lt;- runTSNE(rescaled2, dimred=&quot;PCA&quot;) rescaled2$batch &lt;- factor(rescaled2$batch) plotTSNE(rescaled2, colour_by=&quot;batch&quot;) 16.7 Performing MNN correction 16.7.1 Algorithm overview Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space. 16.7.2 Application to the data The batchelor package provides an implementation of the MNN approach via the fastMNN() function. (Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps.) We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN(rescaled, auto.merge=TRUE, d=50, k=20, subset.row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out ## class: SingleCellExperiment ## dim: 11167 2000 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(11167): ENSG00000000457 ENSG00000000460 ... ENSG00000285458 ## ENSG00000285476 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out.corre.dim &lt;- dim(reducedDim(mnn.out, &quot;corrected&quot;)) mnn.out.corre.dim ## [1] 2000 50 mnn.out.recon.dim &lt;- dim(assay(mnn.out, &quot;reconstructed&quot;)) mnn.out.recon.dim ## [1] 11167 2000 The function returns a SCE object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses (2000 cells and 50 PCs). A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space (11167 genes and 2000 cells). We do not recommend using this for anything other than visualization. print(assay(mnn.out, &quot;reconstructed&quot;)[1:5,1:3]) ## &lt;5 x 3&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ## ENSG00000000457 5.736159e-04 -2.877962e-04 -4.801776e-04 ## ENSG00000000460 2.604826e-04 9.815244e-05 -5.479885e-04 ## ENSG00000000938 8.475445e-07 -2.255415e-03 -2.458375e-03 ## ENSG00000000971 -3.212715e-05 -1.626546e-04 -3.600975e-05 ## ENSG00000001036 -1.765695e-04 -6.451413e-05 -7.620657e-04 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. 16.8 Correction diagnostics 16.8.1 Mixing between batches We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the batches are replicates of each other. snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, k=20) clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster GSM3872438 GSM3872439 ## 1 192 236 ## 2 20 0 ## 3 383 240 ## 4 57 23 ## 5 264 477 ## 6 53 10 ## 7 31 14 Cluster size and cell contribution by sample, with clusters sorted by size: tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$batch) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) We can also compute the variation in the log-abundances to rank the clusters with the greatest variability in their proportional abundances across batches. We can then focus on batch-specific clusters that may be indicative of incomplete batch correction. Obviously, though, this diagnostic is subject to interpretation as the same outcome can be caused by batch-specific populations; some prior knowledge about the biological context is necessary to distinguish between these two possibilities. The table below shows the number of cells for each cluster (row) and sample (column) together with the variance in cell number across these samples (‘var’ column). # Avoid minor difficulties with the &#39;table&#39; class. tab.mnn &lt;- unclass(tab.mnn) # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) # Ranking clusters by the largest variances. rv &lt;- rowVars(norm) %&gt;% round(2) # show #DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),] DataFrame(tab.mnn, var=rv)[order(rv, decreasing=TRUE),] ## DataFrame with 7 rows and 3 columns ## GSM3872438 GSM3872439 var ## &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; ## 6 53 10 1.37 ## 2 20 0 1.26 ## 4 57 23 0.52 ## 5 264 477 0.34 ## 7 31 14 0.30 ## 3 383 240 0.21 ## 1 192 236 0.04 We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from batches provides a comforting illusion that the correction was successful. set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;) mnn.out$batch &lt;- factor(mnn.out$batch) plotTSNE(mnn.out, colour_by=&quot;batch&quot;) #mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) #p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, shape_by=&quot;type&quot;) #p + facet_wrap(. ~ mnn.out$type) For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). round(metadata(mnn.out)$merge.info$lost.var,2) ## GSM3872438 GSM3872439 ## [1,] 0.01 0.02 Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. The following t-SNE shows the clusters identified: mnn.out$cluster &lt;- paste0(&quot;c&quot;, clusters.mnn) p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;) p p + facet_wrap(~colData(mnn.out)$batch) The following t-SNE plots show expression levels of known cell type marker genes. genesToShow &lt;- c( &quot;CD79A&quot;, # CD79A B *** &quot;CST3&quot;, # CST3 monocytes *** &quot;CD3D&quot;, # CD3D T cells *** &quot;HBA1&quot; # HBA1 erythrocytes *** ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] B cells: genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) monocytes: genex &lt;- ensToShow[2] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Compare to the uncorrected values, T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Compare to the uncorrected values, erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Other genes (exercise) genesToShow2 &lt;- c( &quot;IL7R&quot;, # IL7R, CCR7 Naive CD4+ T &quot;CCR7&quot;, # IL7R, CCR7 Naive CD4+ T &quot;S100A4&quot;, # IL7R, S100A4 Memory CD4+ &quot;CD14&quot;, # CD14, LYZ CD14+ Mono &quot;LYZ&quot;, # CD14, LYZ CD14+ Mono &quot;MS4A1&quot;, # MS4A1 B &quot;CD8A&quot;, # CD8A CD8+ T &quot;FCGR3A&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;MS4A7&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;GNLY&quot;, # GNLY, NKG7 NK &quot;NKG7&quot;, # GNLY, NKG7 NK &quot;FCER1A&quot;, # DC &quot;CST3&quot;, # DC &quot;PPBP&quot; # Platelet ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow2) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] table(ensToShow %in% rownames(rowData(mnn.out))) ensToShow &lt;- ensToShow[ensToShow %in% rownames(rowData(mnn.out))] for (genex in ensToShow) { p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;])) print(p) } 16.8.2 Preserving biological heterogeneity 16.8.2.1 Comparison between within-batch clusters and across-batch clusters obtained after MNN correction Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries are zero, though this may depend on whether specific clusters of interest are gained or lost. One heatmap is generated for each dataset, where each entry is colored according to the number of cells with each pair of labels (before and after correction), on the log10 scale with pseudocounts (+10) for a smoother color transition (so a minimum value of log10(0+10) == 1). plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled2$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled[[splIdx]]), cl.2=clusters.mnn[rescaled2$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) #gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, nrow=2, ncol=1, heights=c(unit(.8, &quot;npc&quot;), unit(.2, &quot;npc&quot;))) if(FALSE) { grobx &lt;- gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, nrow=3, ncol=2, heights=c(unit(.8, &quot;npc&quot;), unit(.1, &quot;npc&quot;), unit(.1, &quot;npc&quot;)), widths=c(unit(.3, &quot;npc&quot;), unit(.7, &quot;npc&quot;)), layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE) ) } if(FALSE) { grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, #nrow=3, ncol=2, #layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE), nrow=2, ncol=3, layout_matrix=matrix(c(1,1,2,5,4,3), ncol=3, byrow=FALSE), widths=c(unit(.70, &quot;npc&quot;), unit(.15, &quot;npc&quot;), unit(.15, &quot;npc&quot;)), heights=c(unit(.7, &quot;npc&quot;), unit(.3, &quot;npc&quot;)) ) } grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##gridExtra::marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’ and ‘after’) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. figSize &lt;- 7 #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} #gridExtra::grid.arrange(grobs = treeList, gridExtra::grid.arrange(grobs = gxList, ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) gridExtra::grid.arrange(grobs = treeList, ncol=2 ) knitr::knit_exit() 16.8.2.2 Coassignment probabilities Another evaluation approach is to compute the coassignment probabilities, i.e. the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place. The plots below display the coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each sample, where each entry is colored according to the coassignment probability between each pair of within-batch clusters: # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled[[splIdx]]), clusters.mnn[rescaled2$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair (in pairwiseRand() with mode=“ratio” and adjusted=FALSE). The Rand index is introduced below. 16.8.2.3 Rand index Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled[[splIdx]])), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## GSM3872438 GSM3872439 ## 0.45 0.46 A sample may show a low Rand index value if cells grouped together in a small cluster before correction are split into distinct clusters after correction because the latter comprise cell populations not observed in that sample but present in other samples. We can also break down the adjusted Rand index (ARI) into per-cluster ratios for more detailed diagnostics. For example, we could see low ratios off the diagonal if distinct clusters in the within-batch clustering were incorrectly aggregated in the merged clustering. Conversely, we might see low ratios on the diagonal if the correction inflated or introduced spurious heterogeneity inside a within-batch cluster. # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled[[splIdx]])), alt=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) 16.9 Encouraging consistency with marker genes In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach that is a natural extension of the strategy described in Section 8.4. We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by SingleR. In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN(). # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. markerList &lt;- lapply(rescaled, function(x){ y &lt;- pairwiseWilcox(x, direction=&quot;up&quot;) getTopMarkers(y[[1]], y[[2]], n=10) %&gt;% unlist %&gt;% unlist }) marker.set &lt;- unique(unlist(markerList)) #length(marker.set) # getting the total number of genes selected in this manner. The total number of genes selected in this manner is: 331. set.seed(1000110) mnn.out2 &lt;- fastMNN(rescaled, subset.row=marker.set, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) # compute t-SNE: mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;) We can also visualize the corrected coordinates using a t-SNE plot: plotTSNE(mnn.out2, colour_by=&quot;batch&quot;) plotTSNE(mnn.out2, colour_by=&quot;batch&quot;) + facet_wrap(~colData(mnn.out2)$batch) A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (x in 1:length(splVec)) { plotList[[x]] &lt;- plotTSNE(mnn.out2[,mnn.out2$batch==splVec[x]], colour_by=I(colLabels(rescaled[[x]]))) + ggtitle(splVec[x]) } gridExtra::grid.arrange(grobs = plotList, ncol=2 ) # by_exprs_values, : cannot find &#39;ENSG00000090382&#39; for ETV6-RUNX1 # B cells genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) ensToShowPostCor &lt;- ensToShow[ensToShow %in% rownames(mnn.out2)] rowData(uncorrected)[ensToShowPostCor,c(&quot;ensembl_gene_id&quot;, &quot;external_gene_name&quot;)] genex &lt;- &quot;ENSG00000156738&quot; # MS4A1 # ensToShowPostCor[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) # ENSG00000203747 is FCGR3A genex &lt;- &quot;ENSG00000203747&quot; # FCGR3A # ensToShowPostCor[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) m.out &lt;- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE]) #lapply(m.out, function(x){head(x[,2:6])}) # A (probably activated?) T cell subtype of some sort: tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) Expression level for the top gene, on violin plots: geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, ENSG00000008517 on t-SNE plot: genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) p + facet_wrap(~colData(mnn.out)$batch) We suggest limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. # save object? #fn &lt;- sprintf(&quot;dataSetIntegration_%s.Rdata&quot;, splSetToGet) fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s.Rdata&quot;, projDir, outDirBit, setName, setSuf, splSetToGet) # &#39;dsi&#39; for data set integration saveRDS(mnn.out, file=fn) 16.10 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] BiocSingular_1.6.0 Cairo_1.5-12.2 ## [3] clustree_0.4.3 ggraph_2.0.5 ## [5] pheatmap_1.0.12 dplyr_1.0.5 ## [7] bluster_1.0.0 batchelor_1.6.3 ## [9] scran_1.18.7 scater_1.18.6 ## [11] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [13] Biobase_2.50.0 GenomicRanges_1.42.0 ## [15] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [17] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [19] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [21] ggplot2_3.3.3 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 RColorBrewer_1.1-2 ## [3] backports_1.2.1 tools_4.0.3 ## [5] bslib_0.2.4 utf8_1.2.1 ## [7] R6_2.5.0 irlba_2.3.3 ## [9] ResidualMatrix_1.0.0 vipor_0.4.5 ## [11] uwot_0.1.10 DBI_1.1.1 ## [13] colorspace_2.0-0 withr_2.4.2 ## [15] tidyselect_1.1.1 gridExtra_2.3 ## [17] compiler_4.0.3 BiocNeighbors_1.8.2 ## [19] DelayedArray_0.16.3 labeling_0.4.2 ## [21] bookdown_0.22 sass_0.3.1 ## [23] checkmate_2.0.0 scales_1.1.1 ## [25] stringr_1.4.0 digest_0.6.27 ## [27] rmarkdown_2.7 XVector_0.30.0 ## [29] pkgconfig_2.0.3 htmltools_0.5.1.1 ## [31] sparseMatrixStats_1.2.1 highr_0.9 ## [33] limma_3.46.0 rlang_0.4.10 ## [35] FNN_1.1.3 DelayedMatrixStats_1.12.3 ## [37] farver_2.1.0 jquerylib_0.1.3 ## [39] generics_0.1.0 jsonlite_1.7.2 ## [41] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [43] magrittr_2.0.1 GenomeInfoDbData_1.2.4 ## [45] scuttle_1.0.4 Matrix_1.3-2 ## [47] Rcpp_1.0.6 ggbeeswarm_0.6.0 ## [49] munsell_0.5.0 fansi_0.4.2 ## [51] viridis_0.6.0 lifecycle_1.0.0 ## [53] stringi_1.5.3 yaml_2.2.1 ## [55] edgeR_3.32.1 MASS_7.3-54 ## [57] zlibbioc_1.36.0 Rtsne_0.15 ## [59] grid_4.0.3 ggrepel_0.9.1 ## [61] dqrng_0.3.0 crayon_1.4.1 ## [63] lattice_0.20-44 cowplot_1.1.1 ## [65] graphlayouts_0.7.1 beachmat_2.6.4 ## [67] locfit_1.5-9.4 pillar_1.6.0 ## [69] igraph_1.2.6 codetools_0.2-18 ## [71] glue_1.4.2 evaluate_0.14 ## [73] tweenr_1.0.2 vctrs_0.3.7 ## [75] polyclip_1.10-0 gtable_0.3.0 ## [77] purrr_0.3.4 tidyr_1.1.3 ## [79] assertthat_0.2.1 ggforce_0.3.3 ## [81] xfun_0.22 rsvd_1.0.5 ## [83] tidygraph_1.2.0 RSpectra_0.16-0 ## [85] viridisLite_0.4.0 tibble_3.1.1 ## [87] beeswarm_0.3.1 statmod_1.4.35 ## [89] ellipsis_0.3.2 "],["DataIntegrationPretTop.html", "Chapter 17 Data integration - PRE-T 17.1 Abbreviations 17.2 Motivation 17.3 Load data 17.4 Loading the data 17.5 Diagnosing batch effects 17.6 Linear regression 17.7 Performing MNN correction 17.8 Correction diagnostics 17.9 Encouraging consistency with marker genes 17.10 Session information", " Chapter 17 Data integration - PRE-T projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool setName &lt;- params$setName splSetToGet &lt;- params$splSetToGet setSuf &lt;- params$setSuf dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;PRE-T&quot; setSuf &lt;- &quot;_allCells&quot; } nbPcToComp &lt;- 50 figSize &lt;- 7 Source: ‘Integrating Datasets’ chapter in the OSCA book. Its text is reproduced below with few modifications to adapt it to the data set under scrutiny here. 17.1 Abbreviations HVG: highly variable genes MNN: mutual nearest neighbors PBMMC: peripheral blood mononuclear cell SCE: SingleCellExperiment 17.2 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. 17.3 Load data Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 17.4 Loading the data We will load the R file keeping the SCE object with the normalised counts, and subset 1000 cells per sample. setName &lt;- &quot;caron&quot; #setSuf &lt;- &quot;&quot; setSuf &lt;- &quot;_allCells&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; We next subset the data for the PRE-T sample group: # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) splVec &lt;- cb_sampleSheet %&gt;% filter(source_name == splSetToGet) %&gt;% pull(Sample.Name) %&gt;% unique sourceNames &lt;- unique(colData(sce)$source_name) sceOrig &lt;- sce sce &lt;- sceOrig[,sce$source_name == splSetToGet ] nbCells &lt;- 1000 all.sce &lt;- list() for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% sample_n(nbCells) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } nbSpl &lt;- length(all.sce) We then apply the standard workflow to each sample separately: * normalisation, * variance modelling * dimensionality reduction * clustering #--- normalization ---# # use logNormCounts() all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# # model varaince with modelGeneVar() # find highly variable genes (HVGs) with getTopHVGs() all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# # use runPCA() # then compute embeddings with runTSNE() and runUMAP() library(BiocSingular) set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) set.seed(100000) all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) set.seed(1000000) all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# # cluster each sample separately for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership #colLabels(all.sce[[n]]) &lt;- factor(clust) all.sce[[n]]$label &lt;- factor(clust) } To prepare for the batch correction: We subset all batches to the common “universe” of features. In this case, it is straightforward as both batches use Ensembl gene annotation. allNames &lt;- unlist(lapply(all.sce, function(x){rownames(x)})) allNamesNb &lt;- table(allNames) universe &lt;- names(allNamesNb)[allNamesNb==nbSpl] #length(universe) The size of this common “universe” of features here is the number of features shared by all 2 samples is: 18431. # Subsetting the SingleCellExperiment object. uni.sce &lt;- lapply(all.sce, function(x){x[universe,]}) # Also subsetting the variance modelling results, for convenience. uni.dec &lt;- lapply(all.dec, function(x){x[universe,]}) We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment (SCE) objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. # rescale each batch to adjust for differences in sequencing depth between batches rescaled &lt;- multiBatchNorm(uni.sce, batch = &quot;Sample.Name&quot;) We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. # compute average variance components across samples #combined.dec &lt;- combineVar(uni.dec[[1]], uni.dec[[2]], uni.dec[[3]], uni.dec[[4]]) combined.dec &lt;- combineVar(uni.dec) # identify highly variables genes # here as those with a positive biological component chosen.hvgs &lt;- combined.dec$bio &gt; 0 #sum(chosen.hvgs) Number of HVGs: 10485. When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons. 17.5 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the SCE objects and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. for (i in 2:nbSpl) { identical(rowData(rescaled[[1]]), rowData(rescaled[[i]])) } rescaled[[1]]$batch &lt;- rescaled[[1]]$Sample.Name rescaled2 &lt;- lapply(rescaled, function(x){x$batch &lt;- x$Sample.Name; x}) rescaled &lt;- rescaled2 # concat matrices: uncorrected &lt;- do.call(cbind, rescaled) # Perform PCA # Using RandomParam() as it is more efficient for file-backed matrices. set.seed(0010101010) uncorrected &lt;- runPCA(uncorrected, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) We use graph-based clustering on the components to obtain a summary of the population structure. As the samples should be replicates, each cluster should ideally consist of cells from each batch. However, we instead see clusters that are comprised of cells from a single batch. This indicates that cells of the same type are artificially separated due to technical differences between batches. # build shared nearest-neighbour graph snn.gr &lt;- buildSNNGraph(uncorrected, use.dimred=&quot;PCA&quot;) # identify cluster with the walk trap method clusters &lt;- igraph::cluster_walktrap(snn.gr)$membership # get number of cells for each {cluster, batch} pair tab &lt;- table(Cluster=clusters, Batch=uncorrected$batch) #tab tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) Cluster size and cell contribution by sample: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() + ggtitle(&quot;uncorrected, cell numbers&quot;) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) + ggtitle(&quot;uncorrected, proportions&quot;) gridExtra::grid.arrange(p1, p2) We can also visualize the uncorrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results. set.seed(1111001) uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;) plotTSNE(uncorrected, colour_by=&quot;batch&quot;) Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations. If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. 17.6 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. rescaled2 &lt;- rescaleBatches(rescaled) rescaled2 ## class: SingleCellExperiment ## dim: 18431 2000 ## metadata(0): ## assays(1): corrected ## rownames(18431): ENSG00000000003 ENSG00000000419 ... ENSG00000285486 ## ENSG00000285492 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## altExpNames(0): After clustering, we observe that most clusters consist of mixtures of cells from the two replicate batches, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches in Figure 13.2. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches. set.seed(1010101010) # To ensure reproducibility of IRLBA. rescaled2 &lt;- runPCA(rescaled2, subset_row=chosen.hvgs, exprs_values=&quot;corrected&quot;) snn.gr &lt;- buildSNNGraph(rescaled2, use.dimred=&quot;PCA&quot;) clusters.resc &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled2$batch) #tab.resc tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.resc, &quot;batch&quot;=rescaled2$batch) Cluster size and cell contribution by sample, with clusters sorted by size: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) Compute and plot t-SNE: rescaled2 &lt;- runTSNE(rescaled2, dimred=&quot;PCA&quot;) rescaled2$batch &lt;- factor(rescaled2$batch) plotTSNE(rescaled2, colour_by=&quot;batch&quot;) 17.7 Performing MNN correction 17.7.1 Algorithm overview Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space. 17.7.2 Application to the data The batchelor package provides an implementation of the MNN approach via the fastMNN() function. (Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps.) We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN(rescaled, auto.merge=TRUE, d=50, k=20, subset.row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out ## class: SingleCellExperiment ## dim: 10485 2000 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(10485): ENSG00000000003 ENSG00000000457 ... ENSG00000285444 ## ENSG00000285476 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out.corre.dim &lt;- dim(reducedDim(mnn.out, &quot;corrected&quot;)) mnn.out.corre.dim ## [1] 2000 50 mnn.out.recon.dim &lt;- dim(assay(mnn.out, &quot;reconstructed&quot;)) mnn.out.recon.dim ## [1] 10485 2000 The function returns a SCE object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses (2000 cells and 50 PCs). A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space (10485 genes and 2000 cells). We do not recommend using this for anything other than visualization. print(assay(mnn.out, &quot;reconstructed&quot;)[1:5,1:3]) ## &lt;5 x 3&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ## ENSG00000000003 5.679825e-04 5.770801e-04 -4.069776e-04 ## ENSG00000000457 8.492035e-04 -2.059444e-04 1.583788e-04 ## ENSG00000000938 -1.399295e-03 -1.799694e-03 -2.562064e-03 ## ENSG00000000971 -3.513720e-05 -4.466999e-05 -9.200578e-05 ## ENSG00000001036 -6.472921e-05 -1.734277e-04 -6.579931e-04 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. 17.8 Correction diagnostics 17.8.1 Mixing between batches We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the batches are replicates of each other. snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, k=20) clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster GSM3872440 GSM3872441 ## 1 183 37 ## 2 2 74 ## 3 1 30 ## 4 438 241 ## 5 116 31 ## 6 15 322 ## 7 7 107 ## 8 8 43 ## 9 2 58 ## 10 228 57 Cluster size and cell contribution by sample, with clusters sorted by size: tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$batch) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) We can also compute the variation in the log-abundances to rank the clusters with the greatest variability in their proportional abundances across batches. We can then focus on batch-specific clusters that may be indicative of incomplete batch correction. Obviously, though, this diagnostic is subject to interpretation as the same outcome can be caused by batch-specific populations; some prior knowledge about the biological context is necessary to distinguish between these two possibilities. The table below shows the number of cells for each cluster (row) and sample (column) together with the variance in cell number across these samples (‘var’ column). Also bear in mind that the variance is computed across 2 samples here and only serves to sort clusters. # Avoid minor difficulties with the &#39;table&#39; class. tab.mnn &lt;- unclass(tab.mnn) # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) # Ranking clusters by the largest variances. rv &lt;- rowVars(norm) %&gt;% round(2) # show #DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),] DataFrame(tab.mnn, var=rv)[order(rv, decreasing=TRUE),] ## DataFrame with 10 rows and 3 columns ## GSM3872440 GSM3872441 var ## &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; ## 6 15 322 6.96 ## 2 2 74 3.94 ## 7 7 107 3.87 ## 9 2 58 3.13 ## 1 183 37 2.08 ## 3 1 30 1.73 ## 10 228 57 1.67 ## 5 116 31 1.31 ## 8 8 43 1.21 ## 4 438 241 0.35 We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from both batches provides a comforting illusion that the correction was successful. set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;) mnn.out$batch &lt;- factor(mnn.out$batch) plotTSNE(mnn.out, colour_by=&quot;batch&quot;) #mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) #p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, shape_by=&quot;type&quot;) #p + facet_wrap(. ~ mnn.out$type) For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). round(metadata(mnn.out)$merge.info$lost.var,2) ## GSM3872440 GSM3872441 ## [1,] 0.01 0.01 Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. The following t-SNE shows the clusters identified: mnn.out$cluster &lt;- paste0(&quot;c&quot;, clusters.mnn) p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;) p p + facet_wrap(~colData(mnn.out)$batch) The following t-SNE plots show expression levels of known cell type marker genes. genesToShow &lt;- c( &quot;CD79A&quot;, # CD79A B *** &quot;CST3&quot;, # CST3 monocytes *** &quot;CD3D&quot;, # CD3D T cells *** &quot;HBA1&quot; # HBA1 erythrocytes *** ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] B cells: genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) monocytes: genex &lt;- ensToShow[2] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Compare to the uncorrected values, T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Compare to the uncorrected values, erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) Other genes (exercise) genesToShow2 &lt;- c( &quot;IL7R&quot;, # IL7R, CCR7 Naive CD4+ T &quot;CCR7&quot;, # IL7R, CCR7 Naive CD4+ T &quot;S100A4&quot;, # IL7R, S100A4 Memory CD4+ &quot;CD14&quot;, # CD14, LYZ CD14+ Mono &quot;LYZ&quot;, # CD14, LYZ CD14+ Mono &quot;MS4A1&quot;, # MS4A1 B &quot;CD8A&quot;, # CD8A CD8+ T &quot;FCGR3A&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;MS4A7&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;GNLY&quot;, # GNLY, NKG7 NK &quot;NKG7&quot;, # GNLY, NKG7 NK &quot;FCER1A&quot;, # DC &quot;CST3&quot;, # DC &quot;PPBP&quot; # Platelet ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow2) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] table(ensToShow %in% rownames(rowData(mnn.out))) ensToShow &lt;- ensToShow[ensToShow %in% rownames(rowData(mnn.out))] for (genex in ensToShow) { p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;])) print(p) } 17.8.2 Preserving biological heterogeneity 17.8.2.1 Comparison between within-batch clusters and across-batch clusters obtained after MNN correction Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries are zero, though this may depend on whether specific clusters of interest are gained or lost. One heatmap is generated for each dataset, where each entry is colored according to the number of cells with each pair of labels (before and after correction), on the log10 scale with pseudocounts (+10) for a smoother color transition (so a minimum value of log10(0+10) == 1). plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled2$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled[[splIdx]]), cl.2=clusters.mnn[rescaled2$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) #gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, nrow=2, ncol=1, heights=c(unit(.8, &quot;npc&quot;), unit(.2, &quot;npc&quot;))) if(FALSE) { grobx &lt;- gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, nrow=3, ncol=2, heights=c(unit(.8, &quot;npc&quot;), unit(.1, &quot;npc&quot;), unit(.1, &quot;npc&quot;)), widths=c(unit(.3, &quot;npc&quot;), unit(.7, &quot;npc&quot;)), layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE) ) } if(FALSE) { grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, #nrow=3, ncol=2, #layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE), nrow=2, ncol=3, layout_matrix=matrix(c(1,1,2,5,4,3), ncol=3, byrow=FALSE), widths=c(unit(.70, &quot;npc&quot;), unit(.15, &quot;npc&quot;), unit(.15, &quot;npc&quot;)), heights=c(unit(.7, &quot;npc&quot;), unit(.3, &quot;npc&quot;)) ) } grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##gridExtra::marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’ in pink, ‘after’ in blue) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. figSize &lt;- 7 #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} #gridExtra::grid.arrange(grobs = treeList, gridExtra::grid.arrange(grobs = gxList, ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) gridExtra::grid.arrange(grobs = treeList, ncol=2 ) knitr::knit_exit() 17.8.2.2 Coassignment probabilities Another evaluation approach is to compute the coassignment probabilities, i.e. the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place. The plots below display the coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each sample, where each entry is colored according to the coassignment probability between each pair of within-batch clusters: # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled[[splIdx]]), clusters.mnn[rescaled2$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair (in pairwiseRand() with mode=“ratio” and adjusted=FALSE). The Rand index is introduced below. 17.8.2.3 Rand index Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled[[splIdx]])), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## GSM3872440 GSM3872441 ## 0.64 0.57 A sample may show a low Rand index value if cells grouped together in a small cluster before correction are split into distinct clusters after correction because the latter comprise cell populations not observed in that sample but present in other samples. This would be the case of GSM3872440 with far fewer erythrocytes (group in a single cluster) than GSM3872441, in which subtypes can be distinguished. We can also break down the adjusted Rand index (ARI) into per-cluster ratios for more detailed diagnostics. For example, we could see low ratios off the diagonal if distinct clusters in the within-batch clustering were incorrectly aggregated in the merged clustering. Conversely, we might see low ratios on the diagonal if the correction inflated or introduced spurious heterogeneity inside a within-batch cluster. # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled[[splIdx]])), alt=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) 17.9 Encouraging consistency with marker genes In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach that is a natural extension of the strategy described in Section 8.4. We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by SingleR. In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN(). # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. markerList &lt;- lapply(rescaled, function(x){ y &lt;- pairwiseWilcox(x, direction=&quot;up&quot;) getTopMarkers(y[[1]], y[[2]], n=10) %&gt;% unlist %&gt;% unlist }) marker.set &lt;- unique(unlist(markerList)) #length(marker.set) # getting the total number of genes selected in this manner. The total number of genes selected in this manner is: 426. set.seed(1000110) mnn.out2 &lt;- fastMNN(rescaled, subset.row=marker.set, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) # compute t-SNE: mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;) We can also visualize the corrected coordinates using a t-SNE plot: plotTSNE(mnn.out2, colour_by=&quot;batch&quot;) plotTSNE(mnn.out2, colour_by=&quot;batch&quot;) + facet_wrap(~colData(mnn.out2)$batch) A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (x in 1:length(splVec)) { plotList[[x]] &lt;- plotTSNE(mnn.out2[,mnn.out2$batch==splVec[x]], colour_by=I(colLabels(rescaled[[x]]))) + ggtitle(splVec[x]) } gridExtra::grid.arrange(grobs = plotList, ncol=2 ) # by_exprs_values, : cannot find &#39;ENSG00000090382&#39; for ETV6-RUNX1 # B cells genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) ensToShowPostCor &lt;- ensToShow[ensToShow %in% rownames(mnn.out2)] rowData(uncorrected)[ensToShowPostCor,c(&quot;ensembl_gene_id&quot;, &quot;external_gene_name&quot;)] genex &lt;- &quot;ENSG00000156738&quot; # MS4A1 # ensToShowPostCor[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) # ENSG00000203747 is FCGR3A genex &lt;- &quot;ENSG00000203747&quot; # FCGR3A # ensToShowPostCor[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) m.out &lt;- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE]) #lapply(m.out, function(x){head(x[,2:6])}) # A (probably activated?) T cell subtype of some sort: tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) Expression level for the top gene, on violin plots: geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, ENSG00000117632 on t-SNE plot: genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) print(p) p + facet_wrap(~colData(mnn.out)$batch) We suggest limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. # save object? #fn &lt;- sprintf(&quot;dataSetIntegration_%s.Rdata&quot;, splSetToGet) fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s.Rdata&quot;, projDir, outDirBit, setName, setSuf, splSetToGet) # &#39;dsi&#39; for data set integration 17.10 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] BiocSingular_1.6.0 Cairo_1.5-12.2 ## [3] clustree_0.4.3 ggraph_2.0.5 ## [5] pheatmap_1.0.12 dplyr_1.0.5 ## [7] bluster_1.0.0 batchelor_1.6.3 ## [9] scran_1.18.7 scater_1.18.6 ## [11] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [13] Biobase_2.50.0 GenomicRanges_1.42.0 ## [15] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [17] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [19] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [21] ggplot2_3.3.3 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 RColorBrewer_1.1-2 ## [3] backports_1.2.1 tools_4.0.3 ## [5] bslib_0.2.4 utf8_1.2.1 ## [7] R6_2.5.0 irlba_2.3.3 ## [9] ResidualMatrix_1.0.0 vipor_0.4.5 ## [11] uwot_0.1.10 DBI_1.1.1 ## [13] colorspace_2.0-0 withr_2.4.2 ## [15] tidyselect_1.1.1 gridExtra_2.3 ## [17] compiler_4.0.3 BiocNeighbors_1.8.2 ## [19] DelayedArray_0.16.3 labeling_0.4.2 ## [21] bookdown_0.22 sass_0.3.1 ## [23] checkmate_2.0.0 scales_1.1.1 ## [25] stringr_1.4.0 digest_0.6.27 ## [27] rmarkdown_2.7 XVector_0.30.0 ## [29] pkgconfig_2.0.3 htmltools_0.5.1.1 ## [31] sparseMatrixStats_1.2.1 highr_0.9 ## [33] limma_3.46.0 rlang_0.4.10 ## [35] FNN_1.1.3 DelayedMatrixStats_1.12.3 ## [37] farver_2.1.0 jquerylib_0.1.3 ## [39] generics_0.1.0 jsonlite_1.7.2 ## [41] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [43] magrittr_2.0.1 GenomeInfoDbData_1.2.4 ## [45] scuttle_1.0.4 Matrix_1.3-2 ## [47] Rcpp_1.0.6 ggbeeswarm_0.6.0 ## [49] munsell_0.5.0 fansi_0.4.2 ## [51] viridis_0.6.0 lifecycle_1.0.0 ## [53] stringi_1.5.3 yaml_2.2.1 ## [55] edgeR_3.32.1 MASS_7.3-54 ## [57] zlibbioc_1.36.0 Rtsne_0.15 ## [59] grid_4.0.3 ggrepel_0.9.1 ## [61] dqrng_0.3.0 crayon_1.4.1 ## [63] lattice_0.20-44 cowplot_1.1.1 ## [65] graphlayouts_0.7.1 beachmat_2.6.4 ## [67] locfit_1.5-9.4 pillar_1.6.0 ## [69] igraph_1.2.6 codetools_0.2-18 ## [71] glue_1.4.2 evaluate_0.14 ## [73] tweenr_1.0.2 vctrs_0.3.7 ## [75] polyclip_1.10-0 gtable_0.3.0 ## [77] purrr_0.3.4 tidyr_1.1.3 ## [79] assertthat_0.2.1 ggforce_0.3.3 ## [81] xfun_0.22 rsvd_1.0.5 ## [83] tidygraph_1.2.0 RSpectra_0.16-0 ## [85] viridisLite_0.4.0 tibble_3.1.1 ## [87] beeswarm_0.3.1 statmod_1.4.35 ## [89] ellipsis_0.3.2 "],["data-integration-pbmmc-and-etv6-runx-dsisetsuf-pbmmc-etv6-runx1top.html", "Chapter 18 Data integration - PBMMC and ETV6-RUNX {#dsi{{setSuf}}_PBMMC_ETV6-RUNX1Top} 18.1 Abbreviations 18.2 Motivation 18.3 Load data 18.4 Loading the data 18.5 Diagnosing batch effects 18.6 Linear regression 18.7 Performing MNN correction 18.8 Correction diagnostics 18.9 Encouraging consistency with marker genes 18.10 Identify clusters with PBMMC cells 18.11 Session information", " Chapter 18 Data integration - PBMMC and ETV6-RUNX {#dsi{{setSuf}}_PBMMC_ETV6-RUNX1Top} projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool splSetToGet &lt;- params$splSetToGet setName &lt;- params$setName setSuf &lt;- params$setSuf if(exists(&quot;isChild&quot;)) { setSuf &lt;- &quot;{{setSuf}}&quot; } if(params$bookType == &quot;mk&quot;){ splSetToGet &lt;- &quot;PBMMC,ETV6-RUNX1&quot; setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_5hCellPerSpl&quot; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 Source: ‘Integrating Datasets’ chapter in the OSCA book. Its text is reproduced below with few modifications to adapt it to the data set under scrutiny here. 18.1 Abbreviations HVG: highly variable genes MNN: mutual nearest neighbors PBMMC: peripheral blood mononuclear cell SCE: SingleCellExperiment 18.2 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. 18.3 Load data Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 18.4 Loading the data We will load the R file keeping the SCE object with the normalised counts, and subset 1000 cells per sample. ##setName &lt;- &quot;caron&quot; #setSuf &lt;- &quot;&quot; ##setSuf &lt;- &quot;_allCells&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 16629 5500 ## metadata(0): ## assays(2): counts logcounts ## rownames(16629): ENSG00000237491 ENSG00000225880 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(16): Barcode Run ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; We next subset the data for the PBMMC,ETV6-RUNX1 sample group: # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) #splVec &lt;- cb_sampleSheet %&gt;% filter(source_name == splSetToGet) %&gt;% splVec &lt;- cb_sampleSheet %&gt;% filter(source_name %in% splSetVec) %&gt;% pull(Sample.Name) %&gt;% unique sourceNames &lt;- unique(colData(sce)$source_name) sceOrig &lt;- sce sce &lt;- sceOrig[,sce$source_name %in% splSetVec ] nbCells &lt;- 1000 #nbCells &lt;- 3000 all.sce &lt;- list() # if &#39;_allCells&#39;, then downsample for faster run # else (ie _5hCellPerSpl so far), do not downsample. if(setSuf == &quot;_allCells&quot;) { for(spx in splVec) { #nbCellsToGet &lt;- min(ncol(sce), nbCells) vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% ###slice_sample(n=nbCellsToGet) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } } else { for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } } nbSpl &lt;- length(all.sce) We then apply the standard workflow to each sample separately: * normalisation, * variance modelling * dimensionality reduction * clustering #--- normalization ---# # use logNormCounts() all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# # model varaince with modelGeneVar() # find highly variable genes (HVGs) with getTopHVGs() all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# # use runPCA() # then compute embeddings with runTSNE() and runUMAP() library(BiocSingular) set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) set.seed(100000) all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) set.seed(1000000) all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# # cluster each sample separately for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership #colLabels(all.sce[[n]]) &lt;- factor(clust) all.sce[[n]]$label &lt;- factor(clust) } To prepare for the batch correction: We subset all batches to the common “universe” of features. In this case, it is straightforward as both batches use Ensembl gene annotation. allNames &lt;- unlist(lapply(all.sce, function(x){rownames(x)})) allNamesNb &lt;- table(allNames) universe &lt;- names(allNamesNb)[allNamesNb==nbSpl] #length(universe) The size of this common “universe” of features here is the number of features shared by all 7 samples is: 16629. # Subsetting the SingleCellExperiment object. uni.sce &lt;- lapply(all.sce, function(x){x[universe,]}) # Also subsetting the variance modelling results, for convenience. uni.dec &lt;- lapply(all.dec, function(x){x[universe,]}) We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment (SCE) objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. # rescale each batch to adjust for differences in sequencing depth between batches rescaled &lt;- multiBatchNorm(uni.sce, batch = &quot;Sample.Name&quot;) We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. # compute average variance components across samples #combined.dec &lt;- combineVar(uni.dec[[1]], uni.dec[[2]], uni.dec[[3]], uni.dec[[4]]) combined.dec &lt;- combineVar(uni.dec) # identify highly variables genes # here as those with a positive biological component chosen.hvgs &lt;- combined.dec$bio &gt; 0 #sum(chosen.hvgs) Number of HVGs: 7930. When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons. 18.5 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the SCE objects and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. for (i in 2:nbSpl) { identical(rowData(rescaled[[1]]), rowData(rescaled[[i]])) } rescaled[[1]]$batch &lt;- rescaled[[1]]$Sample.Name rescaled2 &lt;- lapply(rescaled, function(x){x$batch &lt;- x$Sample.Name; x}) rescaled &lt;- rescaled2 # concat matrices: uncorrected &lt;- do.call(cbind, rescaled) # Perform PCA # Using RandomParam() as it is more efficient for file-backed matrices. set.seed(0010101010) uncorrected &lt;- runPCA(uncorrected, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) We use graph-based clustering on the components to obtain a summary of the population structure. As the samples should be replicates, each cluster should ideally consist of cells from each batch. However, we instead see clusters that are comprised of cells from a single batch. This indicates that cells of the same type are artificially separated due to technical differences between batches. # build shared nearest-neighbour graph snn.gr &lt;- buildSNNGraph(uncorrected, use.dimred=&quot;PCA&quot;) # identify cluster with the walk trap method clusters &lt;- igraph::cluster_walktrap(snn.gr)$membership # get number of cells for each {cluster, batch} pair tab &lt;- table(Cluster=clusters, Batch=uncorrected$batch) #tab tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) Cluster size and cell contribution by sample: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(&quot;uncorrected, cell numbers&quot;) + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(&quot;uncorrected, proportions&quot;) + theme(legend.text = element_text(size = 7)) gridExtra::grid.arrange(p1, p2) We can also visualize the uncorrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results. set.seed(1111001) uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;) p &lt;- plotTSNE(uncorrected, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) + theme(legend.text = element_text(size = 7)) p p + facet_wrap(~uncorrected$source_name) Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations. If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. Let us write the corresponding SCE object. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s_uncorr.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(uncorrected, file=fn) 18.6 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. rescaled2 &lt;- rescaleBatches(rescaled) rescaled2 ## class: SingleCellExperiment ## dim: 16629 3500 ## metadata(0): ## assays(1): corrected ## rownames(16629): ENSG00000000003 ENSG00000000419 ... ENSG00000285486 ## ENSG00000285492 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## altExpNames(0): After clustering, we observe that most clusters consist of mixtures of cells from the two replicate batches, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches in Figure 13.2. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches. set.seed(1010101010) # To ensure reproducibility of IRLBA. rescaled2 &lt;- runPCA(rescaled2, subset_row=chosen.hvgs, exprs_values=&quot;corrected&quot;) snn.gr &lt;- buildSNNGraph(rescaled2, use.dimred=&quot;PCA&quot;) clusters.resc &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled2$batch) #tab.resc tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.resc, &quot;batch&quot;=rescaled2$batch) Cluster size and cell contribution by sample, with clusters sorted by size: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) + theme(legend.text = element_text(size = 7)) gridExtra::grid.arrange(p1, p2) Compute and plot t-SNE: rescaled2 &lt;- runTSNE(rescaled2, dimred=&quot;PCA&quot;) rescaled2$batch &lt;- factor(rescaled2$batch) p &lt;- plotTSNE(rescaled2, colour_by=&quot;batch&quot;) p p + facet_wrap(~uncorrected$source_name) 18.7 Performing MNN correction 18.7.1 Algorithm overview Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space. 18.7.2 Application to the data The batchelor package provides an implementation of the MNN approach via the fastMNN() function. (Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps.) We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN(rescaled, auto.merge=TRUE, d=50, k=20, subset.row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out ## class: SingleCellExperiment ## dim: 7930 3500 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(7930): ENSG00000000938 ENSG00000001084 ... ENSG00000285476 ## ENSG00000285486 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out.corre.dim &lt;- dim(reducedDim(mnn.out, &quot;corrected&quot;)) mnn.out.corre.dim ## [1] 3500 50 mnn.out.recon.dim &lt;- dim(assay(mnn.out, &quot;reconstructed&quot;)) mnn.out.recon.dim ## [1] 7930 3500 The function returns a SCE object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses (3500 cells and 50 PCs). A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space (7930 genes and 3500 cells). We do not recommend using this for anything other than visualization. print(assay(mnn.out, &quot;reconstructed&quot;)[1:5,1:3]) ## &lt;5 x 3&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ## ENSG00000000938 -1.778764e-03 -9.573360e-04 -1.024012e-04 ## ENSG00000001084 -5.499423e-04 -1.165937e-03 -8.177201e-04 ## ENSG00000001461 -4.356311e-04 -4.438449e-04 -4.345478e-04 ## ENSG00000001561 -1.754212e-04 7.425442e-06 4.786712e-05 ## ENSG00000001617 -3.443706e-04 -2.886196e-04 -2.352076e-04 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. colDataList &lt;- lapply(rescaled, function(x){colData(x)}) colDataDf &lt;- do.call(rbind, colDataList) #colData(mnn.out) &lt;- cbind(colDataDf, colData(mnn.out)$cluster) colData(mnn.out) &lt;- DataFrame(colDataDf) # no rearrainging of columns by mnncorrect 18.8 Correction diagnostics 18.8.1 Mixing between batches We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the batches are replicates of each other. snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, k=20) clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 ## 1 2 0 6 6 4 21 ## 2 40 38 14 47 63 9 ## 3 87 1 3 3 62 16 ## 4 31 273 154 82 64 16 ## 5 0 1 7 16 1 30 ## 6 0 0 0 0 30 17 ## 7 1 15 157 21 183 128 ## 8 0 0 3 19 0 22 ## 9 88 34 22 73 32 2 ## 10 2 10 50 12 13 51 ## 11 0 0 12 48 0 66 ## 12 1 0 5 7 3 35 ## 13 0 0 11 30 0 37 ## 14 233 112 36 125 6 2 ## 15 2 1 13 4 20 23 ## 16 0 2 2 2 4 4 ## 17 13 13 5 4 5 5 ## 18 0 0 0 1 10 16 ## Batch ## Cluster GSM3872444 ## 1 6 ## 2 36 ## 3 18 ## 4 88 ## 5 6 ## 6 23 ## 7 131 ## 8 5 ## 9 20 ## 10 54 ## 11 3 ## 12 59 ## 13 3 ## 14 6 ## 15 30 ## 16 3 ## 17 0 ## 18 9 Cluster size and cell contribution by sample, with clusters sorted by size: #mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions mnn.out$Sample.Name &lt;- uncorrected$Sample.Name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$Sample.Name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) + theme(legend.text = element_text(size = 7)) gridExtra::grid.arrange(p1, p2) Cluster size and cell contribution by sample type, with clusters sorted by size: mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) We can also compute the variation in the log-abundances to rank the clusters with the greatest variability in their proportional abundances across batches. We can then focus on batch-specific clusters that may be indicative of incomplete batch correction. Obviously, though, this diagnostic is subject to interpretation as the same outcome can be caused by batch-specific populations; some prior knowledge about the biological context is necessary to distinguish between these two possibilities. The table below shows the number of cells for each cluster (row) and sample (column) together with the variance in cell number across these samples (‘var’ column). # Avoid minor difficulties with the &#39;table&#39; class. tab.mnn &lt;- unclass(tab.mnn) # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) # Ranking clusters by the largest variances. rv &lt;- rowVars(norm) %&gt;% round(2) # show #DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),] DataFrame(tab.mnn, var=rv)[order(rv, decreasing=TRUE),] ## DataFrame with 18 rows and 8 columns ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 14 233 112 36 125 6 2 ## 7 1 15 157 21 183 128 ## 11 0 0 12 48 0 66 ## 3 87 1 3 3 62 16 ## 4 31 273 154 82 64 16 ## ... ... ... ... ... ... ... ## 2 40 38 14 47 63 9 ## 18 0 0 0 1 10 16 ## 1 2 0 6 6 4 21 ## 17 13 13 5 4 5 5 ## 16 0 2 2 2 4 4 ## GSM3872444 var ## &lt;integer&gt; &lt;numeric&gt; ## 14 6 3.09 ## 7 131 2.73 ## 11 3 1.58 ## 3 18 1.55 ## 4 88 1.34 ## ... ... ... ## 2 36 0.48 ## 18 9 0.35 ## 1 6 0.26 ## 17 0 0.18 ## 16 3 0.03 We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from both batches provides a comforting illusion that the correction was successful. set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;) mnn.out$batch &lt;- factor(mnn.out$batch) p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;) p #mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) #p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, shape_by=&quot;type&quot;) #p + facet_wrap(. ~ mnn.out$type) p + facet_wrap(. ~ mnn.out$source_name) For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). round(metadata(mnn.out)$merge.info$lost.var,2) ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 ## [1,] 0.00 0.00 0.00 0.00 0.03 0.00 ## [2,] 0.00 0.00 0.00 0.00 0.02 0.08 ## [3,] 0.00 0.00 0.10 0.00 0.01 0.01 ## [4,] 0.00 0.00 0.01 0.09 0.01 0.00 ## [5,] 0.00 0.08 0.00 0.00 0.01 0.00 ## [6,] 0.08 0.01 0.01 0.01 0.01 0.01 ## GSM3872444 ## [1,] 0.03 ## [2,] 0.03 ## [3,] 0.01 ## [4,] 0.00 ## [5,] 0.01 ## [6,] 0.00 Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. The following t-SNE shows the clusters identified: mnn.out$cluster &lt;- paste0(&quot;c&quot;, clusters.mnn) p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;, shape_by=&quot;source_name&quot;) p p + facet_wrap(~colData(mnn.out)$batch) The following t-SNE plots show expression levels of known cell type marker genes. genesToShow &lt;- c( &quot;CD79A&quot;, # CD79A B *** &quot;CST3&quot;, # CST3 monocytes *** &quot;CD3D&quot;, # CD3D T cells *** &quot;HBA1&quot; # HBA1 erythrocytes *** ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] #``` #B cells: #```{r fastmnn_diagTsneB_dsi{{setSuf}}_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pB &lt;- p #``` #T cells: #```{r fastmnn_diagTsneT_dsi{{setSuf}}_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[3] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pT &lt;- p #``` #monocytes: #```{r fastmnn_diagTsneM_dsi{{setSuf}}_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[2] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pM &lt;- p #``` #erythrocytes: #```{r fastmnn_diagTsneE_dsi{{setSuf}}_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pE &lt;- p gridExtra::grid.arrange(pB + theme(legend.position=&quot;bottom&quot;), pT + theme(legend.position=&quot;bottom&quot;), pM + theme(legend.position=&quot;bottom&quot;), pE + theme(legend.position=&quot;bottom&quot;), ncol=2) Compare to the uncorrected values: # B cells genex &lt;- ensToShow[1] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pBu &lt;- p #``` #Compare to the uncorrected values, T cells: #```{r uncorr_diagTsneT_dsi{{setSuf}}_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[3] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pTu &lt;- p #``` #Compare to the uncorrected values, monocytes: #```{r uncorr_diagTsneM_dsi{{setSuf}}_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[2] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pMu &lt;- p #``` #Compare to the uncorrected values, erythrocytes: #```{r uncorr_diagTsneE_dsi{{setSuf}}_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[4] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pEu &lt;- p gridExtra::grid.arrange(pBu + theme(legend.position=&quot;bottom&quot;), pTu + theme(legend.position=&quot;bottom&quot;), pMu + theme(legend.position=&quot;bottom&quot;), pEu + theme(legend.position=&quot;bottom&quot;), ncol=2) Other genes (exercise) genesToShow2 &lt;- c( &quot;IL7R&quot;, # IL7R, CCR7 Naive CD4+ T &quot;CCR7&quot;, # IL7R, CCR7 Naive CD4+ T &quot;S100A4&quot;, # IL7R, S100A4 Memory CD4+ &quot;CD14&quot;, # CD14, LYZ CD14+ Mono &quot;LYZ&quot;, # CD14, LYZ CD14+ Mono &quot;MS4A1&quot;, # MS4A1 B &quot;CD8A&quot;, # CD8A CD8+ T &quot;FCGR3A&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;MS4A7&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;GNLY&quot;, # GNLY, NKG7 NK &quot;NKG7&quot;, # GNLY, NKG7 NK &quot;FCER1A&quot;, # DC &quot;CST3&quot;, # DC &quot;PPBP&quot; # Platelet ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow2) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] table(ensToShow %in% rownames(rowData(mnn.out))) ensToShow &lt;- ensToShow[ensToShow %in% rownames(rowData(mnn.out))] for (genex in ensToShow) { p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;])) print(p) } 18.8.2 Preserving biological heterogeneity 18.8.2.1 Comparison between within-batch clusters and across-batch clusters obtained after MNN correction Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries are zero, though this may depend on whether specific clusters of interest are gained or lost. One heatmap is generated for each dataset, where each entry is colored according to the number of cells with each pair of labels (before and after correction), on the log10 scale with pseudocounts (+10) for a smoother color transition (so a minimum value of log10(0+10) == 1). plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled2$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled[[splIdx]]), cl.2=clusters.mnn[rescaled2$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) #gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, nrow=2, ncol=1, heights=c(unit(.8, &quot;npc&quot;), unit(.2, &quot;npc&quot;))) if(FALSE) { grobx &lt;- gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, nrow=3, ncol=2, heights=c(unit(.8, &quot;npc&quot;), unit(.1, &quot;npc&quot;), unit(.1, &quot;npc&quot;)), widths=c(unit(.3, &quot;npc&quot;), unit(.7, &quot;npc&quot;)), layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE) ) } if(FALSE) { grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, #nrow=3, ncol=2, #layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE), nrow=2, ncol=3, layout_matrix=matrix(c(1,1,2,5,4,3), ncol=3, byrow=FALSE), widths=c(unit(.70, &quot;npc&quot;), unit(.15, &quot;npc&quot;), unit(.15, &quot;npc&quot;)), heights=c(unit(.7, &quot;npc&quot;), unit(.3, &quot;npc&quot;)) ) } grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##gridExtra::marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’ in pink, ‘after’ in blue) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} #gridExtra::grid.arrange(grobs = treeList, gridExtra::grid.arrange(grobs = gxList, ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) gridExtra::grid.arrange(grobs = treeList, ncol=2 ) 18.8.2.2 Coassignment probabilities Another evaluation approach is to compute the coassignment probabilities, i.e. the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place. The plots below display the coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each sample, where each entry is colored according to the coassignment probability between each pair of within-batch clusters: # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled[[splIdx]]), clusters.mnn[rescaled2$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair (in pairwiseRand() with mode=“ratio” and adjusted=FALSE). The Rand index is introduced below. 18.8.2.3 Rand index Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled[[splIdx]])), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 GSM3872444 ## 0.29 0.21 0.76 0.50 0.74 0.63 0.78 A sample may show a low Rand index value if cells grouped together in a small cluster before correction are split into distinct clusters after correction because the latter comprise cell populations not observed in that sample but present in other samples. This would be the case of GSM3872434 with far fewer erythrocytes (grouped in a single cluster) than GSM3872443, in which subtypes can be distinguished. We can also break down the adjusted Rand index (ARI) into per-cluster ratios for more detailed diagnostics. For example, we could see low ratios off the diagonal if distinct clusters in the within-batch clustering were incorrectly aggregated in the merged clustering. Conversely, we might see low ratios on the diagonal if the correction inflated or introduced spurious heterogeneity inside a within-batch cluster. # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled[[splIdx]])), alt=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) 18.9 Encouraging consistency with marker genes In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach that is a natural extension of the strategy described in the feature selection section. We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by SingleR. In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN(). # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. markerList &lt;- lapply(rescaled, function(x){ y &lt;- pairwiseWilcox(x, direction=&quot;up&quot;) getTopMarkers(y[[1]], y[[2]], n=10) %&gt;% unlist %&gt;% unlist }) marker.set &lt;- unique(unlist(markerList)) #length(marker.set) # getting the total number of genes selected in this manner. The total number of genes selected in this manner is: 430. set.seed(1000110) mnn.out2 &lt;- fastMNN(rescaled, subset.row=marker.set, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out2$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions # compute t-SNE: mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;) We can also visualize the corrected coordinates using a t-SNE plot: plotTSNE(mnn.out2, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) plotTSNE(mnn.out2, colour_by=&quot;source_name&quot;) + facet_wrap(~colData(mnn.out2)$source_name, ncol=2) plotTSNE(mnn.out2, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) + facet_wrap(~colData(mnn.out2)$batch, ncol=3) A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (x in 1:length(splVec)) { plotList[[x]] &lt;- plotTSNE(mnn.out2[,mnn.out2$batch==splVec[x]], colour_by=I(colLabels(rescaled[[x]]))) + ggtitle(splVec[x]) } gridExtra::grid.arrange(grobs = plotList, ncol=3 ) m.out &lt;- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE]) #lapply(m.out, function(x){head(x[,2:6])}) tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) Expression level for the top gene, on violin plots: geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, ENSG00000008517 on t-SNE plot: Not Encouraging consistency with marker genes genex &lt;- rownames(demo)[1] genex &lt;- demo %&gt;% data.frame %&gt;% filter(!str_detect(Symbol, &quot;^RP&quot;)) %&gt;% pull(ensembl_gene_id) %&gt;% head(1) p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out)$batch) gridExtra::grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) Encouraging consistency with marker genes #genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out2)$batch) gridExtra::grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) We suggest limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. # before we save the mnn.out object in a file, # we should copy some of the cell meta data over, # eg Barcode and lib size. # Mind sets may have been downsampled, eg with nbCells set to 1000. # But that is not in the file name (yet?) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s.Rds&quot;, #fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi2_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(mnn.out, file=fn) #saveRDS(mnn.out2, file=fn) 18.10 Identify clusters with PBMMC cells Cluster size and cell contribution by sample type, with clusters sorted by size: mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) Cluster size and cell contribution by sample type, with clusters sorted by decreasing proportion of PBMMC: tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name, &quot;Sample.Name&quot;=mnn.out$batch ) sortVecNames &lt;- round(tmpMatTab/rowSums(tmpMatTab),2) %&gt;% as.data.frame() %&gt;% filter(batch==&quot;PBMMC&quot;) %&gt;% arrange(desc(Freq)) %&gt;% pull(clusters) tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(&quot;clusters&quot;=tmpMat$clusters, &quot;batch&quot;=tmpMat$batch) #tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() tmpMatDf &lt;- tmpMatTab[,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) #gridExtra::grid.arrange(p1, p2) p3 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=Sample.Name)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) p4 &lt;- p3 + scale_y_continuous(labels = scales::percent) p1 &lt;- p1 + theme(legend.text = element_text(size = 5)) p2 &lt;- p2 + theme(legend.text = element_text(size = 5)) p3 &lt;- p3 + theme(legend.text = element_text(size = 5)) + facet_wrap(~tmpMat$batch) p4 &lt;- p4 + theme(legend.text = element_text(size = 5)) #gridExtra::grid.arrange(p1, p2, p3) gridExtra::grid.arrange(p1, p2, p4, p3, ncol=1) rm(p1, p2, p3, p4) tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=as.character(mnn.out$batch)) #Batch=as.character(mnn.out$source_name)) #tab.mnn &lt;- as.data.frame(tab.mnn, stringsAsFactors=FALSE) ##tab.mnn # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) normNoLog &lt;- normalizeCounts(tab.mnn, pseudo_count=10, log=FALSE) sortVecNames &lt;- rowSums(normNoLog) %&gt;% round(2) %&gt;% sort(decreasing=TRUE) %&gt;% names #norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% #tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% #tidyr::pivot_longer(!clusters, names_to=&quot;Sample.Name&quot;, values_to=&quot;Freq&quot;) norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% rename(clusters = Cluster) %&gt;% rename(Sample.Name = Batch) norm2 &lt;- norm2 %&gt;% left_join(unique(cb_sampleSheet[,c(&quot;Sample.Name&quot;, &quot;source_name&quot;)]), by=&quot;Sample.Name&quot;) norm2$clusters &lt;- factor(norm2$clusters, levels=sortVecNames) #norm2 &lt;- norm2 %&gt;% as.data.frame() # fill by sample type p1 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() # fill by sample name p2 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=Sample.Name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() # split by sample type p3 &lt;- p2 + facet_wrap(~source_name) # show gridExtra::grid.arrange(p1, p2, p3) rm(p1, p2, p3) tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=as.character(mnn.out$source_name)) ##tab.mnn # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. #norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) normNoLog &lt;- normalizeCounts(tab.mnn, pseudo_count=10, log=FALSE) normNoLog &lt;- normNoLog %&gt;% as.data.frame.matrix() # sort by PBMMC proportion: normNoLog &lt;- normNoLog %&gt;% mutate(sum=rowSums(.)) normNoLog &lt;- normNoLog %&gt;% mutate(prop=PBMMC/sum) sortVecNames &lt;- normNoLog %&gt;% tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% arrange(desc(prop)) %&gt;% pull(clusters) norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% select(-sum, -prop) %&gt;% tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% tidyr::pivot_longer(!clusters, names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) norm2$clusters &lt;- factor(norm2$clusters, levels=sortVecNames) p1 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- p1 + facet_wrap(~source_name) # show gridExtra::grid.arrange(p1, p2) rm(p1, p2) Have threshold for proportion of PBMMC cells, say 50%, and keep clusters with PBMMC proportion below that threshold. normNoLog$propLt090 &lt;- normNoLog$prop &lt; 0.9 normNoLog$propLt080 &lt;- normNoLog$prop &lt; 0.8 normNoLog$propLt050 &lt;- normNoLog$prop &lt; 0.5 norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% select(-sum, -prop) %&gt;% tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% #tidyr::pivot_longer(!c(clusters,propLt090), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) #tidyr::pivot_longer(!c(clusters,propLt090,propLt080), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) #tidyr::pivot_longer(!c(clusters,propLt090,propLt080,propLt050), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) tidyr::pivot_longer(!c(clusters, grep(&quot;propLt&quot;, colnames(normNoLog), value=TRUE) ), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) norm2$clusters &lt;- factor(norm2$clusters, levels=sortVecNames) p1 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() #p + facet_wrap(~propLt090) #p + facet_wrap(~propLt080) p2 &lt;- p1 + facet_wrap(~propLt050) # show gridExtra::grid.arrange(p1, p2) rm(p1, p2) Corresponding TSNE, with cluster and expression level of top gene: propLtDf &lt;- norm2 %&gt;% select(clusters,propLt050) %&gt;% unique() propLtDf$cluster &lt;- paste0(&quot;c&quot;, propLtDf$clusters) colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% left_join(propLtDf[,c(&quot;cluster&quot;,&quot;propLt050&quot;)], by=&quot;cluster&quot;) %&gt;% DataFrame() # cluster: p &lt;- plotTSNE(mnn.out, colour_by = &quot;cluster&quot;, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(&quot;clusters&quot;) p1 &lt;- p + facet_wrap(~mnn.out$propLt050) + theme(legend.position=&#39;bottom&#39;) # top gene for some cluster: #genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) p2 &lt;- p + facet_wrap(~mnn.out$propLt050) + theme(legend.position=&#39;bottom&#39;) # show gridExtra::grid.arrange(p1, p2) rm(p, p1, p2) Same as above but with propLt080: keep clusters with PBMMC proportion lower than 80%: propLtDf &lt;- norm2 %&gt;% select(clusters,propLt080) %&gt;% unique() propLtDf$cluster &lt;- paste0(&quot;c&quot;, propLtDf$clusters) propLtDf$clusters &lt;- NULL colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% left_join(propLtDf, by=&quot;cluster&quot;) %&gt;% DataFrame() p1 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() #p + facet_wrap(~propLt090) #p + facet_wrap(~propLt080) p2 &lt;- p1 + facet_wrap(~propLt080) # show gridExtra::grid.arrange(p1, p2) rm(p1, p2) # cluster: p &lt;- plotTSNE(mnn.out, colour_by = &quot;cluster&quot;, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(&quot;clusters&quot;) p1 &lt;- p + facet_wrap(~mnn.out$propLt080) + theme(legend.position=&#39;bottom&#39;) # top gene for some cluster: genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) p2 &lt;- p + facet_wrap(~mnn.out$propLt080) + theme(legend.position=&#39;bottom&#39;) # show gridExtra::grid.arrange(p1, p2) rm(p, p1, p2) Check expression of cell type marker genes, for PBMMC proportion threshold of 50%: for (genex in ensToShow) { p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) + ggtitle(paste(rowData(uncorrected)[genex,&quot;Symbol&quot;], &quot; aka&quot;, genex)) + facet_wrap(~mnn.out$propLt050) print(p) } Some clusters with a high proportion of PBMMC cells also comprise a large number of cancer cells. To select clusters to keep, we could use the following inclusion criteria: proportion of PBMMC cells in cluster is lower than the threshold for the proportion of PBMMC cells in a cluster, eg 50% proportion of cancer cells in cluster higher than 5% of cells of that sample type The bar plots below show the clusters ordered by decreasing proportion of PBMMC and also split by selection outcome (where ‘TRUE’ means inclusion). normNoLog &lt;- normNoLog %&gt;% tibble::rownames_to_column(&quot;cluster&quot;) normNoLog$cluster &lt;- paste0(&quot;c&quot;, normNoLog$cluster) otherSplType &lt;- setdiff(splSetVec, &quot;PBMMC&quot;) # ok for pairs of sample types #thdSize &lt;- sum(normNoLog[,otherSplType])*0.02 thdSize &lt;- sum(normNoLog[,otherSplType])*0.05 thdPropPbmmc &lt;- 0.5 #propLtDf &lt;- norm2 %&gt;% select(clusters,propLt050) %&gt;% unique() #propLtDf$cluster &lt;- paste0(&quot;c&quot;, propLtDf$clusters) propLtDf &lt;- normNoLog %&gt;% filter(prop &lt; thdPropPbmmc | !!sym(otherSplType) &gt; thdSize) # ok for pairs of sample types normNoLog &lt;- normNoLog %&gt;% mutate(tmpCluBool= ifelse((prop &lt; thdPropPbmmc | !!sym(otherSplType) &gt; thdSize), TRUE, FALSE)) colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% #select(-tmpCluBool) %&gt;% left_join(normNoLog[,c(&quot;cluster&quot;, &quot;tmpCluBool&quot;)], by=&quot;cluster&quot;) %&gt;% DataFrame() norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% select(-sum, -prop) %&gt;% select(-c(grep(&quot;propOut&quot;, colnames(normNoLog), value=TRUE))) %&gt;% select(-c(grep(&quot;propLt&quot;, colnames(normNoLog), value=TRUE))) %&gt;% #tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% tidyr::pivot_longer(!c(cluster, grep(&quot;tmpCluBool&quot;, colnames(normNoLog), value=TRUE) ), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) norm2$cluster &lt;- factor(norm2$cluster, levels=paste0(&quot;c&quot;, sortVecNames)) p &lt;- ggplot(data=norm2, aes(x=cluster,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() gridExtra::grid.arrange(p, p + facet_wrap(norm2$tmpCluBool)) rm(p) # cluster: p &lt;- plotTSNE(mnn.out, colour_by = &quot;cluster&quot;, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(&quot;clusters&quot;) p1 &lt;- p + facet_wrap(~mnn.out$tmpCluBool) + theme(legend.position=&#39;bottom&#39;) # show p1 rm(p, p1) #mnn.out$tmpCluBool &lt;- NULL splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s_normNoLog.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(normNoLog, file=fn) 18.11 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] forcats_0.5.1 stringr_1.4.0 ## [3] purrr_0.3.4 readr_1.4.0 ## [5] tidyr_1.1.3 tibble_3.1.1 ## [7] tidyverse_1.3.1 BiocSingular_1.6.0 ## [9] Cairo_1.5-12.2 clustree_0.4.3 ## [11] ggraph_2.0.5 pheatmap_1.0.12 ## [13] dplyr_1.0.5 bluster_1.0.0 ## [15] batchelor_1.6.3 scran_1.18.7 ## [17] scater_1.18.6 SingleCellExperiment_1.12.0 ## [19] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [21] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [23] IRanges_2.24.1 S4Vectors_0.28.1 ## [25] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [27] matrixStats_0.58.0 ggplot2_3.3.3 ## [29] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] ggbeeswarm_0.6.0 colorspace_2.0-0 ## [3] ellipsis_0.3.2 scuttle_1.0.4 ## [5] XVector_0.30.0 fs_1.5.0 ## [7] BiocNeighbors_1.8.2 rstudioapi_0.13 ## [9] farver_2.1.0 graphlayouts_0.7.1 ## [11] ggrepel_0.9.1 fansi_0.4.2 ## [13] lubridate_1.7.10 xml2_1.3.2 ## [15] codetools_0.2-18 sparseMatrixStats_1.2.1 ## [17] polyclip_1.10-0 jsonlite_1.7.2 ## [19] ResidualMatrix_1.0.0 broom_0.7.6 ## [21] dbplyr_2.1.1 ggforce_0.3.3 ## [23] compiler_4.0.3 httr_1.4.2 ## [25] dqrng_0.3.0 backports_1.2.1 ## [27] assertthat_0.2.1 Matrix_1.3-2 ## [29] cli_2.4.0 limma_3.46.0 ## [31] tweenr_1.0.2 htmltools_0.5.1.1 ## [33] tools_4.0.3 rsvd_1.0.5 ## [35] igraph_1.2.6 gtable_0.3.0 ## [37] glue_1.4.2 GenomeInfoDbData_1.2.4 ## [39] Rcpp_1.0.6 cellranger_1.1.0 ## [41] jquerylib_0.1.3 vctrs_0.3.7 ## [43] DelayedMatrixStats_1.12.3 xfun_0.22 ## [45] ps_1.6.0 rvest_1.0.0 ## [47] beachmat_2.6.4 lifecycle_1.0.0 ## [49] irlba_2.3.3 statmod_1.4.35 ## [51] edgeR_3.32.1 zlibbioc_1.36.0 ## [53] MASS_7.3-54 scales_1.1.1 ## [55] tidygraph_1.2.0 hms_1.0.0 ## [57] RColorBrewer_1.1-2 yaml_2.2.1 ## [59] gridExtra_2.3 sass_0.3.1 ## [61] stringi_1.5.3 highr_0.9 ## [63] BiocParallel_1.24.1 rlang_0.4.10 ## [65] pkgconfig_2.0.3 bitops_1.0-7 ## [67] evaluate_0.14 lattice_0.20-44 ## [69] labeling_0.4.2 cowplot_1.1.1 ## [71] tidyselect_1.1.1 magrittr_2.0.1 ## [73] bookdown_0.22 R6_2.5.0 ## [75] generics_0.1.0 DelayedArray_0.16.3 ## [77] DBI_1.1.1 pillar_1.6.0 ## [79] haven_2.4.1 withr_2.4.2 ## [81] RCurl_1.98-1.3 modelr_0.1.8 ## [83] crayon_1.4.1 utf8_1.2.1 ## [85] rmarkdown_2.7 viridis_0.6.0 ## [87] locfit_1.5-9.4 grid_4.0.3 ## [89] readxl_1.3.1 reprex_2.0.0 ## [91] digest_0.6.27 munsell_0.5.0 ## [93] beeswarm_0.3.1 viridisLite_0.4.0 ## [95] vipor_0.4.5 bslib_0.2.4 "],["data-integration-all-caron-sample-types-dsisetsuf-allsetstop.html", "Chapter 19 Data integration - all Caron sample types {#dsi{{setSuf}}_allSetsTop} 19.1 Motivation 19.2 Load the data 19.3 Diagnosing batch effects 19.4 Linear regression 19.5 Mutual Nearest Neighbour correction 19.6 Correction diagnostics 19.7 Challenge Same but with an ordered merging 19.8 Identify clusters with PBMMC cells 19.9 Session information", " Chapter 19 Data integration - all Caron sample types {#dsi{{setSuf}}_allSetsTop} projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool splSetToGet &lt;- params$splSetToGet setName &lt;- params$setName setSuf &lt;- params$setSuf if(exists(&quot;isChild&quot;)) { setSuf &lt;- &quot;{{setSuf}}&quot; } dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;dummy&quot; setSuf &lt;- &quot;_allCells&quot; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 library(BiocParallel) bpp &lt;- MulticoreParam(8) Source: Integrating Datasets of the OSCA book and the fastMNN manual. 19.1 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 19.2 Load the data We will load the R file keeping the SCE object with the normalised counts. #setName &lt;- &quot;caron&quot; # Read object in: #setSuf &lt;- &quot;&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; # to avoid error later #head(rowData(sce)) #head(colData(sce)) table(colData(sce)$block) ## ## ABMMC ETV6-RUNX1 HHD PBMMC PRE-T ## 0 19488 9988 10885 7469 #assayNames(sce) #reducedDimNames(sce) Read in the sample sheet: # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) cb_sampleSheet &lt;- cb_sampleSheet %&gt;% filter(!Run == &quot;SRR9264351&quot;) cb_sampleSheet[1:2,] ## Run Assay.Type AvgSpotLen Bases BioProject BioSample ## 1 SRR9264343 RNA-Seq 132 27850288884 PRJNA548203 SAMN12011162 ## 2 SRR9264344 RNA-Seq 132 43613421192 PRJNA548203 SAMN12011172 ## Bytes Cell_type ## 1 18644549905 Pre-B t(12;21) [ETV6-RUNX1] acute lymphoblastic leukemia cells ## 2 27638885644 Pre-B t(12;21) [ETV6-RUNX1] acute lymphoblastic leukemia cells ## Center.Name Consent DATASTORE.filetype DATASTORE.provider ## 1 GEO public fastq,sra gs,ncbi,s3 ## 2 GEO public fastq,sra gs,ncbi,s3 ## DATASTORE.region disease_state ## 1 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 2 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## Experiment GEO_Accession..exp. Instrument LibraryLayout ## 1 SRX6034681 GSM3872434 Illumina HiSeq 4000 PAIRED ## 2 SRX6034682 GSM3872435 Illumina HiSeq 4000 PAIRED ## LibrarySelection LibrarySource Organism Platform ReleaseDate ## 1 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 2 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## Sample.Name source_name SRA.Study ## 1 GSM3872434 ETV6-RUNX1 SRP201012 ## 2 GSM3872435 ETV6-RUNX1 SRP201012 Have sample names: cb_sampleSheet$Sample.Name2 &lt;- &quot;NA&quot; typeVec &lt;- unique(cb_sampleSheet$source_name) for (tx in typeVec) { tmpInd &lt;- which(cb_sampleSheet$source_name == tx) for (i in 1:length(tmpInd)) { cb_sampleSheet$Sample.Name2[tmpInd[i]] &lt;- sprintf(&quot;%s_%s&quot;, tx, i) } } colData(sce)$Sample.Name2 &lt;- colData(sce) %&gt;% data.frame() %&gt;% left_join( cb_sampleSheet, by=&quot;Sample.Name&quot;) %&gt;% pull(Sample.Name2) splVec &lt;- cb_sampleSheet %&gt;% #filter(source_name == &quot;ETV6-RUNX1&quot;) %&gt;% pull(Sample.Name2) splVec ## [1] &quot;ETV6-RUNX1_1&quot; &quot;ETV6-RUNX1_2&quot; &quot;ETV6-RUNX1_3&quot; &quot;ETV6-RUNX1_4&quot; &quot;HHD_1&quot; ## [6] &quot;HHD_2&quot; &quot;PRE-T_1&quot; &quot;PRE-T_2&quot; &quot;PBMMC_1&quot; &quot;PBMMC_2&quot; ## [11] &quot;PBMMC_3&quot; # mind we now have a downsampled set to use all along # so avoid doing it again # also, changes setsuf to shorter form eg _5hCps, which we could use from the start TODO all.sce &lt;- list() if(setSuf == &quot;_allCells&quot; | setSuf == &quot;_5hCellPerSpl&quot;) { for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name2 == spx) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } } else { nbCells &lt;- 500 setSuf &lt;- &quot;_5hCps&quot; # &quot;_5hCellPerSpl&quot; #nbCells &lt;- 1000 #setSuf &lt;- &quot;_1kCps&quot; # &quot;_1kCellPerSpl&quot; for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name2 == spx) %&gt;% slice_sample(n=nbCells) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } } # show size of sets: lapply(all.sce, dim) ## $`ETV6-RUNX1_1` ## [1] 18431 2853 ## ## $`ETV6-RUNX1_2` ## [1] 18431 6615 ## ## $`ETV6-RUNX1_3` ## [1] 18431 4727 ## ## $`ETV6-RUNX1_4` ## [1] 18431 5293 ## ## $HHD_1 ## [1] 18431 4551 ## ## $HHD_2 ## [1] 18431 5437 ## ## $`PRE-T_1` ## [1] 18431 3841 ## ## $`PRE-T_2` ## [1] 18431 3628 ## ## $PBMMC_1 ## [1] 18431 2084 ## ## $PBMMC_2 ## [1] 18431 4658 ## ## $PBMMC_3 ## [1] 18431 4143 # set number of samples: nbSpl &lt;- length(all.sce) We will analyse each sample separately, namely: normalise counts model gene expression variance identify highly variable genes perform dimensionality reduction cluster cells #--- normalization ---# all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# library(scran) all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) # TSNE #set.seed(100000) #all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) # UMAP #set.seed(1000000) #all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;, BPPARAM=bpp) clust &lt;- igraph::cluster_walktrap(g)$membership colLabels(all.sce[[n]]) &lt;- factor(clust) } To prepare for the batch correction, we need to: subset all batches to the common “universe” of features rescale each batch to adjust for differences in sequencing depth between batches perform feature selection by averaging the variance components across all batches We subset all batches to the common “universe” of features. In this case, it is straightforward as batches use Ensembl gene annotation. allNames &lt;- unlist(lapply(all.sce, function(x){rownames(x)})) allNamesNb &lt;- table(allNames) universe &lt;- names(allNamesNb)[allNamesNb==length(splVec)] length(universe) ## [1] 18431 # Subsetting the SingleCellExperiment object. uni.sce &lt;- lapply(all.sce, function(x){x[universe,]}) # Also subsetting the variance modelling results, for convenience. uni.dec &lt;- lapply(all.dec, function(x){x[universe,]}) We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. library(batchelor) rescaled.mbn &lt;- multiBatchNorm(uni.sce, batch = &quot;Sample.Name2&quot;) We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. This allows us to use the same strategies described in Section 8.3 to select genes of interest. In contrast, approaches based on taking the intersection or union of HVGs across batches become increasingly conservative or liberal, respectively, with an increasing number of batches. library(scran) combined.dec &lt;- combineVar( uni.dec[[1]], uni.dec[[2]], uni.dec[[3]], uni.dec[[4]], uni.dec[[5]], uni.dec[[6]], uni.dec[[7]], uni.dec[[8]], uni.dec[[9]], uni.dec[[10]], uni.dec[[11]] ) chosen.hvgs &lt;- combined.dec$bio &gt; 0 sum(chosen.hvgs) ## [1] 12466 When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. That said, many of the signal-to-noise considerations described in Section 8.3 still apply here, so some experimentation may be necessary for best results. Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons. 19.3 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the SingleCellExperiments and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. #identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[2]])) #identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[3]])) #identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[4]])) rescaled2 &lt;- lapply(rescaled.mbn, function(x){x$batch &lt;- x$Sample.Name2; x}) rescaled.mbn &lt;- rescaled2 rm(rescaled2) uncorrected &lt;- do.call(cbind, rescaled.mbn) # Using RandomParam() as it is more efficient for file-backed matrices. library(scater) set.seed(0010101010) uncorrected &lt;- runPCA( uncorrected, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) # adjust walk.trap number of steps to that of cells nSteps &lt;- 4 # walktrap default if(ncol(uncorrected) &gt; 10000){ nSteps &lt;- 20 # or else get 63 clusters with caron allCells } We use graph-based clustering on the components to obtain a summary of the population structure. As our each sample group is represented by at least two replicates, each cluster should ideally consist of cells from several batches. This is the case for some but not all clusters. Some clusters comprise of cells from a single sample. This may indicate that cells of the same type are artificially separated due to technical differences between batches. They may also be cancer cell population private to samples. # 30+ min run # see clusterRows below for faster run ptm &lt;- proc.time() library(scran) snn.gr &lt;- buildSNNGraph(uncorrected, use.dimred=&quot;PCA&quot;, BPPARAM=bpp) #clusters &lt;- igraph::cluster_walktrap(snn.gr, steps=nSteps)$membership # slow clusters &lt;- igraph::cluster_fast_greedy(snn.gr)$membership proc.time() - ptm ## user system elapsed ## 47.680 1.346 35.602 #tab &lt;- table(Cluster=clusters, Batch=uncorrected$batch) #tab df.uncorr &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) tab.uncorr &lt;- table(df.uncorr) pheatmap::pheatmap(tab.uncorr, border_color = NA, drop_levels = TRUE, cluster_cols = FALSE ) # NNGraphParam k? # k is for makeSNNGraph: nearest neighbors to consider during graph construction ptm &lt;- proc.time() set.seed(1000) nSteps &lt;- 4 # walktrap default clusters &lt;- clusterRows(reducedDim(uncorrected, &quot;PCA&quot;), TwoStepParam(KmeansParam(centers=2000,iter.max=30), NNGraphParam( shared = TRUE, k=5, cluster.fun = &quot;walktrap&quot;, cluster.args = list(steps=nSteps) ))) proc.time() - ptm ## user system elapsed ## 14.104 0.012 14.133 ##tab2 &lt;- table(Cluster=clusters, Batch=uncorrected$batch) ##tab2 df.uncorr &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) tab.uncorr &lt;- table(df.uncorr) pheatmap::pheatmap(tab.uncorr, border_color = NA, drop_levels = TRUE, cluster_cols = FALSE ) Cluster size and cell contribution by sample: tmpMat &lt;- df.uncorr tmpMatTab &lt;- tab.uncorr sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(&quot;uncorrected, cell numbers&quot;) + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(&quot;uncorrected, proportions&quot;) + theme(legend.text = element_text(size = 7)) grid.arrange(p1, p2) #legend &lt;- get_legend(p1) legend &lt;- get_legend(p1 + theme(legend.position=&quot;bottom&quot;)) #p1 &lt;- p1 + theme(legend.position=&quot;none&quot;) #p2 &lt;- p2 + theme(legend.position=&quot;none&quot;) grid.arrange(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), legend, ncol=1, heights=c(5, 5, 2) ) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) We can also visualize the corrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results. set.seed(1111001) #uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;) uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) # draw: p &lt;- plotTSNE(uncorrected, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) + theme(legend.text = element_text(size = 7)) p p + facet_wrap(~uncorrected$source_name, ncol=2) We can also visualize the corrected coordinates using a UMAP plot: set.seed(1111001) #uncorrected &lt;- runUMAP(uncorrected, dimred=&quot;PCA&quot;) uncorrected &lt;- runUMAP(uncorrected, dimred=&quot;PCA&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) p &lt;- plotUMAP(uncorrected, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) p p + facet_wrap(~uncorrected$source_name, ncol=2) #grid.arrange( # p, # p + facet_wrap(~uncorrected$source_name, ncol=2), # ncol=2) legend &lt;- get_legend(p) p &lt;- p + theme(legend.position=&quot;none&quot;) grid.arrange(arrangeGrob(p, p + facet_wrap(~uncorrected$source_name, ncol=2), ncol=2), legend, widths=c(5/6, 1/6), ncol=2) Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations. If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. 19.4 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. #library(batchelor) rescaled.rb &lt;- rescaleBatches(rescaled.mbn) rescaled.rb ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(1): corrected ## rownames(18431): ENSG00000000003 ENSG00000000419 ... ENSG00000285486 ## ENSG00000285492 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## altExpNames(0): After clustering, we observe fewer clusters and these consist of mixtures of cells from the several replicates, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches on the TSNE plot below. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches. ptm &lt;- proc.time() set.seed(1010101010) # To ensure reproducibility of IRLBA. rescaled.rb &lt;- runPCA(rescaled.rb, subset_row=chosen.hvgs, exprs_values=&quot;corrected&quot;, #BSPARAM=IrlbaParam(), BSPARAM=RandomParam(), BPPARAM=bpp ) proc.time() - ptm ## user system elapsed ## 6.285 5.873 105.605 ptm &lt;- proc.time() snn.gr &lt;- buildSNNGraph(rescaled.rb, use.dimred=&quot;PCA&quot;, # or use BSPARAM BPPARAM=bpp) proc.time() - ptm ## user system elapsed ## 586.222 143.829 19.208 ptm &lt;- proc.time() #clusters.resc &lt;- igraph::cluster_walktrap(snn.gr, steps=nSteps)$membership # slow clusters.resc &lt;- igraph::cluster_louvain(snn.gr)$membership #clusters.resc &lt;- igraph::cluster_fast_greedy(snn.gr)$membership # coarse proc.time() - ptm ## user system elapsed ## 31.407 0.335 31.799 rescaled.rb$clusters.resc &lt;- factor(clusters.resc) ##tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled.rb$batch) ##tab.resc df.resc &lt;- data.frame(&quot;clusters&quot;=clusters.resc, &quot;batch&quot;=rescaled.rb$batch) tab.resc &lt;- table(df.resc) pheatmap::pheatmap(tab.resc, border_color = NA, drop_levels = TRUE, cluster_cols = FALSE ) Cluster size and cell contribution by sample, with clusters sorted by size: tmpMat &lt;- df.resc tmpMatTab &lt;- tab.resc sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) + theme(legend.text = element_text(size = 7)) #grid.arrange(p1, p2) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) Compute and plot t-SNE: rescaled.rb &lt;- runTSNE(rescaled.rb, dimred=&quot;PCA&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) rescaled.rb$batch &lt;- factor(rescaled.rb$batch) rescaled.rb$source_name &lt;- uncorrected$source_name p &lt;- plotTSNE(rescaled.rb, colour_by=&quot;batch&quot;, point_size=0.3) p p + facet_wrap(~rescaled.rb$source_name) ptm &lt;- proc.time() p.clu &lt;- plotTSNE(rescaled.rb, colour_by=&quot;clusters.resc&quot;, point_size=0.3) p.batch &lt;- plotTSNE(rescaled.rb, colour_by=&quot;batch&quot;, point_size=0.3) grid.arrange(p.clu, p.batch, ncol=2) proc.time() - ptm ## user system elapsed ## 0.539 0.031 0.572 19.5 Mutual Nearest Neighbour correction 19.5.1 Algorithm overview Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors (MNNs) are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space. 19.5.2 Application to the data The batchelor package provides an implementation of the MNN approach via the fastMNN() function. Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps. We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN( rescaled.mbn, auto.merge=TRUE, d=50, k=20, subset.row=chosen.hvgs, BSPARAM=RandomParam(deferred=TRUE), BPPARAM=bpp ) mnn.out ## class: SingleCellExperiment ## dim: 12466 47830 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(12466): ENSG00000000003 ENSG00000000457 ... ENSG00000285476 ## ENSG00000285492 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out$batch &lt;- factor(mnn.out$batch) mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) mnn.out.corre.dim &lt;- dim(reducedDim(mnn.out, &quot;corrected&quot;)) mnn.out.corre.dim ## [1] 47830 50 mnn.out.recon.dim &lt;- dim(assay(mnn.out, &quot;reconstructed&quot;)) mnn.out.recon.dim ## [1] 12466 47830 The function returns a SingleCellExperiment object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses (47830 cells and 50 PCs). A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space (12466 genes and 47830 cells). We do not recommend using this for anything other than visualization. print(assay(mnn.out, &quot;reconstructed&quot;)[1:5,1:3]) ## &lt;5 x 3&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ## ENSG00000000003 -8.970458e-05 -6.411674e-05 -6.896130e-05 ## ENSG00000000457 6.004816e-05 5.014359e-04 2.004637e-04 ## ENSG00000000938 -3.567196e-04 3.084119e-04 4.221600e-04 ## ENSG00000001167 2.328682e-04 7.270576e-04 6.971589e-04 ## ENSG00000001461 -8.717612e-04 -6.734327e-04 -7.530539e-04 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. colDataList &lt;- lapply(rescaled.mbn, function(x){colData(x)}) colDataDf &lt;- do.call(rbind, colDataList) #colData(mnn.out) &lt;- cbind(colDataDf, colData(mnn.out)$cluster) colData(mnn.out) &lt;- DataFrame(cbind(colData(mnn.out), colDataDf)) # no rearranging of columns by mnncorrect 19.6 Correction diagnostics We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the two batches are replicates of each other. snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, # or use BSPARAM BPPARAM=bpp) #clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr, steps=nSteps)$membership clusters.mnn &lt;- igraph::cluster_louvain(snn.gr)$membership #clusters.mnn &lt;- igraph::cluster_fast_greedy(snn.gr)$membership mnn.out$clusters.mnn &lt;- factor(clusters.mnn) tab.mnn &lt;- table(Cluster=mnn.out$clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PBMMC_1 ## 1 1155 1552 336 1566 470 349 37 ## 2 366 578 113 568 251 491 234 ## 3 112 2129 1246 291 188 1278 17 ## 4 306 595 194 825 216 514 50 ## 5 7 101 462 140 229 37 61 ## 6 730 823 191 330 1517 2307 43 ## 7 2 192 8 3 588 52 2 ## 8 108 372 96 130 439 119 25 ## 9 33 6 31 26 178 44 250 ## 10 1 1 5 2 32 34 19 ## 11 0 7 22 42 51 13 270 ## 12 3 3 117 234 1 13 25 ## 13 0 2 2 1 11 1 336 ## 14 14 75 390 117 159 74 98 ## 15 10 144 1306 219 213 86 595 ## 16 0 21 10 5 2 6 15 ## 17 6 14 198 794 6 19 7 ## Batch ## Cluster PBMMC_2 PBMMC_3 PRE-T_1 PRE-T_2 ## 1 25 70 1 0 ## 2 87 255 181 22 ## 3 18 96 3 1 ## 4 18 45 12 5 ## 5 422 402 21 114 ## 6 22 47 6 49 ## 7 1 7 1 0 ## 8 24 14 860 211 ## 9 321 247 633 237 ## 10 14 12 2058 2012 ## 11 431 755 6 235 ## 12 463 92 1 74 ## 13 195 738 1 6 ## 14 470 395 28 366 ## 15 1050 875 24 251 ## 16 33 33 1 25 ## 17 1064 60 4 20 pheatmap::pheatmap(tab.mnn, border_color = NA, drop_levels = TRUE, cluster_cols = FALSE ) Cluster size and cell contribution by sample, with clusters sorted by size: #mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions mnn.out$Sample.Name &lt;- uncorrected$Sample.Name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$Sample.Name2) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) + theme(legend.text = element_text(size = 7)) #grid.arrange(p1, p2) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) Cluster size and cell contribution by sample type, with clusters sorted by size: mnn.out$source_name &lt;- factor(uncorrected$source_name) # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) #grid.arrange(p1, p2) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from batches provides a comforting illusion that the correction was successful. set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, point_size=0.3) p p + facet_wrap(~mnn.out$type, ncol=2) # show clusters p.clu &lt;- plotTSNE(mnn.out, colour_by=&quot;clusters.mnn&quot;) p.batch &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;) #grid.arrange(p.clu, p.batch, ncol=2) grid.arrange(p.clu, p.batch+facet_wrap(~mnn.out$type), ncol=2) We can also compute the variation in the log-abundances to rank the clusters with the greatest variability in their proportional abundances across batches. We can then focus on batch-specific clusters that may be indicative of incomplete batch correction. Obviously, though, this diagnostic is subject to interpretation as the same outcome can be caused by batch-specific populations; some prior knowledge about the biological context is necessary to distinguish between these two possibilities. The table below shows the number of cells for each cluster (row) and sample (column) together with the variance in cell number across these samples (‘var’ column). # Avoid minor difficulties with the &#39;table&#39; class. tab.mnn &lt;- unclass(tab.mnn) # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) # Ranking clusters by the largest variances. rv &lt;- rowVars(norm) %&gt;% round(2) # show #DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),] DataFrame(tab.mnn, var=rv)[order(rv, decreasing=TRUE),] ## DataFrame with 17 rows and 12 columns ## ETV6.RUNX1_1 ETV6.RUNX1_2 ETV6.RUNX1_3 ETV6.RUNX1_4 HHD_1 HHD_2 ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 10 1 1 5 2 32 34 ## 1 1155 1552 336 1566 470 349 ## 13 0 2 2 1 11 1 ## 3 112 2129 1246 291 188 1278 ## 11 0 7 22 42 51 13 ## ... ... ... ... ... ... ... ## 8 108 372 96 130 439 119 ## 5 7 101 462 140 229 37 ## 14 14 75 390 117 159 74 ## 2 366 578 113 568 251 491 ## 16 0 21 10 5 2 6 ## PBMMC_1 PBMMC_2 PBMMC_3 PRE.T_1 PRE.T_2 var ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; ## 10 19 14 12 2058 2012 8.20 ## 1 37 25 70 1 0 6.99 ## 13 336 195 738 1 6 6.35 ## 3 17 18 96 3 1 6.29 ## 11 270 431 755 6 235 5.47 ## ... ... ... ... ... ... ... ## 8 25 24 14 860 211 2.48 ## 5 61 422 402 21 114 2.37 ## 14 98 470 395 28 366 2.10 ## 2 234 87 255 181 22 1.53 ## 16 15 33 33 1 25 0.72 For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). round(metadata(mnn.out)$merge.info$lost.var,2) ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PRE-T_1 ## [1,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [2,] 0.00 0.00 0.08 0.00 0.00 0.00 0.00 ## [3,] 0.00 0.00 0.01 0.10 0.00 0.00 0.00 ## [4,] 0.00 0.06 0.02 0.04 0.00 0.00 0.00 ## [5,] 0.00 0.01 0.04 0.07 0.05 0.00 0.00 ## [6,] 0.00 0.00 0.00 0.00 0.00 0.07 0.00 ## [7,] 0.00 0.01 0.02 0.03 0.02 0.02 0.00 ## [8,] 0.00 0.01 0.01 0.00 0.01 0.01 0.00 ## [9,] 0.08 0.00 0.01 0.01 0.00 0.00 0.00 ## [10,] 0.01 0.01 0.01 0.01 0.01 0.01 0.07 ## PRE-T_2 PBMMC_1 PBMMC_2 PBMMC_3 ## [1,] 0.00 0.00 0.07 0.04 ## [2,] 0.00 0.00 0.00 0.01 ## [3,] 0.00 0.00 0.01 0.00 ## [4,] 0.00 0.00 0.04 0.01 ## [5,] 0.00 0.00 0.08 0.02 ## [6,] 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.08 0.04 0.02 ## [8,] 0.11 0.01 0.00 0.01 ## [9,] 0.01 0.00 0.02 0.01 ## [10,] 0.01 0.01 0.02 0.01 tmpData &lt;- metadata(mnn.out)$merge.info$lost.var pheatmap::pheatmap(tmpData, border_color = NA, drop_levels = TRUE, cluster_rows = FALSE, cluster_cols = FALSE ) rm(tmpData) Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. The following t-SNE shows the clusters identified: mnn.out$cluster &lt;- paste0(&quot;c&quot;, clusters.mnn) p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;, shape_by=&quot;source_name&quot;, point_size=0.3) p p + facet_wrap(~colData(mnn.out)$source_name, ncol=2) The following t-SNE plots show expression levels of known cell type marker genes. genesToShow &lt;- c( &quot;CD79A&quot;, # CD79A B *** &quot;CST3&quot;, # CST3 monocytes *** &quot;CD3D&quot;, # CD3D T cells *** &quot;HBA1&quot; # HBA1 erythrocytes *** ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] #B cells: genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pB &lt;- p #T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pT &lt;- p #monocytes: genex &lt;- ensToShow[2] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pM &lt;- p #erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pE &lt;- p grid.arrange(pB + theme(legend.position=&quot;bottom&quot;), pT + theme(legend.position=&quot;bottom&quot;), pM + theme(legend.position=&quot;bottom&quot;), pE + theme(legend.position=&quot;bottom&quot;), ncol=2) Compare to the uncorrected values: # B cells genex &lt;- ensToShow[1] p &lt;- plotTSNE(uncorrected, colour_by = genex, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pBu &lt;- p #Compare to the uncorrected values, T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(uncorrected, colour_by = genex, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pTu &lt;- p #Compare to the uncorrected values, monocytes: genex &lt;- ensToShow[2] p &lt;- plotTSNE(uncorrected, colour_by = genex, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pMu &lt;- p #Compare to the uncorrected values, erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(uncorrected, colour_by = genex, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pEu &lt;- p grid.arrange(pBu + theme(legend.position=&quot;bottom&quot;), pTu + theme(legend.position=&quot;bottom&quot;), pMu + theme(legend.position=&quot;bottom&quot;), pEu + theme(legend.position=&quot;bottom&quot;), ncol=2) 19.6.1 Preserving biological heterogeneity 19.6.1.1 Comparison to within-batch clusters Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries are zero, though this may depend on whether specific clusters of interest are gained or lost. One heatmap is generated for each dataset, where each entry is colored according to the number of cells with each pair of labels (before and after correction), on the log10 scale with pseudocounts (+10) for a smoother color transition (so a minimum value of log10(0+10) == 1). # OLD library(pheatmap) # For the first batch (adding +10 for a smoother color transition # from zero to non-zero counts for any given matrix entry). batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[tmpInd]), paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) heat1 &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison&quot;, splVec[batchPlace]), silent=TRUE) # For the second batch. batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[tmpInd]), paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) heat2 &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison&quot;, splVec[batchPlace]), silent=TRUE) grid.arrange(heat1[[4]], heat2[[4]]) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled.mbn[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled.rb$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled.mbn[[splIdx]]), cl.2=clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) grobx &lt;- arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’ in pink, ‘after’ in blue) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. #```{r biolHet_plotShowTree1_dsi{{setSuf}}_allSets, fig.height=figSize*length(treeList)*2/3, fig.width=figSize} #grid.arrange(grobs = treeList, grid.arrange(grobs = gxList[1:4], ncol=1 ) grid.arrange(grobs = gxList[5:6], ncol=1 ) grid.arrange(grobs = gxList[7:8], ncol=1 ) grid.arrange(grobs = gxList[9:11], ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) grid.arrange(grobs = treeList, ncol=2 ) 19.6.1.2 Coassignment probabilities Another evaluation approach is to compute the coassignment probabilities, i.e. the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place. The plots below display the coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each sample, where each entry is colored according to the coassignment probability between each pair of within-batch clusters: # OLD # For the first batch. batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd]) heat1 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[batchPlace]), silent=TRUE) # For the second batch. batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd]) heat2 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[batchPlace]), silent=TRUE) grid.arrange(heat1[[4]], heat2[[4]]) # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled.mbn[[splIdx]]), clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3 ) Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair (in pairwiseRand() with mode=“ratio” and adjusted=FALSE). The Rand index is introduced below. 19.6.1.3 Rand index Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. # OLD suppressMessages(library(fossil)) batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] ri1 &lt;- rand.index(as.integer(clusters.mnn[tmpInd]), as.integer(colLabels(rescaled.mbn[[batchPlace]]))) ri1 batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] ri2 &lt;- rand.index(as.integer(clusters.mnn[tmpInd]), as.integer(colLabels(rescaled.mbn[[batchPlace]]))) ri2 # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled.mbn[[splIdx]])), alt=as.integer(clusters.mnn[rescaled.rb$batch==splVec[splIdx]]), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 ## 0.30 0.24 0.73 0.42 0.35 0.48 ## PRE-T_1 PRE-T_2 PBMMC_1 PBMMC_2 PBMMC_3 ## 0.41 0.54 0.59 0.72 0.69 A sample may show a low Rand index value if cells grouped together in a small cluster before correction are split into distinct clusters after correction because the latter comprise cell populations not observed in that sample but present in other samples. This would be the case of GSM3872434 aka ETV6-RUNX1_1 with far fewer erythrocytes (grouped in a single cluster) than GSM3872443 aka PBMMC_2, in which subtypes can be distinguished. We can also break down the adjusted Rand index (ARI) into per-cluster ratios for more detailed diagnostics. For example, we could see low ratios off the diagonal if distinct clusters in the within-batch clustering were incorrectly aggregated in the merged clustering. Conversely, we might see low ratios on the diagonal if the correction inflated or introduced spurious heterogeneity inside a within-batch cluster. # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled.mbn[[splIdx]])), alt=as.integer(clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3 ) 19.6.2 Encouraging consistency with marker genes In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach that is a natural extension of the strategy described in the feature selection section. We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by SingleR. In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN(). # OLD # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. stats1 &lt;- pairwiseWilcox(rescaled.mbn[[1]], direction=&quot;up&quot;) markers1 &lt;- getTopMarkers(stats1[[1]], stats1[[2]], n=10) stats2 &lt;- pairwiseWilcox(rescaled.mbn[[2]], direction=&quot;up&quot;) markers2 &lt;- getTopMarkers(stats2[[1]], stats2[[2]], n=10) stats3 &lt;- pairwiseWilcox(rescaled.mbn[[3]], direction=&quot;up&quot;) markers3 &lt;- getTopMarkers(stats3[[1]], stats3[[2]], n=10) stats4 &lt;- pairwiseWilcox(rescaled.mbn[[4]], direction=&quot;up&quot;) markers4 &lt;- getTopMarkers(stats4[[1]], stats4[[2]], n=10) marker.set &lt;- unique(unlist(c(unlist(markers1), unlist(markers2), unlist(markers3), unlist(markers4)))) length(marker.set) # getting the total number of genes selected in this manner. # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. markerList &lt;- lapply(rescaled.mbn, function(x){ y &lt;- pairwiseWilcox(x, direction=&quot;up&quot;, BPPARAM=bpp) getTopMarkers(y[[1]], y[[2]], n=10) %&gt;% unlist %&gt;% unlist }) marker.set &lt;- unique(unlist(markerList)) #length(marker.set) # getting the total number of genes selected in this manner. set.seed(1000110) mnn.out2 &lt;- fastMNN( rescaled.mbn[1:4], subset.row=marker.set, BSPARAM=RandomParam(deferred=TRUE), BPPARAM=bpp) The total number of genes selected in this manner is: 1188. set.seed(1000110) mnn.out2 &lt;- fastMNN(rescaled.mbn, subset.row=marker.set, BSPARAM=RandomParam(deferred=TRUE), BPPARAM=bpp) mnn.out2$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions # compute t-SNE: mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) We can also visualize the corrected coordinates using a t-SNE plot: plotTSNE(mnn.out2, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) plotTSNE(mnn.out2, colour_by=&quot;source_name&quot;) + facet_wrap(~colData(mnn.out2)$source_name, ncol=2) plotTSNE(mnn.out2, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) + facet_wrap(~colData(mnn.out2)$batch, ncol=4) A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context. mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) mnn.out$batch &lt;- factor(mnn.out$batch) batchVec &lt;- levels(mnn.out$batch) # for sample type in batchVec[1] grid.arrange( plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[1]], colour_by=I(colLabels(rescaled.mbn[[1]]))) + ggtitle(batchVec[1]), plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[2]], colour_by=I(colLabels(rescaled.mbn[[2]]))) + ggtitle(batchVec[2]), plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[3]], colour_by=I(colLabels(rescaled.mbn[[3]]))) + ggtitle(batchVec[3]), plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[4]], colour_by=I(colLabels(rescaled.mbn[[4]]))) + ggtitle(batchVec[4]), ncol=2 ) 19.6.3 Using the corrected values it is preferable to perform DE analyses using the uncorrected expression values with blocking on the batch. This strategy is based on the expectation that any genuine DE between clusters should still be present in a within-batch comparison where batch effects are absent. It penalizes genes that exhibit inconsistent DE across batches, thus protecting against misleading conclusions when a population in one batch is aligned to a similar-but-not-identical population in another batch. We demonstrate this approach below using a blocked t-test to detect markers in the PBMC dataset, where the presence of the same pattern across clusters within each batch is reassuring. If integration is performed across multiple conditions, it is even more important to use the uncorrected expression values for downstream analyses - see Section 14.5.2 for a discussion. m.out &lt;- findMarkers( uncorrected, clusters.mnn, block=uncorrected$batch, # TODO batch or type? direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[, c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;), drop=FALSE]) demo &lt;- m.out[[&quot;1&quot;]] as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;)]) #as.data.frame(demo[1:20,c(&quot;external_gene_name&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;)]) Expression level for the top gene, : geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) m.out &lt;- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE], BPPARAM=bpp) #lapply(m.out, function(x){head(x[,2:6])}) tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) geneEnsId &lt;- demo %&gt;% data.frame %&gt;% filter(!str_detect(Symbol, &quot;^RP&quot;)) %&gt;% pull(ensembl_gene_id) %&gt;% head(1) geneSymbol &lt;- rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, FTL on t-SNE plot: Not Encouraging consistency with marker genes p &lt;- plotTSNE(mnn.out, colour_by = geneEnsId, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, geneEnsId, geneSymbol)) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out)$batch) grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) Encouraging consistency with marker genes p &lt;- plotTSNE(mnn.out2, colour_by = geneEnsId, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, geneEnsId, geneSymbol)) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out2)$batch) grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) We suggest limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. # before we save the mnn.out object in a file, # we should copy some of the cell meta data over, # eg Barcode and lib size. # Mind sets may have been downsampled, eg with nbCells set to 1000. # But that is not in the file name (yet?) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s.Rds&quot;, #fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi2_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(mnn.out, file=fn) #saveRDS(mnn.out2, file=fn) 19.7 Challenge Same but with an ordered merging We will first merge replicates in each sample group separately, then sample groups, starting with the group with the larger number of ‘cell types’. Hint: use the merge.order option in fastMNN ( … maybe with “list( list(1,2,3,4), list(9,10,11), list(5,6), list(7,8) )” ) # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) rm(mnn.out) mnn.out &lt;- fastMNN(rescaled.mbn, merge.order=list( list(1,2,3,4), list(9,10,11), list(5,6), list(7,8) ), d=50, k=20, subset.row=chosen.hvgs, BSPARAM=RandomParam(deferred=TRUE), BPPARAM=bpp ) mnn.out ## class: SingleCellExperiment ## dim: 12466 47830 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(12466): ENSG00000000003 ENSG00000000457 ... ENSG00000285476 ## ENSG00000285492 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out$batch &lt;- factor(mnn.out$batch) mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) mnn.out$type &lt;- factor(mnn.out$type) #class(mnn.out$batch) #head(mnn.out$batch) #dim(reducedDim(mnn.out, &quot;corrected&quot;)) #assay(mnn.out, &quot;reconstructed&quot;) print(dim(assay(mnn.out, &quot;reconstructed&quot;))) ## [1] 12466 47830 print(assay(mnn.out, &quot;reconstructed&quot;)[1:5,1:3]) ## &lt;5 x 3&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ## ENSG00000000003 -1.272426e-04 -6.787507e-05 -5.702688e-05 ## ENSG00000000457 -3.356405e-05 4.087098e-04 1.054453e-04 ## ENSG00000000938 -2.351897e-03 -4.617906e-04 -3.513377e-04 ## ENSG00000001167 -6.807745e-05 2.264625e-04 2.274302e-04 ## ENSG00000001461 -2.447150e-04 -4.125638e-05 -2.362878e-04 Diagnostic table and plots: snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, BPPARAM=bpp) #clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership clusters.mnn &lt;- igraph::cluster_louvain(snn.gr)$membership mnn.out$clusters.mnn &lt;- sprintf(&quot;c%s&quot;, clusters.mnn) tab.mnn &lt;- table(Cluster=mnn.out$clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PBMMC_1 ## c1 756 696 298 279 1142 1804 166 ## c10 8 1 5 8 24 12 93 ## c11 7 11 39 10 9 14 128 ## c12 0 24 3 2 679 128 221 ## c13 0 1 16 11 1 1 403 ## c14 3 3 138 261 1 15 67 ## c15 6 101 458 140 228 37 62 ## c16 1 7 23 42 51 10 194 ## c17 0 21 10 5 2 7 36 ## c2 384 645 109 582 337 560 319 ## c3 101 374 92 85 353 108 22 ## c4 996 803 175 1433 303 392 27 ## c5 13 138 1350 218 192 89 210 ## c6 6 14 187 781 6 19 7 ## c7 11 80 327 107 175 70 79 ## c8 395 519 195 806 406 595 14 ## c9 166 3177 1302 523 642 1576 36 ## Batch ## Cluster PBMMC_2 PBMMC_3 PRE-T_1 PRE-T_2 ## c1 168 207 4 51 ## c10 44 38 1972 1104 ## c11 21 72 181 1057 ## c12 160 439 1 6 ## c13 186 26 2 6 ## c14 617 144 2 68 ## c15 420 459 23 114 ## c16 337 641 6 224 ## c17 67 60 2 28 ## c2 113 319 736 124 ## c3 31 12 849 189 ## c4 27 61 2 0 ## c5 871 884 22 324 ## c6 1066 59 4 44 ## c7 461 361 28 282 ## c8 24 54 5 0 ## c9 45 307 2 7 pheatmap::pheatmap(tab.mnn, border_color = NA, drop_levels = TRUE, #cluster_rows = FALSE, cluster_cols = FALSE ) set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) p.batch &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, point_size=0.3) p.clu &lt;- plotTSNE(mnn.out, colour_by=&quot;clusters.mnn&quot;, point_size=0.3) #grid.arrange(p.clu, p.batch, ncol=2) grid.arrange(p.clu, p.batch+facet_wrap(~mnn.out$type), ncol=2) Write mnn.out object to file colData(mnn.out) &lt;- cbind(colData(uncorrected),colData(mnn.out)[,c(&quot;type&quot;, &quot;clusters.mnn&quot;)]) # Write object to file # fastMnnWholeByList -&gt; Fmwbl tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_Fmwbl.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(mnn.out, tmpFn) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_Fmwbl2.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(list(&quot;chosen.hvgs&quot;=chosen.hvgs, &quot;uncorrected&quot;=uncorrected,&quot;rescaled.mbn&quot;=rescaled.mbn), tmpFn) Proportions of lost variance round(metadata(mnn.out)$merge.info$lost.var,2) ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PRE-T_1 ## [1,] 0.00 0.00 0.00 0.00 0.00 0.00 0.02 ## [2,] 0.00 0.00 0.00 0.00 0.01 0.03 0.00 ## [3,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [4,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [5,] 0.02 0.02 0.00 0.00 0.00 0.00 0.00 ## [6,] 0.01 0.01 0.04 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.00 0.01 0.06 0.00 0.00 0.00 ## [8,] 0.04 0.04 0.11 0.16 0.00 0.00 0.00 ## [9,] 0.01 0.02 0.03 0.04 0.07 0.08 0.00 ## [10,] 0.02 0.02 0.03 0.03 0.02 0.02 0.07 ## PRE-T_2 PBMMC_1 PBMMC_2 PBMMC_3 ## [1,] 0.01 0.00 0.00 0.00 ## [2,] 0.00 0.00 0.00 0.00 ## [3,] 0.00 0.04 0.18 0.00 ## [4,] 0.00 0.00 0.00 0.07 ## [5,] 0.00 0.00 0.00 0.00 ## [6,] 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.00 0.00 0.00 ## [8,] 0.00 0.02 0.02 0.02 ## [9,] 0.00 0.02 0.05 0.02 ## [10,] 0.12 0.02 0.02 0.02 tmpData &lt;- metadata(mnn.out)$merge.info$lost.var pheatmap::pheatmap(tmpData, border_color = NA, drop_levels = TRUE, cluster_rows = FALSE, cluster_cols = FALSE ) 19.7.1 Preserving biological heterogeneity 19.7.1.1 Comparison to within-batch clusters # OLD mnn.out$batch &lt;- factor(mnn.out$batch) # somehow need to re-factor batch levels(mnn.out$batch) # For the first batch (adding +10 for a smoother color transition # from zero to non-zero counts for any given matrix entry). batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] length(paste(&quot;after&quot;, clusters.mnn[tmpInd])) rescaled.mbn[[batchPlace]] rescaled.mbn[[batchPlace]] %&gt;% colData %&gt;% head length(paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) #save.image(&quot;dataSetIntegrationWhole.debug.Rdata&quot;) table(paste(&quot;after&quot;, clusters.mnn[tmpInd])) table(paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[tmpInd]), paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) heat1 &lt;- pheatmap( log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison&quot;, splVec[batchPlace]), silent=TRUE) # For the second batch. batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[tmpInd]), paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) heat2 &lt;- pheatmap( log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison&quot;, splVec[batchPlace]), silent=TRUE) grid.arrange(heat1[[4]], heat2[[4]]) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled.mbn[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled.rb$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled.mbn[[splIdx]]), cl.2=clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) grobx &lt;- arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’ in pink, ‘after’ in blue) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} grid.arrange(grobs = treeList, ncol=1 ) #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} #grid.arrange(grobs = treeList, grid.arrange(grobs = gxList[1:4], ncol=1 ) grid.arrange(grobs = gxList[5:6], ncol=1 ) grid.arrange(grobs = gxList[7:8], ncol=1 ) grid.arrange(grobs = gxList[9:11], ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) grid.arrange(grobs = treeList, ncol=3 ) Co-assignment probabilities # For the first batch. batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd]) heat1 &lt;- pheatmap( tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[batchPlace]), silent=TRUE) # For the second batch. batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd]) heat2 &lt;- pheatmap( tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[batchPlace]), silent=TRUE) grid.arrange(heat1[[4]], heat2[[4]]) # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled.mbn[[splIdx]]), clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), #main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3 ) 19.7.1.2 Rand index: # OLD library(fossil) batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] ri1 &lt;- rand.index(as.integer(clusters.mnn[tmpInd]), as.integer(colLabels(rescaled.mbn[[batchPlace]]))) ri1 batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] ri2 &lt;- rand.index(as.integer(clusters.mnn[tmpInd]), as.integer(colLabels(rescaled.mbn[[batchPlace]]))) ri2 # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled.rb$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled.mbn[[splIdx]])), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 ## 0.35 0.25 0.72 0.41 0.34 0.54 ## PRE-T_1 PRE-T_2 PBMMC_1 PBMMC_2 PBMMC_3 ## 0.36 0.66 0.75 0.64 0.59 # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled.rb$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled.mbn[[splIdx]])) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, #main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3 ) 19.7.2 Cluster markers: # OLD m.out &lt;- findMarkers( uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[, c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;), drop=FALSE]) #m.out &lt;- findMarkers(uncorrected, m.out &lt;- findMarkers(uncorrected[rownames(mnn.out),], clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, #row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE], row.data=rowData(uncorrected)[rownames(mnn.out),c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE], BPPARAM=bpp) #lapply(m.out, function(x){head(x[,2:6])}) tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) geneEnsId &lt;- demo %&gt;% data.frame %&gt;% filter(!str_detect(Symbol, &quot;^RP&quot;)) %&gt;% pull(ensembl_gene_id) %&gt;% head(1) geneSymbol &lt;- rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;] Expression level for the top gene in cluster 5, CD3D, (ENSG00000167286): # OLD geneEnsId &lt;- rownames(demo)[1] plotExpression( uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) #geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, CD3D on t-SNE plot: Not Encouraging consistency with marker genes p &lt;- plotTSNE(mnn.out, colour_by = geneEnsId, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle(paste(&quot;cluster&quot;, cluToGet, geneEnsId,geneSymbol)) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out)$batch) grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) 19.8 Identify clusters with PBMMC cells Cluster size and cell contribution by sample type, with clusters sorted by size: mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) #grid.arrange(p1, p2) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) Cluster size and cell contribution by sample type, with clusters sorted by decreasing proportion of PBMMC: tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=factor(mnn.out$source_name), &quot;Sample.Name&quot;=mnn.out$batch ) sortVecNames &lt;- round(tmpMatTab/rowSums(tmpMatTab),2) %&gt;% as.data.frame() %&gt;% filter(batch==&quot;PBMMC&quot;) %&gt;% arrange(desc(Freq)) %&gt;% pull(clusters) tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(&quot;clusters&quot;=tmpMat$clusters, &quot;batch&quot;=tmpMat$batch) #tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() tmpMatDf &lt;- tmpMatTab[,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) #grid.arrange(p1, p2) p3 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=Sample.Name)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) p4 &lt;- p3 + scale_y_continuous(labels = scales::percent) p1 &lt;- p1 + theme(legend.text = element_text(size = 5)) p2 &lt;- p2 + theme(legend.text = element_text(size = 5)) p3 &lt;- p3 + theme(legend.text = element_text(size = 5)) + facet_wrap(~tmpMat$batch) p4 &lt;- p4 + theme(legend.text = element_text(size = 5)) #grid.arrange(p1, p2, p3) #grid.arrange(p1, p2, p4, p3, ncol=1) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) ggplot(data=tmpMat, aes(x=clusters, fill=Sample.Name)) + geom_bar() + facet_wrap(~tmpMat$batch) legend &lt;- get_legend(p3) grid.arrange(arrangeGrob(p4 + theme(legend.position=&quot;none&quot;), p3 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) #rm(p1, p2, p3, p4) tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=as.character(mnn.out$batch)) #Batch=as.character(mnn.out$source_name)) #tab.mnn &lt;- as.data.frame(tab.mnn, stringsAsFactors=FALSE) ##tab.mnn # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) normNoLog &lt;- normalizeCounts(tab.mnn, pseudo_count=10, log=FALSE) sortVecNames &lt;- rowSums(normNoLog) %&gt;% round(2) %&gt;% sort(decreasing=TRUE) %&gt;% names tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=as.character(mnn.out$source_name)) ##tab.mnn # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. #norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) normNoLog &lt;- normalizeCounts(tab.mnn, pseudo_count=10, log=FALSE) normNoLog &lt;- normNoLog %&gt;% as.data.frame.matrix() # sort by PBMMC proportion: normNoLog &lt;- normNoLog %&gt;% mutate(sum=rowSums(.)) normNoLog &lt;- normNoLog %&gt;% mutate(prop=PBMMC/sum) sortVecNames &lt;- normNoLog %&gt;% tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% arrange(desc(prop)) %&gt;% pull(clusters) Some clusters with a high proportion of PBMMC cells also comprise a large number of cancer cells. To select clusters to keep, we could use the following inclusion criteria: proportion of PBMMC cells in cluster is lower than the threshold for the proportion of PBMMC cells in a cluster, eg 50% proportion of cancer cells in cluster higher than 5% of cells of that sample type The bar plots below show the clusters ordered by decreasing proportion of PBMMC and also split by selection outcome (where ‘TRUE’ means inclusion). normNoLog &lt;- normNoLog %&gt;% tibble::rownames_to_column(&quot;cluster&quot;) normNoLog$cluster &lt;- paste0(&quot;c&quot;, normNoLog$cluster) splSetVec &lt;- colnames(tab.mnn) otherSplType &lt;- setdiff(colnames(tab.mnn), &quot;PBMMC&quot;) # ok for pairs of sample types thdSize &lt;- sum(normNoLog[,otherSplType])*0.02 #thdSize &lt;- sum(normNoLog[,otherSplType])*0.05 thdPropPbmmc &lt;- 0.5 normNoLog &lt;- normNoLog %&gt;% mutate(Non_PBMMC=rowSums(normNoLog[,otherSplType])) otherSplType &lt;- &quot;Non_PBMMC&quot; #propLtDf &lt;- norm2 %&gt;% select(clusters,propLt050) %&gt;% unique() #propLtDf$cluster &lt;- paste0(&quot;c&quot;, propLtDf$clusters) propLtDf &lt;- normNoLog %&gt;% filter(prop &lt; thdPropPbmmc | !!sym(otherSplType) &gt; thdSize) # ok for pairs of sample types normNoLog &lt;- normNoLog %&gt;% mutate(tmpCluBool= ifelse((prop &lt; thdPropPbmmc | !!sym(otherSplType) &gt; thdSize), TRUE, FALSE)) colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% mutate(cluster=clusters.mnn) %&gt;% #select(-tmpCluBool) %&gt;% left_join(normNoLog[,c(&quot;cluster&quot;, &quot;tmpCluBool&quot;)], by=&quot;cluster&quot;) %&gt;% DataFrame() norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% select(-sum, -prop) %&gt;% select(-c(grep(&quot;propOut&quot;, colnames(normNoLog), value=TRUE))) %&gt;% select(-c(grep(&quot;propLt&quot;, colnames(normNoLog), value=TRUE))) %&gt;% #tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% tidyr::pivot_longer(!c(cluster, grep(&quot;tmpCluBool&quot;, colnames(normNoLog), value=TRUE) ), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) norm2$cluster &lt;- factor(norm2$cluster, levels=paste0(&quot;c&quot;, sortVecNames)) p &lt;- ggplot(data=norm2, aes(x=cluster,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() grid.arrange(p, p + facet_wrap(norm2$tmpCluBool)) rm(p) colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% mutate(cluster=clusters.mnn) %&gt;% #select(-tmpCluBool) %&gt;% left_join(normNoLog[,c(&quot;cluster&quot;, &quot;prop&quot;)], by=&quot;cluster&quot;) %&gt;% DataFrame() # cluster: p &lt;- plotTSNE(mnn.out, colour_by=&quot;prop&quot;, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle(&quot;PBMMC cell proportion&quot;) p1 &lt;- p + facet_wrap(~mnn.out$tmpCluBool) + theme(legend.position=&#39;bottom&#39;) # show #p1 p rm(p, p1) #mnn.out$tmpCluBool &lt;- NULL # cluster: p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle(&quot;clusters&quot;) p1 &lt;- p + facet_wrap(~mnn.out$tmpCluBool) + theme(legend.position=&#39;bottom&#39;) # show p1 splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s_normNoLog.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(normNoLog, file=fn) 19.9 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] gridExtra_2.3 cowplot_1.1.1 ## [3] clustree_0.4.3 ggraph_2.0.5 ## [5] forcats_0.5.1 stringr_1.4.0 ## [7] purrr_0.3.4 readr_1.4.0 ## [9] tidyr_1.1.3 tibble_3.1.2 ## [11] tidyverse_1.3.1 fossil_0.4.0 ## [13] shapefiles_0.7 foreign_0.8-81 ## [15] maps_3.3.0 sp_1.4-5 ## [17] pheatmap_1.0.12 batchelor_1.6.3 ## [19] BiocSingular_1.6.0 Cairo_1.5-12.2 ## [21] bluster_1.0.0 BiocNeighbors_1.8.2 ## [23] dplyr_1.0.6 scran_1.18.7 ## [25] scater_1.18.6 SingleCellExperiment_1.12.0 ## [27] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [29] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [31] IRanges_2.24.1 S4Vectors_0.28.1 ## [33] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [35] matrixStats_0.58.0 ggplot2_3.3.3 ## [37] knitr_1.33 BiocParallel_1.24.1 ## ## loaded via a namespace (and not attached): ## [1] Rtsne_0.15 ggbeeswarm_0.6.0 ## [3] colorspace_2.0-1 ellipsis_0.3.2 ## [5] scuttle_1.0.4 XVector_0.30.0 ## [7] fs_1.5.0 rstudioapi_0.13 ## [9] farver_2.1.0 graphlayouts_0.7.1 ## [11] ggrepel_0.9.1 RSpectra_0.16-0 ## [13] fansi_0.4.2 lubridate_1.7.10 ## [15] xml2_1.3.2 codetools_0.2-18 ## [17] sparseMatrixStats_1.2.1 polyclip_1.10-0 ## [19] jsonlite_1.7.2 ResidualMatrix_1.0.0 ## [21] broom_0.7.6 dbplyr_2.1.1 ## [23] uwot_0.1.10 ggforce_0.3.3 ## [25] compiler_4.0.3 httr_1.4.2 ## [27] dqrng_0.3.0 backports_1.2.1 ## [29] assertthat_0.2.1 Matrix_1.3-3 ## [31] cli_2.5.0 limma_3.46.0 ## [33] tweenr_1.0.2 htmltools_0.5.1.1 ## [35] tools_4.0.3 rsvd_1.0.5 ## [37] igraph_1.2.6 gtable_0.3.0 ## [39] glue_1.4.2 GenomeInfoDbData_1.2.4 ## [41] Rcpp_1.0.6 cellranger_1.1.0 ## [43] jquerylib_0.1.4 vctrs_0.3.8 ## [45] DelayedMatrixStats_1.12.3 xfun_0.23 ## [47] ps_1.6.0 beachmat_2.6.4 ## [49] rvest_1.0.0 lifecycle_1.0.0 ## [51] irlba_2.3.3 statmod_1.4.36 ## [53] edgeR_3.32.1 MASS_7.3-54 ## [55] zlibbioc_1.36.0 scales_1.1.1 ## [57] tidygraph_1.2.0 hms_1.0.0 ## [59] RColorBrewer_1.1-2 yaml_2.2.1 ## [61] sass_0.4.0 stringi_1.6.1 ## [63] highr_0.9 checkmate_2.0.0 ## [65] rlang_0.4.11 pkgconfig_2.0.3 ## [67] bitops_1.0-7 evaluate_0.14 ## [69] lattice_0.20-44 labeling_0.4.2 ## [71] tidyselect_1.1.1 magrittr_2.0.1 ## [73] bookdown_0.22 R6_2.5.0 ## [75] generics_0.1.0 DelayedArray_0.16.3 ## [77] DBI_1.1.1 pillar_1.6.1 ## [79] haven_2.4.1 withr_2.4.2 ## [81] RCurl_1.98-1.3 modelr_0.1.8 ## [83] crayon_1.4.1 utf8_1.2.1 ## [85] rmarkdown_2.8 viridis_0.6.1 ## [87] locfit_1.5-9.4 grid_4.0.3 ## [89] readxl_1.3.1 reprex_2.0.0 ## [91] digest_0.6.27 munsell_0.5.0 ## [93] beeswarm_0.3.1 viridisLite_0.4.0 ## [95] vipor_0.4.5 bslib_0.2.5 # OLD #projDir &lt;- &quot;/mnt/scratcha/bioinformatics/baller01/20200511_FernandesM_ME_crukBiSs2020&quot; projDir &lt;- &quot;/data/personal/baller01/20200511_FernandesM_ME_crukBiSs2020&quot; outDirBit &lt;- &quot;AnaWiSce/Attempt3&quot; nbPcToComp &lt;- 50 splSetToGet &lt;- &quot;PBMMC,ETV6-RUNX1&quot; # params may not be read in if knitting book. splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting if(interactive()) { paramsToUse &lt;- params2 } else { paramsToUse &lt;- params } projDir &lt;- paramsToUse$projDir dirRel &lt;- paramsToUse$dirRel outDirBit &lt;- paramsToUse$outDirBit cacheBool &lt;- paramsToUse$cacheBool setName &lt;- paramsToUse$setName splSetToGet &lt;- paramsToUse$splSetToGet setSuf &lt;- paramsToUse$setSuf dsiSuf &lt;- paramsToUse$dsiSuf # &#39;dsi&#39; for data set integration if(paramsToUse$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;PBMMC,ETV6-RUNX1&quot; setSuf &lt;- &quot;_5hCellPerSpl&quot; dsiSuf &lt;- &#39;_dsi&#39; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 anaStg &lt;- sprintf(&quot;&#39;%s_%s&#39;&quot;, splSetToGet2, setSuf) #displayToUse &lt;- Sys.getenv(&quot;DISPLAY&quot;) #Cairo::CairoX11(display=displayToUse); #```{r setup, include=FALSE, echo=FALSE} # removing chunk name for now because would need to make it dynamic, eg {{anaStg}} and expand # TODO do that later # First, set some variables: require(knitr) ## Loading required package: knitr opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE, cache=cacheBool) opts_chunk$set(echo = TRUE) opts_chunk$set(eval = TRUE) opts_chunk$set(dev=&quot;CairoPNG&quot;) opts_chunk$set(fig.width=7, fig.height=7) #opts_chunk$set(dev = c(&quot;png&quot;)) options(bitmapType=&#39;cairo&#39;) options(stringsAsFactors = FALSE) set.seed(123) # for reproducibility capabilities(&quot;cairo&quot;) ## cairo ## TRUE getOption(&#39;bitmapType&#39;) ## [1] &quot;cairo&quot; options(bitmapType=&#39;cairo&#39;) getOption(&#39;bitmapType&#39;) ## [1] &quot;cairo&quot; library(ggplot2) library(scater) library(scran) library(dplyr) library(dynamicTreeCut) library(cluster) # for silhouette library(igraph) # for graph-based clustering and plotting networks library(leiden) # for community detection library(pheatmap) library(Cairo) fontsize &lt;- theme(axis.text=element_text(size=12), axis.title=element_text(size=16)) "],["clustering-with-pbmmcetv6-runx1-and-5hcellperspl-clusteringpbmmc-etv6-runx1-5hcellperspltop.html", "Chapter 20 Clustering with ‘’PBMMC,ETV6-RUNX1’’ and ’_5hCellPerSpl’ {#clustering’PBMMC_ETV6-RUNX1__5hCellPerSpl’Top} 20.1 Load data 20.2 Clustering cells into putative subpopulations 20.3 Comparing two sets of clusters 20.4 Expression of known marker genes 20.5 Save data 20.6 Session information", " Chapter 20 Clustering with ‘’PBMMC,ETV6-RUNX1’’ and ’_5hCellPerSpl’ {#clustering’PBMMC_ETV6-RUNX1__5hCellPerSpl’Top} Source: clustering methods in the Hemberg group material and its ‘biocellgen variant’, with some of its text copied with few edits only. Also see the OSCA chapter on clustering and a benchmark study. Once we have normalized the data and removed confounders we can carry out analyses that are relevant to the biological questions at hand. The exact nature of the analysis depends on the dataset. One of the most promising applications of scRNA-seq is de novo discovery and annotation of cell-types based on transcription profiles. This requires the identification of groups of cells based on the similarities of the transcriptomes without any prior knowledge of the labels, or unsupervised clustering. To avoid the challenges caused by the noise and high dimensionality of the scRNA-seq data, clustering is performed after feature selection and dimensionality reduction, usually on the PCA output. We will introduce three widely used clustering methods: 1) hierarchical, 2) k-means and 3) graph-based clustering. In short, the first two were developed first and are faster for small data sets, while the third is more recent and better suited for scRNA-seq, especially large data sets. All three identify non-overlapping clusters. We will apply them to the denoised log-expression values on the data set studied and measure clustering quality. 20.1 Load data #setName &lt;- &quot;caron&quot; #setSuf &lt;- &quot;_5hCellPerSpl&quot; #setSuf &lt;- &quot;&quot; # dev with 1k/spl, should be _1kCellPerSpl #setSuf &lt;- &quot;_allCells&quot; # dev with 1k/spl, should be _1kCellPerSpl # need library size # all sample types tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) if(!file.exists(tmpFn)) { knitr::knit_exit() } sce0 &lt;- readRDS(tmpFn) # Read mnn.out object in: # only sample types in splSetToGet2 splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) # ex mnn.out #sce2 &lt;- readRDS(tmpFn) # ex mnn.out #rownames(sce) &lt;- rownames(sce2) rowData(sce) &lt;- cbind(rowData(sce), rowData(sce0)[rownames(sce),]) %&gt;% DataFrame Number of cells: . Number of genes: 7930. 20.2 Clustering cells into putative subpopulations 20.2.1 Hierarchical clustering Hierarchical clustering builds a hierarchy of clusters yielding a dendrogram that groups together cells with similar expression patterns across the chosen genes. There are two types of strategies: Agglomerative (bottom-up): each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy. Divisive (top-down): all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy. The raw data: knitr::include_graphics(&quot;../Images/bioCellGenHierar1.png&quot;) The hierarchical clustering dendrogram: knitr::include_graphics(&quot;../Images/bioCellGenHierar2.png&quot;) Pros: deterministic method returns partitions at all levels along the dendrogram Cons: computationally expensive in time and memory that increase proportionally to the square of the number of data points 20.2.1.1 Clustering Here we will apply hierarchical clustering on the Euclidean distances between cells, using the Ward D2 criterion to minimize the total variance within each cluster. # get PCs #pcs &lt;- reducedDim(sce, &quot;PCA&quot;) pcs &lt;- reducedDim(sce, &quot;corrected&quot;) # compute distance pc.dist &lt;- dist(pcs) # derive tree hc.tree &lt;- hclust(pc.dist, method=&quot;ward.D2&quot;) hcd &lt;- as.dendrogram(hc.tree) The dendrogram below shows each cell as a leaf. #plot(hc.tree, labels = FALSE, xlab = NULL, sub = NULL) plot(hcd, type = &quot;rectangle&quot;, ylab = &quot;Height&quot;, leaflab = &quot;none&quot;) Clusters are identified in the dendrogram using the shape of branches as well as their height (‘dynamic tree cut’ (???)). # identify clusters by cutting branches, requesting a minimum cluster size of 20 cells. hc.clusters &lt;- unname(cutreeDynamic(hc.tree, distM = as.matrix(pc.dist), minClusterSize = 20, verbose = 0)) Cell counts for each cluster (rows) and each sample group (columns): # per sample group table(hc.clusters, sce$source_name) ## ## hc.clusters ABMMC ETV6-RUNX1 HHD PBMMC PRE-T ## 1 0 609 0 183 0 ## 2 0 189 0 441 0 ## 3 0 512 0 94 0 ## 4 0 340 0 151 0 ## 5 0 99 0 107 0 ## 6 0 76 0 126 0 ## 7 0 13 0 167 0 ## 8 0 45 0 70 0 ## 9 0 73 0 25 0 ## 10 0 24 0 68 0 ## 11 0 20 0 68 0 Cell counts for each cluster (rows) and each sample (columns): # per sample table(hc.clusters, sce$Sample.Name) ## ## hc.clusters GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 ## 1 50 301 159 99 73 18 ## 2 1 15 154 19 185 125 ## 3 299 83 28 102 57 15 ## 4 121 61 38 120 90 11 ## 5 0 0 21 78 0 101 ## 6 2 9 51 14 17 54 ## 7 1 0 5 7 38 50 ## 8 0 1 11 33 1 57 ## 9 20 28 11 14 6 10 ## 10 4 1 8 11 14 36 ## 11 2 1 14 3 19 23 ## ## hc.clusters GSM3872444 ## 1 92 ## 2 131 ## 3 22 ## 4 50 ## 5 6 ## 6 55 ## 7 79 ## 8 12 ## 9 9 ## 10 18 ## 11 26 This data (cell number) may also be shown as heatmap. tmpTab &lt;- table(hc.clusters, sce$Sample.Name) rownames(tmpTab) = paste(&quot;hc&quot;, rownames(tmpTab), sep = &quot;_&quot;) # columns annotation with cell name: mat_col &lt;- colData(sce) %&gt;% data.frame() %&gt;% select(Sample.Name, source_name) %&gt;% unique rownames(mat_col) &lt;- mat_col$Sample.Name mat_col$Sample.Name &lt;- NULL # Prepare colours for clusters: colourCount = length(unique(mat_col$source_name)) getPalette = grDevices::colorRampPalette(RColorBrewer::brewer.pal(9, &quot;Set1&quot;)) mat_colors &lt;- list(source_name = getPalette(colourCount)) names(mat_colors$source_name) &lt;- unique(mat_col$source_name) Heatmap, with samples ordered as in sample sheet: # without column clustering pheatmap(tmpTab, cluster_cols = FALSE, annotation_col = mat_col, annotation_colors = mat_colors) Heatmap, with samples ordered by similarity of cell distribution across clusters: # with column clustering pheatmap(tmpTab, annotation_col = mat_col, annotation_colors = mat_colors) If clusters mostly include cells from one sample or the other, it suggests that the samples differ, and/or the presence of batch effect. Let us show cluster assignments on the t-SNE, with cells shaped by cell type, colored by cluster and sized total UMI counts (‘sum’). # store cluster assignment in SCE object: sce$cluster &lt;- factor(hc.clusters) # make, store and show TSNE plot: #g &lt;- plotTSNE(sce, colour_by = &quot;cluster&quot;, size_by = &quot;sum&quot;, shape_by=&quot;source_name&quot;) g &lt;- plotTSNE(sce, colour_by = &quot;cluster&quot;, shape_by=&quot;source_name&quot;) g Split by sample group: # split by sample and show: g &lt;- g + facet_wrap(. ~ sce$source_name) g In some areas cells are not all assigned to the same cluster. 20.2.1.2 Separatedness The congruence of clusters may be assessed by computing the sillhouette for each cell. The larger the value the closer the cell to cells in its cluster than to cells in other clusters. Cells closer to cells in other clusters have a negative value. Good cluster separation is indicated by clusters whose cells have large silhouette values. We first compute silhouette values. sil &lt;- silhouette(hc.clusters, dist = pc.dist) We then plot silhouettes with one color per cluster and cells with a negative silhouette with the color of their closest cluster. We also add the average silhouette for each cluster and all cells. # prepare colours: clust.col &lt;- scater:::.get_palette(&quot;tableau10medium&quot;) # hidden scater colours sil.cols &lt;- clust.col[ifelse(sil[,3] &gt; 0, sil[,1], sil[,2])] sil.cols &lt;- sil.cols[order(-sil[,1], sil[,3])] # plot: plot(sil, main = paste(length(unique(hc.clusters)), &quot;clusters&quot;), border = sil.cols, col = sil.cols, do.col.sort = FALSE) The plot shows cells with negative silhouette indicating that too many clusters may have been defined. The method and parameters used defined clusters with properties that may not fit the data set, eg clusters with the same diameter. 20.2.2 k-means 20.2.2.1 Description In k-means clustering, the goal is to partition N cells into k different clusters. In an iterative manner, cluster centers are defined and each cell is assigned to its nearest cluster. The aim is to minimise within-cluster variation and maximise between-cluster variation, using the following steps: randomly select k data points to serve as initial cluster centers, for each point, compute the distance between that point and each of the centroids and assign the point to the cluster with the closest centroid, calculate the mean of each cluster (the ‘mean’ in ‘k-mean’) to define its centroid, and for each point compute the distance to these means to choose the closest, repeat until the distance between centroids and data points is minimal (ie clusters do not change) or the maximum number of iterations is reached, compute the total variation within clusters, assign new centroids and repeat steps above Pros: fast Cons: assumes a pre-determined number of clusters sensitive to outliers tends to define equally-sized clusters 20.2.2.2 Example The dendogram built above suggests there may be six large cell populations. Let us define six clusters. # define clusters with kmeans() # because results depend on the initial cluster centers, # it is usually best to try several times, # by setting &#39;nstart&#39; to say 20, # kmeans() will then retain the run with the lowest within cluster variation. kclust &lt;- kmeans(pcs, centers=6, nstart = 20) # compute silhouette sil &lt;- silhouette(kclust$cluster, dist(pcs)) # plot silhouette clust.col &lt;- scater:::.get_palette(&quot;tableau10medium&quot;) # hidden scater colours sil.cols &lt;- clust.col[ifelse(sil[,3] &gt; 0, sil[,1], sil[,2])] sil.cols &lt;- sil.cols[order(-sil[,1], sil[,3])] plot(sil, main = paste(length(unique(kclust$cluster)), &quot;clusters&quot;), border=sil.cols, col=sil.cols, do.col.sort=FALSE) The t-SNE plot below shows cells color-coded by cluster membership: # get cell coordinates from &quot;TSNE&quot; slot: tSneCoord &lt;- as.data.frame(reducedDim(sce, &quot;TSNE&quot;)) colnames(tSneCoord) &lt;- c(&quot;TSNE1&quot;, &quot;TSNE2&quot;) # add sample type: tSneCoord$source_name &lt;- sce$source_name # add cluster info: tSneCoord$cluster &lt;- as.factor(kclust$cluster) # draw plot p2 &lt;- ggplot(tSneCoord, aes(x=TSNE1, y=TSNE2, colour=cluster, shape=source_name)) + geom_point() p2 Split by sample type: p2 + facet_wrap(~ sce$source_name) To find the most appropriate number of clusters, one performs the analysis for a series of values for k and for each k value computes a ‘measure of fit’ of the clusters defined. Several metrics exist. We will look at: * within-cluster sum-of-squares * silhouette * gap statistic 20.2.2.3 Within-cluster sum-of-squares The within-cluster sum-of-squares is the sum of the squared deviations from each observation and the cluster centroid. This metric measures the variability of observations within a cluster. It decreases as k increases, by an amount that decreases with k. Indeed, for low k values increasing k usually improves clustering, as shown by a sharp drop in the within-cluster sum-of-squares. For higher k values, increasing k does not reduce the within-cluster sum-of-squares much: dividing clusters further only slightly reduces variablility inside clusters. On a plot of the within-cluster sum-of-squares against k, the curve shows two parts: the first with a steep negative slope and the second with a small slope. The ‘elbow’ of the curve indicates the most appropriate number of clusters. library(broom) library(tibble) library(tidyr) library(purrr) # get PCA matrix (i.e. rotated values) points &lt;- as_tibble(pcs) # define clusters for different number of clusters # from 1 to 20: kclusts &lt;- tibble(k = 1:20) %&gt;% mutate( kclust = map(k, ~kmeans(points, .x)), # define clusters tidied = map(kclust, tidy), # &#39;flatten&#39; kmeans() output into tibble glanced = map(kclust, glance), # convert model or other R object to convert to single-row data frame augmented = map(kclust, augment, points) # extract per-observation information ) # get cluster assignments # unnest a list column with unnest(), # i.e. make each element of the list its own row. clusters &lt;- kclusts %&gt;% unnest(tidied) # get assignments assignments &lt;- kclusts %&gt;% unnest(augmented) # get clustering outcome clusterings &lt;- kclusts %&gt;% unnest(glanced) We now plot the total within-cluster sum-of-squares and decide on k. ggplot(clusterings, aes(k, tot.withinss)) + geom_point() + geom_line() clusterings %&gt;% mutate(tot.withinss.diff = tot.withinss - lag(tot.withinss)) %&gt;% arrange(desc(tot.withinss.diff)) ## # A tibble: 20 x 9 ## k kclust tidied totss tot.withinss betweenss iter augmented ## &lt;int&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;list&gt; ## 1 17 &lt;kmean… &lt;tibble[,53… 418. 126. 2.92e+ 2 5 &lt;tibble[,51] [… ## 2 20 &lt;kmean… &lt;tibble[,53… 418. 120. 2.98e+ 2 6 &lt;tibble[,51] [… ## 3 8 &lt;kmean… &lt;tibble[,53… 418. 170. 2.48e+ 2 4 &lt;tibble[,51] [… ## 4 19 &lt;kmean… &lt;tibble[,53… 418. 120. 2.98e+ 2 6 &lt;tibble[,51] [… ## 5 14 &lt;kmean… &lt;tibble[,53… 418. 133. 2.85e+ 2 4 &lt;tibble[,51] [… ## 6 16 &lt;kmean… &lt;tibble[,53… 418. 124. 2.94e+ 2 5 &lt;tibble[,51] [… ## 7 12 &lt;kmean… &lt;tibble[,53… 418. 138. 2.80e+ 2 4 &lt;tibble[,51] [… ## 8 13 &lt;kmean… &lt;tibble[,53… 418. 135. 2.84e+ 2 4 &lt;tibble[,51] [… ## 9 11 &lt;kmean… &lt;tibble[,53… 418. 142. 2.76e+ 2 4 &lt;tibble[,51] [… ## 10 15 &lt;kmean… &lt;tibble[,53… 418. 127. 2.91e+ 2 4 &lt;tibble[,51] [… ## 11 18 &lt;kmean… &lt;tibble[,53… 418. 120. 2.98e+ 2 4 &lt;tibble[,51] [… ## 12 10 &lt;kmean… &lt;tibble[,53… 418. 146. 2.72e+ 2 5 &lt;tibble[,51] [… ## 13 7 &lt;kmean… &lt;tibble[,53… 418. 170. 2.49e+ 2 4 &lt;tibble[,51] [… ## 14 6 &lt;kmean… &lt;tibble[,53… 418. 182. 2.37e+ 2 5 &lt;tibble[,51] [… ## 15 9 &lt;kmean… &lt;tibble[,53… 418. 156. 2.62e+ 2 5 &lt;tibble[,51] [… ## 16 5 &lt;kmean… &lt;tibble[,53… 418. 195. 2.23e+ 2 4 &lt;tibble[,51] [… ## 17 4 &lt;kmean… &lt;tibble[,53… 418. 219. 1.99e+ 2 3 &lt;tibble[,51] [… ## 18 3 &lt;kmean… &lt;tibble[,53… 418. 249. 1.69e+ 2 3 &lt;tibble[,51] [… ## 19 2 &lt;kmean… &lt;tibble[,53… 418. 305. 1.13e+ 2 1 &lt;tibble[,51] [… ## 20 1 &lt;kmean… &lt;tibble[,53… 418. 418. -2.27e-13 1 &lt;tibble[,51] [… ## # … with 1 more variable: tot.withinss.diff &lt;dbl&gt; # get the smallest negative drop k_neg &lt;- clusterings %&gt;% mutate(tot.withinss.diff = tot.withinss - lag(tot.withinss)) %&gt;% filter(tot.withinss.diff &lt; 0) %&gt;% #arrange(desc(tot.withinss.diff)) %&gt;% slice_max(tot.withinss.diff, n = 1) %&gt;% pull(k) k_neg &lt;- k_neg -1 # get the first positive diff k_pos &lt;- clusterings %&gt;% mutate(tot.withinss.diff = tot.withinss - lag(tot.withinss)) %&gt;% filter(tot.withinss.diff &gt;= 0) %&gt;% #arrange(desc(tot.withinss.diff)) %&gt;% slice_min(k, n = 1) %&gt;% pull(k) k_pos &lt;- k_pos -1 The plot above suggests reasonable values for k may be: 13 (where the drop in total within-cluster sum-of-squares is the smallest) 7 (lowest cluster number where the difference in consecutive total within-cluster sum-of-squares is positive) 20.2.2.4 Silhouette We now compute the Silhouette values for each set of clusters defined above for the series of values of k. # compute pairwise distance between cells in the PC space, # as it is needed to compute silhouette: pcDist &lt;- dist(pcs) # compute silhouette for each set of clusters defined above for a series of values of k: Ks=sapply(2:20, function(i) { tmpClu &lt;- as.numeric(kclusts$augmented[[i]]$.cluster) #table(tmpClu) sil &lt;- silhouette(tmpClu, pcDist) summary(sil)$avg.width } ) # plot average width against k: plot(2:20, Ks, xlab=&quot;k&quot;, ylab=&quot;av. silhouette&quot;, type=&quot;b&quot;, pch=19) 20.2.2.5 Gap statistic Because the variation quantity decreases as the number of clusters increases, a more reliable approach is to compare the observed variation to that expected from a null distribution. With the gap statistic, the expected variation is computed: by generating several reference data sets using the uniform distribution (no cluster), for each such set and the series of k values, by clustering and computing the within-cluster variation. The gap statistic measures for a given k the difference between the expected and observed variation. The most appropriate number of clusters is that with the higest gap value. We will use cluster::clusGap() to compute the gap statistic for k between 1 and 20. set.seed(123) gaps &lt;- cluster::clusGap( x = pcs, FUNcluster = kmeans, K.max = 20, nstart = 5, # low for expediency here but should use higher B = 10 # low for expediency here but should use higher ) ## find the &quot;best&quot; k best.k &lt;- cluster::maxSE(gaps$Tab[, &quot;gap&quot;], gaps$Tab[, &quot;SE.sim&quot;]) # in case the the best k was &#39;1&#39;, # skip first row of output table: gapsTab &lt;- gaps$Tab[2:nrow(gaps$Tab),] best.k &lt;- cluster::maxSE(gapsTab[, &quot;gap&quot;], gapsTab[, &quot;SE.sim&quot;]) #best.k The “optimal” k value is 19. # try other method to choose best k: ##best.k &lt;- cluster::maxSE(gapsTab[, &quot;gap&quot;], gapsTab[, &quot;SE.sim&quot;], method=&quot;Tibs2001SEmax&quot;) ##best.k &lt;- cluster::maxSE(gapsTab[, &quot;gap&quot;], gapsTab[, &quot;SE.sim&quot;], method=&quot;firstmax&quot;) ##best.k We next copy the cluster assignment to the SCE object. df &lt;- as.data.frame(assignments) # here only copy outcome for k == 10 sce$kmeans10 &lt;- as.numeric(df[df$k == 10, &quot;.cluster&quot;]) We now check silhouette values for a k of 10: library(cluster) clust.col &lt;- scater:::.get_palette(&quot;tableau10medium&quot;) # hidden scater colours sil &lt;- silhouette(sce$kmeans10, dist = pc.dist) sil.cols &lt;- clust.col[ifelse(sil[,3] &gt; 0, sil[,1], sil[,2])] sil.cols &lt;- sil.cols[order(-sil[,1], sil[,3])] plot(sil, main = paste(length(unique(sce$kmeans10)), &quot;clusters&quot;), border=sil.cols, col=sil.cols, do.col.sort=FALSE) df &lt;- as.data.frame(assignments) sce$kmeans.best &lt;- as.numeric(df[df$k == best.k, &quot;.cluster&quot;]) We now check silhouette values for a k of 19: library(cluster) clust.col &lt;- colorRampPalette(RColorBrewer::brewer.pal(9,&quot;RdBu&quot;))(best.k) sil &lt;- silhouette(sce$kmeans.best, dist = pc.dist) sil.cols &lt;- clust.col[ifelse(sil[,3] &gt; 0, sil[,1], sil[,2])] sil.cols &lt;- sil.cols[order(-sil[,1], sil[,3])] plot(sil, main = paste(length(unique(sce$kmeans.best)), &quot;clusters&quot;), border=sil.cols, col=sil.cols, do.col.sort=FALSE) For the same number of clusters (10), fewer cells have negative values with k-means than with hierarchical clustering. The average silhouette is similar though, and all clusters show a wide range. 20.2.2.6 Multi-metric One may also use multiple metrics rather than only one and check how they concord, using NbClust::NbClust() (see manual for a description of metrics computed): # run only once and save outcome to file to load later. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_500CellK2to20NbClust.Rds&quot;, projDir, outDirBit, setName, setSuf) if(file.exists(tmpFn)) { nb &lt;- readRDS(file=tmpFn) } else { library(NbClust) # tried with k from 2 to 20 but that takes too long with all cells. # subsample 500 cells tmpInd &lt;- sample(nrow(pcs), 500) nb = NbClust(data=pcs[tmpInd,], distance = &quot;euclidean&quot;, min.nc = 2, max.nc = 20, #min.nc = 8, #max.nc = 16, method = &quot;kmeans&quot;, index=c(&quot;kl&quot;,&quot;ch&quot;,&quot;cindex&quot;,&quot;db&quot;,&quot;silhouette&quot;, &quot;duda&quot;,&quot;pseudot2&quot;,&quot;beale&quot;,&quot;ratkowsky&quot;, &quot;gap&quot;,&quot;gamma&quot;,&quot;mcclain&quot;,&quot;gplus&quot;, &quot;tau&quot;,&quot;sdindex&quot;,&quot;sdbw&quot;)) saveRDS(nb, file=tmpFn) rm(tmpInd) } rm(tmpFn) Table showing the number of methods selecting values of k as the best choice: table(nb$Best.nc[1,]) # consensus seems to be 3 clusters ## ## 2 3 7 11 14 20 ## 7 4 1 1 1 2 rm(nb) No strong support for a single sensible value of k is observed. 20.2.3 Graph-based clustering Graph-based clustering entails building a nearest-neighbour (NN) graph using cells as nodes and their similarity as edges, then identifying ‘communities’ of cells within the network (more details there). In this k-NN graph two nodes (cells), say A and B, are connected by an edge if the distance between them is amongst the k smallest distances from A to other cells (‘KNN’), and from B to other cells (shared-NN, ‘SNN’). An edge may be weighted based on the number or closeness of shared nearest neighbours. Clusters are identified using metrics related to the number of neighbours (‘connections’) to find groups of highly interconnected cells. “The value of ‘k’ can be roughly interpreted as the anticipated size of the smallest subpopulation” (see scran’s buildSNNGraph() manual). Pros: fast and memory efficient (avoids the need to construct a distance matrix for all pairs of cells) no assumptions on the shape of the clusters or the distribution of cells within each cluster no need to specify a number of clusters to identify (but the size of the neigbourhood used affects the size of clusters) Cons: loss of information beyond neighboring cells, which can affect community detection in regions with many cells. The plot below shows the same data set as a network built using three different numbers of neighbours: 5, 15 and 25 (from here). We will: build the graph, define clusters, check membership across samples, show membership on a t-SNE plot, assess clustering quality. We now build the shared nearest neighbour (SNN) graph, using scran’s buildSNNGraph() with: the reduced and denoised data set (PCs) the default number of neighbours (k=10) the default type of edge weight (type=“rank”) # compute graph using buildSNNGraph # check manual with: ?buildSNNGraph #snn.gr &lt;- buildSNNGraph(sce, use.dimred=&quot;PCA&quot;) snn.gr &lt;- buildSNNGraph(sce, use.dimred=&quot;corrected&quot;) The number of cells in the data set is large so we randomly choose 1000 nodes (cells) in the network before plotting the resulting smaller network. Cells are color-coded by sample type: # subset graph down to 1000 cells # https://igraph.org/r/doc/subgraph.html # Add vertices (nodes. ie cells) annotation V(snn.gr)$Sample.Name &lt;- colData(sce)$Sample.Name V(snn.gr)$source_name &lt;- as.character(colData(sce)$source_name) # pick 1000 nodes randomly edgesToGet &lt;- sample(nrow(snn.gr[]), 1000) # subset graph for these 1000 ramdomly chosen nodes snn.gr.subset &lt;- subgraph(snn.gr, edgesToGet) g &lt;- snn.gr.subset # set colors for clusters if(length(unique(V(g)$source_name)) &lt;= 2) { cols &lt;- colorspace::rainbow_hcl(length(unique(V(g)$source_name))) } else { cols &lt;- RColorBrewer::brewer.pal(n = length(unique(V(g)$source_name)), name = &quot;RdYlBu&quot;) } names(cols) &lt;- unique(V(g)$source_name) # plot graph plot.igraph( g, layout = layout_with_fr(g), vertex.size = 3, vertex.label = NA, vertex.color = cols[V(g)$source_name], frame.color = cols[V(g)$source_name], main = &quot;default parameters&quot; ) # add legend legend(&#39;bottomright&#39;, legend=names(cols), pch=21, col=cols, # &quot;#777777&quot;, pt.bg=cols, pt.cex=1, cex=.6, bty=&quot;n&quot;, ncol=1) 20.2.3.1 Modularity Several methods to detect clusters (‘communities’) in networks rely on the ‘modulatrity’ metric. For a given partition of cells into clusters, modularity measures how separated clusters are from each other, based on the difference between the observed and expected weight of edges between nodes. For the whole graph, the closer to 1 the better. 20.2.3.2 Walktrap method The walktrap method relies on short random walks (a few steps) through the network. These walks tend to be ‘trapped’ in highly-connected regions of the network. Node similarity is measured based on these walks. Nodes are first each assigned their own community. Pairwise distances are computed and the two closest communities are grouped. These steps are repeated a given number of times to produce a dendrogram. Hierarchical clustering is then applied to the distance matrix. The best partition is that with the highest modularity. # identify clusters with walktrap # default number of steps: 4 cluster.out &lt;- cluster_walktrap(snn.gr) We will now count cells in each cluster for each sample type and each sample. We first retrieve membership. # cluster assignments are stored in the membership slot wt.clusters &lt;- cluster.out$membership Cluster number and sizes (number of cells): table(wt.clusters) ## wt.clusters ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## 709 193 341 63 137 33 66 23 629 56 35 98 127 536 100 191 86 59 18 The table below shows the cluster distribution across sample types. Many clusters are observed in only one sample type. table(wt.clusters, sce$source_name) ## ## wt.clusters ABMMC ETV6-RUNX1 HHD PBMMC PRE-T ## 1 0 543 0 166 0 ## 2 0 100 0 93 0 ## 3 0 250 0 91 0 ## 4 0 27 0 36 0 ## 5 0 68 0 69 0 ## 6 0 6 0 27 0 ## 7 0 0 0 66 0 ## 8 0 6 0 17 0 ## 9 0 191 0 438 0 ## 10 0 26 0 30 0 ## 11 0 1 0 34 0 ## 12 0 3 0 95 0 ## 13 0 58 0 69 0 ## 14 0 521 0 15 0 ## 15 0 23 0 77 0 ## 16 0 75 0 116 0 ## 17 0 44 0 42 0 ## 18 0 48 0 11 0 ## 19 0 10 0 8 0 The table below shows the cluster distribution across samples. Most clusters comprise cells from several replicates of a same sample type, while few are observed in only one sample. tmpTab &lt;- table(wt.clusters, sce$Sample.Name) rownames(tmpTab) = paste(&quot;4-step&quot;, rownames(tmpTab), sep = &quot;_&quot;) # columns annotation with cell name: mat_col &lt;- colData(sce) %&gt;% data.frame() %&gt;% select(Sample.Name, source_name) %&gt;% unique rownames(mat_col) &lt;- mat_col$Sample.Name mat_col$Sample.Name &lt;- NULL # Prepare colours for clusters: colourCount = length(unique(mat_col$source_name)) getPalette = grDevices::colorRampPalette(RColorBrewer::brewer.pal(9, &quot;Set1&quot;)) mat_colors &lt;- list(source_name = getPalette(colourCount)) names(mat_colors$source_name) &lt;- unique(mat_col$source_name) pheatmap(tmpTab, annotation_col = mat_col, annotation_colors = mat_colors) We next check the effect of the number of steps on the clusters detected by increasing it (default number of steps: 4). With 5-step walks: Cluster sizes: cluster.out.s5 &lt;- cluster_walktrap(snn.gr, steps = 5) wt.clusters.s5 &lt;- cluster.out.s5$membership table(wt.clusters.s5) ## wt.clusters.s5 ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## 338 525 63 80 131 779 23 629 38 140 128 84 194 39 47 100 85 59 18 Comparison with 4-step clusters: tmpTab &lt;- table(wt.clusters, wt.clusters.s5) rownames(tmpTab) = paste(&quot;4-step&quot;, rownames(tmpTab), sep = &quot;_&quot;) colnames(tmpTab) = paste(&quot;5-step&quot;, colnames(tmpTab) , sep = &quot;_&quot;) pheatmap(tmpTab) With 15-step walks: Cluster sizes: cluster.out.s15 &lt;- cluster_walktrap(snn.gr, steps = 15) wt.clusters.s15 &lt;- cluster.out.s15$membership table(wt.clusters.s15) ## wt.clusters.s15 ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## 65 23 126 62 664 249 181 37 131 250 187 91 562 39 122 49 603 59 Comparison with 4-step clusters: tmpTab &lt;- table(wt.clusters, wt.clusters.s15) rownames(tmpTab) = paste(&quot;4-step&quot;, rownames(tmpTab), sep = &quot;_&quot;) colnames(tmpTab) = paste(&quot;15-step&quot;, colnames(tmpTab) , sep = &quot;_&quot;) pheatmap(tmpTab) The network may also be built and clusters identified at once with scran::clusterSNNGraph() that also allows for large data sets to first cluster cells with k-means into a large number of clusters and then perform graph-based clustering on cluster centroids. # set use.kmeans to TRUE to &#39;create centroids that are then subjected to graph-based clustering&#39; (see manual) # with kmeans.centers default (square root of the number of cells) # or set kmeans.centers to another value, eg 30 clustersOnce &lt;- clusterSNNGraph(sce, #use.dimred=&quot;PCA&quot;, use.dimred=&quot;corrected&quot;, use.kmeans=TRUE, kmeans.centers = 200, full.stats=TRUE) Distribution of the size of the 200 k-means clusters: # &#39;kmeans&#39;: assignment of each cell to a k-means cluster ##table(clustersOnce$kmeans) # no good with many clusters summary(data.frame(table(clustersOnce$kmeans))$Freq) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.0 9.0 15.0 17.5 24.0 52.0 Graph-based cluster sizes in cell number: # &#39;igraph&#39;: assignment of each cell to a graph-based cluster operating on the k-means clusters table(clustersOnce$igraph) ## ## 1 2 3 4 5 6 7 ## 734 555 509 840 365 355 142 The heatmap below displays the contingency table for the graph-based clusters (rows) and the k-means clusters (columns) used to build the network (color-code by size, i.e. number of cells). #table(clustersOnce$igraph, # clustersOnce$kmeans) tmpTab &lt;- table(clustersOnce$igraph, clustersOnce$kmeans) rownames(tmpTab) = paste(&quot;igraph&quot;, rownames(tmpTab), sep = &quot;_&quot;) colnames(tmpTab) = paste(&quot;kmeans&quot;, colnames(tmpTab) , sep = &quot;_&quot;) pheatmap(tmpTab, show_colnames = FALSE) Graph-based cluster sizes in k-mean cluster number: # ‘membership’, the graph-based cluster to which each node is assigned table(metadata(clustersOnce)$membership) ## ## 1 2 3 4 5 6 7 ## 36 51 27 42 17 19 8 The plot below show the network build with the 200 k-means clusters used the identify the graph-based clusters. g &lt;- metadata(clustersOnce)$graph V(g)$membership &lt;- metadata(clustersOnce)$membership # set colors for clusters rgb.palette &lt;- colorRampPalette(c(&quot;purple&quot;,&quot;yellow&quot;), space=&quot;rgb&quot;) # Seurat-like cols &lt;- rgb.palette(length(unique(V(g)$membership))) names(cols) &lt;- as.character(1:length(unique(V(g)$membership))) # plot graph plot.igraph( g, layout = layout_with_fr(g), vertex.size = 3, vertex.label = NA, vertex.color = cols[V(g)$membership], frame.color = cols[V(g)$membership], main = &quot;with 200 k-means clusters&quot; ) # add legend legend(&#39;bottomright&#39;, legend=names(cols), pch=21, col=cols, # &quot;#777777&quot;, pt.bg=cols, pt.cex=1, cex=.6, bty=&quot;n&quot;, ncol=2) 20.2.3.3 Louvain method With the Louvain method, nodes are also first assigned their own community. This hierarchical agglomerative method then progresses in two-step iterations: 1) nodes are re-assigned one at a time to the community for which they increase modularity the most, if any, 2) a new, ‘aggregate’ network is built where nodes are the communities formed in the previous step. This is repeated until modularity stops increasing. The diagram below is copied from this article. We now apply the Louvain approach, store its outcome in the SCE object and show cluster sizes. ig.louvain &lt;- igraph::cluster_louvain(snn.gr) cl &lt;- ig.louvain$membership cl &lt;- factor(cl) # store membership sce$louvain &lt;- cl # show cluster sizes: table(sce$louvain) ## ## 1 2 3 4 5 6 7 8 9 10 ## 653 194 60 605 272 552 519 152 124 369 The plot below displays the network with nodes (the 1000 randomly chosen cells) color-coded by cluster membership: ## Define a set of colors to use (must be at least as many as the number of ## communities) ##cols &lt;- RColorBrewer::brewer.pal(n = nlevels(sce$cluster), name = &quot;RdYlBu&quot;) ##cols &lt;- grDevices:::colorRampPalette(RColorBrewer::brewer.pal(nlevels(sce$cluster), &quot;RdYlBu&quot;)) V(snn.gr)$Sample.Name &lt;- colData(sce)$Sample.Name V(snn.gr)$source_name &lt;- as.character(colData(sce)$source_name) V(snn.gr)$louvain &lt;- as.character(colData(sce)$louvain) # once only # edgesToGet &lt;- sample(nrow(snn.gr[]), 1000) snn.gr.subset &lt;- subgraph(snn.gr, edgesToGet) g &lt;- snn.gr.subset tmpLayout &lt;- layout_with_fr(g) rgb.palette &lt;- colorRampPalette(c(&quot;purple&quot;,&quot;yellow&quot;), space=&quot;rgb&quot;) # Seurat-like #rgb.palette &lt;- colorRampPalette(c(&quot;yellow2&quot;,&quot;goldenrod&quot;,&quot;darkred&quot;), space=&quot;rgb&quot;) ##rgb.palette &lt;- colorRampPalette(c(&quot;red&quot;,&quot;orange&quot;,&quot;blue&quot;), space=&quot;rgb&quot;) cols &lt;- rgb.palette(length(unique(V(g)$louvain))) names(cols) &lt;- as.character(1:length(unique(V(g)$louvain))) # Plot the graph, color by cluster assignment igraph::plot.igraph( g, layout = tmpLayout, vertex.color = cols[V(g)$louvain], frame.color = cols[V(g)$louvain], vertex.size = 3, vertex.label = NA, main = &quot;Louvain&quot; ) # add legend legend(&#39;bottomright&#39;, legend=names(cols), pch=21, col=cols, # &quot;#777777&quot;, pt.bg=cols, pt.cex=1, cex=.6, bty=&quot;n&quot;, ncol=2) The t-SNE plot shows cells color-coded by cluster membership: # show clusters on TSNE p &lt;- plotTSNE(sce, colour_by=&quot;louvain&quot;) + fontsize p Split by sample type: # facet by sample group: p + facet_wrap(~ sce$source_name) 20.2.3.4 Leiden method The Leiden method improves on the Louvain method by garanteeing that at each iteration clusters are connected and well-separated. The method includes an extra step in the iterations: after nodes are moved (step 1), the resulting partition is refined (step2) and only then the new aggregate network made, and refined (step 3). The diagram below is copied from this article. # have logical to check we can use the required python modules: leidenOk &lt;- FALSE # use the reticulate R package to use python modules library(reticulate) # set path to python use_python(&quot;/home/baller01/.local/share/r-miniconda/envs/r-reticulate/bin/python&quot;) # check availability of python modules and set logical accordingly if(reticulate::py_module_available(&quot;igraph&quot;) &amp; reticulate::py_module_available(&quot;leidenalg&quot;)) { leidenOk &lt;- TRUE } We now apply the Leiden approach, store its outcome in the SCE object and show cluster sizes. # mind eval above is set to the logical set above # so that chunk will only run if python modules were found. library(&quot;leiden&quot;) adjacency_matrix &lt;- igraph::as_adjacency_matrix(snn.gr) partition &lt;- leiden(adjacency_matrix) # store membership sce$leiden &lt;- factor(partition) # show cluster sizes: table(sce$leiden) ## ## 1 2 3 4 5 6 7 8 9 ## 762 611 595 488 401 310 194 117 22 The plot below displays the network with nodes (the 1000 randomly chosen cells) color-coded by cluster membership: ## Define a set of colors to use (must be at least as many as the number of ## communities) ##cols &lt;- RColorBrewer::brewer.pal(n = nlevels(sce$cluster), name = &quot;RdYlBu&quot;) ##cols &lt;- grDevices:::colorRampPalette(RColorBrewer::brewer.pal(nlevels(sce$cluster), &quot;RdYlBu&quot;)) ##V(snn.gr)$Sample.Name &lt;- colData(sce)$Sample.Name ##V(snn.gr)$source_name &lt;- as.character(colData(sce)$source_name) V(snn.gr)$leiden &lt;- as.character(colData(sce)$leiden) # once only # edgesToGet &lt;- sample(nrow(snn.gr[]), 1000) snn.gr.subset &lt;- subgraph(snn.gr, edgesToGet) g &lt;- snn.gr.subset #cols &lt;- RColorBrewer::brewer.pal(n = length(unique(V(g)$leiden)), name = &quot;RdYlBu&quot;) # 11 max #cols &lt;- RColorBrewer::brewer.pal(n = length(unique(V(g)$leiden)), name = &quot;Spectral&quot;) # 11 max #names(cols) &lt;- unique(V(g)$leiden) rgb.palette &lt;- colorRampPalette(c(&quot;purple&quot;,&quot;yellow&quot;), space=&quot;rgb&quot;) # Seurat-like #rgb.palette &lt;- colorRampPalette(c(&quot;yellow2&quot;,&quot;goldenrod&quot;,&quot;darkred&quot;), space=&quot;rgb&quot;) ##rgb.palette &lt;- colorRampPalette(c(&quot;red&quot;,&quot;orange&quot;,&quot;blue&quot;), space=&quot;rgb&quot;) cols &lt;- rgb.palette(length(unique(V(g)$leiden))) names(cols) &lt;- as.character(1:length(unique(V(g)$leiden))) ## Plot the graph, color by cluster assignment igraph::plot.igraph( g, layout = tmpLayout, vertex.color = cols[V(g)$leiden], frame.color = cols[V(g)$leiden], vertex.size = 3, vertex.label = NA, main = &quot;Leiden&quot; ) legend(&#39;bottomright&#39;, legend=names(cols), pch=21, col=cols, # &quot;#777777&quot;, pt.bg=cols, pt.cex=1, cex=.6, bty=&quot;n&quot;, ncol=2) The t-SNE plot below shows cells color-coded by cluster membership: # show clusters on TSNE p &lt;- plotTSNE(sce, colour_by=&quot;leiden&quot;) + fontsize p Split by sample type: # facet by sample group: p + facet_wrap(~ sce$source_name) 20.2.3.5 Modularity to assess clusters quality We now compute modularity to assess clusters quality (the division of cells into several groups, ‘clusters’, is compared to that in an equivalent random network with no structure). The overall modularity obtained with the Louvain method is 0.72. Modularity can also be computed for each cluster, with scran’s clusterModularity() (now in the bluster package). This function returns an upper diagonal matrix with values for each pair of clusters. # compute cluster-wise modularities, # with clusterModularity(), # which returns a matrix keeping values for each pair of clusters ##mod.out &lt;- clusterModularity(snn.gr, wt.clusters, get.weights=TRUE) mod.out &lt;- bluster::pairwiseModularity(snn.gr, #wt.clusters, sce$louvain, get.weights=TRUE) # Modularity is proportional to the cluster size, # so we compute the ratio of the observed to expected weights # for each cluster pair ratio &lt;- mod.out$observed/mod.out$expected lratio &lt;- log10(ratio + 1) # on log scale to improve colour range We display below the cluster-wise modularity on a heatmap. Clusters that are well separated mostly comprise intra-cluster edges and harbour a high modularity score on the diagonal and low scores off that diagonal. Two poorly separated clusters will share edges and the pair will have a high score. pheatmap(lratio, cluster_rows=FALSE, cluster_cols=FALSE, color=colorRampPalette(c(&quot;white&quot;, &quot;blue&quot;))(100)) The cluster-wise modularity matrix may also be shown as a network, with clusters as nodes and edges weighted by modularity: cluster.gr &lt;- igraph::graph_from_adjacency_matrix( ratio, mode=&quot;undirected&quot;, weighted=TRUE, diag=FALSE) plot(cluster.gr, label.cex = 0.2, edge.width = igraph::E(cluster.gr)$weight) 20.2.3.6 Choose the number of clusters Some community detection methods are hierarchical, e.g. walktrap. With these methods, one can choose the number of clusters. We can now retrieve a given number of clusters, e.g. 10 here to match the k-means clusters defined above: # remember cluster.out keeps the walktrap outcome cluster.out.10 &lt;- igraph::cut_at(cluster.out, no = 10) cluster.out.10 &lt;- factor(cluster.out.10) table(cluster.out.10) ## cluster.out.10 ## 1 2 3 4 5 6 7 8 9 10 ## 269 182 96 1497 478 23 629 35 100 191 The plot below displays the network with nodes (the 1000 randomly chosen cells) color-coded by cluster membership, split by sample type: # annotate nodes V(snn.gr)$walkCutAt10 &lt;- as.character(cluster.out.10) # subset graph snn.gr.subset &lt;- subgraph(snn.gr, edgesToGet) g &lt;- snn.gr.subset # make colors: cols &lt;- rgb.palette(length(unique(V(g)$walkCutAt10))) names(cols) &lt;- as.character(1:length(unique(V(g)$walkCutAt10))) # Plot the graph, color by cluster assignment igraph::plot.igraph( g, layout = tmpLayout, vertex.color = cols[V(g)$walkCutAt10], vertex.size = 3, vertex.label = NA, main = &quot;walkCutAt10&quot; ) legend(&#39;bottomright&#39;, legend=names(cols), pch=21, col=&quot;#777777&quot;, pt.bg=cols, pt.cex=2, cex=.8, bty=&quot;n&quot;, ncol=2) The t-SNE plot below shows cells color-coded by cluster membership split by sample type: # ```{r, out.width = &#39;100%&#39;} sce$cluster.out.10 &lt;- cluster.out.10 sce$cluster.out.10.col &lt;- cols[cluster.out.10] # show clusters on TSNE #p &lt;- plotTSNE(sce, colour_by=&quot;cluster.out.10&quot;) + fontsize tSneCoord &lt;- as.data.frame(reducedDim(sce, &quot;TSNE&quot;)) colnames(tSneCoord) &lt;- c(&quot;TSNE1&quot;, &quot;TSNE2&quot;) # add sample type: tSneCoord$source_name &lt;- sce$source_name # add cluster info: tSneCoord$cluster.out.10.col &lt;- sce$cluster.out.10.col # draw plot p2 &lt;- ggplot(tSneCoord, aes(x=TSNE1, y=TSNE2, color=cluster.out.10, shape=source_name)) + geom_point() p2 &lt;- p2 + scale_color_manual(values = cols) # facet by sample group: p2 + facet_wrap(~ sce$source_name) + theme(legend.text=element_text(size=rel(0.7))) 20.3 Comparing two sets of clusters The contingency table below shows the concordance between the walk-trap (rows) and k-means (columns) clustering methods: # rows: walktrap # columns: kmeans ##tmpTab &lt;- table(cluster.out$membership, sce$kmeans10) tmpTab &lt;- table(sce$cluster.out.10, sce$kmeans10) tmpTab ## ## 1 2 3 4 5 6 7 8 9 10 ## 1 0 0 0 0 0 0 0 252 17 0 ## 2 0 0 0 1 19 1 161 0 0 0 ## 3 0 0 0 0 0 0 0 0 96 0 ## 4 14 748 2 5 184 10 0 0 0 534 ## 5 0 11 0 0 49 418 0 0 0 0 ## 6 19 0 0 0 2 0 0 0 1 1 ## 7 0 0 610 19 0 0 0 0 0 0 ## 8 0 0 0 0 23 0 0 0 12 0 ## 9 0 0 0 100 0 0 0 0 0 0 ## 10 191 0 0 0 0 0 0 0 0 0 Concordance is moderate, with some clusters defined with one method comprising cells assigned to several clusters defined with the other method. Concordance can also be displayed on a heatmap: rownames(tmpTab) = paste(&quot;walk&quot;, rownames(tmpTab), sep = &quot;_&quot;) colnames(tmpTab) = paste(&quot;kmeans10&quot;, colnames(tmpTab) , sep = &quot;_&quot;) pheatmap(tmpTab) Concordance can also be measured with the adjusted Rand index that ranges between 0 and 1 from random partitions to perfect agreement. Here, the adjusted Rand index is 0.600216. 20.4 Expression of known marker genes We first show clusters on a t-SNE plot: cluToUse &lt;- &quot;cluster.out.10&quot; plotTSNE(sce, colour_by = cluToUse) + ggtitle(&quot;walktrap, 10 clusters&quot;) Having identified clusters, we now display the level of expression of cell type marker genes to quickly match clusters with cell types (e.g. MS4A1 for B cell marker gene). For each marker we will plot its expression on a t-SNE, and show distribution across each cluster on a violin plot. Example with B cell marker genes MS4A1 and CD79A: rownames(sce) &lt;- scater::uniquifyFeatureNames( rowData(sce)$ensembl_gene_id, rowData(sce)$Symbol) p1 &lt;- plotTSNE(sce, by_exprs_values = &quot;reconstructed&quot;, colour_by = &quot;MS4A1&quot;) + ggtitle(&quot;B cells: MS4A1&quot;) p2 &lt;- plotTSNE(sce, by_exprs_values = &quot;reconstructed&quot;, colour_by = &quot;CD79A&quot;) + ggtitle(&quot;B cells: CD79A&quot;) gridExtra::grid.arrange(p1, p2, ncol=2) rm(p1, p2) p1 &lt;- plotExpression(sce, exprs_values = &quot;reconstructed&quot;, x=cluToUse, colour_by=cluToUse, features= &quot;MS4A1&quot;) + ggtitle(&quot;B cells&quot;) p2 &lt;- plotExpression(sce, exprs_values = &quot;reconstructed&quot;, x=cluToUse, colour_by=cluToUse, features= &quot;CD79A&quot;) + ggtitle(&quot;B cells&quot;) gridExtra::grid.arrange(p1, p2, ncol=2) rm(p1, p2) We now show the distribution of expression levels for marker genes of other PBMC types. #markGenes &lt;- c(&quot;IL7R&quot;, &quot;CCR7&quot;, &quot;S100A4&quot;, &quot;CD14&quot;, &quot;LYZ&quot;, &quot;MS4A1&quot;, &quot;CD8A&quot;, &quot;FCGR3A&quot;, &quot;MS4A7&quot;, &quot;GNLY&quot;, &quot;NKG7&quot;, &quot;FCER1A&quot;, &quot;CST3&quot;, &quot;PPBP&quot;) markGenesFull &lt;- list( &quot;Naive CD4+ T cells&quot;=c(&quot;IL7R&quot;, &quot;CCR7&quot;), &quot;Memory CD4+ T cells&quot;=c(&quot;IL7R&quot;, &quot;S100A4&quot;), &quot;B cells&quot;=c(&quot;MS4A1&quot;), &quot;CD8+ T cells&quot;=c(&quot;CD8A&quot;), &quot;NK cells&quot;=c(&quot;GNLY&quot;, &quot;NKG7&quot;), &quot;CD14+ Monocytes&quot;=c(&quot;CD14&quot;, &quot;LYZ&quot;), &quot;FCGR3A+ Monocytes&quot;=c(&quot;FCGR3A&quot;, &quot;MS4A7&quot;), &quot;Dendritic Cells&quot;=c(&quot;FCER1A&quot;, &quot;CST3&quot;), &quot;Platelets&quot;=c(&quot;PPBP&quot;) ) markGenesAvail &lt;- lapply(markGenesFull, function(x){ x[x %in% rownames(sce)] }) plotExpression2 &lt;- function(sce, ctx, markGenesAvail) { if(length(markGenesAvail[[ctx]])&gt;0) { plotExpression(sce, exprs_values = &quot;reconstructed&quot;, x=cluToUse, colour_by=cluToUse, features=markGenesAvail[[ctx]]) + ggtitle(ctx) } } # Naive CD4+ T ctx &lt;- &quot;Naive CD4+ T cells&quot; plotExpression2(sce, ctx, markGenesAvail) # Memory CD4+ ctx &lt;- &quot;Memory CD4+ T cells&quot; plotExpression2(sce, ctx, markGenesAvail) # B cells ##plotExpression(sce, exprs_values = &quot;reconstructed&quot;, x=cluToUse, colour_by=cluToUse, features=markGenes[6]) + ggtitle(&quot;B cells&quot;) ctx &lt;- &quot;B cells&quot; plotExpression2(sce, ctx, markGenesAvail) # CD8+ T ctx &lt;- &quot;CD8+ T cells&quot; plotExpression2(sce, ctx, markGenesAvail) # NK ctx &lt;- &quot;NK cells&quot; plotExpression2(sce, ctx, markGenesAvail) # CD14+ Mono ctx &lt;- &quot;CD14+ Monocytes&quot; plotExpression2(sce, ctx, markGenesAvail) # FCGR3A+ Mono ctx &lt;- &quot;FCGR3A+ Monocytes&quot; plotExpression2(sce, ctx, markGenesAvail) # DC ctx &lt;- &quot;Dendritic Cells&quot; plotExpression2(sce, ctx, markGenesAvail) # Platelet ctx &lt;- &quot;Platelets&quot; plotExpression2(sce, ctx, markGenesAvail) 20.5 Save data Write SCE object to file. #tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_clustered.Rds&quot;, tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_clust.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1_clust.Rds&quot; saveRDS(sce, file=tmpFn) 20.6 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] pheatmap_1.0.12 reticulate_1.18 ## [3] NbClust_3.0 purrr_0.3.4 ## [5] tidyr_1.1.3 tibble_3.1.1 ## [7] broom_0.7.6 Cairo_1.5-12.2 ## [9] leiden_0.3.7 igraph_1.2.6 ## [11] cluster_2.1.2 dynamicTreeCut_1.63-1 ## [13] dplyr_1.0.5 scran_1.18.7 ## [15] scater_1.18.6 SingleCellExperiment_1.12.0 ## [17] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [19] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [21] IRanges_2.24.1 S4Vectors_0.28.1 ## [23] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [25] matrixStats_0.58.0 ggplot2_3.3.3 ## [27] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 RColorBrewer_1.1-2 ## [3] backports_1.2.1 tools_4.0.3 ## [5] bslib_0.2.4 utf8_1.2.1 ## [7] R6_2.5.0 irlba_2.3.3 ## [9] vipor_0.4.5 DBI_1.1.1 ## [11] colorspace_2.0-0 withr_2.4.2 ## [13] tidyselect_1.1.1 gridExtra_2.3 ## [15] compiler_4.0.3 cli_2.4.0 ## [17] BiocNeighbors_1.8.2 DelayedArray_0.16.3 ## [19] labeling_0.4.2 bookdown_0.22 ## [21] sass_0.3.1 scales_1.1.1 ## [23] rappdirs_0.3.3 stringr_1.4.0 ## [25] digest_0.6.27 rmarkdown_2.7 ## [27] XVector_0.30.0 pkgconfig_2.0.3 ## [29] htmltools_0.5.1.1 sparseMatrixStats_1.2.1 ## [31] highr_0.9 limma_3.46.0 ## [33] rlang_0.4.10 rstudioapi_0.13 ## [35] DelayedMatrixStats_1.12.3 farver_2.1.0 ## [37] jquerylib_0.1.3 generics_0.1.0 ## [39] jsonlite_1.7.2 mclust_5.4.7 ## [41] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [43] magrittr_2.0.1 BiocSingular_1.6.0 ## [45] GenomeInfoDbData_1.2.4 scuttle_1.0.4 ## [47] Matrix_1.3-2 Rcpp_1.0.6 ## [49] ggbeeswarm_0.6.0 munsell_0.5.0 ## [51] fansi_0.4.2 viridis_0.6.0 ## [53] lifecycle_1.0.0 stringi_1.5.3 ## [55] yaml_2.2.1 edgeR_3.32.1 ## [57] zlibbioc_1.36.0 grid_4.0.3 ## [59] dqrng_0.3.0 crayon_1.4.1 ## [61] lattice_0.20-44 cowplot_1.1.1 ## [63] beachmat_2.6.4 locfit_1.5-9.4 ## [65] ps_1.6.0 pillar_1.6.0 ## [67] codetools_0.2-18 glue_1.4.2 ## [69] evaluate_0.14 vctrs_0.3.7 ## [71] gtable_0.3.0 assertthat_0.2.1 ## [73] xfun_0.22 rsvd_1.0.5 ## [75] viridisLite_0.4.0 beeswarm_0.3.1 ## [77] bluster_1.0.0 statmod_1.4.35 ## [79] ellipsis_0.3.2 "],["cluster-marker-genes.html", "Chapter 21 Cluster marker genes 21.1 Learning objectives 21.2 Load data 21.3 Detecting genes differentially expressed between clusters 21.4 Using the log-fold change 21.5 Finding cluster-specific markers 21.6 Using the Wilcoxon rank sum test 21.7 Using a binomial test 21.8 Combining multiple marker statistics 21.9 Invalidity of p-values 21.10 Session information", " Chapter 21 Cluster marker genes if(interactive()) { paramsToUse &lt;- params2 } else { paramsToUse &lt;- params } projDir &lt;- paramsToUse$projDir dirRel &lt;- paramsToUse$dirRel outDirBit &lt;- paramsToUse$outDirBit cacheBool &lt;- paramsToUse$cacheBool setName &lt;- paramsToUse$setName splSetToGet &lt;- paramsToUse$splSetToGet setSuf &lt;- paramsToUse$setSuf dsiSuf &lt;- paramsToUse$dsiSuf # &#39;dsi&#39; for data set integration if(paramsToUse$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;PBMMC,ETV6-RUNX1&quot; setSuf &lt;- &quot;_5hCellPerSpl&quot; dsiSuf &lt;- &#39;_dsi&#39; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 library(ggplot2) library(scater) library(scran) library(dplyr) library(RColorBrewer) library(pheatmap) library(Cairo) library(glue) fontsize &lt;- theme(axis.text=element_text(size=12), axis.title=element_text(size=16)) Source: we will follow the OSCA chapter on marker detection (with some of its text copied here with little modification). See also the Hemberg group chapter on differential analysis section. To interpret our clustering results, we identify the genes that drive separation between clusters. These marker genes allow us to assign biological meaning to each cluster based on their functional annotation. In the most obvious case, the marker genes for each cluster are a priori associated with particular cell types, allowing us to treat the clustering as a proxy for cell type identity. The same principle can be applied to discover more subtle differences between clusters (e.g., changes in activation or differentiation state) based on the behavior of genes in the affected pathways. Identification of marker genes is usually based around the retrospective detection of differential expression between clusters. Genes that are more strongly DE are more likely to have caused separate clustering of cells in the first place. Several different statistical tests are available to quantify the differences in expression profiles, and different approaches can be used to consolidate test results into a single ranking of genes for each cluster. 21.1 Learning objectives identify genes that differentially expressed between clusters, exclusively or not, using different methods that test: the mean expression level, the whole distribution, or the proportion of cells expressing the gene compile a summary table. 21.2 Load data We will load the R file keeping the SCE (SingleCellExperiment) object with the outcome of the clustering performed after feature selection and dimensionality reduction of the normalised counts for 500 cells per sample. # read uncorrected counts fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_uncorr.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2) # &#39;dsi&#39; for data set integration uncorrected &lt;- readRDS(file=fn) # Read object in: #tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_clustered.Rds&quot;, projDir, outDirBit, setName, setSuf) #tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_clust.Rds&quot;, # projDir, outDirBit, setName, setSuf) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_clust.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1_clust.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } mnn.out &lt;- readRDS(tmpFn) rm(tmpFn) mnn.out &lt;- runUMAP(mnn.out, dimred=&quot;corrected&quot;) # copy clustering output to uncorrected SCE sce &lt;- uncorrected x &lt;- colData(mnn.out)[,c(&quot;Barcode&quot;,&quot;leiden&quot;)] %&gt;% data.frame() colData(sce) &lt;- colData(uncorrected) %&gt;% data.frame() %&gt;% dplyr::left_join(x, by=&quot;Barcode&quot;) %&gt;% DataFrame colData(sce)$cluster &lt;- colData(sce)$leiden sce$clusterStg &lt;- factor(paste0(&quot;c&quot;, sce$cluster), levels = paste0(&quot;c&quot;, levels(sce$cluster))) rm(uncorrected) Number of cells: . Number of genes: 16629. 21.3 Detecting genes differentially expressed between clusters The TSNE plots below show the structure observed with and without data set integration Cells colored by cluster: tsney &lt;- plotTSNE(mnn.out, colour_by=&quot;leiden&quot;) + fontsize tsnex &lt;- plotTSNE(sce, colour_by=&quot;clusterStg&quot;) + fontsize gridExtra::grid.arrange(tsney, tsnex, ncol=2) Cells colored by sample name: p1 &lt;- plotTSNE(mnn.out, colour_by=&quot;Sample.Name&quot;) + fontsize p2 &lt;- plotTSNE(sce, colour_by=&quot;Sample.Name&quot;) + fontsize gridExtra::grid.arrange(p1, p2, ncol=2) rm(p1, p2) The UMAP plots below show the structure observed with and without data set integration: Cells colored by cluster: umapy &lt;- plotUMAP(mnn.out, colour_by=&quot;leiden&quot;) + fontsize umapx &lt;- plotUMAP(sce, colour_by=&quot;clusterStg&quot;) + fontsize gridExtra::grid.arrange(umapy, umapx, ncol=2) Cells colored by sample name: p1 &lt;- plotUMAP(mnn.out, colour_by=&quot;Sample.Name&quot;) + fontsize p2 &lt;- plotUMAP(sce, colour_by=&quot;Sample.Name&quot;) + fontsize gridExtra::grid.arrange(p1, p2, ncol=2) rm(p1, p2) 21.3.1 Differential expression analysis For each cluster, we will identify genes whose expression differ to that of other clusters, for each pair of cluster, using scran::findMarkers(). The function fits a linear model to the log-expression values for each gene using limma (???) and allows testing for differential expression in each cluster compared to the others while accounting for known, uninteresting factors. We will first identify genes whose average expression differ between clusters, using the Welch t-test (default) with a log-fold change threshold of 0 (default) and ranking genes based on the outcome of any of the pairwise comparisons (default). # Clusters called with igraph::cluster_walktrap() are named with digits. # We add a &#39;c&#39; prefix (for-cluster) to avoid any confusion: these values are labels, not numerical values # run scran::findMarkers() # with default parameters for now # check the function&#39;s manual for details (?scran::findMarkers) # (the test.type and pval.type options are covered below) markersWoBatch &lt;- findMarkers(x=sce, groups=sce$clusterStg) markersWiBatch &lt;- findMarkers(x=sce, groups=sce$clusterStg, block=sce$block, #direction=&quot;up&quot;, #lfc=1, row.data=rowData(sce)[, #c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), , drop=FALSE]) # A cell type of some sort: demo &lt;- markersWiBatch[[&quot;c4&quot;]] as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;)]) ## Symbol Top p.value FDR ## ENSG00000117632 STMN1 1 1.079294e-262 3.589517e-259 ## ENSG00000123416 TUBA1B 1 7.555766e-241 1.794926e-237 ## ENSG00000124795 DEK 1 6.490005e-99 1.254910e-96 ## ENSG00000164104 HMGB2 1 7.316822e-200 7.604465e-197 ## ENSG00000177954 RPS27 1 1.667516e-299 1.386456e-295 ## ENSG00000189403 HMGB1 1 5.448322e-223 7.550012e-220 ## ENSG00000244734 HBB 1 0.000000e+00 0.000000e+00 ## ENSG00000124766 SOX4 2 7.604466e-77 9.802688e-75 ## ENSG00000196230 TUBB 2 1.605728e-235 3.337707e-232 ## ENSG00000206172 HBA1 2 4.353300e-288 2.413034e-284 ## ENSG00000128322 IGLL1 3 2.129167e-89 3.505536e-87 ## ENSG00000188536 HBA2 3 1.114332e-285 4.632558e-282 ## ENSG00000128218 VPREB3 4 8.331210e-124 2.613956e-121 ## ENSG00000164032 H2AFZ 4 5.890852e-158 3.377896e-155 ## ENSG00000169877 AHSP 4 1.610936e-241 4.464710e-238 ## ENSG00000272398 CD24 4 2.185315e-112 5.118254e-110 ## ENSG00000087086 FTL 5 1.168331e-117 3.184947e-115 ## ENSG00000122026 RPL21 5 2.077203e-231 3.837980e-228 ## ENSG00000166710 B2M 5 1.080283e-207 1.197602e-204 ## ENSG00000196549 MME 5 3.392406e-67 3.318371e-65 featx &lt;- demo[1,&quot;ensembl_gene_id&quot;] featy &lt;- demo %&gt;% data.frame %&gt;% filter(ensembl_gene_id == featx) %&gt;% pull(&quot;Symbol&quot;) plotExpression(sce, x=I(factor(sce$clusterStg)), features=featx, # &quot;ENSG00000007312&quot;, colour_by=&quot;block&quot;) + facet_wrap(~colour_by) + ggtitle(glue(&#39;{featx} aka {featy}&#39;)) markers &lt;- markersWiBatch Results are compiled in a single table per cluster that stores the outcome of comparisons against the other clusters. One can then select differentially expressed genes from each pairwise comparison between clusters. We will define a set of genes for cluster 1 by selecting the top 10 genes of each comparison, and check the test output, eg adjusted p-values and log-fold changes. clux &lt;- &quot;c1&quot; # get output table for cluster of interest: marker.set &lt;- markers[[clux]] head(marker.set, 3) ## DataFrame with 3 rows and 23 columns ## ensembl_gene_id external_gene_name chromosome_name ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000123416 ENSG00000123416 TUBA1B 12 ## ENSG00000124766 ENSG00000124766 SOX4 6 ## ENSG00000128218 ENSG00000128218 VPREB3 22 ## start_position end_position strandNum Symbol ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;character&gt; ## ENSG00000123416 49127782 49131397 -1 TUBA1B ## ENSG00000124766 21593751 21598619 1 SOX4 ## ENSG00000128218 23752743 23754425 -1 VPREB3 ## Type mean detected gene_sparsity Top ## &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;integer&gt; ## ENSG00000123416 Gene Expression 6.13696 55.0540 0.331165 1 ## ENSG00000124766 Gene Expression 2.45547 40.8965 0.387268 1 ## ENSG00000128218 Gene Expression 1.11073 28.6456 0.547111 1 ## p.value FDR summary.logFC logFC.c2 logFC.c3 ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000123416 1.65043e-162 2.28708e-159 -1.91797 0.719778 0.3009426 ## ENSG00000124766 3.84668e-90 1.16302e-87 1.36547 1.077273 0.3147620 ## ENSG00000128218 8.91659e-183 2.47123e-179 1.33706 1.337060 0.0150614 ## logFC.c4 logFC.c5 logFC.c6 logFC.c7 logFC.c8 logFC.c9 ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000123416 -1.917974 -0.468056 -0.0390704 0.577349 0.676016 0.375056 ## ENSG00000124766 0.404482 1.192600 0.7622680 1.234901 1.264353 1.365467 ## ENSG00000128218 0.174119 1.081052 0.7889714 0.714617 1.302928 1.162344 # add gene annotation: ##tmpDf &lt;- marker.set ##tmpDf$ensembl_gene_id &lt;- rownames(tmpDf) ##tmpDf2 &lt;- base::merge(tmpDf, rowData(sce), by=&quot;ensembl_gene_id&quot;, all.x=TRUE, all.y=F, sort=F) Write table to file: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_%s.tsv&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2, clux) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1_c1.tsv&quot; write.table(marker.set, file=tmpFn, sep=&quot;\\t&quot;, quote=FALSE, row.names=FALSE) rm(tmpFn) Show expression of marker on t-SNE and UMAP: mrkSet &lt;- marker.set %&gt;% data.frame() %&gt;% filter(Symbol %in% rowData(mnn.out)$Symbol) %&gt;% arrange(FDR) geneInd &lt;- 2 geneEns &lt;- mrkSet[geneInd,&quot;ensembl_gene_id&quot;] geneExt &lt;- mrkSet[geneInd,&quot;external_gene_name&quot;] # external_gene_name ~ Symbol #tsne1 &lt;- plotTSNE(sce, colour_by=mrkSet[geneInd,&quot;ensembl_gene_id&quot;]) + fontsize tsne1 &lt;- plotTSNE(sce, colour_by=geneEns) + fontsize + scale_color_continuous(type = &#39;viridis&#39;, guide = guide_legend(title = geneExt)) umap1 &lt;- plotUMAP(sce, colour_by=geneEns) + fontsize + scale_color_continuous(type = &#39;viridis&#39;, guide = guide_legend(title = geneExt)) tsne1b &lt;- plotTSNE(mnn.out, colour_by=geneExt, by_exprs_values = &quot;reconstructed&quot;) + fontsize umap1b &lt;- plotUMAP(mnn.out, colour_by=mrkSet[geneInd,&quot;Symbol&quot;], by_exprs_values = &quot;reconstructed&quot;) + fontsize Expresion levels of ENSG00000244734 aka HBB: plotExpression(sce, x=I(factor(sce$clusterStg)), features=geneEns, # &quot;ENSG00000007312&quot;, colour_by=&quot;block&quot;) + facet_wrap(~colour_by) + ggtitle(glue(&#39;{geneEns} aka {geneExt}&#39;)) Without data set integration (sce) #tsne1 #umap1 gridExtra::grid.arrange(tsne1, umap1, ncol=2) With data set integration (mnn.out): #tsne1b #umap1b gridExtra::grid.arrange(tsne1b, umap1b, ncol=2) With data integration (mnn.out), TSNE with leiden clusters and HBB levels: gridExtra::grid.arrange(tsney, tsne1b, ncol=2) Without data integration (sce), TSNE with leiden clusters and HBB levels: gridExtra::grid.arrange(tsnex, tsne1, ncol=2) With data integration (mnn.out), UMAP with leiden clusters and HBB levels: gridExtra::grid.arrange(umapy, umap1b, ncol=2) Without data integration (sce), UMAP with leiden clusters and HBB levels: gridExtra::grid.arrange(umapx, umap1, ncol=2) rm(tsne1, tsne1b, umap1, umap1b) rm(tsnex, tsney, umapx, umapy) Gene set enrichment analyses used for bulk RNA-seq may be used to characterise clusters further. 21.3.2 Heatmap As for bulk RNA, differences in expression profiles of the top genes can be visualised with a heatmap. Normalised counts: # select some top genes: top.markers &lt;- rownames(marker.set)[marker.set$Top &lt;= 10] # have matrix to annotate sample with cluster and sample: tmpData &lt;- logcounts(sce)[top.markers,] # concat sample and barcode names to make unique name across the whole data set tmpCellNames &lt;- paste(colData(sce)$Sample.Name, colData(sce)$Barcode, sep=&quot;_&quot;) # use these to namecolumn of matrix the show as heatmap: colnames(tmpData) &lt;- tmpCellNames # colData(sce)$Barcode # columns annotation with cell name: mat_col &lt;- data.frame(cluster = sce$cluster, sample = sce$Sample.Name, type = sce$source_name ) rownames(mat_col) &lt;- colnames(tmpData) rownames(mat_col) &lt;- tmpCellNames # colData(sce)$Barcode # Prepare colours for clusters: colourCount = length(unique(sce$cluster)) getPalette = colorRampPalette(brewer.pal(9, &quot;Set1&quot;)) mat_colors &lt;- list(group = getPalette(colourCount)) names(mat_colors$group) &lt;- unique(sce$cluster) breaksVec = seq(-5, 5, by = 0.1) # plot heatmap: pheatmap(tmpData, border_color = NA, show_colnames = FALSE, #show_rownames = FALSE, show_rownames = TRUE, drop_levels = TRUE, labels_row = rowData(sce)[rownames(tmpData),&quot;Symbol&quot;], annotation_col = mat_col, annotation_colors = mat_colors, color = colorRampPalette( rev(brewer.pal(n = 7, name = &quot;RdYlBu&quot;)))(length(breaksVec)), breaks = breaksVec, fontsize_row = 7 ) # remove MALAT1 tmpData2 &lt;- tmpData %&gt;% as.matrix() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;ensId&quot;) %&gt;% filter(ensId != &quot;ENSG00000251562&quot;) %&gt;% tibble::column_to_rownames(&quot;ensId&quot;) colnames(tmpData2) &lt;- gsub(&quot;\\\\.&quot;, &quot;-&quot;, colnames(tmpData2)) pheatmap(tmpData2, border_color = NA, show_colnames = FALSE, #show_rownames = FALSE, show_rownames = TRUE, drop_levels = TRUE, labels_row = rowData(sce)[rownames(tmpData2),&quot;Symbol&quot;], annotation_col = mat_col, annotation_colors = mat_colors, color = colorRampPalette( rev(brewer.pal(n = 7, name = &quot;RdYlBu&quot;)))(length(breaksVec)), breaks = breaksVec, fontsize_row = 7 ) rm(tmpData2) library(dendsort) mat &lt;- tmpData mat_cluster_cols &lt;- hclust(dist(t(mat))) sort_hclust &lt;- function(...) as.hclust(dendsort(as.dendrogram(...))) mat_cluster_cols &lt;- sort_hclust(mat_cluster_cols) #plot(mat_cluster_cols, main = &quot;Sorted Dendrogram&quot;, xlab = &quot;&quot;, sub = &quot;&quot;) mat_cluster_rows &lt;- sort_hclust(hclust(dist(mat))) rm(mat) pheatmap(tmpData, border_color = NA, show_colnames = FALSE, show_rownames = FALSE, drop_levels = TRUE, annotation_col = mat_col, annotation_colors = mat_colors, cluster_cols = mat_cluster_cols, cluster_rows = mat_cluster_rows ) Counts corrected for batch effect (‘corrected’): # select some top genes: #top.markers &lt;- rownames(marker.set)[marker.set$Top &lt;= 10] top.markers &lt;- marker.set[marker.set$Top &lt;= 10,] %&gt;% data.frame() %&gt;% pull(Symbol) # have matrix to annotate sample with cluster and sample: tmpData3 &lt;- assay(mnn.out) %&gt;% as.matrix() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Symbol&quot;) %&gt;% filter(Symbol %in% top.markers) %&gt;% tibble::column_to_rownames(&quot;Symbol&quot;) colnames(tmpData3) &lt;- colData(mnn.out)$Barcode colnames(tmpData3) &lt;- gsub(&quot;\\\\.&quot;, &quot;-&quot;, colnames(tmpData3)) # concat sample and barcode names to make unique name across the whole data set tmpCellNames &lt;- paste(colData(mnn.out)$Sample.Name, colData(mnn.out)$Barcode, sep=&quot;_&quot;) # use these to name columns of matrix the show as heatmap: colnames(tmpData3) &lt;- tmpCellNames # colData(sce)$Barcode # columns annotation with cell name: mat_col &lt;- data.frame(cluster = sce$cluster, sample = sce$Sample.Name, type = sce$source_name ) rownames(mat_col) &lt;- colnames(tmpData) rownames(mat_col) &lt;- tmpCellNames # colData(sce)$Barcode # Prepare colours for clusters: colourCount = length(unique(sce$cluster)) getPalette = colorRampPalette(brewer.pal(9, &quot;Set1&quot;)) mat_colors &lt;- list(group = getPalette(colourCount)) names(mat_colors$group) &lt;- unique(sce$cluster) # plot heatmap: pheatmap(tmpData3[,order(colData(sce)$clusterStg)], border_color = NA, show_colnames = FALSE, #show_rownames = FALSE, show_rownames = TRUE, drop_levels = TRUE, labels_row = rowData(sce)[rownames(tmpData),&quot;Symbol&quot;], annotation_col = mat_col, annotation_colors = mat_colors, cluster_cols = FALSE, fontsize_row = 7 ) rm(tmpData3) rm(mnn.out, tmpData) To demonstrate how to interpret the results, we will use cluster 9 as our cluster of interest. The relevant DataFrame contains log2-fold changes of expression in cluster 9 over each other cluster, along with several statistics obtained by combining p-values (Simes 1986) across the pairwise comparisons involving cluster 9. chosen &lt;- &quot;c9&quot; interesting &lt;- markers[[chosen]] print(colnames(interesting)) ## [1] &quot;ensembl_gene_id&quot; &quot;external_gene_name&quot; &quot;chromosome_name&quot; ## [4] &quot;start_position&quot; &quot;end_position&quot; &quot;strandNum&quot; ## [7] &quot;Symbol&quot; &quot;Type&quot; &quot;mean&quot; ## [10] &quot;detected&quot; &quot;gene_sparsity&quot; &quot;Top&quot; ## [13] &quot;p.value&quot; &quot;FDR&quot; &quot;summary.logFC&quot; ## [16] &quot;logFC.c1&quot; &quot;logFC.c2&quot; &quot;logFC.c3&quot; ## [19] &quot;logFC.c4&quot; &quot;logFC.c5&quot; &quot;logFC.c6&quot; ## [22] &quot;logFC.c7&quot; &quot;logFC.c8&quot; Of particular interest is the Top field. The set of genes with Top ≤X is the union of the top X genes (ranked by p-value) from each pairwise comparison involving cluster 9. For example, the set of all genes with Top values of 1 contains the gene with the lowest p-value from each comparison. Similarly, the set of genes with Top values less than or equal to 10 contains the top 10 genes from each comparison. The Top field represents findMarkers()’s approach to consolidating multiple pairwise comparisons into a single ranking for each cluster; each DataFrame produced by findMarkers() will order genes based on the Top value by default. interesting.coluToShow &lt;- c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;) interesting[1:10,interesting.coluToShow] ## DataFrame with 10 rows and 4 columns ## Symbol Top FDR summary.logFC ## &lt;character&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000090013 BLVRB 1 5.73724e-151 -4.045409 ## ENSG00000124766 SOX4 1 7.99580e-87 -1.365467 ## ENSG00000124795 DEK 1 1.79870e-95 -1.053542 ## ENSG00000156738 MS4A1 1 4.06226e-41 -1.557764 ## ENSG00000204482 LST1 1 3.17916e-52 -1.154475 ## ENSG00000227507 LTB 1 1.52234e-81 -1.419390 ## ENSG00000271503 CCL5 1 5.71426e-27 -2.236276 ## ENSG00000004939 SLC4A1 2 1.49020e-122 -3.175878 ## ENSG00000082074 FYB1 2 4.57767e-74 -0.882386 ## ENSG00000105374 NKG7 2 2.62740e-26 -2.054456 We use the Top field to identify a set of genes that is guaranteed to distinguish cluster 9 from any other cluster. Here, we examine the top 6 genes from each pairwise comparison. best.set &lt;- interesting[interesting$Top &lt;= 6,] logFCs &lt;- getMarkerEffects(best.set) logFCs.ens &lt;- rownames(logFCs) rownames(logFCs) &lt;- rowData(sce)[rownames(logFCs), &quot;Symbol&quot;] library(pheatmap) pheatmap(logFCs, breaks=seq(-5, 5, length.out=101)) 21.4 Using the log-fold change Our previous findMarkers() call considers both up- and downregulated genes to be potential markers. However, downregulated genes are less appealing as markers as it is more difficult to interpret and experimentally validate an absence of expression. To focus on up-regulated markers, we can instead perform a one-sided t-test to identify genes that are upregulated in each cluster compared to the others. This is achieved by setting direction=“up” in the findMarkers() call. markersWoBatch.up &lt;- findMarkers(sce, groups = sce$clusterStg, direction = &quot;up&quot;) markersWiBatch.up &lt;- findMarkers(x = sce, groups = sce$clusterStg, block = sce$block, direction = &quot;up&quot;, #lfc=1, row.data = rowData(sce)[, #c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), , drop=FALSE]) markers.up &lt;- markersWiBatch.up interesting.up &lt;- markers.up[[chosen]] interesting.up[1:10,interesting.coluToShow] ## DataFrame with 10 rows and 4 columns ## Symbol Top FDR summary.logFC ## &lt;character&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000051523 CYBA 1 1.46243e-09 2.10059 ## ENSG00000113387 SUB1 1 2.70422e-09 2.12860 ## ENSG00000137818 RPLP1 1 2.70422e-09 1.62362 ## ENSG00000166710 B2M 1 2.68397e-08 1.84380 ## ENSG00000140988 RPS2 2 6.10877e-09 1.36627 ## ENSG00000166562 SEC11C 2 7.40121e-08 2.01498 ## ENSG00000170476 MZB1 3 2.69120e-07 3.31396 ## ENSG00000180879 SSR4 3 1.75120e-07 2.50935 ## ENSG00000234745 HLA-B 3 4.35316e-08 1.89577 ## ENSG00000172183 ISG20 4 7.19818e-07 1.35939 The t-test also allows us to specify a non-zero log-fold change as the null hypothesis. This allows us to consider the magnitude of the log-fold change in our p-value calculations, in a manner that is more rigorous than simply filtering directly on the log-fold changes (McCarthy and Smyth 2009). (Specifically, a simple threshold does not consider the variance and can enrich for genes that have both large log-fold changes and large variances.) We perform this by setting lfc= in our findMarkers() call - when combined with direction=, this tests for genes with log-fold changes that are significantly greater than 1: markersWoBatch.up2 &lt;- findMarkers(sce, groups=sce$clusterStg, direction=&quot;up&quot;, lfc=1) markersWiBatch.up2 &lt;- findMarkers(x=sce, groups=sce$clusterStg, block=sce$block, direction=&quot;up&quot;, #lfc=1, row.data=rowData(sce)[, #c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), , drop=FALSE]) markers.up2 &lt;- markersWiBatch.up2 interesting.up2 &lt;- markers.up2[[chosen]] interesting.up2[1:10,interesting.coluToShow] ## DataFrame with 10 rows and 4 columns ## Symbol Top FDR summary.logFC ## &lt;character&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000051523 CYBA 1 1.46243e-09 2.10059 ## ENSG00000113387 SUB1 1 2.70422e-09 2.12860 ## ENSG00000137818 RPLP1 1 2.70422e-09 1.62362 ## ENSG00000166710 B2M 1 2.68397e-08 1.84380 ## ENSG00000140988 RPS2 2 6.10877e-09 1.36627 ## ENSG00000166562 SEC11C 2 7.40121e-08 2.01498 ## ENSG00000170476 MZB1 3 2.69120e-07 3.31396 ## ENSG00000180879 SSR4 3 1.75120e-07 2.50935 ## ENSG00000234745 HLA-B 3 4.35316e-08 1.89577 ## ENSG00000172183 ISG20 4 7.19818e-07 1.35939 These two settings yield a more focused set of candidate marker genes that are upregulated in cluster 9. best.set &lt;- interesting.up2[interesting.up2$Top &lt;= 5,] logFCs &lt;- getMarkerEffects(best.set) logFCs.ens &lt;- rownames(logFCs) rownames(logFCs) &lt;- rowData(sce)[rownames(logFCs), &quot;Symbol&quot;] library(pheatmap) pheatmap(logFCs, breaks=seq(-5, 5, length.out=101)) Of course, this increased stringency is not without cost. If only upregulated genes are requested from findMarkers(), any cluster defined by downregulation of a marker gene will not contain that gene among the top set of features in its DataFrame. This is occasionally relevant for subtypes or other states that are distinguished by high versus low expression of particular genes. Similarly, setting an excessively high log-fold change threshold may discard otherwise useful genes. For example, a gene upregulated in a small proportion of cells of a cluster will have a small log-fold change but can still be an effective marker if the focus is on specificity rather than sensitivity. 21.5 Finding cluster-specific markers By default, findMarkers() will give a high ranking to genes that are differentially expressed in any pairwise comparison. This is because a gene only needs a very low p -value in a single pairwise comparison to achieve a low Top value. A more stringent approach would only consider genes that are differentially expressed in all pairwise comparisons involving the cluster of interest. To achieve this, we set pval.type=“all” in findMarkers() to use an intersection-union test (Berger and Hsu 1996) where the combined p-value for each gene is the maximum of the p-values from all pairwise comparisons. A gene will only achieve a low combined p-value if it is strongly DE in all comparisons to other clusters. # We can combine this with &#39;direction=&#39;. markersWoBatch.up3 &lt;- findMarkers(sce, groups=sce$clusterStg, pval.type=&quot;all&quot;, direction=&quot;up&quot;) markersWiBatch.up3 &lt;- findMarkers(x=sce, groups=sce$clusterStg, block=sce$block, pval.type=&quot;all&quot;, direction=&quot;up&quot;, #lfc=1, row.data=rowData(sce)[, #c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), , drop=FALSE]) markers.up3 &lt;- markersWiBatch.up3 interesting.up3 &lt;- markers.up3[[chosen]] interesting.colu &lt;- intersect(interesting.coluToShow, colnames(interesting.up3)) interesting.up3[1:10,interesting.colu] ## DataFrame with 10 rows and 3 columns ## Symbol FDR summary.logFC ## &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000113387 SUB1 2.59042e-07 1.88802 ## ENSG00000166562 SEC11C 2.59042e-07 1.91824 ## ENSG00000180879 SSR4 2.38922e-06 2.37547 ## ENSG00000132465 JCHAIN 4.57138e-06 4.96266 ## ENSG00000134285 FKBP11 2.35844e-05 1.71931 ## ENSG00000048462 TNFRSF17 2.35844e-05 1.60136 ## ENSG00000166794 PPIB 2.35844e-05 1.87611 ## ENSG00000170476 MZB1 2.35844e-05 2.31249 ## ENSG00000166598 HSP90B1 2.72866e-05 1.96988 ## ENSG00000106803 SEC61B 1.64771e-04 1.20282 This strategy will only report genes that are highly specific to the cluster of interest. When it works, it can be highly effective as it generates a small focused set of candidate markers. However, any gene that is expressed at the same level in two or more clusters will simply not be detected. This is likely to discard many interesting genes, especially if the clusters are finely resolved with weak separation. To give a concrete example, consider a mixed population of CD4+-only, CD8+-only, double-positive and double-negative T cells. With pval.type=“all”, neither Cd4 or Cd8 would be detected as subpopulation-specific markers because each gene is expressed in two subpopulations. In comparison, pval.type=“any” will detect both of these genes as they will be DE between at least one pair of subpopulations. If pval.type=“all” is too stringent yet pval.type=“any” is too generous, a compromise is to set pval.type=“some”. For each gene, we apply the Holm-Bonferroni correction across its p -values and take the middle-most value as the combined p-value. This effectively tests the global null hypothesis that at least 50% of the individual pairwise comparisons exhibit no DE. We then rank the genes by their combined p-values to obtain an ordered set of marker candidates. The aim is to improve the conciseness of the top markers for defining a cluster while mitigating the risk of discarding useful genes that are not DE to all other clusters. The downside is that taking this compromise position sacrifices the theoretical guarantees offered at the other two extremes. markersWoBatch.up4 &lt;- findMarkers(sce, groups=sce$clusterStg, pval.type=&quot;some&quot;, direction=&quot;up&quot;) markersWiBatch.up4 &lt;- findMarkers(x=sce, groups=sce$clusterStg, block=sce$block, pval.type=&quot;some&quot;, direction=&quot;up&quot;, #lfc=1, row.data=rowData(sce)[, #c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), , drop=FALSE]) markers.up4 &lt;- markersWiBatch.up4 interesting.up4 &lt;- markers.up4[[chosen]] interesting.colu &lt;- intersect(interesting.coluToShow, colnames(interesting.up4)) interesting.up4[1:10,interesting.colu] ## DataFrame with 10 rows and 3 columns ## Symbol FDR summary.logFC ## &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000113387 SUB1 5.95797e-08 2.02728 ## ENSG00000051523 CYBA 3.93001e-07 1.76665 ## ENSG00000166562 SEC11C 6.15867e-07 1.95627 ## ENSG00000180879 SSR4 9.31346e-07 2.60317 ## ENSG00000170476 MZB1 1.43640e-06 2.74844 ## ENSG00000132465 JCHAIN 5.53928e-06 5.41802 ## ENSG00000166598 HSP90B1 2.03107e-05 2.13393 ## ENSG00000166794 PPIB 2.03107e-05 1.87550 ## ENSG00000172183 ISG20 2.03107e-05 1.12174 ## ENSG00000134285 FKBP11 2.44952e-05 1.91535 In both cases, a different method is used to compute the summary effect size compared to pval.type=“any”. For pval.type=“all”, the summary log-fold change is defined as that corresponding to the pairwise comparison with the largest p-value, while for pval.type=“some”, it is defined as the log-fold change for the comparison with the middle-most p-value. This reflects the calculation of the combined p-value and avoids focusing on genes with strong changes in only one comparison. 21.6 Using the Wilcoxon rank sum test The Wilcoxon rank sum test (also known as the Wilcoxon-Mann-Whitney test, or WMW test) is another widely used method for pairwise comparisons between groups of observations. Its strength lies in the fact that it directly assesses separation between the expression distributions of different clusters. The WMW test statistic is proportional to the area-under-the-curve (AUC), i.e., the concordance probability, which is the probability of a random cell from one cluster having higher expression than a random cell from another cluster. In a pairwise comparison, AUCs of 1 or 0 indicate that the two clusters have perfectly separated expression distributions. Thus, the WMW test directly addresses the most desirable property of a candidate marker gene, while the t-test only does so indirectly via the difference in the means and the intra-group variance. We perform WMW tests by again using the findMarkers() function, this time with test=“wilcox”. This returns a list of DataFrames containing ranked candidate markers for each cluster. The direction=, lfc= and pval.type= arguments can be specified and have the same interpretation as described for t-tests. We demonstrate below by detecting upregulated genes in each cluster with direction=“up”. markers.wmw &lt;- findMarkers(sce, groups=sce$clusterStg, test=&quot;wilcox&quot;, direction=&quot;up&quot;) markersWiBatch.wmw &lt;- findMarkers(x=sce, groups=sce$clusterStg, block=sce$block, test=&quot;wilcox&quot;, direction=&quot;up&quot;, row.data=rowData(sce)[, #c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), , drop=FALSE]) markers.wmw &lt;- markersWiBatch.wmw #print(names(markers.wmw)) To explore the results in more detail, we focus on the DataFrame for cluster 9. The interpretation of Top is the same as described for t-tests, and Simes’ method is again used to combine p-values across pairwise comparisons. If we want more focused sets, we can also change pval.type= as previously described. interesting.coluToShow &lt;- c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;FDR&quot;, &quot;summary.AUC&quot;) interesting.wmw &lt;- markers.wmw[[chosen]] interesting.wmw[1:10,interesting.coluToShow] ## DataFrame with 10 rows and 4 columns ## Symbol Top FDR summary.AUC ## &lt;character&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000048462 TNFRSF17 1 3.68222e-123 0.996267 ## ENSG00000134285 FKBP11 1 9.56095e-83 0.966667 ## ENSG00000254709 IGLL5 1 5.05036e-161 0.979676 ## ENSG00000070081 NUCB2 2 1.49469e-26 0.925664 ## ENSG00000099958 DERL3 2 1.30411e-84 0.917676 ## ENSG00000110777 POU2AF1 2 3.24097e-68 0.888594 ## ENSG00000138185 ENTPD1 2 1.22295e-133 0.895064 ## ENSG00000165272 AQP3 2 3.14631e-107 0.972418 ## ENSG00000103811 CTSH 3 2.08541e-73 0.851989 ## ENSG00000124772 CPNE5 3 4.73626e-63 0.788544 The DataFrame contains the AUCs from comparing cluster 9 to every other cluster. A value greater than 0.5 indicates that the gene is upregulated in the current cluster compared to the other cluster, while values less than 0.5 correspond to downregulation. We would typically expect AUCs of 0.7-0.8 for a strongly upregulated candidate marker. best.set &lt;- interesting.wmw[interesting.wmw$Top &lt;= 5,] AUCs &lt;- getMarkerEffects(best.set, prefix=&quot;AUC&quot;) AUCs.ens &lt;- rownames(AUCs) rownames(AUCs) &lt;- rowData(sce)[rownames(AUCs), &quot;Symbol&quot;] library(pheatmap) pheatmap(AUCs, breaks = seq(0, 1, length.out=21), color = viridis::viridis(21)) One practical advantage of the WMW test over the Welch t-test is that it is symmetric with respect to differences in the size of the groups being compared. This means that, all else being equal, the top-ranked genes on each side of a DE comparison will have similar expression profiles regardless of the number of cells in each group. In contrast, the t-test will favor genes where the larger group has the higher relative variance as this increases the estimated degrees of freedom and decreases the resulting p-value. This can lead to unappealing rankings when the aim is to identify genes upregulated in smaller groups. The WMW test is not completely immune to variance effects - for example, it will slightly favor detection of DEGs at low average abundance where the greater number of ties at zero deflates the approximate variance of the rank sum statistic - but this is relatively benign as the selected genes are still fairly interesting. print(head(sce$clusterStg)) type1 &lt;- &quot;c1&quot; #type2 &lt;- &quot;c10&quot; type2 &lt;- levels(sce$clusterStg)[nlevels(sce$clusterStg)] marker.t &lt;- findMarkers(sce, groups=sce$clusterStg, direction=&quot;up&quot;, block=sce$block, restrict=c(type1, type2), row.data=rowData(sce)[, c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), drop=FALSE]) marker.w &lt;- findMarkers(sce, groups=sce$clusterStg, direction=&quot;up&quot;, block=sce$block, restrict=c(type1, type2), test.type=&quot;wilcox&quot;, row.data=rowData(sce)[, c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), drop=FALSE] ) # Upregulated in type 1: marker.type1.t &lt;- marker.t[[type1]] marker.type1.w &lt;- marker.w[[type1]] chosen.type1.t &lt;- rownames(marker.type1.t)[1:30] chosen.type1.w &lt;- rownames(marker.type1.w)[1:30] u.type1.t &lt;- setdiff(chosen.type1.t, chosen.type1.w) u.type1.w &lt;- setdiff(chosen.type1.w, chosen.type1.t) # Upregulated in gamma: marker.type2.t &lt;- marker.t[[type2]] marker.type2.w &lt;- marker.w[[type2]] chosen.type2.t &lt;- rownames(marker.type2.t)[1:30] chosen.type2.w &lt;- rownames(marker.type2.w)[1:30] u.type2.t &lt;- setdiff(chosen.type2.t, chosen.type2.w) u.type2.w &lt;- setdiff(chosen.type2.w, chosen.type2.t) u.type1.t &lt;- u.type1.t[1:min(4,length(u.type1.t))] u.type1.w &lt;- u.type1.w[1:min(4,length(u.type1.w))] u.type2.t &lt;- u.type2.t[1:min(4,length(u.type2.t))] u.type2.w &lt;- u.type2.w[1:min(4,length(u.type2.w))] u.type1.t marker.type1.t[,] %&gt;% data.frame() %&gt;% filter(ensembl_gene_id %in% u.type1.t) ## Symbol ensembl_gene_id Top p.value FDR ## ENSG00000242574 HLA-DMB ENSG00000242574 4 7.999069e-43 3.325413e-39 ## ENSG00000066923 STAG3 ENSG00000066923 5 2.123082e-40 7.060948e-37 ## ENSG00000164330 EBF1 ENSG00000164330 6 1.970585e-39 5.461476e-36 ## ENSG00000124795 DEK ENSG00000124795 7 1.384151e-38 3.288151e-35 ## summary.logFC logFC.c9 ## ENSG00000242574 0.3230307 0.3230307 ## ENSG00000066923 0.3309251 0.3309251 ## ENSG00000164330 0.4874803 0.4874803 ## ENSG00000124795 0.4620890 0.4620890 u.type1.w marker.type1.w[,] %&gt;% data.frame() %&gt;% filter(ensembl_gene_id %in% u.type1.w) ## Symbol ensembl_gene_id Top p.value FDR ## ENSG00000204287 HLA-DRA ENSG00000204287 1 1.981116e-06 0.03294397 ## ENSG00000117632 STMN1 ENSG00000117632 2 2.729759e-05 0.09106999 ## ENSG00000223865 HLA-DPB1 ENSG00000223865 3 3.244727e-05 0.09106999 ## ENSG00000019582 CD74 ENSG00000019582 4 3.474180e-05 0.09106999 ## summary.AUC AUC.c9 ## ENSG00000204287 0.9933637 0.9933637 ## ENSG00000117632 0.9321858 0.9321858 ## ENSG00000223865 0.9299046 0.9299046 ## ENSG00000019582 0.9311489 0.9311489 u.type2.t marker.type2.t[,] %&gt;% data.frame() %&gt;% filter(ensembl_gene_id %in% u.type2.t) ## Symbol ensembl_gene_id Top p.value FDR ## ENSG00000051523 CYBA ENSG00000051523 1 9.320325e-13 1.257556e-08 ## ENSG00000113387 SUB1 ENSG00000113387 2 1.512485e-12 1.257556e-08 ## ENSG00000166562 SEC11C ENSG00000166562 3 6.632282e-12 3.676274e-08 ## ENSG00000180879 SSR4 ENSG00000180879 4 1.053099e-11 4.377998e-08 ## summary.logFC logFC.c1 ## ENSG00000051523 1.680844 1.680844 ## ENSG00000113387 2.107369 2.107369 ## ENSG00000166562 2.014979 2.014979 ## ENSG00000180879 2.509347 2.509347 u.type2.w marker.type2.w[,] %&gt;% data.frame() %&gt;% filter(ensembl_gene_id %in% u.type2.w) ## Symbol ensembl_gene_id Top p.value FDR ## ENSG00000254709 IGLL5 ENSG00000254709 1 3.796350e-166 6.312951e-162 ## ENSG00000138185 ENTPD1 ENSG00000138185 2 2.757867e-138 1.528685e-134 ## ENSG00000240505 TNFRSF13B ENSG00000240505 3 2.757867e-138 1.528685e-134 ## ENSG00000211890 IGHA2 ENSG00000211890 5 8.148131e-116 2.709905e-112 ## summary.AUC AUC.c1 ## ENSG00000254709 0.9796765 0.9796765 ## ENSG00000138185 0.8950643 0.8950643 ## ENSG00000240505 0.8950643 0.8950643 ## ENSG00000211890 0.8947532 0.8947532 # Examining all uniquely detected markers in each direction. library(scater) subset &lt;- sce[,sce$clusterStg %in% c(type1, type2)] gridExtra::grid.arrange( plotExpression(subset, x=&quot;clusterStg&quot;, features=u.type1.t, ncol=2) + ggtitle(sprintf(&quot;Upregulated in %s, t-test-only&quot;, type1)), plotExpression(subset, x=&quot;clusterStg&quot;, features=u.type1.w, ncol=2) + ggtitle(sprintf(&quot;Upregulated in %s, WMW-test-only&quot;, type1)), plotExpression(subset, x=&quot;clusterStg&quot;, features=u.type2.t, ncol=2) + ggtitle(sprintf(&quot;Upregulated in %s, t-test-only&quot;, type2)), plotExpression(subset, x=&quot;clusterStg&quot;, features=u.type2.w, ncol=2) + ggtitle(sprintf(&quot;Upregulated in %s, WMW-test-only&quot;, type2)), ncol=2 ) rm(u.type1.t, u.type1.w, u.type2.t, u.type2.w) The main disadvantage of the WMW test is that the AUCs are much slower to compute compared to t-statistics. This may be inconvenient for interactive analyses involving multiple iterations of marker detection. We can mitigate this to some extent by parallelizing these calculations using the BPPARAM= argument in findMarkers(). 21.7 Using a binomial test The binomial test identifies genes that differ in the proportion of expressing cells between clusters. (For the purposes of this section, a cell is considered to express a gene simply if it has non-zero expression for that gene.) This represents a much more stringent definition of marker genes compared to the other methods, as differences in expression between clusters are effectively ignored if both distributions of expression values are not near zero. The premise is that genes are more likely to contribute to important biological decisions if they were active in one cluster and silent in another, compared to more subtle “tuning” effects from changing the expression of an active gene. From a practical perspective, a binary measure of presence/absence is easier to validate. We perform pairwise binomial tests between clusters using the findMarkers() function with test=“binom”. This returns a list of DataFrames containing marker statistics for each cluster such as the Top rank and its p-value. Here, the effect size is reported as the log-fold change in this proportion between each pair of clusters. Large positive log-fold changes indicate that the gene is more frequently expressed in one cluster compared to the other. We focus on genes that are upregulated in each cluster compared to the others by setting direction=“up”. markersWoBatch.binom &lt;- findMarkers(sce, test=&quot;binom&quot;, direction=&quot;up&quot;, groups=sce$clusterStg) markersWiBatch.binom &lt;- findMarkers(x=sce, groups=sce$clusterStg, block=sce$block, test=&quot;binom&quot;, direction=&quot;up&quot;, row.data=rowData(sce)[, #c(&quot;Symbol&quot;, &quot;ensembl_gene_id&quot;), , drop=FALSE]) markers.binom &lt;- markersWiBatch.binom print(names(markers.binom)) ## [1] &quot;c1&quot; &quot;c2&quot; &quot;c3&quot; &quot;c4&quot; &quot;c5&quot; &quot;c6&quot; &quot;c7&quot; &quot;c8&quot; &quot;c9&quot; interesting.binom &lt;- markers.binom[[chosen]] print(colnames(interesting.binom)) ## [1] &quot;ensembl_gene_id&quot; &quot;external_gene_name&quot; &quot;chromosome_name&quot; ## [4] &quot;start_position&quot; &quot;end_position&quot; &quot;strandNum&quot; ## [7] &quot;Symbol&quot; &quot;Type&quot; &quot;mean&quot; ## [10] &quot;detected&quot; &quot;gene_sparsity&quot; &quot;Top&quot; ## [13] &quot;p.value&quot; &quot;FDR&quot; &quot;summary.logFC&quot; ## [16] &quot;logFC.c1&quot; &quot;logFC.c2&quot; &quot;logFC.c3&quot; ## [19] &quot;logFC.c4&quot; &quot;logFC.c5&quot; &quot;logFC.c6&quot; ## [22] &quot;logFC.c7&quot; &quot;logFC.c8&quot; The plot below confirms that the top genes exhibit strong differences in the proportion of expressing cells in cluster 9 compared to the others. top.genes &lt;- head(rownames(interesting.binom)) #plotExpression(sce, x=&quot;clusterStg&quot;, features=top.genes) plotExpression(sce, x=&quot;clusterStg&quot;, colour_by=&quot;clusterStg&quot;, features=top.genes[1:4] ) plotExpression(sce, x=&quot;clusterStg&quot;, colour_by=&quot;clusterStg&quot;, features=top.genes[1] ) plotExpression(sce, x=&quot;clusterStg&quot;, colour_by=&quot;clusterStg&quot;, features=top.genes[2] ) plotExpression(sce, x=&quot;clusterStg&quot;, colour_by=&quot;clusterStg&quot;, features=top.genes[3] ) plotExpression(sce, x=&quot;clusterStg&quot;, colour_by=&quot;clusterStg&quot;, features=top.genes[4] ) 21.8 Combining multiple marker statistics On occasion, we might want to combine marker statistics from several testing regimes into a single DataFrame. This allows us to easily inspect multiple statistics at once to verify that a particular gene is a strong candidate marker. For example, a large AUC from the WMW test indicates that the expression distributions are well-separated between clusters, while the log-fold change reported with the t-test provides a more interpretable measure of the magnitude of the change in expression. We use the multiMarkerStats() to merge the results of separate findMarkers() calls into one DataFrame per cluster, with statistics interleaved to facilitate a direct comparison between different test regimes. combined &lt;- multiMarkerStats( t=findMarkers(sce, groups=sce$clusterStg, direction=&quot;up&quot;), wilcox=findMarkers(sce, groups=sce$clusterStg, test=&quot;wilcox&quot;, direction=&quot;up&quot;), binom=findMarkers(sce, groups=sce$clusterStg, test=&quot;binom&quot;, direction=&quot;up&quot;) ) combined &lt;- multiMarkerStats( t=findMarkers(sce, groups=sce$clusterStg, direction=&quot;up&quot;, block=sce$block), wilcox=findMarkers(sce, groups=sce$clusterStg, test=&quot;wilcox&quot;, direction=&quot;up&quot;, block=sce$block), binom=findMarkers(sce, groups=sce$clusterStg, test=&quot;binom&quot;, direction=&quot;up&quot;, block=sce$block) ) # Interleaved marker statistics from both tests for each cluster. print(colnames(combined[[&quot;c1&quot;]])) ## [1] &quot;Top&quot; &quot;p.value&quot; &quot;FDR&quot; ## [4] &quot;t.Top&quot; &quot;wilcox.Top&quot; &quot;binom.Top&quot; ## [7] &quot;t.p.value&quot; &quot;wilcox.p.value&quot; &quot;binom.p.value&quot; ## [10] &quot;t.FDR&quot; &quot;wilcox.FDR&quot; &quot;binom.FDR&quot; ## [13] &quot;t.summary.logFC&quot; &quot;wilcox.summary.AUC&quot; &quot;binom.summary.logFC&quot; ## [16] &quot;t.logFC.c2&quot; &quot;wilcox.AUC.c2&quot; &quot;binom.logFC.c2&quot; ## [19] &quot;t.logFC.c3&quot; &quot;wilcox.AUC.c3&quot; &quot;binom.logFC.c3&quot; ## [22] &quot;t.logFC.c4&quot; &quot;wilcox.AUC.c4&quot; &quot;binom.logFC.c4&quot; ## [25] &quot;t.logFC.c5&quot; &quot;wilcox.AUC.c5&quot; &quot;binom.logFC.c5&quot; ## [28] &quot;t.logFC.c6&quot; &quot;wilcox.AUC.c6&quot; &quot;binom.logFC.c6&quot; ## [31] &quot;t.logFC.c7&quot; &quot;wilcox.AUC.c7&quot; &quot;binom.logFC.c7&quot; ## [34] &quot;t.logFC.c8&quot; &quot;wilcox.AUC.c8&quot; &quot;binom.logFC.c8&quot; ## [37] &quot;t.logFC.c9&quot; &quot;wilcox.AUC.c9&quot; &quot;binom.logFC.c9&quot; #head(combined[[&quot;c1&quot;]][,1:9]) combined[[&quot;c1&quot;]]$Symbol &lt;- rowData(sce)[rownames(combined[[&quot;c1&quot;]]), &quot;Symbol&quot;] tmpCol &lt;- c(&quot;Symbol&quot;, colnames(combined[[&quot;c1&quot;]])[1:9]) head(combined[[&quot;c1&quot;]][,tmpCol]) ## DataFrame with 6 rows and 10 columns ## Symbol Top p.value FDR t.Top ## &lt;character&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;integer&gt; ## ENSG00000124766 SOX4 3 1.49550e-41 1.18422e-38 1 ## ENSG00000128218 VPREB3 4 6.04516e-64 1.00525e-59 1 ## ENSG00000231389 HLA-DPA1 4 3.20211e-53 1.77493e-49 1 ## ENSG00000198771 RCSD1 5 8.91780e-43 8.23856e-40 5 ## ENSG00000276043 UHRF1 6 1.16106e-45 1.37909e-42 1 ## ENSG00000196549 MME 6 4.77191e-49 8.81690e-46 2 ## wilcox.Top binom.Top t.p.value wilcox.p.value binom.p.value ## &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000124766 3 1 1.92334e-90 5.72384e-56 1.49550e-41 ## ENSG00000128218 4 1 4.45829e-183 1.59904e-79 6.04516e-64 ## ENSG00000231389 3 4 5.19868e-214 5.18703e-90 3.20211e-53 ## ENSG00000198771 2 1 2.47346e-90 1.43745e-67 8.91780e-43 ## ENSG00000276043 6 1 1.76876e-139 6.69601e-56 1.16106e-45 ## ENSG00000196549 6 2 8.20175e-139 3.72890e-58 4.77191e-49 rm(sce) In addition, multiMarkerStats() will compute a number of new statistics by combining the per-regime statistics. The combined Top value is obtained by simply taking the largest Top value across all tests for a given gene, while the reported p.value is obtained by taking the largest p-value. Ranking on either metric focuses on genes with robust differences that are highly ranked and detected by each of the individual testing regimes. Of course, this might be considered an overly conservative approach in practice, so it is entirely permissible to re-rank the DataFrame according to the Top or p.value for an individual regime (effectively limiting the use of the other regimes’ statistics to diagnostics only). Write list to file: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_clustMarkCombi.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1_clustMarkCombi.Rds&quot; saveRDS(combined, file=tmpFn) rm(combined,tmpFn) 21.9 Invalidity of p-values 21.9.1 From data snooping All of our DE strategies for detecting marker genes between clusters are statistically flawed to some extent. The DE analysis is performed on the same data used to obtain the clusters, which represents “data dredging” (also known as fishing or data snooping). The hypothesis of interest - are there differences between clusters? - is formulated from the data, so we are more likely to get a positive result when we re-use the data set to test that hypothesis. The practical effect of data dredging is best illustrated with a simple simulation. We simulate i.i.d. normal values, perform k-means clustering and test for DE between clusters of cells with findMarkers(). The resulting distribution of p-values is heavily skewed towards low values. Thus, we can detect “significant” differences between clusters even in the absence of any real substructure in the data. This effect arises from the fact that clustering, by definition, yields groups of cells that are separated in expression space. Testing for DE genes between clusters will inevitably yield some significant results as that is how the clusters were defined. Distribution of \\(p\\)-values from a DE analysis between two clusters in a simulation with no true subpopulation structure: library(scran) set.seed(0) y &lt;- matrix(rnorm(100000), ncol=200) clusters &lt;- kmeans(t(y), centers=2)$cluster out &lt;- findMarkers(y, clusters) hist(out[[1]]$p.value, col=&quot;grey80&quot;, xlab=&quot;p-value&quot;) For marker gene detection, this effect is largely harmless as the p-values are used only for ranking. However, it becomes an issue when the p-values are used to define “significant differences” between clusters with respect to an error rate threshold. Meaningful interpretation of error rates require consideration of the long-run behavior, i.e., the rate of incorrect rejections if the experiment were repeated many times. The concept of statistical significance for differences between clusters is not applicable if clusters and their interpretations are not stably reproducible across (hypothetical) replicate experiments. 21.9.2 Nature of replication The naive application of DE analysis methods will treat counts from the same cluster of cells as replicate observations. This is not the most relevant level of replication when cells are derived from the same biological sample (i.e., cell culture, animal or patient). DE analyses that treat cells as replicates fail to properly model the sample-to-sample variability (Lun and Marioni 2017). The latter is arguably the more important level of replication as different samples will necessarily be generated if the experiment is to be replicated. Indeed, the use of cells as replicates only masks the fact that the sample size is actually one in an experiment involving a single biological sample. This reinforces the inappropriateness of using the marker gene p-values to perform statistical inference. “We strongly recommend selecting some markers for use in validation studies with an independent replicate population of cells. A typical strategy is to identify a corresponding subset of cells that express the upregulated markers and do not express the downregulated markers. Ideally, a different technique for quantifying expression would also be used during validation, e.g., fluorescent in situ hybridisation or quantitative PCR. This confirms that the subpopulation genuinely exists and is not an artifact of the scRNA-seq protocol or the computational analysis.” See the OSCA chapter on Marker gene detection Challenge Identify markers for a different cluster and try to identify the cell type. 21.10 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] glue_1.4.2 Cairo_1.5-12.2 ## [3] pheatmap_1.0.12 RColorBrewer_1.1-2 ## [5] dplyr_1.0.5 scran_1.18.7 ## [7] scater_1.18.6 SingleCellExperiment_1.12.0 ## [9] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [11] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [13] IRanges_2.24.1 S4Vectors_0.28.1 ## [15] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [17] matrixStats_0.58.0 ggplot2_3.3.3 ## [19] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 tools_4.0.3 ## [3] bslib_0.2.4 utf8_1.2.1 ## [5] R6_2.5.0 irlba_2.3.3 ## [7] vipor_0.4.5 DBI_1.1.1 ## [9] colorspace_2.0-0 withr_2.4.2 ## [11] tidyselect_1.1.1 gridExtra_2.3 ## [13] compiler_4.0.3 BiocNeighbors_1.8.2 ## [15] DelayedArray_0.16.3 labeling_0.4.2 ## [17] bookdown_0.22 sass_0.3.1 ## [19] scales_1.1.1 stringr_1.4.0 ## [21] digest_0.6.27 rmarkdown_2.7 ## [23] XVector_0.30.0 pkgconfig_2.0.3 ## [25] htmltools_0.5.1.1 sparseMatrixStats_1.2.1 ## [27] limma_3.46.0 highr_0.9 ## [29] rlang_0.4.10 DelayedMatrixStats_1.12.3 ## [31] jquerylib_0.1.3 generics_0.1.0 ## [33] farver_2.1.0 jsonlite_1.7.2 ## [35] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [37] magrittr_2.0.1 BiocSingular_1.6.0 ## [39] GenomeInfoDbData_1.2.4 scuttle_1.0.4 ## [41] Matrix_1.3-2 Rcpp_1.0.6 ## [43] ggbeeswarm_0.6.0 munsell_0.5.0 ## [45] fansi_0.4.2 viridis_0.6.0 ## [47] lifecycle_1.0.0 stringi_1.5.3 ## [49] yaml_2.2.1 edgeR_3.32.1 ## [51] zlibbioc_1.36.0 grid_4.0.3 ## [53] dqrng_0.3.0 crayon_1.4.1 ## [55] lattice_0.20-44 cowplot_1.1.1 ## [57] beachmat_2.6.4 locfit_1.5-9.4 ## [59] pillar_1.6.0 igraph_1.2.6 ## [61] codetools_0.2-18 evaluate_0.14 ## [63] vctrs_0.3.7 gtable_0.3.0 ## [65] purrr_0.3.4 assertthat_0.2.1 ## [67] xfun_0.22 rsvd_1.0.5 ## [69] viridisLite_0.4.0 tibble_3.1.1 ## [71] beeswarm_0.3.1 bluster_1.0.0 ## [73] statmod_1.4.35 ellipsis_0.3.2 projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool splSetToGet &lt;- params$splSetToGet setName &lt;- params$setName setSuf &lt;- params$setSuf dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;PBMMC,ETV6-RUNX1&quot; setSuf &lt;- &quot;_5hCellPerSpl&quot; dsiSuf &lt;- &#39;_dsi&#39; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 library(ggplot2) library(scater) library(scran) library(dplyr) library(Cairo) fontsize &lt;- theme(axis.text=element_text(size=12), axis.title=element_text(size=16)) "],["cellCyclePhasesTop.html", "Chapter 22 Cell cycle assignment 22.1 Load data 22.2 Motivation 22.3 Using the cyclins 22.4 Using the cyclone() classifier 22.5 Regressing out cell cycle phase 22.6 Session information", " Chapter 22 Cell cycle assignment Source: Cell cycle assignment of the OSCA book. 22.1 Load data We will load the R file keeping the SCE object with the normalised counts for 500 cells per sample. # read uncorrected counts fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_uncorr.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, # &#39;dsi&#39; for data set integration splSetToGet2) uncorrected &lt;- readRDS(file=fn) # Read object in: #tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_clust.Rds&quot;, # projDir, outDirBit, setName, setSuf) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_clust.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1_clust.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } mnn.out &lt;- readRDS(tmpFn) mnn.out &lt;- runUMAP(mnn.out, dimred=&quot;corrected&quot;) mnn.out ## class: SingleCellExperiment ## dim: 7930 3500 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(7930): FGR GCLC ... AC139491.7 AC003043.2 ## rowData names(12): rotation ensembl_gene_id ... detected gene_sparsity ## colnames: NULL ## colData names(25): Barcode Run ... cluster.out.10 cluster.out.10.col ## reducedDimNames(3): corrected TSNE UMAP ## altExpNames(0): # copy clustering output to uncorrected SCE sce &lt;- uncorrected x &lt;- colData(mnn.out)[,c(&quot;Barcode&quot;,&quot;leiden&quot;)] %&gt;% data.frame() colData(sce) &lt;- colData(uncorrected) %&gt;% data.frame() %&gt;% dplyr::left_join(x, by=&quot;Barcode&quot;) %&gt;% DataFrame colData(sce)$cluster &lt;- colData(sce)$leiden sce$clusterStg &lt;- factor(paste0(&quot;c&quot;, sce$cluster), levels = paste0(&quot;c&quot;, levels(sce$cluster))) rm(uncorrected) 22.2 Motivation On occasion, it can be desirable to determine cell cycle activity from scRNA-seq data. In and of itself, the distribution of cells across phases of the cell cycle is not usually informative, but we can use this to determine if there are differences in proliferation between subpopulations or across treatment conditions. Many of the key events in the cell cycle (e.g., passage through checkpoints) are post-translational and thus not directly visible in transcriptomic data; nonetheless, there are enough changes in expression that can be exploited to determine cell cycle phase. 22.3 Using the cyclins The cyclins control progression through the cell cycle and have well-characterized patterns of expression across cell cycle phases. Cyclin D is expressed throughout but peaks at G1; cyclin E is expressed highest in the G1/S transition; cyclin A is expressed across S and G2; and cyclin B is expressed highest in late G2 and mitosis. Inspection of the relative expression of cyclins across the population can often be sufficient to determine the relative cell cycle activity in each cluster. We the table below lists the 10 most variables cyclin genes. cyclin.genes &lt;- grep(&quot;^CCN[ABDE]+&quot;, rowData(sce)$Symbol) cyclin.genes &lt;- rownames(sce)[cyclin.genes] #rowData(sce)[cyclin.genes,] # only use the 10 most variable cyclins: require(DelayedArray) tmpVar &lt;- DelayedMatrixStats::rowVars( DelayedArray(assay(sce[cyclin.genes,], &quot;logcounts&quot;))) names(tmpVar) &lt;- cyclin.genes cyclin.genes.sub &lt;- names(tmpVar[order(tmpVar, decreasing=T)])[1:10] rowData(sce)[cyclin.genes.sub,c(&quot;ensembl_gene_id&quot;, &quot;Symbol&quot;)] ## DataFrame with 10 rows and 2 columns ## ensembl_gene_id Symbol ## &lt;character&gt; &lt;character&gt; ## ENSG00000166946 ENSG00000166946 CCNDBP1 ## ENSG00000112576 ENSG00000112576 CCND3 ## ENSG00000134057 ENSG00000134057 CCNB1 ## ENSG00000157456 ENSG00000157456 CCNB2 ## ENSG00000118971 ENSG00000118971 CCND2 ## ENSG00000100814 ENSG00000100814 CCNB1IP1 ## ENSG00000145386 ENSG00000145386 CCNA2 ## ENSG00000105173 ENSG00000105173 CCNE1 ## ENSG00000175305 ENSG00000175305 CCNE2 ## ENSG00000110092 ENSG00000110092 CCND1 Heatmap showing expression levels measured as normalised counts: plotHeatmap(sce, order_columns_by=&quot;clusterStg&quot;, colour_columns_by=c(&quot;clusterStg&quot;, &quot;Sample.Name&quot;, &quot;source_name&quot;), cluster_rows=TRUE, features=sort(cyclin.genes.sub)) With the gene expression levels reconstructed after batch correction with fastMNN: top.markers &lt;- rowData(sce) %&gt;% data.frame() %&gt;% filter(ensembl_gene_id %in% cyclin.genes.sub) %&gt;% pull(Symbol) # have matrix to annotate sample with cluster and sample: #tmpData &lt;- logcounts(sce)[top.markers,] tmpData3 &lt;- assay(mnn.out) %&gt;% as.matrix() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Symbol&quot;) %&gt;% filter(Symbol %in% top.markers) %&gt;% tibble::column_to_rownames(&quot;Symbol&quot;) colnames(tmpData3) &lt;- colData(mnn.out)$Barcode colnames(tmpData3) &lt;- gsub(&quot;\\\\.&quot;, &quot;-&quot;, colnames(mnn.out)) # concat sample and barcode names to make unique name across the whole data set tmpCellNames &lt;- paste(colData(mnn.out)$Sample.Name, colData(mnn.out)$Barcode, sep=&quot;_&quot;) # use these to name columns of matrix the show as heatmap: colnames(tmpData3) &lt;- tmpCellNames # colData(sce)$Barcode # columns annotation with cell name: mat_col &lt;- data.frame(cluster = sce$cluster, sample = sce$Sample.Name, type = sce$source_name ) rownames(mat_col) &lt;- colnames(tmpData3) rownames(mat_col) &lt;- tmpCellNames # colData(sce)$Barcode # Prepare colours for clusters: colourCount = length(unique(sce$cluster)) getPalette = colorRampPalette(RColorBrewer::brewer.pal(9, &quot;Set1&quot;)) mat_colors &lt;- list(group = getPalette(colourCount)) names(mat_colors$group) &lt;- unique(sce$cluster) # plot heatmap: #pheatmap(tmpData3, pheatmap::pheatmap(tmpData3[,order(colData(sce)$clusterStg)], border_color = NA, show_colnames = FALSE, #show_rownames = FALSE, show_rownames = TRUE, drop_levels = TRUE, annotation_col = mat_col, annotation_colors = mat_colors, cluster_cols = FALSE ) For example, we can use standard DE methods to look for upregulation of each cyclin, which would imply that a subpopulation contains more cells in the corresponding cell cycle phase. The same logic applies to comparisons between treatment conditions. library(scran) markers &lt;- findMarkers(sce, groups=sce$clusterStg, subset.row=cyclin.genes, test.type=&quot;wilcox&quot;, block=sce$block, direction=&quot;up&quot;) # We can infer that cluster 4 or 6 has more cells in G2/M than the other clusters, # based on higher expression of the cyclin B&#39;s. markers[[4]] %&gt;% data.frame() %&gt;% #markers[[6]] %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;ensembl_gene_id&quot;) %&gt;% left_join(data.frame(rowData(sce))[, c(&quot;ensembl_gene_id&quot;, &quot;Symbol&quot;)], by=&quot;ensembl_gene_id&quot;) %&gt;% select(Symbol, Top, p.value, FDR, summary.AUC) ## Symbol Top p.value FDR summary.AUC ## 1 CCND3 1 1.869544e-30 5.141247e-30 0.7190648 ## 2 CCNA2 1 8.079867e-57 4.443927e-56 0.6600351 ## 3 CCNB2 1 4.798720e-59 5.278592e-58 0.6947310 ## 4 CCNB1IP1 2 6.860581e-12 1.078091e-11 0.5667133 ## 5 CCNB1 3 2.047976e-40 7.509247e-40 0.6410588 ## 6 CCNE1 4 4.627794e-13 8.484289e-13 0.5498505 ## 7 CCND2 4 1.015642e-05 1.241340e-05 0.5467980 ## 8 CCNE2 4 2.553081e-14 5.616779e-14 0.5498098 ## 9 CCNDBP1 7 2.785746e-08 3.830400e-08 0.5701041 ## 10 CCND1 9 1.000000e+00 1.000000e+00 0.4980599 ## 11 CCNA1 11 1.000000e+00 1.000000e+00 0.5015083 Direct examination of cyclin expression is easily to understand, interpret and experimentally validate. However, it is best suited for statements about relative cell cycle activity; for example, we would find it difficult to assign cell cycle phase without the presence of clusters spanning all phases to provide benchmarks for “high” and “low” expression of each cyclin. We also assume that cyclin expression is not affected by biological processes other than the cell cycle, which may be a strong assumption in some cases, e.g., malignant cells. This strategy is strongly dependent on having good sequencing coverage of the cyclins, which is less of an issue for the whole-of-transcriptome methods described below that use information from more genes. 22.4 Using the cyclone() classifier The prediction method described by Scialdone et al. (2015) is another approach for classifying cells into cell cycle phases. Using a reference dataset, we first compute the sign of the difference in expression between each pair of genes. Pairs with changes in the sign across cell cycle phases are chosen as markers. Cells in a test dataset can then be classified into the appropriate phase, based on whether the observed sign for each marker pair is consistent with one phase or another. This approach is implemented in the cyclone() function from the scran package, which also contains pre-trained set of marker pairs for mouse and human data. set.seed(100) library(scran) hs.pairs &lt;- readRDS(system.file(&quot;exdata&quot;, &quot;human_cycle_markers.rds&quot;, package=&quot;scran&quot;)) # Using Ensembl IDs to match up with the annotation in &#39;mm.pairs&#39;. assignments &lt;- cyclone(sce, hs.pairs, gene.names=rowData(sce)$ensembl_gene_id) # SLOW, even with 3500 cells only Write assignments to file. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_cyclone.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1_cyclone.Rds&quot; saveRDS(assignments, file=tmpFn) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_cyclone.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1_cyclone.Rds&quot; assignments &lt;- readRDS(file=tmpFn) Copy cell cycle assignments to SCE object: colData(sce)$phases &lt;- assignments$phases For each cell, a higher score for a phase corresponds to a higher probability that the cell is in that phase. We focus on the G1 and G2/M scores as these are the most informative for classification. The plot below show the cell cycle phase scores obtained by applying the pair-based classifier on the dataset. Each point represents a cell, plotted according to its scores for G1 and G2/M phases. #plot(assignments$score$G1, assignments$score$G2M, # xlab=&quot;G1 score&quot;, ylab=&quot;G2/M score&quot;, pch=16) ggplot(assignments$score, aes(x=G1, y=G2M, col=S)) + geom_point() Cells are classified as being in G1 phase if the G1 score is above 0.5 and greater than the G2/M score; in G2/M phase if the G2/M score is above 0.5 and greater than the G1 score; and in S phase if neither score is above 0.5. Contingency table (cell number): colLabels(sce) &lt;- colData(sce)$source_name table(assignments$phases, colLabels(sce)) ## ## ABMMC ETV6-RUNX1 HHD PBMMC PRE-T ## G1 0 1585 0 1075 0 ## G2M 0 114 0 239 0 ## S 0 301 0 186 0 Contingency table (proportions by cell cycle phase): # prop per phase round(proportions(table(assignments$phases, colLabels(sce)),1),2) ## ## ABMMC ETV6-RUNX1 HHD PBMMC PRE-T ## G1 0.00 0.60 0.00 0.40 0.00 ## G2M 0.00 0.32 0.00 0.68 0.00 ## S 0.00 0.62 0.00 0.38 0.00 Contingency table (proportions by sample type): # prop per type round(proportions(table(assignments$phases, colLabels(sce)),2),2) ## ## ABMMC ETV6-RUNX1 HHD PBMMC PRE-T ## G1 0.79 0.72 ## G2M 0.06 0.16 ## S 0.15 0.12 TSNE and UMAP plots obtained without data set integration. TSNE split by sample type: tsne1 &lt;- plotTSNE(sce, colour_by=&quot;phases&quot;) + fontsize tsne1 + facet_wrap(. ~ sce$source_name) TSNE split by cell cycle phase: tsne1 + facet_wrap(. ~ sce$phases) UMAP split by sample type: umap1 &lt;- plotUMAP(sce, colour_by=&quot;phases&quot;) + fontsize umap1 + facet_wrap(. ~ sce$source_name) UMAP split by cell cycle phase: umap1 + facet_wrap(. ~ sce$phases) TSNE and UMAP plots obtained with data set integration. tmpPhases &lt;- colData(sce)$phases names(tmpPhases) &lt;- colData(sce)$Barcode colData(mnn.out)$phases &lt;- tmpPhases[colData(mnn.out)$Barcode] tsne1b &lt;- plotTSNE(mnn.out, colour_by=&quot;phases&quot;, by_exprs_values = &quot;reconstructed&quot;) + fontsize umap1b &lt;- plotUMAP(mnn.out, colour_by=&quot;phases&quot;, by_exprs_values = &quot;reconstructed&quot;) + fontsize TSNE split by cell cycle phase: tsne1b + facet_wrap(. ~ mnn.out$phases) UMAP split by cell cycle phase: umap1b + facet_wrap(. ~ mnn.out$phases) rm(tsne1, tsne1b, umap1, umap1b, mnn.out) Cell cycle phase may also by assigned for each sample separately. The table below compares assigned made above with pooled samples and those obtained for each sample separately: # CaronBourque2020 #cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) #cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) #splVec &lt;- cb_sampleSheet %&gt;% filter(source_name == splSetToGet) %&gt;% # pull(Sample.Name) %&gt;% unique splVec &lt;- unique(colData(sce)$Sample.Name) all.sce &lt;- list() for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } #--- normalization ---# # use logNormCounts() all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# # model varaince with modelGeneVar() # find highly variable genes (HVGs) with getTopHVGs() all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# # use runPCA() # then compute embeddings with runTSNE() and runUMAP() library(BiocSingular) set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) set.seed(100000) all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) set.seed(1000000) all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# # cluster each sample separately for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership #colLabels(all.sce[[n]]) &lt;- factor(clust) all.sce[[n]]$label &lt;- factor(clust) } #--- cyclone ---# hs.pairs &lt;- readRDS(system.file(&quot;exdata&quot;, &quot;human_cycle_markers.rds&quot;, package=&quot;scran&quot;)) for (n in names(all.sce)) { assignments &lt;- cyclone(all.sce[[n]], hs.pairs, gene.names=rowData(all.sce[[n]])$ensembl_gene_id) all.sce[[n]]$phases &lt;- assignments$phases } #lapply(all.sce, function(x){table(colData(x)$phases)}) tmpList &lt;- lapply(all.sce, function(x){ #colData(x)[,c(&quot;Barcode&quot;, &quot;phases&quot;)] data.frame( &quot;Barcode&quot; = colData(x)$Barcode, &quot;phasesBySpl&quot; = colData(x)$phases ) } ) phaseBySpl &lt;- do.call(rbind, tmpList) colData(sce) &lt;- colData(sce) %&gt;% data.frame() %&gt;% left_join(phaseBySpl, by=&quot;Barcode&quot;) %&gt;% DataFrame table(colData(sce)$phases, colData(sce)$phasesBySpl) ## ## G1 G2M S ## G1 2647 5 8 ## G2M 9 341 3 ## S 15 7 465 22.5 Regressing out cell cycle phase For some time, it was popular to regress out the cell cycle phase prior to downstream analyses. The aim was to remove uninteresting variation due to cell cycle, thus improving resolution of other biological processes of interest. We could implement this by performing cell cycle phase assignment as described above, treating each phase as a separate batch and applying any of the batch correction strategies. The most common approach is to use a linear model to simply regress out the phase effect, e.g., via regressBatches(). library(batchelor) sce.nocycle &lt;- regressBatches(sce, batch=sce$phases) # PCA #plotPCA(sce, colour_by = &quot;Sample.Name&quot;) sce.nocycle &lt;- runPCA( sce.nocycle, exprs_values = &quot;corrected&quot; ) p1 &lt;- plotPCA( sce.nocycle, colour_by = &quot;batch&quot; ) + ggtitle(&quot;PCA&quot;) # TSNE sce.nocycle &lt;- runTSNE( sce.nocycle, exprs_values = &quot;corrected&quot;) p2 &lt;- plotTSNE( sce.nocycle, colour_by = &quot;batch&quot; ) + ggtitle(&quot;TSNE&quot;) gridExtra::grid.arrange(p1, p2, ncol=2) That said, we do not consider adjusting for cell cycle to be a necessary step in routine scRNA-seq analyses. In most applications, the cell cycle is a minor factor of variation, secondary to differences between cell types. Any attempt at removal would also need to assume that the cell cycle effect is orthogonal to other biological processes. For example, regression would potentially remove interesting signal if cell cycle activity varied across clusters or conditions, with a prime example being the increased proliferation of activated T cells (Richard et al. 2018). We suggest only performing cell cycle adjustment on an as-needed basis in populations with clear cell cycle effects. Exercise Remove the cell cycle genes listed in the ‘cell cycle’ GO term, perform PCA and plot t-SNE. # 2021-04-14: issue with org.Hs.eg.db, see https://support.bioconductor.org/p/9136239/ library(org.Hs.eg.db) cc.genes &lt;- select(org.Hs.eg.db, keys=&quot;GO:0007049&quot;, keytype=&quot;GOALL&quot;, column=&quot;ENSEMBL&quot;) length(cc.genes) sce.uncycle &lt;- sce[!rowData(sce)$ensembl_gene_id %in% cc.genes$ENSEMBL,] # PCA sce.uncycle &lt;- runPCA( sce.uncycle, exprs_values = &quot;logcounts&quot; ) p &lt;- plotPCA( sce.uncycle, colour_by = &quot;phases&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) p # TSNE sce.uncycle &lt;- runTSNE(sce.uncycle, exprs_values = &quot;logcounts&quot;) p &lt;- plotTSNE( sce.uncycle, colour_by = &quot;phases&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) p # UMAP sce.uncycle &lt;- runUMAP(sce.uncycle, exprs_values = &quot;logcounts&quot;) p &lt;- plotUMAP( sce.uncycle, colour_by = &quot;phases&quot;, size_by = &quot;sum&quot;, shape_by = &quot;source_name&quot; ) p Write SCE object to file. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s%s_%s_cellCycle.Rds&quot;, projDir, outDirBit, setName, setSuf, dsiSuf, splSetToGet2) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_5hCellPerSpl_dsi_PBMMC_ETV6-RUNX1_cellCycle.Rds&quot; saveRDS(sce, file=tmpFn) 22.6 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] batchelor_1.6.3 BiocSingular_1.6.0 ## [3] DelayedArray_0.16.3 Matrix_1.3-2 ## [5] Cairo_1.5-12.2 dplyr_1.0.5 ## [7] scran_1.18.7 scater_1.18.6 ## [9] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [11] Biobase_2.50.0 GenomicRanges_1.42.0 ## [13] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [15] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [17] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [19] ggplot2_3.3.3 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 RColorBrewer_1.1-2 ## [3] tools_4.0.3 bslib_0.2.4 ## [5] utf8_1.2.1 R6_2.5.0 ## [7] irlba_2.3.3 ResidualMatrix_1.0.0 ## [9] vipor_0.4.5 DBI_1.1.1 ## [11] colorspace_2.0-0 withr_2.4.2 ## [13] tidyselect_1.1.1 gridExtra_2.3 ## [15] compiler_4.0.3 BiocNeighbors_1.8.2 ## [17] labeling_0.4.2 bookdown_0.22 ## [19] sass_0.3.1 scales_1.1.1 ## [21] stringr_1.4.0 digest_0.6.27 ## [23] rmarkdown_2.7 XVector_0.30.0 ## [25] pkgconfig_2.0.3 htmltools_0.5.1.1 ## [27] sparseMatrixStats_1.2.1 limma_3.46.0 ## [29] highr_0.9 rlang_0.4.10 ## [31] DelayedMatrixStats_1.12.3 jquerylib_0.1.3 ## [33] generics_0.1.0 farver_2.1.0 ## [35] jsonlite_1.7.2 BiocParallel_1.24.1 ## [37] RCurl_1.98-1.3 magrittr_2.0.1 ## [39] GenomeInfoDbData_1.2.4 scuttle_1.0.4 ## [41] Rcpp_1.0.6 ggbeeswarm_0.6.0 ## [43] munsell_0.5.0 fansi_0.4.2 ## [45] viridis_0.6.0 lifecycle_1.0.0 ## [47] stringi_1.5.3 yaml_2.2.1 ## [49] edgeR_3.32.1 zlibbioc_1.36.0 ## [51] Rtsne_0.15 grid_4.0.3 ## [53] dqrng_0.3.0 crayon_1.4.1 ## [55] lattice_0.20-44 cowplot_1.1.1 ## [57] beachmat_2.6.4 locfit_1.5-9.4 ## [59] pillar_1.6.0 igraph_1.2.6 ## [61] codetools_0.2-18 glue_1.4.2 ## [63] evaluate_0.14 vctrs_0.3.7 ## [65] gtable_0.3.0 purrr_0.3.4 ## [67] assertthat_0.2.1 xfun_0.22 ## [69] rsvd_1.0.5 viridisLite_0.4.0 ## [71] tibble_3.1.1 pheatmap_1.0.12 ## [73] beeswarm_0.3.1 bluster_1.0.0 ## [75] statmod_1.4.35 ellipsis_0.3.2 projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool splSetToGet &lt;- params$splSetToGet setName &lt;- params$setName setSuf &lt;- params$setSuf dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;PBMMC,ETV6-RUNX1&quot; setSuf &lt;- &quot;_5hCps&quot; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 "],["differential-expression-and-abundance-between-conditions.html", "Chapter 23 Differential expression and abundance between conditions 23.1 Motivation 23.2 Setting up the data 23.3 Differential expression between conditions 23.4 Differential abundance between conditions 23.5 Session information", " Chapter 23 Differential expression and abundance between conditions Source: Multi-sample comparisons of the OSCA book. 23.1 Motivation A powerful use of scRNA-seq technology lies in the design of replicated multi-condition experiments to detect changes in composition or expression between conditions. For example, a researcher could use this strategy to detect changes in cell type abundance after drug treatment (Richard et al. 2018) or genetic modifications (Scialdone et al. 2016). This provides more biological insight than conventional scRNA-seq experiments involving only one biological condition, especially if we can relate population changes to specific experimental perturbations. Differential analyses of multi-condition scRNA-seq experiments can be broadly split into two categories - differential expression (DE) and differential abundance (DA) analyses. The former tests for changes in expression between conditions for cells of the same type that are present in both conditions, while the latter tests for changes in the composition of cell types (or states, etc.) between conditions. 23.2 Setting up the data We will use the data set comprising the 11 samples (500 or 1000 cells per sample) analysed with fastMNN and the nested list of samples. The differential analyses in this chapter will be predicated on many of the pre-processing steps covered previously. For brevity, we will not explicitly repeat them here, only noting that we have already merged cells from all samples into the same coordinate system and clustered the merged dataset to obtain a common partitioning across all samples. Load the SCE object: #setName &lt;- &quot;caron&quot; # Read object in: ##setSuf &lt;- &quot;_1kCellPerSpl&quot; ##tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_clustered.Rds&quot;, projDir, outDirBit, setName, setSuf) #setSuf &lt;- &quot;_1kCps&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_Fmwbl.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells_Fmwbl.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 12466 47830 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(12466): ENSG00000000003 ENSG00000000457 ... ENSG00000285476 ## ENSG00000285492 ## rowData names(1): rotation ## colnames: NULL ## colData names(22): Sample Barcode ... type clusters.mnn ## reducedDimNames(2): corrected TSNE ## altExpNames(0): A brief inspection of the results shows clusters contain varying contributions from batches: library(scater) colLabels(sce) &lt;- sce$clusters.mnn tab &lt;- table(colLabels(sce), sce$type) tab ## ## ETV6-RUNX1 HHD PBMMC PRE-T ## c1 3 2 6 904 ## c10 2110 1019 102 21 ## c11 212 7 235 17 ## c12 88 1 6 0 ## c13 385 92 112 17 ## c14 89 2 20 1 ## c15 37 1 143 21 ## c16 59 4 138 14 ## c17 164 3 125 6 ## c18 1745 295 2169 372 ## c19 649 418 65 30 ## c2 5272 2952 190 12 ## c20 125 81 410 548 ## c21 6 1 55 17 ## c22 30 18 318 49 ## c23 38 0 7 0 ## c24 475 206 42 34 ## c25 231 466 141 22 ## c26 1 2 23 1372 ## c27 2 16 85 348 ## c28 5 4 491 89 ## c29 16 2 48 12 ## c3 18 58 76 760 ## c30 3 1 270 2 ## c31 41 0 70 0 ## c32 4 0 199 25 ## c33 59 4 140 0 ## c34 0 0 80 15 ## c35 4 1 20 3 ## c36 4250 2137 203 6 ## c37 164 4 391 9 ## c38 83 52 100 28 ## c39 363 167 529 75 ## c4 798 575 63 998 ## c40 19 6 33 14 ## c41 0 1 7 554 ## c42 532 43 3 0 ## c43 10 2 26 4 ## c44 1 15 30 260 ## c45 329 96 327 62 ## c46 1 2 74 5 ## c47 3 1 140 52 ## c48 5 3 18 3 ## c49 3 4 20 100 ## c5 13 0 127 9 ## c50 117 9 171 15 ## c51 161 1 217 1 ## c52 1 2 99 3 ## c53 27 1 24 4 ## c54 49 0 0 0 ## c55 2 0 48 1 ## c56 20 0 26 0 ## c57 55 54 103 33 ## c58 7 19 78 6 ## c59 8 16 45 184 ## c6 414 167 457 223 ## c60 2 1 23 3 ## c61 40 0 1 0 ## c62 2 0 439 2 ## c63 1 1 80 4 ## c64 0 0 26 0 ## c65 26 0 0 1 ## c66 8 1 30 0 ## c7 40 51 352 67 ## c8 61 900 579 4 ## c9 2 1 210 28 pheatmap::pheatmap(tab, border_color = NA, drop_levels = TRUE, cluster_rows = FALSE, cluster_cols = FALSE ) tab &lt;- table(colLabels(sce), sce$Sample.Name2) pheatmap::pheatmap(tab, border_color = NA, drop_levels = TRUE, cluster_rows = FALSE, cluster_cols = FALSE ) On the t-SNE plots below, cells colored by type or sample (‘batch of origin’). Cluster numbers are superimposed based on the median coordinate of cells assigned to that cluster. p1 &lt;- plotTSNE(sce, colour_by=&quot;type&quot;, text_by=&quot;label&quot;) p2 &lt;- plotTSNE(sce, colour_by=&quot;Sample.Name2&quot;) gridExtra::grid.arrange(p1, p2+facet_wrap(~colData(sce)$type), ncol=2) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_Fmwbl2.Rds&quot;, projDir, outDirBit, setName, setSuf) tmpList &lt;- readRDS(tmpFn) chosen.hvgs &lt;- tmpList$chosen.hvgs rescaled.mbn &lt;- tmpList$rescaled.mbn uncorrected &lt;- tmpList$uncorrected colToKeep &lt;- c(&quot;Run&quot;, &quot;Sample.Name&quot;, &quot;source_name&quot;, &quot;block&quot;, &quot;setName&quot;, &quot;Sample.Name2&quot;) colData(uncorrected) &lt;- colData(uncorrected)[,colToKeep] colData(uncorrected)[1:3,] ## DataFrame with 3 rows and 6 columns ## Run Sample.Name source_name block setName Sample.Name2 ## &lt;character&gt; &lt;character&gt; &lt;factor&gt; &lt;factor&gt; &lt;character&gt; &lt;character&gt; ## 1 SRR9264343 GSM3872434 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_1 ## 2 SRR9264343 GSM3872434 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_1 ## 3 SRR9264343 GSM3872434 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_1 #--- merging ---# library(batchelor) set.seed(01001001) merged &lt;- correctExperiments(uncorrected, batch=uncorrected$Sample.Name2, subset.row=chosen.hvgs, PARAM=FastMnnParam( merge.order=list( list(1,2,3,4), list(9,10,11), list(5,6), list(7,8) ) ) ) merged ## class: SingleCellExperiment ## dim: 12466 47830 ## metadata(2): merge.info pca.info ## assays(3): reconstructed counts logcounts ## rownames(12466): ENSG00000000003 ENSG00000000457 ... ENSG00000285476 ## ENSG00000285492 ## rowData names(12): rotation ensembl_gene_id ... detected gene_sparsity ## colnames: NULL ## colData names(7): batch Run ... setName Sample.Name2 ## reducedDimNames(4): corrected PCA TSNE UMAP ## altExpNames(0): #--- clustering ---# g &lt;- buildSNNGraph(merged, use.dimred=&quot;corrected&quot;) clusters &lt;- igraph::cluster_louvain(g) merged$clusters.mnn &lt;- factor(paste0(&quot;c&quot;, clusters$membership)) #colLabels(merged) &lt;- merged$clusters.mnn #--- dimensionality-reduction ---# merged &lt;- runTSNE(merged, dimred=&quot;corrected&quot;, external_neighbors=TRUE) merged &lt;- runUMAP(merged, dimred=&quot;corrected&quot;, external_neighbors=TRUE) library(scater) tab &lt;- table(merged$clusters.mnn, merged$block) pheatmap::pheatmap(tab, border_color = NA, drop_levels = TRUE, cluster_rows = FALSE, cluster_cols = FALSE ) tab &lt;- table(merged$clusters.mnn, merged$Sample.Name2) pheatmap::pheatmap(tab, border_color = NA, drop_levels = TRUE, cluster_rows = FALSE, cluster_cols = FALSE ) #plotTSNE(merged, colour_by=&quot;block&quot;, text_by=&quot;clusters.mnn&quot;) #plotTSNE(merged, colour_by=&quot;Sample.Name2&quot;) p1 &lt;- plotTSNE(merged, colour_by=&quot;block&quot;, text_by=&quot;clusters.mnn&quot;) p2 &lt;- plotTSNE(merged, colour_by=&quot;Sample.Name2&quot;) gridExtra::grid.arrange(p1, p2+facet_wrap(~colData(sce)$type), ncol=2) 23.3 Differential expression between conditions 23.3.1 Creating pseudo-bulk samples The most obvious differential analysis is to look for changes in expression between conditions. We perform the DE analysis separately for each label. The actual DE testing is performed on “pseudo-bulk” expression profiles (Tung et al. 2017), generated by summing counts together for all cells with the same combination of label and sample. This leverages the resolution offered by single-cell technologies to define the labels, and combines it with the statistical rigor of existing methods for DE analyses involving a small number of samples. # Using &#39;label&#39; and &#39;sample&#39; as our two factors; each column of the output # corresponds to one unique combination of these two factors. summed &lt;- aggregateAcrossCells(merged, id = DataFrame( label=merged$clusters.mnn, sample=merged$Sample.Name2 ) ) summed ## class: SingleCellExperiment ## dim: 12466 187 ## metadata(2): merge.info pca.info ## assays(1): counts ## rownames(12466): ENSG00000000003 ENSG00000000457 ... ENSG00000285476 ## ENSG00000285492 ## rowData names(12): rotation ensembl_gene_id ... detected gene_sparsity ## colnames: NULL ## colData names(11): batch Run ... sample ncells ## reducedDimNames(4): corrected PCA TSNE UMAP ## altExpNames(0): colData(summed) %&gt;% head(3) ## DataFrame with 3 rows and 11 columns ## batch Run Sample.Name source_name block setName ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;factor&gt; &lt;factor&gt; &lt;character&gt; ## 1 ETV6-RUNX1_1 SRR9264343 GSM3872434 ETV6-RUNX1 ETV6-RUNX1 Caron ## 2 ETV6-RUNX1_2 SRR9264344 GSM3872435 ETV6-RUNX1 ETV6-RUNX1 Caron ## 3 ETV6-RUNX1_3 SRR9264345 GSM3872436 ETV6-RUNX1 ETV6-RUNX1 Caron ## Sample.Name2 clusters.mnn label sample ncells ## &lt;character&gt; &lt;factor&gt; &lt;factor&gt; &lt;character&gt; &lt;integer&gt; ## 1 ETV6-RUNX1_1 c1 c1 ETV6-RUNX1_1 937 ## 2 ETV6-RUNX1_2 c1 c1 ETV6-RUNX1_2 722 ## 3 ETV6-RUNX1_3 c1 c1 ETV6-RUNX1_3 165 At this point, it is worth reflecting on the motivations behind the use of pseudo-bulking: Larger counts are more amenable to standard DE analysis pipelines designed for bulk RNA-seq data. Normalization is more straightforward and certain statistical approximations are more accurate e.g., the saddlepoint approximation for quasi-likelihood methods or normality for linear models. Collapsing cells into samples reflects the fact that our biological replication occurs at the sample level (Lun and Marioni 2017). Each sample is represented no more than once for each condition, avoiding problems from unmodelled correlations between samples. Supplying the per-cell counts directly to a DE analysis pipeline would imply that each cell is an independent biological replicate, which is not true from an experimental perspective. (A mixed effects model can handle this variance structure but involves extra statistical and computational complexity for little benefit, see Crowell et al. (2019).) Variance between cells within each sample is masked, provided it does not affect variance across (replicate) samples. This avoids penalizing DEGs that are not uniformly up- or down-regulated for all cells in all samples of one condition. Masking is generally desirable as DEGs - unlike marker genes - do not need to have low within-sample variance to be interesting, e.g., if the treatment effect is consistent across replicate populations but heterogeneous on a per-cell basis. (Of course, high per-cell variability will still result in weaker DE if it affects the variability across populations, while homogeneous per-cell responses will result in stronger DE due to a larger population-level log-fold change. These effects are also largely desirable.) 23.3.2 Performing the DE analysis 23.3.2.1 Introduction The DE analysis will be performed using quasi-likelihood (QL) methods from the edgeR package (Robinson, McCarthy, and Smyth 2010; Chen, Lun, and Smyth 2016). This uses a negative binomial generalized linear model (NB GLM) to handle overdispersed count data in experiments with limited replication. In our case, we have biological variation with three paired replicates per condition, so edgeR (or its contemporaries) is a natural choice for the analysis. We do not use all labels for GLM fitting as the strong DE between labels makes it difficult to compute a sensible average abundance to model the mean-dispersion trend. Moreover, label-specific batch effects would not be easily handled with a single additive term in the design matrix for the batch. Instead, we arbitrarily pick one of the labels to use for this demonstration. labelToGet &lt;- &quot;c1&quot; current &lt;- summed[,summed$label==labelToGet] # Creating up a DGEList object for use in edgeR: suppressMessages(library(edgeR)) y &lt;- DGEList(counts(current), samples=colData(current)) y ## An object of class &quot;DGEList&quot; ## $counts ## Sample1 Sample2 Sample3 Sample4 Sample5 Sample6 Sample7 Sample8 ## ENSG00000000003 0 1 0 0 0 2 0 0 ## ENSG00000000457 25 24 2 43 4 6 0 1 ## ENSG00000000938 0 0 0 0 2 0 0 1 ## ENSG00000001167 31 43 13 87 1 29 2 3 ## ENSG00000001461 71 16 2 37 15 31 0 1 ## Sample9 Sample10 Sample11 ## ENSG00000000003 0 2 0 ## ENSG00000000457 0 0 0 ## ENSG00000000938 1 1 0 ## ENSG00000001167 4 5 0 ## ENSG00000001461 0 1 0 ## 12461 more rows ... ## ## $samples ## group lib.size norm.factors batch Run Sample.Name ## Sample1 1 2399260 1 ETV6-RUNX1_1 SRR9264343 GSM3872434 ## Sample2 1 1158608 1 ETV6-RUNX1_2 SRR9264344 GSM3872435 ## Sample3 1 289586 1 ETV6-RUNX1_3 SRR9264345 GSM3872436 ## Sample4 1 2161489 1 ETV6-RUNX1_4 SRR9264346 GSM3872437 ## Sample5 1 773606 1 HHD_1 SRR9264347 GSM3872438 ## source_name block setName Sample.Name2 clusters.mnn label ## Sample1 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_1 c1 c1 ## Sample2 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_2 c1 c1 ## Sample3 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_3 c1 c1 ## Sample4 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_4 c1 c1 ## Sample5 HHD HHD Caron HHD_1 c1 c1 ## sample ncells ## Sample1 ETV6-RUNX1_1 937 ## Sample2 ETV6-RUNX1_2 722 ## Sample3 ETV6-RUNX1_3 165 ## Sample4 ETV6-RUNX1_4 1363 ## Sample5 HHD_1 276 ## 6 more rows ... 23.3.2.2 Pre-processing A typical step in bulk RNA-seq data analyses is to remove samples with very low library sizes due to failed library preparation or sequencing. The very low counts in these samples can be troublesome in downstream steps such as normalization (Chapter 7) or for some statistical approximations used in the DE analysis. In our situation, this is equivalent to removing label-sample combinations that have very few or lowly-sequenced cells. The exact definition of “very low” will vary, but in this case, we remove combinations containing fewer than 20 cells (Crowell et al. 2019). Alternatively, we could apply the outlier-based strategy described in Chapter 6, but this makes the strong assumption that all label-sample combinations have similar numbers of cells that are sequenced to similar depth. discarded &lt;- current$ncells &lt; 20 y &lt;- y[,!discarded] summary(discarded) ## Mode FALSE TRUE ## logical 10 1 Another typical step in bulk RNA-seq analyses is to remove genes that are lowly expressed. This reduces computational work, improves the accuracy of mean-variance trend modelling and decreases the severity of the multiple testing correction. Genes are discarded if they are not expressed above a log-CPM threshold in a minimum number of samples (determined from the size of the smallest treatment group in the experimental design). keep &lt;- filterByExpr(y, group=current$source_name) y &lt;- y[keep,] summary(keep) ## Mode FALSE TRUE ## logical 6478 5988 Finally, we correct for composition biases by computing normalization factors with the trimmed mean of M-values method (Robinson and Oshlack 2010). We do not need the bespoke single-cell methods described in Chapter 7, as the counts for our pseudo-bulk samples are large enough to apply bulk normalization methods. (Readers should be aware that edgeR normalization factors are closely related but not the same as the size factors described elsewhere in this book.) y &lt;- calcNormFactors(y) y$samples ## group lib.size norm.factors batch Run Sample.Name ## Sample1 1 2399260 0.7743944 ETV6-RUNX1_1 SRR9264343 GSM3872434 ## Sample2 1 1158608 0.9666536 ETV6-RUNX1_2 SRR9264344 GSM3872435 ## Sample3 1 289586 0.9940259 ETV6-RUNX1_3 SRR9264345 GSM3872436 ## Sample4 1 2161489 0.8767754 ETV6-RUNX1_4 SRR9264346 GSM3872437 ## Sample5 1 773606 0.6914457 HHD_1 SRR9264347 GSM3872438 ## Sample6 1 1117032 0.8861710 HHD_2 SRR9264348 GSM3872439 ## Sample7 1 37637 1.1549506 PBMMC_1 SRR9264351 GSM3872442 ## Sample8 1 45151 1.3305647 PBMMC_2 SRR9264353 GSM3872443 ## Sample9 1 37099 1.2773938 PBMMC_3 SRR9264354 GSM3872444 ## Sample10 1 66418 1.2743275 PRE-T_1 SRR9264349 GSM3872440 ## source_name block setName Sample.Name2 clusters.mnn label ## Sample1 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_1 c1 c1 ## Sample2 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_2 c1 c1 ## Sample3 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_3 c1 c1 ## Sample4 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_4 c1 c1 ## Sample5 HHD HHD Caron HHD_1 c1 c1 ## Sample6 HHD HHD Caron HHD_2 c1 c1 ## Sample7 PBMMC PBMMC Caron PBMMC_1 c1 c1 ## Sample8 PBMMC PBMMC Caron PBMMC_2 c1 c1 ## Sample9 PBMMC PBMMC Caron PBMMC_3 c1 c1 ## Sample10 PRE-T PRE-T Caron PRE-T_1 c1 c1 ## sample ncells ## Sample1 ETV6-RUNX1_1 937 ## Sample2 ETV6-RUNX1_2 722 ## Sample3 ETV6-RUNX1_3 165 ## Sample4 ETV6-RUNX1_4 1363 ## Sample5 HHD_1 276 ## Sample6 HHD_2 345 ## Sample7 PBMMC_1 26 ## Sample8 PBMMC_2 27 ## Sample9 PBMMC_3 41 ## Sample10 PRE-T_1 37 23.3.2.3 Statistical modelling Our aim is to test whether the log-fold change between sample groups is significantly different from zero. design &lt;- model.matrix(~factor(source_name), y$samples) design ## (Intercept) factor(source_name)HHD factor(source_name)PBMMC ## Sample1 1 0 0 ## Sample2 1 0 0 ## Sample3 1 0 0 ## Sample4 1 0 0 ## Sample5 1 1 0 ## Sample6 1 1 0 ## Sample7 1 0 1 ## Sample8 1 0 1 ## Sample9 1 0 1 ## Sample10 1 0 0 ## factor(source_name)PRE-T ## Sample1 0 ## Sample2 0 ## Sample3 0 ## Sample4 0 ## Sample5 0 ## Sample6 0 ## Sample7 0 ## Sample8 0 ## Sample9 0 ## Sample10 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 1 1 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$`factor(source_name)` ## [1] &quot;contr.treatment&quot; We estimate the negative binomial (NB) dispersions with estimateDisp(). The role of the NB dispersion is to model the mean-variance trend, which is not easily accommodated by QL dispersions alone due to the quadratic nature of the NB mean-variance trend. y &lt;- estimateDisp(y, design) summary(y$trended.dispersion) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1498 0.1546 0.1639 0.1843 0.1876 0.3670 Biological coefficient of variation (BCV) for each gene as a function of the average abundance. The BCV is computed as the square root of the NB dispersion after empirical Bayes shrinkage towards the trend. Trended and common BCV estimates are shown in blue and red, respectively. plotBCV(y) We also estimate the quasi-likelihood dispersions with glmQLFit() (Chen, Lun, and Smyth 2016). This fits a GLM to the counts for each gene and estimates the QL dispersion from the GLM deviance. We set robust=TRUE to avoid distortions from highly variable clusters (Phipson et al. 2016). The QL dispersion models the uncertainty and variability of the per-gene variance - which is not well handled by the NB dispersions, so the two dispersion types complement each other in the final analysis. fit &lt;- glmQLFit(y, design, robust=TRUE) summary(fit$var.prior) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4648 0.7190 0.8145 0.8089 0.8702 1.2078 summary(fit$df.prior) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.3833 10.1200 10.1200 9.5004 10.1200 10.1200 QL dispersion estimates for each gene as a function of abundance. Raw estimates (black) are shrunk towards the trend (blue) to yield squeezed estimates (red). plotQLDisp(fit) We test for differences in expression due to sample group using glmQLFTest(). DEGs are defined as those with non-zero log-fold changes at a false discovery rate of 5%. If very few genes are significantly DE that sample group has little effect on the transcriptome. res &lt;- glmQLFTest(fit, coef=ncol(design)) summary(decideTests(res)) ## factor(source_name)PRE-T ## Down 186 ## NotSig 5726 ## Up 76 topTab &lt;- topTags(res)$table tmpAnnot &lt;- rowData(current)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;)] %&gt;% data.frame topTab %&gt;% tibble::rownames_to_column(&quot;ensembl_gene_id&quot;) %&gt;% left_join(tmpAnnot, by=&quot;ensembl_gene_id&quot;) ## ensembl_gene_id logFC logCPM F PValue FDR ## 1 ENSG00000137731 11.750497 8.081049 200.14071 1.137048e-09 6.808645e-06 ## 2 ENSG00000100721 -14.574197 11.841139 86.06404 7.246895e-08 2.169720e-04 ## 3 ENSG00000019582 -7.293701 13.419485 75.91130 1.699885e-07 3.392971e-04 ## 4 ENSG00000030419 5.108326 4.324652 60.99556 7.199543e-07 9.130830e-04 ## 5 ENSG00000204287 -5.991293 12.828441 60.45677 7.624274e-07 9.130830e-04 ## 6 ENSG00000229989 3.928677 7.844280 57.24178 1.082802e-06 1.080637e-03 ## 7 ENSG00000081189 -5.661665 9.823323 55.76542 1.278801e-06 1.093923e-03 ## 8 ENSG00000272398 -7.136564 10.987138 53.63986 1.635052e-06 1.210049e-03 ## 9 ENSG00000128218 -5.479618 11.067708 52.73912 1.818710e-06 1.210049e-03 ## 10 ENSG00000100629 4.635353 4.820067 49.53548 2.687517e-06 1.422310e-03 ## Symbol ## 1 FXYD2 ## 2 TCL1A ## 3 CD74 ## 4 IKZF2 ## 5 HLA-DRA ## 6 MIR181A1HG ## 7 MEF2C ## 8 CD24 ## 9 VPREB3 ## 10 CEP128 23.3.2.4 Differential expression for each cluster The steps illustrated above with cluster c1 are now repeated for each cluster: Subset pseudo-bulk counts for that cluster Create edgeR object with these pseudo-bulk counts Pre-process Remove samples with very small library size Remove genes with low UMI counts Correct for compositional bias Perform differential expression analysis Estimate negative binomial dispersion Estimate quasi-likelihood dispersion Test for differential expression de.results &lt;- list() for (labelToGet in levels(summed$label)) { current &lt;- summed[,summed$label==labelToGet] y &lt;- DGEList(counts(current), samples=colData(current)) discarded &lt;- isOutlier(colSums(counts(current)), log=TRUE, type=&quot;lower&quot;) y &lt;- y[,!discarded] y &lt;- y[filterByExpr(y, group=current$source_name),] y &lt;- calcNormFactors(y) design &lt;- try( model.matrix(~factor(source_name), y$samples), silent=TRUE ) if (is(design, &quot;try-error&quot;) || qr(design)$rank==nrow(design) || qr(design)$rank &lt; ncol(design)) { # Skipping labels without contrasts or without # enough residual d.f. to estimate the dispersion. next } y &lt;- estimateDisp(y, design) fit &lt;- glmQLFit(y, design) res &lt;- glmQLFTest(fit, coef=ncol(design)) de.results[[labelToGet]] &lt;- res } 23.3.2.4.1 Number of DEGs by cluster and direction We examine the numbers of DEGs at a FDR of 5% for each label (i.e. cluster). In general, there seems to be very little differential expression between the on and off conditions. summaries &lt;- lapply(de.results, FUN=function(x) summary(decideTests(x))[,1]) sum.tab &lt;- do.call(rbind, summaries) #sum.tab sum.tab[order(rownames(sum.tab)),] %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(&quot;Cluster&quot;) %&gt;% datatable(rownames = FALSE, options = list(pageLength = 20, scrollX = TRUE)) 23.3.2.4.2 List of DEGs We now list DEGs and the number of clusters they were detected in: degs &lt;- lapply(de.results, FUN=function(x) rownames(topTags(x, p.value=0.05))) common.degs &lt;- sort(table(unlist(degs)), decreasing=TRUE) #head(common.degs, 20) common.degs %&gt;% as.data.frame %&gt;% dplyr::rename(ensembl_gene_id = Var1, NbClu = Freq) %&gt;% left_join( data.frame(rowData(summed)[,c(&quot;ensembl_gene_id&quot;, &quot;Symbol&quot;)]), by=&quot;ensembl_gene_id&quot;) %&gt;% #rename(Gene = ensembl_gene_id) %&gt;% relocate(c(&quot;Symbol&quot;,&quot;NbClu&quot;,&quot;ensembl_gene_id&quot;)) %&gt;% datatable(rownames = FALSE, options = list(pageLength = 20, scrollX = TRUE)) 23.3.2.4.3 Number of clusters skipped “We also list the labels that were skipped due to the absence of replicates or contrasts. If it is necessary to extract statistics in the absence of replicates, several strategies can be applied such as reducing the complexity of the model or using a predefined value for the NB dispersion. We refer readers to the edgeR user’s guide for more details.” skippedClusters &lt;- setdiff(unique(summed$label), names(summaries)) The number of clusters skipped is 0. if(length(skippedClusters)&gt;0) { skippedClusters } grmToShowList &lt;- vector(&quot;list&quot;, length = nlevels(merged$clusters.mnn)) names(grmToShowList) &lt;- levels(merged$clusters.mnn) genesToExclude &lt;- c() nbGeneToShow &lt;- 20 #degs &lt;- lapply(de.results, FUN=function(x) (topTags(x, p.value=0.05))) degs &lt;- lapply(de.results, FUN=function(x) (as.data.frame(topTags(x, n=nbGeneToShow)))) for( namex in levels(merged$clusters.mnn) ) { nbGeneToUse &lt;- min(c(nrow(degs[[namex]]), nbGeneToShow)) # format # format p value: tmpCol &lt;- grep(&quot;PValue|FDR&quot;, colnames(degs[[namex]]), value=TRUE) degs[[namex]][,tmpCol] &lt;- apply(degs[[namex]][,tmpCol], 2, function(x){format(x, scientific = TRUE, digits = 1)}) # format logFC: tmpCol &lt;- c(&quot;logFC&quot;, &quot;logCPM&quot;, &quot;F&quot;) degs[[namex]][,tmpCol] &lt;- apply(degs[[namex]][,tmpCol], 2, function(x){round(x, 2)}) rm(tmpCol) # subset data grmToShow &lt;- degs[[namex]] %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(&quot;gene&quot;) %&gt;% arrange(FDR, desc(abs(logFC))) %&gt;% filter(! gene %in% genesToExclude) %&gt;% group_modify(~ head(.x, nbGeneToUse)) # keep data grmToShow$cluster &lt;- namex grmToShowList[[namex]] &lt;- grmToShow # tidy rm(nbGeneToUse) } grmToShowDf &lt;- do.call(&quot;rbind&quot;, grmToShowList) tmpCol &lt;- c(&quot;cluster&quot;, &quot;gene&quot;) grmToShowDf %&gt;% select(tmpCol, setdiff(colnames(grmToShowDf), tmpCol)) %&gt;% filter(gene %in% names(common.degs) &amp; as.numeric(FDR) &lt; 0.05) %&gt;% datatable(rownames = FALSE, filter=&quot;top&quot;, options=list(scrollX = TRUE, pageLength = 15)) tmpBool &lt;- as.numeric(grmToShowDf$FDR) &lt; 0.05 markers.to.plot &lt;- unique(grmToShowDf[tmpBool, &quot;gene&quot;]) markers.to.plot &lt;- markers.to.plot[1:5] 23.3.3 Putting it all together Now that we have laid out the theory underlying the DE analysis, we repeat this process for each of the labels. This is conveniently done using the pseudoBulkDGE() function from scran, which will loop over all labels and apply the exact analysis described above to each label. To prepare for this, we filter out all sample-label combinations with insufficient cells. summed.filt &lt;- summed[,summed$ncells &gt;= 20] We construct a common design matrix that will be used in the analysis for each label. Recall that this matrix should have one row per unique sample (and named as such), reflecting the fact that we are modelling counts on the sample level instead of the cell level. # Pulling out a sample-level &#39;targets&#39; data.frame: targets &lt;- colData(merged)[!duplicated(merged$Sample.Name2),] # Constructing the design matrix: design &lt;- model.matrix(~factor(source_name), data=targets) rownames(design) &lt;- targets$Sample.Name2 We then apply the pseudoBulkDGE() function to obtain a list of DE genes for each label. This function puts some additional effort into automatically dealing with labels that are not represented in all sample groups, for which a DE analysis between conditions is meaningless; or are not represented in a sufficient number of replicate samples to enable modelling of biological variability. library(scran) de.results &lt;- pseudoBulkDGE(summed.filt, sample=summed.filt$Sample.Name2, label=summed.filt$label, design=design, coef=ncol(design), # &#39;condition&#39; sets the group size for filterByExpr(), # to perfectly mimic our previous manual analysis. condition=targets$source_name ) We examine the numbers of DEGs at a FDR of 5% for each label using the decideTestsPerLabel() function. Note that genes listed as NA were either filtered out as low-abundance genes for a given label’s analysis, or the comparison of interest was not possible for a particular label, e.g., due to lack of residual degrees of freedom or an absence of samples from both conditions. is.de &lt;- decideTestsPerLabel(de.results, threshold=0.05) summarizeTestsPerLabel(is.de) ## -1 0 1 NA ## c1 202 6786 91 5387 ## c10 621 4186 429 7230 ## c11 462 2763 355 8886 ## c13 64 5309 206 6887 ## c15 0 2829 0 9637 ## c17 5 2056 20 10385 ## c2 708 4033 508 7217 ## c3 942 5766 701 5057 ## c4 951 5396 705 5414 ## c6 6 3701 12 8747 ## c8 257 1764 156 10289 For each gene, we compute the percentage of cell types in which that gene is upregulated or downregulated. (Here, we consider a gene to be non-DE if it is not retained after filtering.). # Upregulated across most cell types. up.de &lt;- is.de &gt; 0 &amp; !is.na(is.de) head(sort(rowMeans(up.de), decreasing=TRUE), 10) ## ENSG00000081059 ENSG00000137731 ENSG00000064886 ENSG00000066294 ENSG00000096060 ## 0.8181818 0.8181818 0.7272727 0.7272727 0.7272727 ## ENSG00000136161 ENSG00000158488 ENSG00000159674 ENSG00000169994 ENSG00000182866 ## 0.7272727 0.7272727 0.7272727 0.7272727 0.7272727 # Downregulated across cell types. down.de &lt;- is.de &lt; 0 &amp; !is.na(is.de) head(sort(rowMeans(down.de), decreasing=TRUE), 10) ## ENSG00000110492 ENSG00000019582 ENSG00000068079 ENSG00000100721 ENSG00000105369 ## 0.8181818 0.7272727 0.7272727 0.7272727 0.7272727 ## ENSG00000120833 ENSG00000162654 ENSG00000184489 ENSG00000196126 ENSG00000197872 ## 0.7272727 0.7272727 0.7272727 0.7272727 0.7272727 We further identify label-specific DE genes that are significant in our label of interest yet not DE in any other label. As hypothesis tests are not typically geared towards identifying genes that are not DE, we use an ad hoc approach where we consider a gene to be consistent with the null hypothesis for a label if it fails to be detected even at a generous FDR threshold of 50%. remotely.de &lt;- decideTestsPerLabel(de.results, threshold=0.5) not.de &lt;- remotely.de==0 | is.na(remotely.de) # first cluster in is.de cx &lt;- colnames(is.de)[1] other.labels &lt;- setdiff(colnames(not.de), cx) unique.degs &lt;- is.de[,cx]!=0 &amp; rowMeans(not.de[,other.labels])==1 unique.degs &lt;- names(which(unique.degs)) head(unique.degs) ## character(0) # 2nd cluster in is.de cx &lt;- colnames(is.de)[2] other.labels &lt;- setdiff(colnames(not.de), cx) unique.degs &lt;- is.de[,cx]!=0 &amp; rowMeans(not.de[,other.labels])==1 unique.degs &lt;- names(which(unique.degs)) # Choosing the top-ranked gene for inspection: de.inspec &lt;- list() de.inspec[[cx]] &lt;- de.results[[cx]] de.inspec[[cx]] &lt;- de.inspec[[cx]][order(de.inspec[[cx]]$PValue),] de.inspec[[cx]] &lt;- de.inspec[[cx]][rownames(de.inspec[[cx]]) %in% unique.degs,] sizeFactors(summed.filt) &lt;- NULL plotExpression(logNormCounts(summed.filt), features=rownames(de.inspec[[cx]])[1], x=&quot;source_name&quot;, colour_by=&quot;source_name&quot;, other_fields=&quot;label&quot;) + facet_wrap(~label) We also list the labels that were skipped due to the absence of replicates or contrasts. If it is necessary to extract statistics in the absence of replicates, several strategies can be applied such as reducing the complexity of the model or using a predefined value for the NB dispersion. We refer readers to the edgeR user’s guide for more details. print(metadata(de.results)$failed) ## [1] &quot;c12&quot; &quot;c14&quot; &quot;c16&quot; &quot;c18&quot; &quot;c5&quot; &quot;c7&quot; &quot;c9&quot; 23.4 Differential abundance between conditions 23.4.1 Overview n a DA analysis, we test for significant changes in per-label cell abundance across conditions. This will reveal which cell types are depleted or enriched upon treatment, which is arguably just as interesting as changes in expression within each cell type. The DA analysis has a long history in flow cytometry (Finak et al. 2014; Lun, Richard, and Marioni 2017) where it is routinely used to examine the effects of different conditions on the composition of complex cell populations. By performing it here, we effectively treat scRNA-seq as a “super-FACS” technology for defining relevant subpopulations using the entire transcriptome. We prepare for the DA analysis by quantifying the number of cells assigned to each label (or cluster). abundances &lt;- table(merged$clusters.mnn, merged$Sample.Name2) abundances &lt;- unclass(abundances) head(abundances) ## ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PBMMC_1 ## c1 937 722 165 1363 276 345 26 ## c10 103 2625 485 512 426 1042 9 ## c11 72 196 713 52 96 191 28 ## c12 0 0 11 7 3 1 396 ## c13 1 7 24 43 52 12 288 ## c14 3 3 135 253 1 15 64 ## ## PBMMC_2 PBMMC_3 PRE-T_1 PRE-T_2 ## c1 27 41 37 2 ## c10 41 131 179 125 ## c11 18 64 171 1142 ## c12 152 13 2 2 ## c13 435 748 6 246 ## c14 611 142 2 96 Performing the DA analysis Our DA analysis will again be performed with the edgeR package. This allows us to take advantage of the NB GLM methods to model overdispersed count data in the presence of limited replication - except that the counts are not of reads per gene, but of cells per label (Lun, Richard, and Marioni 2017). The aim is to share information across labels to improve our estimates of the biological variability in cell abundance between replicates. # Attaching some column metadata. extra.info &lt;- colData(merged)[match(colnames(abundances), merged$Sample.Name2),] y.ab &lt;- DGEList(abundances, samples=extra.info) y.ab ## An object of class &quot;DGEList&quot; ## $counts ## ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PBMMC_1 ## c1 937 722 165 1363 276 345 26 ## c10 103 2625 485 512 426 1042 9 ## c11 72 196 713 52 96 191 28 ## c12 0 0 11 7 3 1 396 ## c13 1 7 24 43 52 12 288 ## ## PBMMC_2 PBMMC_3 PRE-T_1 PRE-T_2 ## c1 27 41 37 2 ## c10 41 131 179 125 ## c11 18 64 171 1142 ## c12 152 13 2 2 ## c13 435 748 6 246 ## 13 more rows ... ## ## $samples ## group lib.size norm.factors batch Run Sample.Name ## ETV6-RUNX1_1 1 2853 1 ETV6-RUNX1_1 SRR9264343 GSM3872434 ## ETV6-RUNX1_2 1 6615 1 ETV6-RUNX1_2 SRR9264344 GSM3872435 ## ETV6-RUNX1_3 1 4727 1 ETV6-RUNX1_3 SRR9264345 GSM3872436 ## ETV6-RUNX1_4 1 5293 1 ETV6-RUNX1_4 SRR9264346 GSM3872437 ## HHD_1 1 4551 1 HHD_1 SRR9264347 GSM3872438 ## source_name block setName Sample.Name2 clusters.mnn ## ETV6-RUNX1_1 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_1 c3 ## ETV6-RUNX1_2 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_2 c4 ## ETV6-RUNX1_3 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_3 c17 ## ETV6-RUNX1_4 ETV6-RUNX1 ETV6-RUNX1 Caron ETV6-RUNX1_4 c1 ## HHD_1 HHD HHD Caron HHD_1 c5 ## 6 more rows ... We filter out low-abundance labels as previously described. This avoids cluttering the result table with very rare subpopulations that contain only a handful of cells. For a DA analysis of cluster abundances, filtering is generally not required as most clusters will not be of low-abundance (otherwise there would not have been enough evidence to define the cluster in the first place). keep &lt;- filterByExpr(y.ab, group=y.ab$samples$source_name) y.ab &lt;- y.ab[keep,] summary(keep) ## Mode TRUE ## logical 18 Unlike DE analyses, we do not perform an additional normalization step with calcNormFactors(). This means that we are only normalizing based on the “library size”, i.e., the total number of cells in each sample. Any changes we detect between conditions will subsequently represent differences in the proportion of cells in each cluster. The motivation behind this decision is discussed in more detail in Section 14.4.3. Here, the log-fold change in our model refers to the change in cell abundance between sample groups, rather than the change in gene expression. design &lt;- model.matrix(~factor(source_name), y.ab$samples) We use the estimateDisp() function to estimate the NB dipersion for each cluster. We turn off the trend as we do not have enough points for its stable estimation. y.ab &lt;- estimateDisp(y.ab, design, trend=&quot;none&quot;) summary(y.ab$common.dispersion) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.9793 0.9793 0.9793 0.9793 0.9793 0.9793 plotBCV(y.ab, cex=1) We repeat this process with the QL dispersion, again disabling the trend. fit.ab &lt;- glmQLFit(y.ab, design, robust=TRUE, abundance.trend=FALSE) summary(fit.ab$var.prior) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.18 1.18 1.18 1.18 1.18 1.18 summary(fit.ab$df.prior) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 120.9 212.5 212.5 199.0 212.5 212.5 plotQLDisp(fit.ab, cex=1) We test for differences in abundance between sample groups using glmQLFTest(). res &lt;- glmQLFTest(fit.ab, coef=ncol(design)) summary(decideTests(res)) ## factor(source_name)PRE-T ## Down 2 ## NotSig 16 ## Up 0 topTags(res) ## Coefficient: factor(source_name)PRE-T ## logFC logCPM F PValue FDR ## c5 -5.970062 16.35445 10.1640813 0.001806486 0.03251675 ## c1 -5.153475 16.31480 8.3152532 0.004624676 0.04162208 ## c13 3.227077 15.51131 5.9376070 0.016218199 0.09730919 ## c7 -3.936424 15.34103 5.0729830 0.026032057 0.11714426 ## c18 3.386502 11.42393 3.4451433 0.065774025 0.23608559 ## c2 2.301146 16.85892 3.1424598 0.078695196 0.23608559 ## c8 1.788105 15.51327 1.9509604 0.164938752 0.37206264 ## c11 1.736525 15.89057 1.8117349 0.180717038 0.37206264 ## c10 -1.963157 16.53987 1.7680054 0.186031318 0.37206264 ## c16 1.144352 11.89816 0.7203937 0.397624426 0.71572397 23.4.2 Handling composition effects 23.4.2.1 Background As mentioned above, we do not use calcNormFactors() in our default DA analysis. This normalization step assumes that most of the input features are not different between conditions. While this assumption is reasonable for most types of gene expression data, it is generally too strong for cell type abundance - most experiments consist of only a few cell types that may all change in abundance upon perturbation. Thus, our default approach is to only normalize based on the total number of cells in each sample, which means that we are effectively testing for differential proportions between conditions. Unfortunately, the use of the total number of cells leaves us susceptible to composition effects. For example, a large increase in abundance for one cell subpopulation will introduce decreases in proportion for all other subpopulations - which is technically correct, but may be misleading if one concludes that those other subpopulations are decreasing in abundance of their own volition. If composition biases are proving problematic for interpretation of DA results, we have several avenues for removing them or mitigating their impact by leveraging a priori biological knowledge. 14.4.3.2 Assuming most labels do not change If it is possible to assume that most labels (i.e., cell types) do not change in abundance, we can use calcNormFactors() to compute normalization factors. y.ab2 &lt;- calcNormFactors(y.ab) y.ab2$samples$norm.factors ## [1] 0.6775040 0.7238884 0.9769490 1.1290651 0.9268008 0.9656680 1.2257770 ## [8] 1.4773071 1.4480029 0.7174753 1.0978745 We then proceed with the remainder of the edgeR analysis, shown below in condensed format. A shift of positive log-fold changes towards zero is consistent with the removal of composition biases. y.ab2 &lt;- estimateDisp(y.ab2, design, trend=&quot;none&quot;) fit.ab2 &lt;- glmQLFit(y.ab2, design, robust=TRUE, abundance.trend=FALSE) res2 &lt;- glmQLFTest(fit.ab2, coef=ncol(design)) topTags(res2, n=10) ## Coefficient: factor(source_name)PRE-T ## logFC logCPM F PValue FDR ## c5 -6.274363 16.53184 10.3342094 0.001658929 0.02986073 ## c1 -5.017465 16.56753 7.6891289 0.006399471 0.05759524 ## c13 3.118403 15.14410 5.4457475 0.021199590 0.11692701 ## c7 -3.826268 15.01359 5.0763350 0.025983780 0.11692701 ## c18 3.430538 11.09678 3.0342207 0.083965998 0.30227759 ## c2 2.072243 17.09976 2.4964424 0.116610952 0.34983286 ## c8 1.811393 15.79196 1.9041067 0.170063044 0.40510432 ## c10 -2.040034 16.76314 1.8173604 0.180046364 0.40510432 ## c11 1.530994 15.91093 1.3570098 0.246257110 0.49251422 ## c17 -0.960683 15.18727 0.4518357 0.502695247 0.83541716 23.5 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] edgeR_3.32.1 limma_3.46.0 ## [3] batchelor_1.6.3 Cairo_1.5-12.2 ## [5] DT_0.18 dplyr_1.0.5 ## [7] scran_1.18.7 scater_1.18.6 ## [9] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [11] Biobase_2.50.0 GenomicRanges_1.42.0 ## [13] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [15] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [17] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [19] ggplot2_3.3.3 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 RColorBrewer_1.1-2 ## [3] tools_4.0.3 bslib_0.2.4 ## [5] utf8_1.2.1 R6_2.5.0 ## [7] irlba_2.3.3 ResidualMatrix_1.0.0 ## [9] vipor_0.4.5 uwot_0.1.10 ## [11] DBI_1.1.1 colorspace_2.0-0 ## [13] withr_2.4.2 tidyselect_1.1.1 ## [15] gridExtra_2.3 compiler_4.0.3 ## [17] cli_2.4.0 BiocNeighbors_1.8.2 ## [19] DelayedArray_0.16.3 labeling_0.4.2 ## [21] bookdown_0.22 sass_0.3.1 ## [23] scales_1.1.1 stringr_1.4.0 ## [25] digest_0.6.27 rmarkdown_2.7 ## [27] XVector_0.30.0 pkgconfig_2.0.3 ## [29] htmltools_0.5.1.1 sparseMatrixStats_1.2.1 ## [31] fastmap_1.1.0 highr_0.9 ## [33] htmlwidgets_1.5.3 rlang_0.4.10 ## [35] rstudioapi_0.13 shiny_1.6.0 ## [37] DelayedMatrixStats_1.12.3 farver_2.1.0 ## [39] jquerylib_0.1.3 generics_0.1.0 ## [41] jsonlite_1.7.2 crosstalk_1.1.1 ## [43] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [45] magrittr_2.0.1 BiocSingular_1.6.0 ## [47] GenomeInfoDbData_1.2.4 scuttle_1.0.4 ## [49] Matrix_1.3-2 Rcpp_1.0.6 ## [51] ggbeeswarm_0.6.0 munsell_0.5.0 ## [53] fansi_0.4.2 viridis_0.6.0 ## [55] lifecycle_1.0.0 stringi_1.5.3 ## [57] yaml_2.2.1 zlibbioc_1.36.0 ## [59] Rtsne_0.15 grid_4.0.3 ## [61] promises_1.2.0.1 dqrng_0.3.0 ## [63] crayon_1.4.1 lattice_0.20-44 ## [65] splines_4.0.3 cowplot_1.1.1 ## [67] beachmat_2.6.4 locfit_1.5-9.4 ## [69] pillar_1.6.0 igraph_1.2.6 ## [71] codetools_0.2-18 glue_1.4.2 ## [73] evaluate_0.14 httpuv_1.5.5 ## [75] vctrs_0.3.7 gtable_0.3.0 ## [77] purrr_0.3.4 assertthat_0.2.1 ## [79] xfun_0.22 mime_0.10 ## [81] rsvd_1.0.5 xtable_1.8-4 ## [83] RSpectra_0.16-0 later_1.2.0 ## [85] viridisLite_0.4.0 pheatmap_1.0.12 ## [87] tibble_3.1.1 beeswarm_0.3.1 ## [89] bluster_1.0.0 statmod_1.4.35 ## [91] ellipsis_0.3.2 "],["pseudoTimeTop.html", "Chapter 24 Pseudotime analysis 24.1 Setting up the data 24.2 Pseudotime Alignment 24.3 Ackowledgements 24.4 Session information", " Chapter 24 Pseudotime analysis projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool splSetToGet &lt;- params$splSetToGet setName &lt;- params$setName setSuf &lt;- params$setSuf dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;hca&quot; splSetToGet &lt;- &quot;dummy&quot; setSuf &lt;- &quot;_5kCellPerSpl&quot; dsiSuf &lt;- &#39;_dummy&#39; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 library(SingleCellExperiment) library(scran) library(scater) library(batchelor) library(cowplot) library(pheatmap) library(tidyverse) library(SingleR) library(destiny) library(gam) library(viridis) library(msigdbr) library(clusterProfiler) library(cellAlign) # https://github.com/shenorrLab/cellAlign library(Cairo) ## Extract T-cells from HCA Dataset {#pseudoTimeExtractTCell} In this section, we are starting our analysis with normalized HCA data and perform integration, clustering and dimensionality reduction. Our aim is to extract T-cells from this dataset and proceed with pseudotime analysis in the next section. We are going to work with HCA data. This data set has been pre-processed and normalized before. #sce&lt;-readRDS(file=&quot;~/Course_Materials/scRNAseq/pseudotime/hca_sce.bone.RDS&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/hca_sce_nz_postDeconv_5kCellPerSpl.Rds&quot; sce &lt;- readRDS(file=tmpFn) We use symbols in place of ENSEMBL IDs for easier interpretation later. # BiocManager::install(&quot;EnsDb.Hsapiens.v86&quot;) #rowData(sce)$Chr &lt;- mapIds(EnsDb.Hsapiens.v86, keys=rownames(sce), column=&quot;SEQNAME&quot;, keytype=&quot;GENEID&quot;) rownames(sce) &lt;- uniquifyFeatureNames(rowData(sce)$ensembl_gene_id, names = rowData(sce)$Symbol) 24.0.1 Variance modeling We block on the donor of origin to mitigate batch effects during highly variable gene (HVG) selection. We select a larger number of HVGs to capture any batch-specific variation that might be present. dec.hca &lt;- modelGeneVar(sce, block=sce$Sample.Name) top.hca &lt;- getTopHVGs(dec.hca, n=5000) 24.0.2 Data integration The batchelor package provides an implementation of the Mutual Nearest Neighbours (MNN) approach via the fastMNN() function. We apply it to our HCA data to remove the donor specific effects across the highly variable genes in top.hca. To reduce computational work and technical noise, all cells in all samples are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses. We store it in ‘MNN’ slot in the main sce object. set.seed(1010001) merged.hca &lt;- fastMNN(sce, batch = sce$Sample.Name, subset.row = top.hca) reducedDim(sce, &#39;MNN&#39;) &lt;- reducedDim(merged.hca, &#39;corrected&#39;) 24.0.3 Dimensionality Reduction We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple samples. We see that all clusters contain contributions from each sample after correction. set.seed(01010100) sce &lt;- runPCA(sce, dimred=&quot;MNN&quot;) sce &lt;- runUMAP(sce, dimred=&quot;MNN&quot;) sce &lt;- runTSNE(sce, dimred=&quot;MNN&quot;) plotPCA(sce, colour_by=&quot;Sample.Name&quot;) + ggtitle(&quot;PCA&quot;) plotTSNE(sce, colour_by=&quot;Sample.Name&quot;) + ggtitle(&quot;tSNE&quot;) plotUMAP(sce, colour_by=&quot;Sample.Name&quot;) + ggtitle(&quot;UMAP&quot;) 24.0.4 Clustering Graph-based clustering generates an excessively large intermediate graph so we will instead use a two-step approach with k-means. We generate 1000 small clusters that are subsequently aggregated into more interpretable groups with a graph-based method. set.seed(1000) clust.hca &lt;- clusterSNNGraph(sce, use.dimred=&quot;MNN&quot;, use.kmeans=TRUE, kmeans.centers=1000) colLabels(sce) &lt;- factor(clust.hca) table(colLabels(sce)) ## ## 1 2 3 4 5 6 7 8 9 10 11 ## 4471 6365 2911 4420 2402 12536 1176 3566 1146 596 411 plotPCA(sce, colour_by=&quot;label&quot;) + ggtitle(&quot;PCA&quot;) plotUMAP(sce, colour_by=&quot;label&quot;) + ggtitle(&quot;UMAP&quot;) plotTSNE(sce, colour_by=&quot;label&quot;) + ggtitle(&quot;tSNE&quot;) 24.0.5 Cell type classification We perform automated cell type classification using a reference dataset to annotate each cluster based on its pseudo-bulk profile. This is for a quick assignment of cluster identity. We are going to use Human Primary Cell Atlas (HPCA) data for that. HumanPrimaryCellAtlasData function provides normalized expression values for 713 microarray samples from HPCA (Mabbott et al., 2013). These 713 samples were processed and normalized as described in Aran, Looney and Liu et al. (2019). Each sample has been assigned to one of 37 main cell types and 157 subtypes. se.aggregated &lt;- sumCountsAcrossCells(sce, id=colLabels(sce)) hpc &lt;- celldex::HumanPrimaryCellAtlasData() anno.hca &lt;- SingleR(se.aggregated, ref = hpc, labels = hpc$label.main, assay.type.test=&quot;sum&quot;) anno.hca ## DataFrame with 11 rows and 5 columns ## scores first.labels tuning.scores ## &lt;matrix&gt; &lt;character&gt; &lt;DataFrame&gt; ## 1 0.270340:0.754119:0.611547:... B_cell 0.754119: 0.6997738 ## 2 0.275371:0.598736:0.693408:... Pre-B_cell_CD34- 0.509690: 0.0634099 ## 3 0.364176:0.613523:0.692287:... CMP 0.594369: 0.3957973 ## 4 0.282579:0.620968:0.575578:... NK_cell 0.584395: 0.4455476 ## 5 0.381883:0.558646:0.649733:... MEP 0.361367: 0.3372588 ## 6 0.291896:0.637409:0.575667:... T_cells 0.773909: 0.7208437 ## 7 0.272533:0.650300:0.600539:... NK_cell 0.805271: 0.7248806 ## 8 0.296865:0.637337:0.590623:... T_cells 0.689381:-0.0530141 ## 9 0.315724:0.599837:0.722784:... Pre-B_cell_CD34- 0.475323: 0.3332805 ## 10 0.321822:0.686603:0.592921:... B_cell 0.488044: 0.2851121 ## 11 0.293917:0.635528:0.597594:... Pre-B_cell_CD34- 0.245206: 0.2048503 ## labels pruned.labels ## &lt;character&gt; &lt;character&gt; ## 1 B_cell B_cell ## 2 Monocyte Monocyte ## 3 CMP CMP ## 4 T_cells T_cells ## 5 BM &amp; Prog. BM &amp; Prog. ## 6 T_cells T_cells ## 7 NK_cell NK_cell ## 8 T_cells T_cells ## 9 Pre-B_cell_CD34- Pre-B_cell_CD34- ## 10 B_cell B_cell ## 11 Pre-B_cell_CD34- Pre-B_cell_CD34- tab &lt;- table(anno.hca$labels, colnames(se.aggregated)) # Adding a pseudo-count of 10 to avoid strong color jumps with just 1 cell. pheatmap(log10(tab+10)) sce$cell_type&lt;-recode(sce$label, &quot;1&quot; = &quot;T_cells&quot;, &quot;2&quot; = &quot;Monocyte&quot;, &quot;3&quot;=&quot;B_cell&quot;, &quot;4&quot;=&quot;MEP&quot;, &quot;5&quot;=&quot;B_cell&quot;, &quot;6&quot;=&quot;CMP&quot;, &quot;7&quot;=&quot;T_cells&quot;, &quot;8&quot;=&quot;Monocyte&quot;, &quot;9&quot;=&quot;T_cells&quot;, &quot;10&quot;=&quot;Pro-B_cell_CD34+&quot;, &quot;11&quot;=&quot;NK_cell&quot;, &quot;12&quot;=&quot;B_cell&quot;) #level_key &lt;- anno.hca %&gt;% # data.frame() %&gt;% # rownames_to_column(&quot;clu&quot;) %&gt;% # #select(clu, labels) # pull(labels) level_key &lt;- anno.hca$labels names(level_key) &lt;- row.names(anno.hca) sce$cell_type &lt;- recode(sce$label, !!!level_key) We can now use the predicted cell types to color PCA, UMAP and tSNE. plotPCA(sce, colour_by=&quot;cell_type&quot;, text_by=&quot;cell_type&quot;) + ggtitle(&quot;PCA&quot;) plotUMAP(sce, colour_by=&quot;cell_type&quot;, text_by=&quot;cell_type&quot;) + ggtitle(&quot;UMAP&quot;) plotTSNE(sce, colour_by=&quot;cell_type&quot;, text_by=&quot;cell_type&quot;) + ggtitle(&quot;tSNE&quot;) We can also check expression of some marker genes. CD3D and TRAC are used as marker genes for T-cells Szabo et al. 2019. plotExpression(sce, features=c(&quot;CD3D&quot;), x=&quot;label&quot;, colour_by=&quot;cell_type&quot;) plotExpression(sce, features=c(&quot;TRAC&quot;), x=&quot;label&quot;, colour_by=&quot;cell_type&quot;) 24.0.6 Extract T-cells We will now extract T-cells and store in a new SCE object to use in pseudotime analysis. Pull barcodes for T-cells tcell.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% group_by(cell_type) %&gt;% dplyr::filter(cell_type == &quot;T_cells&quot;) %&gt;% pull(Barcode) table(colData(sce)$Barcode %in% tcell.bc) ## ## FALSE TRUE ## 19478 20522 Create a new SingleCellExperiment object for T-cells tmpInd &lt;- which(colData(sce)$Barcode %in% tcell.bc) sce.tcell &lt;- sce[,tmpInd] #saveRDS(sce.tcell,&quot;~/Course_Materials/scRNAseq/pseudotime/sce.tcell.RDS&quot;) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_tcell.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/hca_sce_nz_postDeconv_5kCellPerSpl_tcell.Rds&quot; saveRDS(sce.tcell, tmpFn) rm(sce.tcell) 24.1 Setting up the data In many situations, one is studying a process where cells change continuously. This includes, for example, many differentiation processes taking place during development: following a stimulus, cells will change from one cell-type to another. Ideally, we would like to monitor the expression levels of an individual cell over time. Unfortunately, such monitoring is not possible with scRNA-seq since the cell is lysed (destroyed) when the RNA is extracted. Instead, we must sample at multiple time-points and obtain snapshots of the gene expression profiles. Since some of the cells will proceed faster along the differentiation than others, each snapshot may contain cells at varying points along the developmental progression. We use statistical methods to order the cells along one or more trajectories which represent the underlying developmental trajectories, this ordering is referred to as “pseudotime”. A recent benchmarking paper by Saelens et al provides a detailed summary of the various computational methods for trajectory inference from single-cell transcriptomics. They discuss 45 tools and evaluate them across various aspects including accuracy, scalability, and usability. They provide dynverse, an open set of packages to benchmark, construct and interpret single-cell trajectories (currently they have a uniform interface for 60 methods). We load the SCE object we have generated previously. This object contains only the T-cells from 8 healthy donors. We will first prepare the data by identifying variable genes, integrating the data across donors and calculating principal components. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_tcell.Rds&quot;, projDir, outDirBit, setName, setSuf) sce.tcell &lt;- readRDS(file=tmpFn) sce.tcell ## class: SingleCellExperiment ## dim: 20425 20522 ## metadata(0): ## assays(2): counts logcounts ## rownames(20425): AL627309.1 AL669831.5 ... AC233755.1 AC240274.1 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(19): Sample Barcode ... label cell_type ## reducedDimNames(4): MNN PCA UMAP TSNE ## altExpNames(0): dec.tcell &lt;- modelGeneVar(sce.tcell, block=sce.tcell$Sample.Name) top.tcell &lt;- getTopHVGs(dec.tcell, n=5000) set.seed(1010001) merged.tcell &lt;- fastMNN(sce.tcell, batch = sce.tcell$Sample.Name, subset.row = top.tcell) reducedDim(sce.tcell, &#39;MNN&#39;) &lt;- reducedDim(merged.tcell, &#39;corrected&#39;) sce.tcell &lt;- runPCA(sce.tcell, dimred=&quot;MNN&quot;) plotPCA(sce.tcell, colour_by=&quot;Sample.Name&quot;) 24.1.1 Trajectory inference with destiny Diffusion maps were introduced by Ronald Coifman and Stephane Lafon, and the underlying idea is to assume that the data are samples from a diffusion process. The method infers the low-dimensional manifold by estimating the eigenvalues and eigenvectors for the diffusion operator related to the data. Angerer et al have applied the diffusion maps concept to the analysis of single-cell RNA-seq data to create an R package called destiny. For ease of computation, we will perform pseudotime analysis only on one sample, and we will downsample the object to 1000 cells. We will select the sample named MantonBM1. # pull the barcodes for MantonBM1 sample &amp; and downsample the set to 1000 genes vec.bc &lt;- colData(sce.tcell) %&gt;% data.frame() %&gt;% filter(Sample.Name == &quot;MantonBM1&quot;) %&gt;% group_by(Sample.Name) %&gt;% sample_n(1000) %&gt;% pull(Barcode) Number of cells in the sample: table(colData(sce.tcell)$Barcode %in% vec.bc) ## ## FALSE TRUE ## 19522 1000 Subset cells from the main SCE object: tmpInd &lt;- which(colData(sce.tcell)$Barcode %in% vec.bc) sce.tcell.BM1 &lt;- sce.tcell[,tmpInd] sce.tcell.BM1 ## class: SingleCellExperiment ## dim: 20425 1000 ## metadata(0): ## assays(2): counts logcounts ## rownames(20425): AL627309.1 AL669831.5 ... AC233755.1 AC240274.1 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(19): Sample Barcode ... label cell_type ## reducedDimNames(4): MNN PCA UMAP TSNE ## altExpNames(0): Identify top 500 highly variable genes dec.tcell.BM1 &lt;- modelGeneVar(sce.tcell.BM1) top.tcell.BM1 &lt;- getTopHVGs(dec.tcell.BM1, n=500) We will extract normalized counts for HVG to use in pseudotime alignment tcell.BM1_counts &lt;- logcounts(sce.tcell.BM1) tcell.BM1_counts &lt;- t(as.matrix(tcell.BM1_counts[top.tcell.BM1,])) cellLabels &lt;- sce.tcell.BM1$Barcode rownames(tcell.BM1_counts) &lt;- cellLabels tcell.BM1_counts[1:4,1:4] ## CCL5 NKG7 S100A4 KLRB1 ## AAACCTGAGCAGCGTA-13 3.733773 1.609114 2.838333 0 ## AAACCTGAGCGATATA-13 0.000000 0.000000 3.889855 0 ## AAACCTGGTAATCACC-13 0.000000 0.000000 3.576974 0 ## AAACCTGGTACAGTTC-13 3.337079 1.712109 3.630169 0 And finally, we can run pseudotime alignment with destiny dm_tcell_BM1 &lt;- DiffusionMap(tcell.BM1_counts,n_pcs = 50) Plot diffusion component 1 vs diffusion component 2 (DC1 vs DC2). tmp &lt;- data.frame(DC1 = eigenvectors(dm_tcell_BM1)[, 1], DC2 = eigenvectors(dm_tcell_BM1)[, 2]) ggplot(tmp, aes(x = DC1, y = DC2)) + geom_point() + xlab(&quot;Diffusion component 1&quot;) + ylab(&quot;Diffusion component 2&quot;) + theme_classic() Stash diffusion components to SCE object sce.tcell.BM1$pseudotime_destiny_1 &lt;- eigenvectors(dm_tcell_BM1)[, 1] sce.tcell.BM1$pseudotime_destiny_2 &lt;- eigenvectors(dm_tcell_BM1)[, 2] 24.1.2 Find temporally expressed genes After running destiny, an interesting next step may be to find genes that change their expression over the course of time We demonstrate one possible method for this type of analysis on the 500 most variable genes. We will regress each gene on the pseudotime variable we have generated, using a general additive model (GAM). This allows us to detect non-linear patterns in gene expression. We are going to use HVG we identified in the previous step, but this analysis can also be done using the whole transcriptome. # Only look at the 500 most variable genes when identifying temporally expressesd genes. # Identify the variable genes by ranking all genes by their variance. # We will use the first diffusion components as a measure of pseudotime Y&lt;-log2(counts(sce.tcell.BM1)+1) colnames(Y)&lt;-cellLabels Y&lt;-Y[top.tcell.BM1,] # Fit GAM for each gene using pseudotime as independent variable. t &lt;- eigenvectors(dm_tcell_BM1)[, 1] gam.pval &lt;- apply(Y, 1, function(z){ d &lt;- data.frame(z=z, t=t) tmp &lt;- gam(z ~ lo(t), data=d) p &lt;- summary(tmp)[4][[1]][1,5] p }) Select top 30 genes for visualization # Identify genes with the most significant time-dependent model fit. topgenes &lt;- names(sort(gam.pval, decreasing = FALSE))[1:30] Visualize these genes in a heatmap heatmapdata &lt;- Y[topgenes,] heatmapdata &lt;- heatmapdata[,order(t, na.last = NA)] t_ann&lt;-as.data.frame(t) colnames(t_ann)&lt;-&quot;pseudotime&quot; pheatmap(heatmapdata, cluster_rows = T, cluster_cols = F, color = plasma(200), show_colnames = F, annotation_col = t_ann) Visualize how some of the temporally expressed genes change in time Following individual genes is very helpful for identifying genes that play an important role in the differentiation process. We illustrate the procedure using the GZMA gene. We have added the pseudotime values computed with destiny to the colData slot of the SCE object. Having done that, the full plotting capabilities of the scater package can be used to investigate relationships between gene expression, cell populations and pseudotime. plotExpression(sce.tcell.BM1, &quot;GZMA&quot;, x = &quot;pseudotime_destiny_1&quot;, show_violin = TRUE, show_smooth = TRUE) 24.1.3 Pseudotime analysis for another HCA sample # pull barcodes for MantonBM2 vec.bc &lt;- colData(sce.tcell) %&gt;% data.frame() %&gt;% filter(Sample.Name == &quot;MantonBM2&quot;) %&gt;% group_by(Sample.Name) %&gt;% sample_n(1000) %&gt;% pull(Barcode) # create another object for MantonBM2 tmpInd &lt;- which(colData(sce.tcell)$Barcode %in% vec.bc) sce.tcell.BM2 &lt;- sce.tcell[,tmpInd] # Identift HVG dec.tcell.BM2 &lt;- modelGeneVar(sce.tcell.BM2) top.tcell.BM2 &lt;- getTopHVGs(dec.tcell.BM2, n=500) # extract normalized count data for HVG tcell.BM2_counts&lt;-logcounts(sce.tcell.BM2) tcell.BM2_counts&lt;-t(as.matrix(tcell.BM2_counts[top.tcell.BM2,])) cellLabels &lt;- sce.tcell.BM2$Barcode rownames(tcell.BM2_counts) &lt;- cellLabels dm_tcell_BM2 &lt;- DiffusionMap(tcell.BM2_counts,n_pcs = 50) tmp &lt;- data.frame(DC1 = eigenvectors(dm_tcell_BM2)[, 1], DC2 = eigenvectors(dm_tcell_BM2)[, 2]) ggplot(tmp, aes(x = DC1, y = DC2)) + geom_point() + xlab(&quot;Diffusion component 1&quot;) + ylab(&quot;Diffusion component 2&quot;) + theme_classic() # tidy rm(sce.tcell) 24.1.4 Exercise 1 Obtain pseudotime for one of the Caron samples. #sce.PRET1&lt;-readRDS(&quot;~/Course_Materials/scRNAseq/pseudotime/sce_caron_PRET1.RDS&quot;) setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_allCells&quot; #tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, # no norm counts yet tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) x &lt;- readRDS(tmpFn) spl.x &lt;- colData(x) %&gt;% data.frame() %&gt;% filter(source_name == &quot;PRE-T&quot;) %&gt;% pull(Sample.Name) %&gt;% unique() %&gt;% head(1) We will use GSM3872440: # downsample by randomly choosing 1000 cells: vec.bc &lt;- colData(x) %&gt;% data.frame() %&gt;% filter(Sample.Name == spl.x) %&gt;% group_by(Sample.Name) %&gt;% sample_n(1000) %&gt;% pull(Barcode) Number of cells in the sample: table(colData(x)$Barcode %in% vec.bc) ## ## FALSE TRUE ## 46830 1000 Subset cells from the main SCE object: tmpInd &lt;- which(colData(x)$Barcode %in% vec.bc) sce.PRET1 &lt;- x[,tmpInd] rownames(sce.PRET1) &lt;- uniquifyFeatureNames(rowData(sce.PRET1)$ensembl_gene_id, names = rowData(sce.PRET1)$Symbol) sce.PRET1 ## class: SingleCellExperiment ## dim: 18431 1000 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): AL627309.1 AL669831.5 ... AC233755.1 AC240274.1 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): rm(x, vec.bc) You need to perform: * variance remodelling * HVG identification * extract normalized counts * run destiny * visualize diffusion components # Identify HVG dec.caron.PRET1 &lt;- modelGeneVar(sce.PRET1) top.caron.PRET1 &lt;- getTopHVGs(dec.caron.PRET1, n=500) # extract normalized count data for HVG caron.PRET1_counts &lt;- logcounts(sce.PRET1) caron.PRET1_counts &lt;- t(as.matrix(caron.PRET1_counts[top.caron.PRET1,])) cellLabels &lt;- sce.PRET1$Barcode rownames(caron.PRET1_counts) &lt;- cellLabels dm_caron.PRET1 &lt;- DiffusionMap(caron.PRET1_counts,n_pcs = 50) tmp &lt;- data.frame(DC1 = eigenvectors(dm_caron.PRET1)[, 1], DC2 = eigenvectors(dm_caron.PRET1)[, 2]) ggplot(tmp, aes(x = DC1, y = DC2)) + geom_point() + xlab(&quot;Diffusion component 1&quot;) + ylab(&quot;Diffusion component 2&quot;) + theme_classic() Y &lt;- log2(counts(sce.PRET1)+1) colnames(Y) &lt;- cellLabels Y &lt;- Y[top.caron.PRET1,] # Fit GAM for each gene using pseudotime as independent variable. t &lt;- eigenvectors(dm_caron.PRET1)[, 1] gam.pval &lt;- apply(Y, 1, function(z){ d &lt;- data.frame(z=z, t=t) tmp &lt;- gam(z ~ lo(t), data=d) p &lt;- summary(tmp)[4][[1]][1,5] p }) Select top 30 genes for visualization # Identify genes with the most significant time-dependent model fit. topgenes &lt;- names(sort(gam.pval, decreasing = FALSE))[1:30] Visualize these genes in a heatmap heatmapdata &lt;- Y[topgenes,] heatmapdata &lt;- heatmapdata[,order(t, na.last = NA)] t_ann&lt;-as.data.frame(t) colnames(t_ann)&lt;-&quot;pseudotime&quot; pheatmap(heatmapdata, cluster_rows = T, cluster_cols = F, color = plasma(200), show_colnames = F, annotation_col = t_ann) What kind of a dynamic process might be taking place in this cancer cell? We can quickly check in which pathways these top genes are enriched using MSigDB. Molecular Signatures Database contains 8 major collections: H: hallmark gene sets C1: positional gene sets C2: curated gene sets C3: motif gene sets C4: computational gene sets C5: GO gene sets C6: oncogenic signatures C7: immunologic signatures We are going to use hallmark gene sets (H) and perform a hypergeometric test with our top 30 genes for all HALLMARK sets. msigdb_hallmark &lt;- msigdbr(species = &quot;Homo sapiens&quot;, category = &quot;H&quot;) %&gt;% dplyr::select(gs_name, gene_symbol) em &lt;- enricher(topgenes, TERM2GENE = msigdb_hallmark) head(em)[,&quot;qvalue&quot;,drop=F] ## qvalue ## HALLMARK_E2F_TARGETS 1.497108e-18 ## HALLMARK_G2M_CHECKPOINT 2.503524e-15 ## HALLMARK_MITOTIC_SPINDLE 7.203216e-03 Let’s also check the ‘oncogenic signatures’ gene sets (C6) and perform a hypergeometric test with our top 30 genes for all these gene sets. msigdb_c6 &lt;- msigdbr(species = &quot;Homo sapiens&quot;, category = &quot;C6&quot;) %&gt;% dplyr::select(gs_name, gene_symbol) em &lt;- enricher(topgenes, TERM2GENE = msigdb_c6) head(em)[,&quot;qvalue&quot;,drop=F] ## qvalue ## CORDENONSI_YAP_CONSERVED_SIGNATURE 0.0000514776 ## GCNP_SHH_UP_LATE.V1_UP 0.0001203704 ## RB_P107_DN.V1_UP 0.0004552384 ## CSR_LATE_UP.V1_UP 0.0008812455 ## VEGF_A_UP.V1_DN 0.0012567178 ## RB_P130_DN.V1_UP 0.0047769824 Let’s write to file for future use the normalised counts for the highly variables genes: setName &lt;- &quot;hca&quot; setSuf &lt;- &quot;_5kCellPerSpl&quot; # BM1 tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, &quot;MantonBM1&quot;) saveRDS(tcell.BM1_counts, file=tmpFn) # BM2 tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, &quot;MantonBM2&quot;) saveRDS(tcell.BM2_counts, file=tmpFn) # PRE-T 1 setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_allCells&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, spl.x) saveRDS(caron.PRET1_counts, file=tmpFn) rm(sce.tcell.BM1, sce.tcell.BM2, sce.tcell.PRET1) rm(tcell.BM1_counts, tcell.BM2_counts, caron.PRET1_counts) 24.2 Pseudotime Alignment CellAlign is a tool for quantitative comparison of expression dynamics within or between single-cell trajectories. The input to the CellAlign workflow is any trajectory vector that orders single cell expression with a pseudo-time spacing and the expression matrix for the cells used to define the trajectory. cellAlign has 3 essential steps: Interpolate the data to have N evenly spaced points along the scaled pseudotime vector using a sliding window of Gaussian weights Determine the genes of interest for alignment Align your trajectory among the selected genes either along the whole trajectory or along a partial segment. The first step is to interpolate the data along the trajectory to represent the data by N (default 200) equally spaced points along the pseudotime trajectory. We included this step because single-cell measurements are often sparse or heterogeneous along the trajectory, leaving gaps that cannot be aligned. Cell-Align interpolates the gene-expression values of equally spaced artificial points using the real single-cell expression data. The expression values of the interpolated points are calculated using all cells, with each single cell assigned a weight given by a Gaussian distribution centered at the interpolated point and a width assigned by a parameter called winSz. The default winSz is 0.1, as this is the range that preserves the dynamics of the trajectory without including excessive noise for standard single cell data sets. We will use the samples analysed in the previous session: two ABMMC and one PRE-T: # HCA ABMMCs: setName &lt;- &quot;hca&quot; setSuf &lt;- &quot;_5kCellPerSpl&quot; # BM1 tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, &quot;MantonBM1&quot;) tcell.BM1_counts &lt;- readRDS(tmpFn) # BM2 tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, &quot;MantonBM2&quot;) tcell.BM2_counts &lt;- readRDS(tmpFn) # Caron PRE-T 1 setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_allCells&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, &quot;GSM3872440&quot;) caron.PRET1_counts &lt;- readRDS(tmpFn) dm_tcell_BM1 &lt;- DiffusionMap(tcell.BM1_counts,n_pcs = 50) interGlobal_hcaBM1 &lt;- interWeights(expDataBatch = t(tcell.BM1_counts), trajCond = eigenvectors(dm_tcell_BM1)[, 1], winSz = 0.1, numPts=200) dm_tcell_BM2 &lt;- DiffusionMap(tcell.BM2_counts,n_pcs = 50) interGlobal_hcaBM2 &lt;- interWeights(expDataBatch = t(tcell.BM2_counts), trajCond = eigenvectors(dm_tcell_BM2)[, 1], winSz = 0.1, numPts=200) dm_caron.PRET1 &lt;- DiffusionMap(caron.PRET1_counts,n_pcs = 50) interGlobal_caronPRET1 &lt;- interWeights(expDataBatch = t(caron.PRET1_counts), trajCond = eigenvectors(dm_caron.PRET1)[, 1], winSz = 0.1, numPts=200) Scale the expression matrix interGlobal_caronPRET1_scaled = scaleInterpolate(interGlobal_caronPRET1) interGlobal_hcaBM1_scaled = scaleInterpolate(interGlobal_hcaBM1) interGlobal_hcaBM2_scaled = scaleInterpolate(interGlobal_hcaBM2) Identify the shared genes across datasets sharedMarkers = Reduce(intersect, list(rownames(interGlobal_caronPRET1$interpolatedVals), rownames(interGlobal_hcaBM1$interpolatedVals), rownames(interGlobal_hcaBM2$interpolatedVals))) length(sharedMarkers) ## [1] 84 Finally, there is the alignment step. CellAlign operates much like sequence alignment algorithms, quantifying overall similarity in expression throughout the trajectory (global alignment), or finding areas of highly conserved expression (local alignment). Cell-Align then finds a path through the matrix that minimizes the overall distance while adhering to the following constraints: for global alignment the alignment must cover the entire extent of both trajectories, always starting in the upper left of the dissimilarity matrix and ending in the lower right. for local alignment the alignment is restricted only to highly similar cells, yielding as output regions with conserved expression dynamics Intuitively, the optimal alignment runs along a “valley” within the dissimilarity matrix. A &lt;- calcDistMat(interGlobal_caronPRET1_scaled$scaledData[sharedMarkers,], interGlobal_hcaBM1_scaled$scaledData[sharedMarkers,], dist.method = &#39;Euclidean&#39;) alignment = globalAlign(A) plotAlign(alignment) ## [1] NA B &lt;- calcDistMat(interGlobal_hcaBM1_scaled$scaledData[sharedMarkers,], interGlobal_hcaBM2_scaled$scaledData[sharedMarkers,], dist.method = &#39;Euclidean&#39;) alignment = globalAlign(B) plotAlign(alignment) ## [1] NA 24.3 Ackowledgements This notebook uses material from: SVI course, OSCA Book, Broad Institute Workshop, Hemberg Group Course, cellAlign. 24.4 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] splines parallel stats4 stats graphics grDevices utils ## [8] datasets methods base ## ## other attached packages: ## [1] celldex_1.0.0 Cairo_1.5-12.2 ## [3] cellAlign_0.1.0 clusterProfiler_3.18.1 ## [5] msigdbr_7.2.1 viridis_0.6.0 ## [7] viridisLite_0.4.0 gam_1.20 ## [9] foreach_1.5.1 destiny_3.4.0 ## [11] SingleR_1.4.1 forcats_0.5.1 ## [13] stringr_1.4.0 dplyr_1.0.5 ## [15] purrr_0.3.4 readr_1.4.0 ## [17] tidyr_1.1.3 tibble_3.1.1 ## [19] tidyverse_1.3.1 pheatmap_1.0.12 ## [21] cowplot_1.1.1 batchelor_1.6.3 ## [23] scater_1.18.6 ggplot2_3.3.3 ## [25] scran_1.18.7 SingleCellExperiment_1.12.0 ## [27] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [29] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [31] IRanges_2.24.1 S4Vectors_0.28.1 ## [33] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [35] matrixStats_0.58.0 knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] rappdirs_0.3.3 ggthemes_4.2.4 ## [3] bit64_4.0.5 irlba_2.3.3 ## [5] DelayedArray_0.16.3 data.table_1.14.0 ## [7] RCurl_1.98-1.3 generics_0.1.0 ## [9] RSQLite_2.2.5 shadowtext_0.0.7 ## [11] proxy_0.4-25 bit_4.0.4 ## [13] enrichplot_1.11.2.994 httpuv_1.5.5 ## [15] xml2_1.3.2 lubridate_1.7.10 ## [17] assertthat_0.2.1 xfun_0.22 ## [19] hms_1.0.0 jquerylib_0.1.3 ## [21] promises_1.2.0.1 evaluate_0.14 ## [23] DEoptimR_1.0-8 fansi_0.4.2 ## [25] dbplyr_2.1.1 readxl_1.3.1 ## [27] igraph_1.2.6 DBI_1.1.1 ## [29] ellipsis_0.3.2 RSpectra_0.16-0 ## [31] backports_1.2.1 bookdown_0.22 ## [33] sparseMatrixStats_1.2.1 vctrs_0.3.7 ## [35] TTR_0.24.2 abind_1.4-5 ## [37] cachem_1.0.4 RcppEigen_0.3.3.9.1 ## [39] withr_2.4.2 ggforce_0.3.3 ## [41] robustbase_0.93-7 vcd_1.4-8 ## [43] treeio_1.14.3 xts_0.12.1 ## [45] DOSE_3.16.0 ExperimentHub_1.16.1 ## [47] ape_5.4-1 lazyeval_0.2.2 ## [49] laeken_0.5.1 crayon_1.4.1 ## [51] labeling_0.4.2 edgeR_3.32.1 ## [53] pkgconfig_2.0.3 tweenr_1.0.2 ## [55] nlme_3.1-152 vipor_0.4.5 ## [57] nnet_7.3-16 rlang_0.4.10 ## [59] lifecycle_1.0.0 downloader_0.4 ## [61] BiocFileCache_1.14.0 modelr_0.1.8 ## [63] rsvd_1.0.5 AnnotationHub_2.22.1 ## [65] cellranger_1.1.0 polyclip_1.10-0 ## [67] RcppHNSW_0.3.0 lmtest_0.9-38 ## [69] Matrix_1.3-2 aplot_0.0.6 ## [71] carData_3.0-4 boot_1.3-28 ## [73] zoo_1.8-9 reprex_2.0.0 ## [75] beeswarm_0.3.1 knn.covertree_1.0 ## [77] bitops_1.0-7 blob_1.2.1 ## [79] DelayedMatrixStats_1.12.3 qvalue_2.22.0 ## [81] beachmat_2.6.4 scales_1.1.1 ## [83] memoise_2.0.0 magrittr_2.0.1 ## [85] plyr_1.8.6 hexbin_1.28.2 ## [87] zlibbioc_1.36.0 scatterpie_0.1.5 ## [89] compiler_4.0.3 dqrng_0.3.0 ## [91] RColorBrewer_1.1-2 pcaMethods_1.82.0 ## [93] dtw_1.22-3 cli_2.4.0 ## [95] XVector_0.30.0 patchwork_1.1.1 ## [97] ps_1.6.0 mgcv_1.8-35 ## [99] ggplot.multistats_1.0.0 MASS_7.3-54 ## [101] tidyselect_1.1.1 stringi_1.5.3 ## [103] highr_0.9 yaml_2.2.1 ## [105] GOSemSim_2.16.1 BiocSingular_1.6.0 ## [107] locfit_1.5-9.4 ggrepel_0.9.1 ## [109] grid_4.0.3 sass_0.3.1 ## [111] fastmatch_1.1-0 tools_4.0.3 ## [113] rio_0.5.26 rstudioapi_0.13 ## [115] bluster_1.0.0 foreign_0.8-81 ## [117] gridExtra_2.3 smoother_1.1 ## [119] Rtsne_0.15 scatterplot3d_0.3-41 ## [121] farver_2.1.0 ggraph_2.0.5 ## [123] digest_0.6.27 rvcheck_0.1.8 ## [125] BiocManager_1.30.12 shiny_1.6.0 ## [127] Rcpp_1.0.6 car_3.0-10 ## [129] broom_0.7.6 scuttle_1.0.4 ## [131] later_1.2.0 BiocVersion_3.12.0 ## [133] RcppAnnoy_0.0.18 httr_1.4.2 ## [135] AnnotationDbi_1.52.0 colorspace_2.0-0 ## [137] rvest_1.0.0 fs_1.5.0 ## [139] ranger_0.12.1 uwot_0.1.10 ## [141] statmod_1.4.35 tidytree_0.3.3 ## [143] graphlayouts_0.7.1 sp_1.4-5 ## [145] xtable_1.8-4 jsonlite_1.7.2 ## [147] ggtree_2.4.1 tidygraph_1.2.0 ## [149] R6_2.5.0 mime_0.10 ## [151] pillar_1.6.0 htmltools_0.5.1.1 ## [153] glue_1.4.2 fastmap_1.1.0 ## [155] VIM_6.1.0 BiocParallel_1.24.1 ## [157] BiocNeighbors_1.8.2 interactiveDisplayBase_1.28.0 ## [159] class_7.3-19 codetools_0.2-18 ## [161] fgsea_1.16.0 utf8_1.2.1 ## [163] lattice_0.20-44 bslib_0.2.4 ## [165] ResidualMatrix_1.0.0 curl_4.3.1 ## [167] ggbeeswarm_0.6.0 zip_2.1.1 ## [169] GO.db_3.12.1 openxlsx_4.2.3 ## [171] limma_3.46.0 rmarkdown_2.7 ## [173] munsell_0.5.0 e1071_1.7-6 ## [175] DO.db_2.9 GenomeInfoDbData_1.2.4 ## [177] iterators_1.0.13 haven_2.4.1 ## [179] reshape2_1.4.4 gtable_0.3.0 "],["doubletDetectionTop.html", "Chapter 25 Doublet detection 25.1 Learning objectives 25.2 Set up analysis 25.3 Load data 25.4 Overview 25.5 Doublet detection by simulation 25.6 Further comments 25.7 Session information", " Chapter 25 Doublet detection Source: Doublet detection chapter of the OSCA book (with only few edits of its text). 25.1 Learning objectives In this section we will learn how to identify droplets that may include more than one cell, using a method based on simulation of doublets from the single-cell expression profiles. 25.2 Set up analysis Let’s set some variables (eg path to files) and load R packages. projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool splSetToGet &lt;- params$splSetToGet setName &lt;- params$setName setSuf &lt;- params$setSuf dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;dummy&quot; setSuf &lt;- &quot;_allCells&quot; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 We will load: ggplot2, for plots dplyr, for data management scater, for UMI count normalisation scran, here for doublet detection library(ggplot2) library(scater) # for logNormCounts library(scran) library(dplyr) #library(BiocSingular) # for faster PCA library(scDblFinder) # for doublet detection library(Cairo) fontsize &lt;- theme(axis.text=element_text(size=12), axis.title=element_text(size=16)) 25.3 Load data We will load the R file keeping the SCE object with the normalised counts (no cell subsampling). tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, # or Qc projDir, outDirBit, setName, setSuf) Input file: /ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells.Rds. if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) Number of genes: . Number of cells: 47830. 25.4 Overview In single-cell RNA sequencing (scRNA-seq) experiments, doublets are artifactual libraries generated from two cells. They typically arise due to errors in cell sorting or capture, especially in droplet-based protocols (Zheng et al. 2017) involving thousands of cells. Doublets are obviously undesirable when the aim is to characterize populations at the single-cell level. In particular, doublets can be mistaken for intermediate populations or transitory states that do not actually exist. Thus, it is desirable to identify and remove doublet libraries so that they do not compromise interpretation of the results. Several experimental strategies are available for doublet removal. One approach exploits natural genetic variation when pooling cells from multiple donor individuals (Kang et al. 2018). Doublets can be identified as libraries with allele combinations that do not exist in any single donor. Another approach is to mark a subset of cells (e.g., all cells from one sample) with an antibody conjugated to a different oligonucleotide (Stoeckius, Zheng, et al. 2017). Upon pooling, libraries that are observed to have different oligonucleotides are considered to be doublets and removed. These approaches can be highly effective but rely on experimental information that may not be available. A more general approach is to infer doublets from the expression profiles alone (Dahlin et al. 2018). The Doublet detection chapter of the OSCA book also describes a second method, which relies on clusters identified, and their quality. 25.5 Doublet detection by simulation This strategy involves in silico simulation of doublets from the single-cell expression profiles (Dahlin et al. 2018). This is performed using the computeDoubletDensity() function from the scDblFinder package. &lt;– ex doubletCells() from scran –&gt;, which will: Simulate thousands of doublets by adding together two randomly chosen single-cell profiles. For each original cell, compute the density of simulated doublets in the surrounding neighborhood. For each original cell, compute the density of other observed cells in the neighborhood. Return the ratio between the two densities as a “doublet score” for each cell. This approach assumes that the simulated doublets are good approximations for real doublets. The use of random selection accounts for the relative abundances of different subpopulations, which affect the likelihood of their involvement in doublets; and the calculation of a ratio avoids high scores for non-doublet cells in highly abundant subpopulations. We see the function in action below. To speed up the density calculations, computeDoubletDensity() will perform a PCA on the log-expression matrix, and we perform some (optional) parametrization to ensure that the computed PCs are consistent with that from our previous analysis on this dataset. We will get data for one sample, e.g. the first PRE-T sample. spl.x &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(source_name == &quot;PRE-T&quot;) %&gt;% pull(Sample.Name) %&gt;% unique() %&gt;% head(1) sce &lt;- sce[,sce$Sample.Name == spl.x ] set.seed(123) #--- normalization ---# library(scran) #set.seed(101000110) clusters &lt;- quickCluster(sce) sce &lt;- computeSumFactors(sce, clusters=clusters) sce &lt;- logNormCounts(sce) #--- variance-modelling ---# #set.seed(00010101) dec.sce &lt;- modelGeneVarByPoisson(sce) top.sce &lt;- getTopHVGs(dec.sce, prop=0.1) #--- dimensionality-reduction ---# #set.seed(101010011) sce &lt;- denoisePCA(sce, technical=dec.sce, subset.row=top.sce) sce &lt;- runTSNE(sce, dimred=&quot;PCA&quot;) #--- clustering ---# snn.gr &lt;- buildSNNGraph(sce, use.dimred=&quot;PCA&quot;, k=25) sce$cluster &lt;- factor(igraph::cluster_walktrap(snn.gr)$membership) sce$clusterStg &lt;- factor(paste0(&quot;c&quot;, sce$cluster), levels = paste0(&quot;c&quot;, levels( sce$cluster)) ) We also plot the t-SNE showing clusters, which are not used for the doublet detection by simulation used here, but help visualise cells with different expression profiles. colLabels(sce) &lt;- sce$clusterStg plotTSNE(sce, colour_by=&quot;clusterStg&quot;) Let us run computeDoubletDensity() and display moments of the distribution of the doublet scores returned: set.seed(100) # Setting up the parameters for consistency with denoisePCA(); # this can be changed depending on your feature selection scheme. dbl.dens &lt;- computeDoubletDensity(sce, subset.row = top.sce, dims = ncol(reducedDim(sce))) summary(dbl.dens) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0000 0.3918 0.8834 1.0596 1.4826 8.8036 The t-SNE plot below help identify any cluster with high number of cell with a high score. sce$DoubletScore &lt;- log10(dbl.dens+1) plotTSNE(sce, colour_by=&quot;DoubletScore&quot;) The violin plot below shows the distribution of score across clusters identified in the whole data set. Clusters with a large fraction of high-scoring cells are worth checking. Comparing marker genes for these clusters to other, ‘doublet-free’ clusters may inform on the type of cells involved. If the ‘source’ clusters are not related biologically these high-scoring cells should be discarded. If on the other hand the ‘source’ clusters are two well defined steps along a differentiation path, the high-scoring cells may represent an intermediary state. plotColData(sce, y = &quot;DoubletScore&quot;, x = &quot;clusterStg&quot;, colour_by = &quot;DoubletScore&quot;) The advantage of computeDoubletDensity() is that it does not depend on clusters, reducing the sensitivity of the results to clustering quality. The downside is that it requires some strong assumptions about how doublets form, such as the combining proportions and the sampling from pure subpopulations. In particular, computeDoubletDensity() treats the library size of each cell as an accurate proxy for its total RNA content. If this is not true, the simulation will not combine expression profiles from different cells in the correct proportions. This means that the simulated doublets will be systematically shifted away from the real doublets, resulting in doublet scores that are too low. Simply removing cells with high doublet scores will not be sufficient to eliminate real doublets from the data set. In some cases, only a subset of the cells in the putative doublet cluster actually have high scores, and removing these would still leave enough cells in that cluster to mislead downstream analyses. In fact, even defining a threshold on the doublet score is difficult as the interpretation of the score is relative. There is no general definition for a fixed threshold above which libraries are to be considered doublets. We recommend interpreting the computeDoubletDensity() scores in the context of cluster annotation. All cells from a cluster with a large average doublet score should be considered suspect, and close neighbors of problematic clusters should also be treated with caution. In contrast, a cluster containing a small proportion of high-scoring cells is probably safe provided that any interesting results are not being driven by those cells (e.g., checking that DE in an interesting gene is not driven solely by cells with high doublet scores). While clustering is still required, this approach is more robust than doubletClusters() to the quality of the clustering as the scores are computed on a per-cell basis. (As an aside, the issue of unknown combining proportions can be solved completely if spike-in information is available, e.g., in plate-based protocols. This will provide an accurate estimate of the total RNA content of each cell. To this end, spike-in-based size factors from Section 7.4 can be supplied to the computeDoubletDensity() function via the size.factors.content= argument. This will use the spike-in size factors to scale the contribution of each cell to a doublet library.) 25.6 Further comments Doublet detection procedures should only be applied to libraries generated in the same experimental batch. It is obviously impossible for doublets to form between two cells that were captured separately. Thus, some understanding of the experimental design is required prior to the use of the above functions. This avoids unnecessary concerns about the validity of batch-specific clusters that cannot possibly consist of doublets. It is also difficult to interpret doublet predictions in data containing cellular trajectories. By definition, cells in the middle of a trajectory are always intermediate between other cells and are liable to be incorrectly detected as doublets. Some protection is provided by the non-linear nature of many real trajectories, which reduces the risk of simulated doublets coinciding with real cells in doubletCells(). One can also put more weight on the relative library sizes in doubletCluster() instead of relying solely on N, under the assumption that sudden spikes in RNA content are unlikely in a continuous biological process. The best solution to the doublet problem is experimental - that is, to avoid generating them in the first place. This should be a consideration when designing scRNA-seq experiments, where the desire to obtain large numbers of cells at minimum cost should be weighed against the general deterioration in data quality and reliability when doublets become more frequent. 25.7 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] Cairo_1.5-12.2 scDblFinder_1.4.0 ## [3] dplyr_1.0.5 scran_1.18.7 ## [5] scater_1.18.6 SingleCellExperiment_1.12.0 ## [7] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [9] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [11] IRanges_2.24.1 S4Vectors_0.28.1 ## [13] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [15] matrixStats_0.58.0 ggplot2_3.3.3 ## [17] knitr_1.32 ## ## loaded via a namespace (and not attached): ## [1] bitops_1.0-7 tools_4.0.3 ## [3] bslib_0.2.4 utf8_1.2.1 ## [5] R6_2.5.0 irlba_2.3.3 ## [7] vipor_0.4.5 DBI_1.1.1 ## [9] colorspace_2.0-0 withr_2.4.2 ## [11] tidyselect_1.1.1 gridExtra_2.3 ## [13] compiler_4.0.3 BiocNeighbors_1.8.2 ## [15] DelayedArray_0.16.3 labeling_0.4.2 ## [17] bookdown_0.22 sass_0.3.1 ## [19] scales_1.1.1 stringr_1.4.0 ## [21] digest_0.6.27 rmarkdown_2.7 ## [23] XVector_0.30.0 pkgconfig_2.0.3 ## [25] htmltools_0.5.1.1 sparseMatrixStats_1.2.1 ## [27] highr_0.9 limma_3.46.0 ## [29] rlang_0.4.10 DelayedMatrixStats_1.12.3 ## [31] farver_2.1.0 jquerylib_0.1.3 ## [33] generics_0.1.0 jsonlite_1.7.2 ## [35] BiocParallel_1.24.1 RCurl_1.98-1.3 ## [37] magrittr_2.0.1 BiocSingular_1.6.0 ## [39] GenomeInfoDbData_1.2.4 scuttle_1.0.4 ## [41] Matrix_1.3-2 Rcpp_1.0.6 ## [43] ggbeeswarm_0.6.0 munsell_0.5.0 ## [45] fansi_0.4.2 viridis_0.6.0 ## [47] lifecycle_1.0.0 stringi_1.5.3 ## [49] yaml_2.2.1 edgeR_3.32.1 ## [51] zlibbioc_1.36.0 Rtsne_0.15 ## [53] grid_4.0.3 dqrng_0.3.0 ## [55] crayon_1.4.1 lattice_0.20-44 ## [57] cowplot_1.1.1 beachmat_2.6.4 ## [59] locfit_1.5-9.4 pillar_1.6.0 ## [61] igraph_1.2.6 xgboost_1.3.2.1 ## [63] codetools_0.2-18 glue_1.4.2 ## [65] evaluate_0.14 data.table_1.14.0 ## [67] vctrs_0.3.7 gtable_0.3.0 ## [69] purrr_0.3.4 assertthat_0.2.1 ## [71] xfun_0.22 rsvd_1.0.5 ## [73] viridisLite_0.4.0 tibble_3.1.1 ## [75] beeswarm_0.3.1 bluster_1.0.0 ## [77] statmod_1.4.35 ellipsis_0.3.2 "],["annex.html", "Chapter 26 Annex", " Chapter 26 Annex The chapters listed below are included in the annex: Data integration - PBMMC and ETV6-RUNX, with all cells (no downsampling) (see @ref(dsi_allCells_allSetsTop)). Data integration - all ‘Caron’ sample types (ETV6-RUNX1, HHD, PBMMCand PRE-T), with all cells (no downsampling) (see @ref(dsi_allCells_PBMMC_ETV6-RUNX1Top)). #qcPlotDirBit &lt;- &quot;NormPlots&quot; #setNameUpp &lt;- &quot;Caron&quot; projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool library(knitr) isChild &lt;- &quot;yes&quot; # TRUE #src &lt;- lapply(c(&quot;_5hCellPerSpl&quot;), src &lt;- lapply(c(&quot;_allCells&quot;), function(setSuf, isChild) { knit_expand(file = &quot;dataSetIntegration_PBMMC_ETV6-RUNX1.Rmd&quot;) }) "],["dsi-allCells-PBMMC-ETV6-RUNX1Top.html", "Chapter 27 Data integration - PBMMC and ETV6-RUNX 27.1 Abbreviations 27.2 Motivation 27.3 Load data 27.4 Loading the data 27.5 Diagnosing batch effects 27.6 Linear regression 27.7 Performing MNN correction 27.8 Correction diagnostics 27.9 Encouraging consistency with marker genes 27.10 Identify clusters with PBMMC cells 27.11 Session information", " Chapter 27 Data integration - PBMMC and ETV6-RUNX projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool splSetToGet &lt;- params$splSetToGet setName &lt;- params$setName setSuf &lt;- params$setSuf if(exists(&quot;isChild&quot;)) { setSuf &lt;- &quot;_allCells&quot; } if(params$bookType == &quot;mk&quot;){ splSetToGet &lt;- &quot;PBMMC,ETV6-RUNX1&quot; setName &lt;- &quot;caron&quot; setSuf &lt;- &quot;_5hCellPerSpl&quot; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 Source: ‘Integrating Datasets’ chapter in the OSCA book. Its text is reproduced below with few modifications to adapt it to the data set under scrutiny here. 27.1 Abbreviations HVG: highly variable genes MNN: mutual nearest neighbors PBMMC: peripheral blood mononuclear cell SCE: SingleCellExperiment 27.2 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. 27.3 Load data Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 27.4 Loading the data We will load the R file keeping the SCE object with the normalised counts, and subset 1000 cells per sample. ##setName &lt;- &quot;caron&quot; #setSuf &lt;- &quot;&quot; ##setSuf &lt;- &quot;_allCells&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; We next subset the data for the PBMMC,ETV6-RUNX1 sample group: # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) #splVec &lt;- cb_sampleSheet %&gt;% filter(source_name == splSetToGet) %&gt;% splVec &lt;- cb_sampleSheet %&gt;% filter(source_name %in% splSetVec) %&gt;% pull(Sample.Name) %&gt;% unique sourceNames &lt;- unique(colData(sce)$source_name) sceOrig &lt;- sce sce &lt;- sceOrig[,sce$source_name %in% splSetVec ] nbCells &lt;- 1000 #nbCells &lt;- 3000 all.sce &lt;- list() # if &#39;_allCells&#39;, then downsample for faster run # else (ie _5hCellPerSpl so far), do not downsample. if(setSuf == &quot;_allCells&quot;) { for(spx in splVec) { #nbCellsToGet &lt;- min(ncol(sce), nbCells) vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% ###slice_sample(n=nbCellsToGet) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } } else { for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name == spx) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } } nbSpl &lt;- length(all.sce) We then apply the standard workflow to each sample separately: * normalisation, * variance modelling * dimensionality reduction * clustering #--- normalization ---# # use logNormCounts() all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# # model varaince with modelGeneVar() # find highly variable genes (HVGs) with getTopHVGs() all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# # use runPCA() # then compute embeddings with runTSNE() and runUMAP() library(BiocSingular) set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) set.seed(100000) all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) set.seed(1000000) all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# # cluster each sample separately for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;) clust &lt;- igraph::cluster_walktrap(g)$membership #colLabels(all.sce[[n]]) &lt;- factor(clust) all.sce[[n]]$label &lt;- factor(clust) } To prepare for the batch correction: We subset all batches to the common “universe” of features. In this case, it is straightforward as both batches use Ensembl gene annotation. allNames &lt;- unlist(lapply(all.sce, function(x){rownames(x)})) allNamesNb &lt;- table(allNames) universe &lt;- names(allNamesNb)[allNamesNb==nbSpl] #length(universe) The size of this common “universe” of features here is the number of features shared by all 7 samples is: 18431. # Subsetting the SingleCellExperiment object. uni.sce &lt;- lapply(all.sce, function(x){x[universe,]}) # Also subsetting the variance modelling results, for convenience. uni.dec &lt;- lapply(all.dec, function(x){x[universe,]}) We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment (SCE) objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. # rescale each batch to adjust for differences in sequencing depth between batches rescaled &lt;- multiBatchNorm(uni.sce, batch = &quot;Sample.Name&quot;) We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. # compute average variance components across samples #combined.dec &lt;- combineVar(uni.dec[[1]], uni.dec[[2]], uni.dec[[3]], uni.dec[[4]]) combined.dec &lt;- combineVar(uni.dec) # identify highly variables genes # here as those with a positive biological component chosen.hvgs &lt;- combined.dec$bio &gt; 0 #sum(chosen.hvgs) Number of HVGs: 11479. When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons. 27.5 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the SCE objects and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. for (i in 2:nbSpl) { identical(rowData(rescaled[[1]]), rowData(rescaled[[i]])) } rescaled[[1]]$batch &lt;- rescaled[[1]]$Sample.Name rescaled2 &lt;- lapply(rescaled, function(x){x$batch &lt;- x$Sample.Name; x}) rescaled &lt;- rescaled2 # concat matrices: uncorrected &lt;- do.call(cbind, rescaled) # Perform PCA # Using RandomParam() as it is more efficient for file-backed matrices. set.seed(0010101010) uncorrected &lt;- runPCA(uncorrected, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) We use graph-based clustering on the components to obtain a summary of the population structure. As the samples should be replicates, each cluster should ideally consist of cells from each batch. However, we instead see clusters that are comprised of cells from a single batch. This indicates that cells of the same type are artificially separated due to technical differences between batches. # build shared nearest-neighbour graph snn.gr &lt;- buildSNNGraph(uncorrected, use.dimred=&quot;PCA&quot;) # identify cluster with the walk trap method clusters &lt;- igraph::cluster_walktrap(snn.gr)$membership # get number of cells for each {cluster, batch} pair tab &lt;- table(Cluster=clusters, Batch=uncorrected$batch) #tab tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) Cluster size and cell contribution by sample: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(&quot;uncorrected, cell numbers&quot;) + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(&quot;uncorrected, proportions&quot;) + theme(legend.text = element_text(size = 7)) gridExtra::grid.arrange(p1, p2) We can also visualize the uncorrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results. set.seed(1111001) uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;) p &lt;- plotTSNE(uncorrected, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) + theme(legend.text = element_text(size = 7)) p p + facet_wrap(~uncorrected$source_name) Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations. If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. Let us write the corresponding SCE object. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s_uncorr.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(uncorrected, file=fn) 27.6 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. rescaled2 &lt;- rescaleBatches(rescaled) rescaled2 ## class: SingleCellExperiment ## dim: 18431 30373 ## metadata(0): ## assays(1): corrected ## rownames(18431): ENSG00000000003 ENSG00000000419 ... ENSG00000285486 ## ENSG00000285492 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## altExpNames(0): After clustering, we observe that most clusters consist of mixtures of cells from the two replicate batches, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches in Figure 13.2. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches. set.seed(1010101010) # To ensure reproducibility of IRLBA. rescaled2 &lt;- runPCA(rescaled2, subset_row=chosen.hvgs, exprs_values=&quot;corrected&quot;) snn.gr &lt;- buildSNNGraph(rescaled2, use.dimred=&quot;PCA&quot;) clusters.resc &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled2$batch) #tab.resc tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.resc, &quot;batch&quot;=rescaled2$batch) Cluster size and cell contribution by sample, with clusters sorted by size: tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) + theme(legend.text = element_text(size = 7)) gridExtra::grid.arrange(p1, p2) Compute and plot t-SNE: rescaled2 &lt;- runTSNE(rescaled2, dimred=&quot;PCA&quot;) rescaled2$batch &lt;- factor(rescaled2$batch) p &lt;- plotTSNE(rescaled2, colour_by=&quot;batch&quot;) p p + facet_wrap(~uncorrected$source_name) 27.7 Performing MNN correction 27.7.1 Algorithm overview Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space. 27.7.2 Application to the data The batchelor package provides an implementation of the MNN approach via the fastMNN() function. (Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps.) We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN(rescaled, auto.merge=TRUE, d=50, k=20, subset.row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out ## class: SingleCellExperiment ## dim: 11479 30373 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(11479): ENSG00000000003 ENSG00000000457 ... ENSG00000285476 ## ENSG00000285492 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out.corre.dim &lt;- dim(reducedDim(mnn.out, &quot;corrected&quot;)) mnn.out.corre.dim ## [1] 30373 50 mnn.out.recon.dim &lt;- dim(assay(mnn.out, &quot;reconstructed&quot;)) mnn.out.recon.dim ## [1] 11479 30373 The function returns a SCE object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses (30373 cells and 50 PCs). A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space (11479 genes and 30373 cells). We do not recommend using this for anything other than visualization. print(assay(mnn.out, &quot;reconstructed&quot;)[1:5,1:3]) ## &lt;5 x 3&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ## ENSG00000000003 -5.902379e-05 -7.632313e-06 9.875261e-06 ## ENSG00000000457 -4.816878e-08 5.578027e-04 1.373828e-04 ## ENSG00000000938 -3.879057e-04 3.008405e-04 -3.233694e-04 ## ENSG00000001167 6.875635e-04 9.056937e-04 9.538919e-04 ## ENSG00000001461 -1.115437e-03 -6.349251e-04 -9.276477e-04 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. colDataList &lt;- lapply(rescaled, function(x){colData(x)}) colDataDf &lt;- do.call(rbind, colDataList) #colData(mnn.out) &lt;- cbind(colDataDf, colData(mnn.out)$cluster) colData(mnn.out) &lt;- DataFrame(colDataDf) # no rearrainging of columns by mnncorrect 27.8 Correction diagnostics 27.8.1 Mixing between batches We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the batches are replicates of each other. snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, k=20) clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 ## 1 0 1 27 48 5 126 ## 2 162 332 69 269 50 16 ## 3 0 2 3 6 126 209 ## 4 1 0 5 3 3 24 ## 5 0 7 12 2 359 191 ## 6 11 139 1320 221 590 1047 ## 7 3 1 38 266 0 503 ## 8 0 13 2 4 4 10 ## 9 1164 415 139 292 41 34 ## 10 1 2 30 90 5 124 ## 11 1 2 18 63 0 0 ## 12 0 0 0 0 44 41 ## 13 0 0 32 87 0 35 ## 14 0 0 22 53 6 146 ## 15 0 1 2 1 7 45 ## 16 0 0 0 0 89 43 ## 17 12 3 2 3 81 58 ## 18 0 5 27 133 2 143 ## 19 0 0 2 8 14 40 ## 20 1 4 49 176 0 301 ## 21 5 19 72 31 58 318 ## 22 1 0 2 1 0 18 ## 23 0 8 8 1 11 21 ## 24 0 0 1 4 17 64 ## 25 925 2692 550 1845 37 30 ## 26 96 132 26 179 15 3 ## 27 224 500 173 736 47 19 ## 28 6 53 289 60 42 137 ## 29 2 0 10 7 12 74 ## 30 1 1 10 17 0 1 ## 31 0 4 17 35 2 12 ## 32 49 1817 1156 189 17 15 ## 33 0 0 0 0 7 16 ## 34 0 0 0 0 23 17 ## 35 80 248 59 85 15 24 ## 36 0 0 0 0 76 18 ## 37 0 0 19 42 1 0 ## 38 2 47 239 71 34 168 ## 39 0 0 7 0 6 53 ## 40 0 0 0 0 51 13 ## 41 0 0 0 0 55 46 ## 42 15 0 2 3 0 8 ## 43 0 1 13 19 0 68 ## 44 1 2 4 1 55 23 ## 45 0 1 0 0 9 12 ## 46 0 0 18 28 0 2 ## 47 4 54 215 71 32 251 ## 48 0 0 0 0 9 31 ## 49 84 101 16 118 2 2 ## 50 0 0 0 0 23 35 ## 51 2 8 22 25 2 23 ## Batch ## Cluster GSM3872444 ## 1 31 ## 2 45 ## 3 394 ## 4 7 ## 5 744 ## 6 872 ## 7 8 ## 8 18 ## 9 72 ## 10 10 ## 11 3 ## 12 52 ## 13 9 ## 14 21 ## 15 137 ## 16 109 ## 17 73 ## 18 11 ## 19 14 ## 20 27 ## 21 197 ## 22 2 ## 23 15 ## 24 16 ## 25 91 ## 26 14 ## 27 44 ## 28 150 ## 29 11 ## 30 7 ## 31 37 ## 32 78 ## 33 10 ## 34 20 ## 35 12 ## 36 81 ## 37 3 ## 38 200 ## 39 16 ## 40 29 ## 41 60 ## 42 11 ## 43 11 ## 44 39 ## 45 20 ## 46 0 ## 47 189 ## 48 32 ## 49 9 ## 50 30 ## 51 52 Cluster size and cell contribution by sample, with clusters sorted by size: #mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions mnn.out$Sample.Name &lt;- uncorrected$Sample.Name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$Sample.Name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) + theme(legend.text = element_text(size = 7)) gridExtra::grid.arrange(p1, p2) Cluster size and cell contribution by sample type, with clusters sorted by size: mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) We can also compute the variation in the log-abundances to rank the clusters with the greatest variability in their proportional abundances across batches. We can then focus on batch-specific clusters that may be indicative of incomplete batch correction. Obviously, though, this diagnostic is subject to interpretation as the same outcome can be caused by batch-specific populations; some prior knowledge about the biological context is necessary to distinguish between these two possibilities. The table below shows the number of cells for each cluster (row) and sample (column) together with the variance in cell number across these samples (‘var’ column). # Avoid minor difficulties with the &#39;table&#39; class. tab.mnn &lt;- unclass(tab.mnn) # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) # Ranking clusters by the largest variances. rv &lt;- rowVars(norm) %&gt;% round(2) # show #DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),] DataFrame(tab.mnn, var=rv)[order(rv, decreasing=TRUE),] ## DataFrame with 51 rows and 8 columns ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 5 0 7 12 2 359 191 ## 3 0 2 3 6 126 209 ## 25 925 2692 550 1845 37 30 ## 7 3 1 38 266 0 503 ## 6 11 139 1320 221 590 1047 ## ... ... ... ... ... ... ... ## 42 15 0 2 3 0 8 ## 4 1 0 5 3 3 24 ## 8 0 13 2 4 4 10 ## 22 1 0 2 1 0 18 ## 30 1 1 10 17 0 1 ## GSM3872444 var ## &lt;integer&gt; &lt;numeric&gt; ## 5 744 8.10 ## 3 394 6.08 ## 25 91 5.28 ## 7 8 5.03 ## 6 872 4.75 ## ... ... ... ## 42 11 0.41 ## 4 7 0.31 ## 8 18 0.27 ## 22 2 0.25 ## 30 7 0.25 We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from both batches provides a comforting illusion that the correction was successful. set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;) mnn.out$batch &lt;- factor(mnn.out$batch) p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;) p #mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) #p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, shape_by=&quot;type&quot;) #p + facet_wrap(. ~ mnn.out$type) p + facet_wrap(. ~ mnn.out$source_name) For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). round(metadata(mnn.out)$merge.info$lost.var,2) ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 ## [1,] 0.00 0.00 0.00 0.00 0.00 0.06 ## [2,] 0.00 0.00 0.08 0.00 0.00 0.00 ## [3,] 0.00 0.00 0.01 0.09 0.00 0.01 ## [4,] 0.00 0.06 0.02 0.04 0.00 0.04 ## [5,] 0.00 0.02 0.07 0.11 0.08 0.13 ## [6,] 0.08 0.00 0.00 0.00 0.00 0.00 ## GSM3872444 ## [1,] 0.03 ## [2,] 0.01 ## [3,] 0.00 ## [4,] 0.01 ## [5,] 0.04 ## [6,] 0.00 Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. The following t-SNE shows the clusters identified: mnn.out$cluster &lt;- paste0(&quot;c&quot;, clusters.mnn) p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;, shape_by=&quot;source_name&quot;) p p + facet_wrap(~colData(mnn.out)$batch) The following t-SNE plots show expression levels of known cell type marker genes. genesToShow &lt;- c( &quot;CD79A&quot;, # CD79A B *** &quot;CST3&quot;, # CST3 monocytes *** &quot;CD3D&quot;, # CD3D T cells *** &quot;HBA1&quot; # HBA1 erythrocytes *** ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] #``` #B cells: #```{r fastmnn_diagTsneB_dsi_allCells_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pB &lt;- p #``` #T cells: #```{r fastmnn_diagTsneT_dsi_allCells_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[3] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pT &lt;- p #``` #monocytes: #```{r fastmnn_diagTsneM_dsi_allCells_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[2] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pM &lt;- p #``` #erythrocytes: #```{r fastmnn_diagTsneE_dsi_allCells_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pE &lt;- p gridExtra::grid.arrange(pB + theme(legend.position=&quot;bottom&quot;), pT + theme(legend.position=&quot;bottom&quot;), pM + theme(legend.position=&quot;bottom&quot;), pE + theme(legend.position=&quot;bottom&quot;), ncol=2) Compare to the uncorrected values: # B cells genex &lt;- ensToShow[1] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pBu &lt;- p #``` #Compare to the uncorrected values, T cells: #```{r uncorr_diagTsneT_dsi_allCells_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[3] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pTu &lt;- p #``` #Compare to the uncorrected values, monocytes: #```{r uncorr_diagTsneM_dsi_allCells_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[2] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pMu &lt;- p #``` #Compare to the uncorrected values, erythrocytes: #```{r uncorr_diagTsneE_dsi_allCells_PBMMC_ETV6-RUNX1} genex &lt;- ensToShow[4] p &lt;- plotTSNE(uncorrected, colour_by = genex) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) pEu &lt;- p gridExtra::grid.arrange(pBu + theme(legend.position=&quot;bottom&quot;), pTu + theme(legend.position=&quot;bottom&quot;), pMu + theme(legend.position=&quot;bottom&quot;), pEu + theme(legend.position=&quot;bottom&quot;), ncol=2) Other genes (exercise) genesToShow2 &lt;- c( &quot;IL7R&quot;, # IL7R, CCR7 Naive CD4+ T &quot;CCR7&quot;, # IL7R, CCR7 Naive CD4+ T &quot;S100A4&quot;, # IL7R, S100A4 Memory CD4+ &quot;CD14&quot;, # CD14, LYZ CD14+ Mono &quot;LYZ&quot;, # CD14, LYZ CD14+ Mono &quot;MS4A1&quot;, # MS4A1 B &quot;CD8A&quot;, # CD8A CD8+ T &quot;FCGR3A&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;MS4A7&quot;, # FCGR3A, MS4A7 FCGR3A+ Mono &quot;GNLY&quot;, # GNLY, NKG7 NK &quot;NKG7&quot;, # GNLY, NKG7 NK &quot;FCER1A&quot;, # DC &quot;CST3&quot;, # DC &quot;PPBP&quot; # Platelet ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow2) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] table(ensToShow %in% rownames(rowData(mnn.out))) ensToShow &lt;- ensToShow[ensToShow %in% rownames(rowData(mnn.out))] for (genex in ensToShow) { p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(paste(genex, rowData(uncorrected)[genex,&quot;Symbol&quot;])) print(p) } 27.8.2 Preserving biological heterogeneity 27.8.2.1 Comparison between within-batch clusters and across-batch clusters obtained after MNN correction Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries are zero, though this may depend on whether specific clusters of interest are gained or lost. One heatmap is generated for each dataset, where each entry is colored according to the number of cells with each pair of labels (before and after correction), on the log10 scale with pseudocounts (+10) for a smoother color transition (so a minimum value of log10(0+10) == 1). plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled2$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled[[splIdx]]), cl.2=clusters.mnn[rescaled2$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) #gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, nrow=2, ncol=1, heights=c(unit(.8, &quot;npc&quot;), unit(.2, &quot;npc&quot;))) if(FALSE) { grobx &lt;- gridExtra::grid.arrange(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, nrow=3, ncol=2, heights=c(unit(.8, &quot;npc&quot;), unit(.1, &quot;npc&quot;), unit(.1, &quot;npc&quot;)), widths=c(unit(.3, &quot;npc&quot;), unit(.7, &quot;npc&quot;)), layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE) ) } if(FALSE) { grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, pColour.leg, pSize.leg, #nrow=3, ncol=2, #layout_matrix=matrix(c(1,1,2,5,4,3), ncol=2, byrow=TRUE), nrow=2, ncol=3, layout_matrix=matrix(c(1,1,2,5,4,3), ncol=3, byrow=FALSE), widths=c(unit(.70, &quot;npc&quot;), unit(.15, &quot;npc&quot;), unit(.15, &quot;npc&quot;)), heights=c(unit(.7, &quot;npc&quot;), unit(.3, &quot;npc&quot;)) ) } grobx &lt;- gridExtra::arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##gridExtra::marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’ in pink, ‘after’ in blue) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} #gridExtra::grid.arrange(grobs = treeList, gridExtra::grid.arrange(grobs = gxList, ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) gridExtra::grid.arrange(grobs = treeList, ncol=2 ) 27.8.2.2 Coassignment probabilities Another evaluation approach is to compute the coassignment probabilities, i.e. the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place. The plots below display the coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each sample, where each entry is colored according to the coassignment probability between each pair of within-batch clusters: # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled[[splIdx]]), clusters.mnn[rescaled2$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair (in pairwiseRand() with mode=“ratio” and adjusted=FALSE). The Rand index is introduced below. 27.8.2.3 Rand index Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled[[splIdx]])), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872442 GSM3872443 GSM3872444 ## 0.22 0.26 0.70 0.50 0.59 0.76 0.72 A sample may show a low Rand index value if cells grouped together in a small cluster before correction are split into distinct clusters after correction because the latter comprise cell populations not observed in that sample but present in other samples. This would be the case of GSM3872434 with far fewer erythrocytes (grouped in a single cluster) than GSM3872443, in which subtypes can be distinguished. We can also break down the adjusted Rand index (ARI) into per-cluster ratios for more detailed diagnostics. For example, we could see low ratios off the diagonal if distinct clusters in the within-batch clustering were incorrectly aggregated in the merged clustering. Conversely, we might see low ratios on the diagonal if the correction inflated or introduced spurious heterogeneity inside a within-batch cluster. # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled[[splIdx]])), alt=as.integer(clusters.mnn[rescaled2$batch==splVec[splIdx]]) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) gridExtra::grid.arrange(grobs = grobList, ncol=2 ) 27.9 Encouraging consistency with marker genes In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach that is a natural extension of the strategy described in the feature selection section. We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by SingleR. In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN(). # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. markerList &lt;- lapply(rescaled, function(x){ y &lt;- pairwiseWilcox(x, direction=&quot;up&quot;) getTopMarkers(y[[1]], y[[2]], n=10) %&gt;% unlist %&gt;% unlist }) marker.set &lt;- unique(unlist(markerList)) #length(marker.set) # getting the total number of genes selected in this manner. The total number of genes selected in this manner is: 1059. set.seed(1000110) mnn.out2 &lt;- fastMNN(rescaled, subset.row=marker.set, BSPARAM=BiocSingular::RandomParam(deferred=TRUE)) mnn.out2$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions # compute t-SNE: mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;) We can also visualize the corrected coordinates using a t-SNE plot: plotTSNE(mnn.out2, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) plotTSNE(mnn.out2, colour_by=&quot;source_name&quot;) + facet_wrap(~colData(mnn.out2)$source_name, ncol=2) plotTSNE(mnn.out2, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) + facet_wrap(~colData(mnn.out2)$batch, ncol=3) A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (x in 1:length(splVec)) { plotList[[x]] &lt;- plotTSNE(mnn.out2[,mnn.out2$batch==splVec[x]], colour_by=I(colLabels(rescaled[[x]]))) + ggtitle(splVec[x]) } gridExtra::grid.arrange(grobs = plotList, ncol=3 ) m.out &lt;- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE]) #lapply(m.out, function(x){head(x[,2:6])}) tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) Expression level for the top gene, on violin plots: geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, ENSG00000008517 on t-SNE plot: Not Encouraging consistency with marker genes genex &lt;- rownames(demo)[1] genex &lt;- demo %&gt;% data.frame %&gt;% filter(!str_detect(Symbol, &quot;^RP&quot;)) %&gt;% pull(ensembl_gene_id) %&gt;% head(1) p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out)$batch) gridExtra::grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) Encouraging consistency with marker genes #genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out2, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out2)$batch) gridExtra::grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) We suggest limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. # before we save the mnn.out object in a file, # we should copy some of the cell meta data over, # eg Barcode and lib size. # Mind sets may have been downsampled, eg with nbCells set to 1000. # But that is not in the file name (yet?) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s.Rds&quot;, #fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi2_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(mnn.out, file=fn) #saveRDS(mnn.out2, file=fn) 27.10 Identify clusters with PBMMC cells Cluster size and cell contribution by sample type, with clusters sorted by size: mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) gridExtra::grid.arrange(p1, p2) Cluster size and cell contribution by sample type, with clusters sorted by decreasing proportion of PBMMC: tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name, &quot;Sample.Name&quot;=mnn.out$batch ) sortVecNames &lt;- round(tmpMatTab/rowSums(tmpMatTab),2) %&gt;% as.data.frame() %&gt;% filter(batch==&quot;PBMMC&quot;) %&gt;% arrange(desc(Freq)) %&gt;% pull(clusters) tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(&quot;clusters&quot;=tmpMat$clusters, &quot;batch&quot;=tmpMat$batch) #tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() tmpMatDf &lt;- tmpMatTab[,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) #gridExtra::grid.arrange(p1, p2) p3 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=Sample.Name)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) p4 &lt;- p3 + scale_y_continuous(labels = scales::percent) p1 &lt;- p1 + theme(legend.text = element_text(size = 5)) p2 &lt;- p2 + theme(legend.text = element_text(size = 5)) p3 &lt;- p3 + theme(legend.text = element_text(size = 5)) + facet_wrap(~tmpMat$batch) p4 &lt;- p4 + theme(legend.text = element_text(size = 5)) #gridExtra::grid.arrange(p1, p2, p3) gridExtra::grid.arrange(p1, p2, p4, p3, ncol=1) rm(p1, p2, p3, p4) tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=as.character(mnn.out$batch)) #Batch=as.character(mnn.out$source_name)) #tab.mnn &lt;- as.data.frame(tab.mnn, stringsAsFactors=FALSE) ##tab.mnn # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) normNoLog &lt;- normalizeCounts(tab.mnn, pseudo_count=10, log=FALSE) sortVecNames &lt;- rowSums(normNoLog) %&gt;% round(2) %&gt;% sort(decreasing=TRUE) %&gt;% names #norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% #tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% #tidyr::pivot_longer(!clusters, names_to=&quot;Sample.Name&quot;, values_to=&quot;Freq&quot;) norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% rename(clusters = Cluster) %&gt;% rename(Sample.Name = Batch) norm2 &lt;- norm2 %&gt;% left_join(unique(cb_sampleSheet[,c(&quot;Sample.Name&quot;, &quot;source_name&quot;)]), by=&quot;Sample.Name&quot;) norm2$clusters &lt;- factor(norm2$clusters, levels=sortVecNames) #norm2 &lt;- norm2 %&gt;% as.data.frame() # fill by sample type p1 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() # fill by sample name p2 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=Sample.Name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() # split by sample type p3 &lt;- p2 + facet_wrap(~source_name) # show gridExtra::grid.arrange(p1, p2, p3) rm(p1, p2, p3) tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=as.character(mnn.out$source_name)) ##tab.mnn # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. #norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) normNoLog &lt;- normalizeCounts(tab.mnn, pseudo_count=10, log=FALSE) normNoLog &lt;- normNoLog %&gt;% as.data.frame.matrix() # sort by PBMMC proportion: normNoLog &lt;- normNoLog %&gt;% mutate(sum=rowSums(.)) normNoLog &lt;- normNoLog %&gt;% mutate(prop=PBMMC/sum) sortVecNames &lt;- normNoLog %&gt;% tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% arrange(desc(prop)) %&gt;% pull(clusters) norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% select(-sum, -prop) %&gt;% tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% tidyr::pivot_longer(!clusters, names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) norm2$clusters &lt;- factor(norm2$clusters, levels=sortVecNames) p1 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- p1 + facet_wrap(~source_name) # show gridExtra::grid.arrange(p1, p2) rm(p1, p2) Have threshold for proportion of PBMMC cells, say 50%, and keep clusters with PBMMC proportion below that threshold. normNoLog$propLt090 &lt;- normNoLog$prop &lt; 0.9 normNoLog$propLt080 &lt;- normNoLog$prop &lt; 0.8 normNoLog$propLt050 &lt;- normNoLog$prop &lt; 0.5 norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% select(-sum, -prop) %&gt;% tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% #tidyr::pivot_longer(!c(clusters,propLt090), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) #tidyr::pivot_longer(!c(clusters,propLt090,propLt080), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) #tidyr::pivot_longer(!c(clusters,propLt090,propLt080,propLt050), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) tidyr::pivot_longer(!c(clusters, grep(&quot;propLt&quot;, colnames(normNoLog), value=TRUE) ), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) norm2$clusters &lt;- factor(norm2$clusters, levels=sortVecNames) p1 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() #p + facet_wrap(~propLt090) #p + facet_wrap(~propLt080) p2 &lt;- p1 + facet_wrap(~propLt050) # show gridExtra::grid.arrange(p1, p2) rm(p1, p2) Corresponding TSNE, with cluster and expression level of top gene: propLtDf &lt;- norm2 %&gt;% select(clusters,propLt050) %&gt;% unique() propLtDf$cluster &lt;- paste0(&quot;c&quot;, propLtDf$clusters) colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% left_join(propLtDf[,c(&quot;cluster&quot;,&quot;propLt050&quot;)], by=&quot;cluster&quot;) %&gt;% DataFrame() # cluster: p &lt;- plotTSNE(mnn.out, colour_by = &quot;cluster&quot;, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(&quot;clusters&quot;) p1 &lt;- p + facet_wrap(~mnn.out$propLt050) + theme(legend.position=&#39;bottom&#39;) # top gene for some cluster: #genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) p2 &lt;- p + facet_wrap(~mnn.out$propLt050) + theme(legend.position=&#39;bottom&#39;) # show gridExtra::grid.arrange(p1, p2) rm(p, p1, p2) Same as above but with propLt080: keep clusters with PBMMC proportion lower than 80%: propLtDf &lt;- norm2 %&gt;% select(clusters,propLt080) %&gt;% unique() propLtDf$cluster &lt;- paste0(&quot;c&quot;, propLtDf$clusters) propLtDf$clusters &lt;- NULL colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% left_join(propLtDf, by=&quot;cluster&quot;) %&gt;% DataFrame() p1 &lt;- ggplot(data=norm2, aes(x=clusters,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() #p + facet_wrap(~propLt090) #p + facet_wrap(~propLt080) p2 &lt;- p1 + facet_wrap(~propLt080) # show gridExtra::grid.arrange(p1, p2) rm(p1, p2) # cluster: p &lt;- plotTSNE(mnn.out, colour_by = &quot;cluster&quot;, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(&quot;clusters&quot;) p1 &lt;- p + facet_wrap(~mnn.out$propLt080) + theme(legend.position=&#39;bottom&#39;) # top gene for some cluster: genex &lt;- rownames(demo)[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) #print(p) p2 &lt;- p + facet_wrap(~mnn.out$propLt080) + theme(legend.position=&#39;bottom&#39;) # show gridExtra::grid.arrange(p1, p2) rm(p, p1, p2) Check expression of cell type marker genes, for PBMMC proportion threshold of 50%: for (genex in ensToShow) { p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;) + ggtitle(paste(rowData(uncorrected)[genex,&quot;Symbol&quot;], &quot; aka&quot;, genex)) + facet_wrap(~mnn.out$propLt050) print(p) } Some clusters with a high proportion of PBMMC cells also comprise a large number of cancer cells. To select clusters to keep, we could use the following inclusion criteria: proportion of PBMMC cells in cluster is lower than the threshold for the proportion of PBMMC cells in a cluster, eg 50% proportion of cancer cells in cluster higher than 5% of cells of that sample type The bar plots below show the clusters ordered by decreasing proportion of PBMMC and also split by selection outcome (where ‘TRUE’ means inclusion). normNoLog &lt;- normNoLog %&gt;% tibble::rownames_to_column(&quot;cluster&quot;) normNoLog$cluster &lt;- paste0(&quot;c&quot;, normNoLog$cluster) otherSplType &lt;- setdiff(splSetVec, &quot;PBMMC&quot;) # ok for pairs of sample types #thdSize &lt;- sum(normNoLog[,otherSplType])*0.02 thdSize &lt;- sum(normNoLog[,otherSplType])*0.05 thdPropPbmmc &lt;- 0.5 #propLtDf &lt;- norm2 %&gt;% select(clusters,propLt050) %&gt;% unique() #propLtDf$cluster &lt;- paste0(&quot;c&quot;, propLtDf$clusters) propLtDf &lt;- normNoLog %&gt;% filter(prop &lt; thdPropPbmmc | !!sym(otherSplType) &gt; thdSize) # ok for pairs of sample types normNoLog &lt;- normNoLog %&gt;% mutate(tmpCluBool= ifelse((prop &lt; thdPropPbmmc | !!sym(otherSplType) &gt; thdSize), TRUE, FALSE)) colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% #select(-tmpCluBool) %&gt;% left_join(normNoLog[,c(&quot;cluster&quot;, &quot;tmpCluBool&quot;)], by=&quot;cluster&quot;) %&gt;% DataFrame() norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% select(-sum, -prop) %&gt;% select(-c(grep(&quot;propOut&quot;, colnames(normNoLog), value=TRUE))) %&gt;% select(-c(grep(&quot;propLt&quot;, colnames(normNoLog), value=TRUE))) %&gt;% #tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% tidyr::pivot_longer(!c(cluster, grep(&quot;tmpCluBool&quot;, colnames(normNoLog), value=TRUE) ), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) norm2$cluster &lt;- factor(norm2$cluster, levels=paste0(&quot;c&quot;, sortVecNames)) p &lt;- ggplot(data=norm2, aes(x=cluster,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() gridExtra::grid.arrange(p, p + facet_wrap(norm2$tmpCluBool)) rm(p) # cluster: p &lt;- plotTSNE(mnn.out, colour_by = &quot;cluster&quot;, by_exprs_values=&quot;reconstructed&quot;) p &lt;- p + ggtitle(&quot;clusters&quot;) p1 &lt;- p + facet_wrap(~mnn.out$tmpCluBool) + theme(legend.position=&#39;bottom&#39;) # show p1 rm(p, p1) #mnn.out$tmpCluBool &lt;- NULL splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s_normNoLog.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(normNoLog, file=fn) 27.11 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] BiocSingular_1.6.0 Cairo_1.5-12.2 ## [3] clustree_0.4.3 ggraph_2.0.5 ## [5] pheatmap_1.0.12 forcats_0.5.1 ## [7] stringr_1.4.0 dplyr_1.0.6 ## [9] purrr_0.3.4 readr_1.4.0 ## [11] tidyr_1.1.3 tibble_3.1.2 ## [13] tidyverse_1.3.1 bluster_1.0.0 ## [15] batchelor_1.6.3 scran_1.18.7 ## [17] scater_1.18.6 SingleCellExperiment_1.12.0 ## [19] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [21] GenomicRanges_1.42.0 GenomeInfoDb_1.26.7 ## [23] IRanges_2.24.1 S4Vectors_0.28.1 ## [25] BiocGenerics_0.36.1 MatrixGenerics_1.2.1 ## [27] matrixStats_0.58.0 ggplot2_3.3.3 ## [29] knitr_1.33 ## ## loaded via a namespace (and not attached): ## [1] Rtsne_0.15 ggbeeswarm_0.6.0 ## [3] colorspace_2.0-1 ellipsis_0.3.2 ## [5] scuttle_1.0.4 XVector_0.30.0 ## [7] BiocNeighbors_1.8.2 fs_1.5.0 ## [9] rstudioapi_0.13 farver_2.1.0 ## [11] graphlayouts_0.7.1 ggrepel_0.9.1 ## [13] RSpectra_0.16-0 fansi_0.4.2 ## [15] lubridate_1.7.10 xml2_1.3.2 ## [17] codetools_0.2-18 sparseMatrixStats_1.2.1 ## [19] polyclip_1.10-0 jsonlite_1.7.2 ## [21] ResidualMatrix_1.0.0 broom_0.7.6 ## [23] dbplyr_2.1.1 uwot_0.1.10 ## [25] ggforce_0.3.3 compiler_4.0.3 ## [27] httr_1.4.2 dqrng_0.3.0 ## [29] backports_1.2.1 assertthat_0.2.1 ## [31] Matrix_1.3-3 limma_3.46.0 ## [33] cli_2.5.0 tweenr_1.0.2 ## [35] htmltools_0.5.1.1 tools_4.0.3 ## [37] rsvd_1.0.5 igraph_1.2.6 ## [39] gtable_0.3.0 glue_1.4.2 ## [41] GenomeInfoDbData_1.2.4 Rcpp_1.0.6 ## [43] cellranger_1.1.0 jquerylib_0.1.4 ## [45] vctrs_0.3.8 DelayedMatrixStats_1.12.3 ## [47] xfun_0.23 ps_1.6.0 ## [49] beachmat_2.6.4 rvest_1.0.0 ## [51] lifecycle_1.0.0 irlba_2.3.3 ## [53] statmod_1.4.36 edgeR_3.32.1 ## [55] zlibbioc_1.36.0 MASS_7.3-54 ## [57] scales_1.1.1 tidygraph_1.2.0 ## [59] hms_1.0.0 RColorBrewer_1.1-2 ## [61] yaml_2.2.1 gridExtra_2.3 ## [63] sass_0.4.0 stringi_1.6.1 ## [65] highr_0.9 checkmate_2.0.0 ## [67] BiocParallel_1.24.1 rlang_0.4.11 ## [69] pkgconfig_2.0.3 bitops_1.0-7 ## [71] evaluate_0.14 lattice_0.20-44 ## [73] labeling_0.4.2 cowplot_1.1.1 ## [75] tidyselect_1.1.1 RcppAnnoy_0.0.18 ## [77] magrittr_2.0.1 bookdown_0.22 ## [79] R6_2.5.0 generics_0.1.0 ## [81] DelayedArray_0.16.3 DBI_1.1.1 ## [83] pillar_1.6.1 haven_2.4.1 ## [85] withr_2.4.2 RCurl_1.98-1.3 ## [87] modelr_0.1.8 crayon_1.4.1 ## [89] utf8_1.2.1 rmarkdown_2.8 ## [91] viridis_0.6.1 locfit_1.5-9.4 ## [93] grid_4.0.3 readxl_1.3.1 ## [95] FNN_1.1.3 reprex_2.0.0 ## [97] digest_0.6.27 munsell_0.5.0 ## [99] beeswarm_0.3.1 viridisLite_0.4.0 ## [101] vipor_0.4.5 bslib_0.2.5 #qcPlotDirBit &lt;- &quot;NormPlots&quot; #setNameUpp &lt;- &quot;Caron&quot; projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool library(knitr) isChild &lt;- &quot;yes&quot; # TRUE #src &lt;- lapply(c(&quot;_5hCellPerSpl&quot;), src &lt;- lapply(c(&quot;_allCells&quot;), function(setSuf, isChild) { knit_expand(file = &quot;dataSetIntegration_allSets.Rmd&quot;) }) "],["dsi-allCells-allSetsTop.html", "Chapter 28 Data integration - all Caron sample types 28.1 Motivation 28.2 Load the data 28.3 Diagnosing batch effects 28.4 Linear regression 28.5 Mutual Nearest Neighbour correction 28.6 Correction diagnostics 28.7 Challenge Same but with an ordered merging 28.8 Identify clusters with PBMMC cells 28.9 Session information", " Chapter 28 Data integration - all Caron sample types projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit cacheBool &lt;- params$cacheBool splSetToGet &lt;- params$splSetToGet setName &lt;- params$setName setSuf &lt;- params$setSuf if(exists(&quot;isChild&quot;)) { setSuf &lt;- &quot;_allCells&quot; } dsiSuf &lt;- params$dsiSuf # &#39;dsi&#39; for data set integration if(params$bookType == &quot;mk&quot;){ setName &lt;- &quot;caron&quot; splSetToGet &lt;- &quot;dummy&quot; setSuf &lt;- &quot;_allCells&quot; } splSetVec &lt;- unlist(strsplit(splSetToGet, &quot;,&quot;)) # params may not be read in if knitting book. splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) nbPcToComp &lt;- 50 figSize &lt;- 7 library(BiocParallel) bpp &lt;- MulticoreParam(8) Source: Integrating Datasets of the OSCA book and the fastMNN manual. 28.1 Motivation Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results. Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable. 28.2 Load the data We will load the R file keeping the SCE object with the normalised counts. #setName &lt;- &quot;caron&quot; # Read object in: #setSuf &lt;- &quot;&quot; tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds&quot;, projDir, outDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/AnaKmWiC/Robjects/caron_sce_nz_postDeconv_allCells.Rds&quot; if(!file.exists(tmpFn)) { knitr::knit_exit() } sce &lt;- readRDS(tmpFn) sce ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(2): counts logcounts ## rownames(18431): ENSG00000238009 ENSG00000237491 ... ENSG00000275063 ## ENSG00000271254 ## rowData names(11): ensembl_gene_id external_gene_name ... detected ## gene_sparsity ## colnames: NULL ## colData names(17): Sample Barcode ... cell_sparsity sizeFactor ## reducedDimNames(0): ## altExpNames(0): colnames(rowData(sce))[colnames(rowData(sce)) == &quot;strand&quot;] &lt;- &quot;strandNum&quot; # to avoid error later #head(rowData(sce)) #head(colData(sce)) table(colData(sce)$block) ## ## ABMMC ETV6-RUNX1 HHD PBMMC PRE-T ## 0 19488 9988 10885 7469 #assayNames(sce) #reducedDimNames(sce) Read in the sample sheet: # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) cb_sampleSheet &lt;- cb_sampleSheet %&gt;% filter(!Run == &quot;SRR9264351&quot;) cb_sampleSheet[1:2,] ## Run Assay.Type AvgSpotLen Bases BioProject BioSample ## 1 SRR9264343 RNA-Seq 132 27850288884 PRJNA548203 SAMN12011162 ## 2 SRR9264344 RNA-Seq 132 43613421192 PRJNA548203 SAMN12011172 ## Bytes Cell_type ## 1 18644549905 Pre-B t(12;21) [ETV6-RUNX1] acute lymphoblastic leukemia cells ## 2 27638885644 Pre-B t(12;21) [ETV6-RUNX1] acute lymphoblastic leukemia cells ## Center.Name Consent DATASTORE.filetype DATASTORE.provider ## 1 GEO public fastq,sra gs,ncbi,s3 ## 2 GEO public fastq,sra gs,ncbi,s3 ## DATASTORE.region disease_state ## 1 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## 2 gs.US,ncbi.public,s3.us-east-1 Childhood acute lymphoblastic leukemia ## Experiment GEO_Accession..exp. Instrument LibraryLayout ## 1 SRX6034681 GSM3872434 Illumina HiSeq 4000 PAIRED ## 2 SRX6034682 GSM3872435 Illumina HiSeq 4000 PAIRED ## LibrarySelection LibrarySource Organism Platform ReleaseDate ## 1 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## 2 cDNA TRANSCRIPTOMIC Homo sapiens ILLUMINA 2020-02-14T00:00:00Z ## Sample.Name source_name SRA.Study ## 1 GSM3872434 ETV6-RUNX1 SRP201012 ## 2 GSM3872435 ETV6-RUNX1 SRP201012 Have sample names: cb_sampleSheet$Sample.Name2 &lt;- &quot;NA&quot; typeVec &lt;- unique(cb_sampleSheet$source_name) for (tx in typeVec) { tmpInd &lt;- which(cb_sampleSheet$source_name == tx) for (i in 1:length(tmpInd)) { cb_sampleSheet$Sample.Name2[tmpInd[i]] &lt;- sprintf(&quot;%s_%s&quot;, tx, i) } } colData(sce)$Sample.Name2 &lt;- colData(sce) %&gt;% data.frame() %&gt;% left_join( cb_sampleSheet, by=&quot;Sample.Name&quot;) %&gt;% pull(Sample.Name2) splVec &lt;- cb_sampleSheet %&gt;% #filter(source_name == &quot;ETV6-RUNX1&quot;) %&gt;% pull(Sample.Name2) splVec ## [1] &quot;ETV6-RUNX1_1&quot; &quot;ETV6-RUNX1_2&quot; &quot;ETV6-RUNX1_3&quot; &quot;ETV6-RUNX1_4&quot; &quot;HHD_1&quot; ## [6] &quot;HHD_2&quot; &quot;PRE-T_1&quot; &quot;PRE-T_2&quot; &quot;PBMMC_1&quot; &quot;PBMMC_2&quot; ## [11] &quot;PBMMC_3&quot; # mind we now have a downsampled set to use all along # so avoid doing it again # also, changes setsuf to shorter form eg _5hCps, which we could use from the start TODO all.sce &lt;- list() if(setSuf == &quot;_allCells&quot; | setSuf == &quot;_5hCellPerSpl&quot;) { for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name2 == spx) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } } else { nbCells &lt;- 500 setSuf &lt;- &quot;_5hCps&quot; # &quot;_5hCellPerSpl&quot; #nbCells &lt;- 1000 #setSuf &lt;- &quot;_1kCps&quot; # &quot;_1kCellPerSpl&quot; for(spx in splVec) { vec.bc &lt;- colData(sce) %&gt;% data.frame() %&gt;% filter(Sample.Name2 == spx) %&gt;% slice_sample(n=nbCells) %&gt;% pull(Barcode) tmpInd &lt;- which(colData(sce)$Barcode %in% vec.bc) all.sce[[spx]] &lt;- sce[,tmpInd] } } # show size of sets: lapply(all.sce, dim) ## $`ETV6-RUNX1_1` ## [1] 18431 2853 ## ## $`ETV6-RUNX1_2` ## [1] 18431 6615 ## ## $`ETV6-RUNX1_3` ## [1] 18431 4727 ## ## $`ETV6-RUNX1_4` ## [1] 18431 5293 ## ## $HHD_1 ## [1] 18431 4551 ## ## $HHD_2 ## [1] 18431 5437 ## ## $`PRE-T_1` ## [1] 18431 3841 ## ## $`PRE-T_2` ## [1] 18431 3628 ## ## $PBMMC_1 ## [1] 18431 2084 ## ## $PBMMC_2 ## [1] 18431 4658 ## ## $PBMMC_3 ## [1] 18431 4143 # set number of samples: nbSpl &lt;- length(all.sce) We will analyse each sample separately, namely: normalise counts model gene expression variance identify highly variable genes perform dimensionality reduction cluster cells #--- normalization ---# all.sce &lt;- lapply(all.sce, logNormCounts) #--- variance-modelling ---# library(scran) all.dec &lt;- lapply(all.sce, modelGeneVar) all.hvgs &lt;- lapply(all.dec, getTopHVGs, prop=0.1) #--- dimensionality-reduction ---# set.seed(10000) all.sce &lt;- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), SIMPLIFY=FALSE) # TSNE #set.seed(100000) #all.sce &lt;- lapply(all.sce, runTSNE, dimred=&quot;PCA&quot;) # UMAP #set.seed(1000000) #all.sce &lt;- lapply(all.sce, runUMAP, dimred=&quot;PCA&quot;) #--- clustering ---# for (n in names(all.sce)) { g &lt;- buildSNNGraph(all.sce[[n]], k=10, use.dimred=&#39;PCA&#39;, BPPARAM=bpp) clust &lt;- igraph::cluster_walktrap(g)$membership colLabels(all.sce[[n]]) &lt;- factor(clust) } To prepare for the batch correction, we need to: subset all batches to the common “universe” of features rescale each batch to adjust for differences in sequencing depth between batches perform feature selection by averaging the variance components across all batches We subset all batches to the common “universe” of features. In this case, it is straightforward as batches use Ensembl gene annotation. allNames &lt;- unlist(lapply(all.sce, function(x){rownames(x)})) allNamesNb &lt;- table(allNames) universe &lt;- names(allNamesNb)[allNamesNb==length(splVec)] length(universe) ## [1] 18431 # Subsetting the SingleCellExperiment object. uni.sce &lt;- lapply(all.sce, function(x){x[universe,]}) # Also subsetting the variance modelling results, for convenience. uni.dec &lt;- lapply(all.dec, function(x){x[universe,]}) We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches. library(batchelor) rescaled.mbn &lt;- multiBatchNorm(uni.sce, batch = &quot;Sample.Name2&quot;) We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. This allows us to use the same strategies described in Section 8.3 to select genes of interest. In contrast, approaches based on taking the intersection or union of HVGs across batches become increasingly conservative or liberal, respectively, with an increasing number of batches. library(scran) combined.dec &lt;- combineVar( uni.dec[[1]], uni.dec[[2]], uni.dec[[3]], uni.dec[[4]], uni.dec[[5]], uni.dec[[6]], uni.dec[[7]], uni.dec[[8]], uni.dec[[9]], uni.dec[[10]], uni.dec[[11]] ) chosen.hvgs &lt;- combined.dec$bio &gt; 0 sum(chosen.hvgs) ## [1] 12466 When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. That said, many of the signal-to-noise considerations described in Section 8.3 still apply here, so some experimentation may be necessary for best results. Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons. 28.3 Diagnosing batch effects Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the SingleCellExperiments and perform a PCA on the log-expression values for all genes with positive (average) biological components. # Synchronizing the metadata for cbind()ing. #identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[2]])) #identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[3]])) #identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[4]])) rescaled2 &lt;- lapply(rescaled.mbn, function(x){x$batch &lt;- x$Sample.Name2; x}) rescaled.mbn &lt;- rescaled2 rm(rescaled2) uncorrected &lt;- do.call(cbind, rescaled.mbn) # Using RandomParam() as it is more efficient for file-backed matrices. library(scater) set.seed(0010101010) uncorrected &lt;- runPCA( uncorrected, subset_row=chosen.hvgs, BSPARAM=BiocSingular::RandomParam()) # adjust walk.trap number of steps to that of cells nSteps &lt;- 4 # walktrap default if(ncol(uncorrected) &gt; 10000){ nSteps &lt;- 20 # or else get 63 clusters with caron allCells } We use graph-based clustering on the components to obtain a summary of the population structure. As our each sample group is represented by at least two replicates, each cluster should ideally consist of cells from several batches. This is the case for some but not all clusters. Some clusters comprise of cells from a single sample. This may indicate that cells of the same type are artificially separated due to technical differences between batches. They may also be cancer cell population private to samples. # 30+ min run # see clusterRows below for faster run ptm &lt;- proc.time() library(scran) snn.gr &lt;- buildSNNGraph(uncorrected, use.dimred=&quot;PCA&quot;, BPPARAM=bpp) #clusters &lt;- igraph::cluster_walktrap(snn.gr, steps=nSteps)$membership # slow clusters &lt;- igraph::cluster_fast_greedy(snn.gr)$membership proc.time() - ptm ## user system elapsed ## 47.374 1.456 35.222 #tab &lt;- table(Cluster=clusters, Batch=uncorrected$batch) #tab df.uncorr &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) tab.uncorr &lt;- table(df.uncorr) pheatmap::pheatmap(tab.uncorr, border_color = NA, drop_levels = TRUE, cluster_cols = FALSE ) # NNGraphParam k? # k is for makeSNNGraph: nearest neighbors to consider during graph construction ptm &lt;- proc.time() set.seed(1000) nSteps &lt;- 4 # walktrap default clusters &lt;- clusterRows(reducedDim(uncorrected, &quot;PCA&quot;), TwoStepParam(KmeansParam(centers=2000,iter.max=30), NNGraphParam( shared = TRUE, k=5, cluster.fun = &quot;walktrap&quot;, cluster.args = list(steps=nSteps) ))) proc.time() - ptm ## user system elapsed ## 14.064 0.007 14.089 ##tab2 &lt;- table(Cluster=clusters, Batch=uncorrected$batch) ##tab2 df.uncorr &lt;- data.frame(&quot;clusters&quot;=clusters, &quot;batch&quot;=uncorrected$batch) tab.uncorr &lt;- table(df.uncorr) pheatmap::pheatmap(tab.uncorr, border_color = NA, drop_levels = TRUE, cluster_cols = FALSE ) Cluster size and cell contribution by sample: tmpMat &lt;- df.uncorr tmpMatTab &lt;- tab.uncorr sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + geom_col() + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(&quot;uncorrected, cell numbers&quot;) + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(labels = scales::percent) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(&quot;uncorrected, proportions&quot;) + theme(legend.text = element_text(size = 7)) grid.arrange(p1, p2) #legend &lt;- get_legend(p1) legend &lt;- get_legend(p1 + theme(legend.position=&quot;bottom&quot;)) #p1 &lt;- p1 + theme(legend.position=&quot;none&quot;) #p2 &lt;- p2 + theme(legend.position=&quot;none&quot;) grid.arrange(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), legend, ncol=1, heights=c(5, 5, 2) ) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) We can also visualize the corrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results. set.seed(1111001) #uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;) uncorrected &lt;- runTSNE(uncorrected, dimred=&quot;PCA&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) # draw: p &lt;- plotTSNE(uncorrected, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) + theme(legend.text = element_text(size = 7)) p p + facet_wrap(~uncorrected$source_name, ncol=2) We can also visualize the corrected coordinates using a UMAP plot: set.seed(1111001) #uncorrected &lt;- runUMAP(uncorrected, dimred=&quot;PCA&quot;) uncorrected &lt;- runUMAP(uncorrected, dimred=&quot;PCA&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) p &lt;- plotUMAP(uncorrected, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) p p + facet_wrap(~uncorrected$source_name, ncol=2) #grid.arrange( # p, # p + facet_wrap(~uncorrected$source_name, ncol=2), # ncol=2) legend &lt;- get_legend(p) p &lt;- p + theme(legend.position=&quot;none&quot;) grid.arrange(arrangeGrob(p, p + facet_wrap(~uncorrected$source_name, ncol=2), ncol=2), legend, widths=c(5/6, 1/6), ncol=2) Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations. If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations. 28.4 Linear regression Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012). To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common. We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix. #library(batchelor) rescaled.rb &lt;- rescaleBatches(rescaled.mbn) rescaled.rb ## class: SingleCellExperiment ## dim: 18431 47830 ## metadata(0): ## assays(1): corrected ## rownames(18431): ENSG00000000003 ENSG00000000419 ... ENSG00000285486 ## ENSG00000285492 ## rowData names(0): ## colnames: NULL ## colData names(1): batch ## reducedDimNames(0): ## altExpNames(0): After clustering, we observe fewer clusters and these consist of mixtures of cells from the several replicates, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches on the TSNE plot below. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches. ptm &lt;- proc.time() set.seed(1010101010) # To ensure reproducibility of IRLBA. rescaled.rb &lt;- runPCA(rescaled.rb, subset_row=chosen.hvgs, exprs_values=&quot;corrected&quot;, #BSPARAM=IrlbaParam(), BSPARAM=RandomParam(), BPPARAM=bpp ) proc.time() - ptm ## user system elapsed ## 6.389 6.325 103.213 ptm &lt;- proc.time() snn.gr &lt;- buildSNNGraph(rescaled.rb, use.dimred=&quot;PCA&quot;, # or use BSPARAM BPPARAM=bpp) proc.time() - ptm ## user system elapsed ## 581.464 140.281 18.888 ptm &lt;- proc.time() #clusters.resc &lt;- igraph::cluster_walktrap(snn.gr, steps=nSteps)$membership # slow clusters.resc &lt;- igraph::cluster_louvain(snn.gr)$membership #clusters.resc &lt;- igraph::cluster_fast_greedy(snn.gr)$membership # coarse proc.time() - ptm ## user system elapsed ## 31.505 0.348 31.912 rescaled.rb$clusters.resc &lt;- factor(clusters.resc) ##tab.resc &lt;- table(Cluster=clusters.resc, Batch=rescaled.rb$batch) ##tab.resc df.resc &lt;- data.frame(&quot;clusters&quot;=clusters.resc, &quot;batch&quot;=rescaled.rb$batch) tab.resc &lt;- table(df.resc) pheatmap::pheatmap(tab.resc, border_color = NA, drop_levels = TRUE, cluster_cols = FALSE ) Cluster size and cell contribution by sample, with clusters sorted by size: tmpMat &lt;- df.resc tmpMatTab &lt;- tab.resc sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) + theme(legend.text = element_text(size = 7)) #grid.arrange(p1, p2) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) Compute and plot t-SNE: rescaled.rb &lt;- runTSNE(rescaled.rb, dimred=&quot;PCA&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) rescaled.rb$batch &lt;- factor(rescaled.rb$batch) rescaled.rb$source_name &lt;- uncorrected$source_name p &lt;- plotTSNE(rescaled.rb, colour_by=&quot;batch&quot;, point_size=0.3) p p + facet_wrap(~rescaled.rb$source_name) ptm &lt;- proc.time() p.clu &lt;- plotTSNE(rescaled.rb, colour_by=&quot;clusters.resc&quot;, point_size=0.3) p.batch &lt;- plotTSNE(rescaled.rb, colour_by=&quot;batch&quot;, point_size=0.3) grid.arrange(p.clu, p.batch, ncol=2) proc.time() - ptm ## user system elapsed ## 0.539 0.015 0.555 28.5 Mutual Nearest Neighbour correction 28.5.1 Algorithm overview Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors (MNNs) are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values. Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space. 28.5.2 Application to the data The batchelor package provides an implementation of the MNN approach via the fastMNN() function. Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps. We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space. # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) mnn.out &lt;- fastMNN( rescaled.mbn, auto.merge=TRUE, d=50, k=20, subset.row=chosen.hvgs, BSPARAM=RandomParam(deferred=TRUE), BPPARAM=bpp ) mnn.out ## class: SingleCellExperiment ## dim: 12466 47830 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(12466): ENSG00000000003 ENSG00000000457 ... ENSG00000285476 ## ENSG00000285492 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out$batch &lt;- factor(mnn.out$batch) mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) mnn.out.corre.dim &lt;- dim(reducedDim(mnn.out, &quot;corrected&quot;)) mnn.out.corre.dim ## [1] 47830 50 mnn.out.recon.dim &lt;- dim(assay(mnn.out, &quot;reconstructed&quot;)) mnn.out.recon.dim ## [1] 12466 47830 The function returns a SingleCellExperiment object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell. The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses (47830 cells and 50 PCs). A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space (12466 genes and 47830 cells). We do not recommend using this for anything other than visualization. print(assay(mnn.out, &quot;reconstructed&quot;)[1:5,1:3]) ## &lt;5 x 3&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ## ENSG00000000003 -8.970458e-05 -6.411674e-05 -6.896130e-05 ## ENSG00000000457 6.004816e-05 5.014359e-04 2.004637e-04 ## ENSG00000000938 -3.567196e-04 3.084119e-04 4.221600e-04 ## ENSG00000001167 2.328682e-04 7.270576e-04 6.971589e-04 ## ENSG00000001461 -8.717612e-04 -6.734327e-04 -7.530539e-04 The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches. colDataList &lt;- lapply(rescaled.mbn, function(x){colData(x)}) colDataDf &lt;- do.call(rbind, colDataList) #colData(mnn.out) &lt;- cbind(colDataDf, colData(mnn.out)$cluster) colData(mnn.out) &lt;- DataFrame(cbind(colData(mnn.out), colDataDf)) # no rearranging of columns by mnncorrect 28.6 Correction diagnostics We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the two batches are replicates of each other. snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, # or use BSPARAM BPPARAM=bpp) #clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr, steps=nSteps)$membership clusters.mnn &lt;- igraph::cluster_louvain(snn.gr)$membership #clusters.mnn &lt;- igraph::cluster_fast_greedy(snn.gr)$membership mnn.out$clusters.mnn &lt;- factor(clusters.mnn) tab.mnn &lt;- table(Cluster=mnn.out$clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PBMMC_1 ## 1 1155 1552 336 1566 470 349 37 ## 2 366 578 113 568 251 491 234 ## 3 112 2129 1246 291 188 1278 17 ## 4 306 595 194 825 216 514 50 ## 5 7 101 462 140 229 37 61 ## 6 730 823 191 330 1517 2307 43 ## 7 2 192 8 3 588 52 2 ## 8 108 372 96 130 439 119 25 ## 9 33 6 31 26 178 44 250 ## 10 1 1 5 2 32 34 19 ## 11 0 7 22 42 51 13 270 ## 12 3 3 117 234 1 13 25 ## 13 0 2 2 1 11 1 336 ## 14 14 75 390 117 159 74 98 ## 15 10 144 1306 219 213 86 595 ## 16 0 21 10 5 2 6 15 ## 17 6 14 198 794 6 19 7 ## Batch ## Cluster PBMMC_2 PBMMC_3 PRE-T_1 PRE-T_2 ## 1 25 70 1 0 ## 2 87 255 181 22 ## 3 18 96 3 1 ## 4 18 45 12 5 ## 5 422 402 21 114 ## 6 22 47 6 49 ## 7 1 7 1 0 ## 8 24 14 860 211 ## 9 321 247 633 237 ## 10 14 12 2058 2012 ## 11 431 755 6 235 ## 12 463 92 1 74 ## 13 195 738 1 6 ## 14 470 395 28 366 ## 15 1050 875 24 251 ## 16 33 33 1 25 ## 17 1064 60 4 20 pheatmap::pheatmap(tab.mnn, border_color = NA, drop_levels = TRUE, cluster_cols = FALSE ) Cluster size and cell contribution by sample, with clusters sorted by size: #mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions mnn.out$Sample.Name &lt;- uncorrected$Sample.Name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$Sample.Name2) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() + theme(legend.text = element_text(size = 7)) p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) + theme(legend.text = element_text(size = 7)) #grid.arrange(p1, p2) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) Cluster size and cell contribution by sample type, with clusters sorted by size: mnn.out$source_name &lt;- factor(uncorrected$source_name) # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) #grid.arrange(p1, p2) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from batches provides a comforting illusion that the correction was successful. set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) p &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, point_size=0.3) p p + facet_wrap(~mnn.out$type, ncol=2) # show clusters p.clu &lt;- plotTSNE(mnn.out, colour_by=&quot;clusters.mnn&quot;) p.batch &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;) #grid.arrange(p.clu, p.batch, ncol=2) grid.arrange(p.clu, p.batch+facet_wrap(~mnn.out$type), ncol=2) We can also compute the variation in the log-abundances to rank the clusters with the greatest variability in their proportional abundances across batches. We can then focus on batch-specific clusters that may be indicative of incomplete batch correction. Obviously, though, this diagnostic is subject to interpretation as the same outcome can be caused by batch-specific populations; some prior knowledge about the biological context is necessary to distinguish between these two possibilities. The table below shows the number of cells for each cluster (row) and sample (column) together with the variance in cell number across these samples (‘var’ column). # Avoid minor difficulties with the &#39;table&#39; class. tab.mnn &lt;- unclass(tab.mnn) # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) # Ranking clusters by the largest variances. rv &lt;- rowVars(norm) %&gt;% round(2) # show #DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),] DataFrame(tab.mnn, var=rv)[order(rv, decreasing=TRUE),] ## DataFrame with 17 rows and 12 columns ## ETV6.RUNX1_1 ETV6.RUNX1_2 ETV6.RUNX1_3 ETV6.RUNX1_4 HHD_1 HHD_2 ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 10 1 1 5 2 32 34 ## 1 1155 1552 336 1566 470 349 ## 13 0 2 2 1 11 1 ## 3 112 2129 1246 291 188 1278 ## 11 0 7 22 42 51 13 ## ... ... ... ... ... ... ... ## 8 108 372 96 130 439 119 ## 5 7 101 462 140 229 37 ## 14 14 75 390 117 159 74 ## 2 366 578 113 568 251 491 ## 16 0 21 10 5 2 6 ## PBMMC_1 PBMMC_2 PBMMC_3 PRE.T_1 PRE.T_2 var ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; ## 10 19 14 12 2058 2012 8.20 ## 1 37 25 70 1 0 6.99 ## 13 336 195 738 1 6 6.35 ## 3 17 18 96 3 1 6.29 ## 11 270 431 755 6 235 5.47 ## ... ... ... ... ... ... ... ## 8 25 24 14 860 211 2.48 ## 5 61 422 402 21 114 2.37 ## 14 98 470 395 28 366 2.10 ## 2 234 87 255 181 22 1.53 ## 16 15 33 33 1 25 0.72 For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row). round(metadata(mnn.out)$merge.info$lost.var,2) ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PRE-T_1 ## [1,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [2,] 0.00 0.00 0.08 0.00 0.00 0.00 0.00 ## [3,] 0.00 0.00 0.01 0.10 0.00 0.00 0.00 ## [4,] 0.00 0.06 0.02 0.04 0.00 0.00 0.00 ## [5,] 0.00 0.01 0.04 0.07 0.05 0.00 0.00 ## [6,] 0.00 0.00 0.00 0.00 0.00 0.07 0.00 ## [7,] 0.00 0.01 0.02 0.03 0.02 0.02 0.00 ## [8,] 0.00 0.01 0.01 0.00 0.01 0.01 0.00 ## [9,] 0.08 0.00 0.01 0.01 0.00 0.00 0.00 ## [10,] 0.01 0.01 0.01 0.01 0.01 0.01 0.07 ## PRE-T_2 PBMMC_1 PBMMC_2 PBMMC_3 ## [1,] 0.00 0.00 0.07 0.04 ## [2,] 0.00 0.00 0.00 0.01 ## [3,] 0.00 0.00 0.01 0.00 ## [4,] 0.00 0.00 0.04 0.01 ## [5,] 0.00 0.00 0.08 0.02 ## [6,] 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.08 0.04 0.02 ## [8,] 0.11 0.01 0.00 0.01 ## [9,] 0.01 0.00 0.02 0.01 ## [10,] 0.01 0.01 0.02 0.01 tmpData &lt;- metadata(mnn.out)$merge.info$lost.var pheatmap::pheatmap(tmpData, border_color = NA, drop_levels = TRUE, cluster_rows = FALSE, cluster_cols = FALSE ) rm(tmpData) Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern. The following t-SNE shows the clusters identified: mnn.out$cluster &lt;- paste0(&quot;c&quot;, clusters.mnn) p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;, shape_by=&quot;source_name&quot;, point_size=0.3) p p + facet_wrap(~colData(mnn.out)$source_name, ncol=2) The following t-SNE plots show expression levels of known cell type marker genes. genesToShow &lt;- c( &quot;CD79A&quot;, # CD79A B *** &quot;CST3&quot;, # CST3 monocytes *** &quot;CD3D&quot;, # CD3D T cells *** &quot;HBA1&quot; # HBA1 erythrocytes *** ) tmpInd &lt;- which(rowData(uncorrected)$Symbol %in% genesToShow) ensToShow &lt;- rowData(uncorrected)$ensembl_gene_id[tmpInd] #B cells: genex &lt;- ensToShow[1] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pB &lt;- p #T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pT &lt;- p #monocytes: genex &lt;- ensToShow[2] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pM &lt;- p #erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(mnn.out, colour_by = genex, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pE &lt;- p grid.arrange(pB + theme(legend.position=&quot;bottom&quot;), pT + theme(legend.position=&quot;bottom&quot;), pM + theme(legend.position=&quot;bottom&quot;), pE + theme(legend.position=&quot;bottom&quot;), ncol=2) Compare to the uncorrected values: # B cells genex &lt;- ensToShow[1] p &lt;- plotTSNE(uncorrected, colour_by = genex, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;B cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pBu &lt;- p #Compare to the uncorrected values, T cells: genex &lt;- ensToShow[3] p &lt;- plotTSNE(uncorrected, colour_by = genex, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;T cells&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pTu &lt;- p #Compare to the uncorrected values, monocytes: genex &lt;- ensToShow[2] p &lt;- plotTSNE(uncorrected, colour_by = genex, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;monocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pMu &lt;- p #Compare to the uncorrected values, erythrocytes: genex &lt;- ensToShow[4] p &lt;- plotTSNE(uncorrected, colour_by = genex, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;erythrocytes&quot;, genex, rowData(uncorrected)[genex,&quot;Symbol&quot;]) ) pEu &lt;- p grid.arrange(pBu + theme(legend.position=&quot;bottom&quot;), pTu + theme(legend.position=&quot;bottom&quot;), pMu + theme(legend.position=&quot;bottom&quot;), pEu + theme(legend.position=&quot;bottom&quot;), ncol=2) 28.6.1 Preserving biological heterogeneity 28.6.1.1 Comparison to within-batch clusters Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries are zero, though this may depend on whether specific clusters of interest are gained or lost. One heatmap is generated for each dataset, where each entry is colored according to the number of cells with each pair of labels (before and after correction), on the log10 scale with pseudocounts (+10) for a smoother color transition (so a minimum value of log10(0+10) == 1). # OLD library(pheatmap) # For the first batch (adding +10 for a smoother color transition # from zero to non-zero counts for any given matrix entry). batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[tmpInd]), paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) heat1 &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison&quot;, splVec[batchPlace]), silent=TRUE) # For the second batch. batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[tmpInd]), paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) heat2 &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison&quot;, splVec[batchPlace]), silent=TRUE) grid.arrange(heat1[[4]], heat2[[4]]) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled.mbn[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled.rb$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled.mbn[[splIdx]]), cl.2=clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) grobx &lt;- arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’ in pink, ‘after’ in blue) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. #```{r biolHet_plotShowTree1_dsi_allCells_allSets, fig.height=figSize*length(treeList)*2/3, fig.width=figSize} #grid.arrange(grobs = treeList, grid.arrange(grobs = gxList[1:4], ncol=1 ) grid.arrange(grobs = gxList[5:6], ncol=1 ) grid.arrange(grobs = gxList[7:8], ncol=1 ) grid.arrange(grobs = gxList[9:11], ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) grid.arrange(grobs = treeList, ncol=2 ) 28.6.1.2 Coassignment probabilities Another evaluation approach is to compute the coassignment probabilities, i.e. the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place. The plots below display the coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each sample, where each entry is colored according to the coassignment probability between each pair of within-batch clusters: # OLD # For the first batch. batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd]) heat1 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[batchPlace]), silent=TRUE) # For the second batch. batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd]) heat2 &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[batchPlace]), silent=TRUE) grid.arrange(heat1[[4]], heat2[[4]]) # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled.mbn[[splIdx]]), clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3 ) Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair (in pairwiseRand() with mode=“ratio” and adjusted=FALSE). The Rand index is introduced below. 28.6.1.3 Rand index Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect. # OLD suppressMessages(library(fossil)) batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] ri1 &lt;- rand.index(as.integer(clusters.mnn[tmpInd]), as.integer(colLabels(rescaled.mbn[[batchPlace]]))) ri1 batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] ri2 &lt;- rand.index(as.integer(clusters.mnn[tmpInd]), as.integer(colLabels(rescaled.mbn[[batchPlace]]))) ri2 # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled.mbn[[splIdx]])), alt=as.integer(clusters.mnn[rescaled.rb$batch==splVec[splIdx]]), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 ## 0.30 0.24 0.73 0.42 0.35 0.48 ## PRE-T_1 PRE-T_2 PBMMC_1 PBMMC_2 PBMMC_3 ## 0.41 0.54 0.59 0.72 0.69 A sample may show a low Rand index value if cells grouped together in a small cluster before correction are split into distinct clusters after correction because the latter comprise cell populations not observed in that sample but present in other samples. This would be the case of GSM3872434 aka ETV6-RUNX1_1 with far fewer erythrocytes (grouped in a single cluster) than GSM3872443 aka PBMMC_2, in which subtypes can be distinguished. We can also break down the adjusted Rand index (ARI) into per-cluster ratios for more detailed diagnostics. For example, we could see low ratios off the diagonal if distinct clusters in the within-batch clustering were incorrectly aggregated in the merged clustering. Conversely, we might see low ratios on the diagonal if the correction inflated or introduced spurious heterogeneity inside a within-batch cluster. # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(colLabels(rescaled.mbn[[splIdx]])), alt=as.integer(clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3 ) 28.6.2 Encouraging consistency with marker genes In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach that is a natural extension of the strategy described in the feature selection section. We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by SingleR. In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN(). # OLD # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. stats1 &lt;- pairwiseWilcox(rescaled.mbn[[1]], direction=&quot;up&quot;) markers1 &lt;- getTopMarkers(stats1[[1]], stats1[[2]], n=10) stats2 &lt;- pairwiseWilcox(rescaled.mbn[[2]], direction=&quot;up&quot;) markers2 &lt;- getTopMarkers(stats2[[1]], stats2[[2]], n=10) stats3 &lt;- pairwiseWilcox(rescaled.mbn[[3]], direction=&quot;up&quot;) markers3 &lt;- getTopMarkers(stats3[[1]], stats3[[2]], n=10) stats4 &lt;- pairwiseWilcox(rescaled.mbn[[4]], direction=&quot;up&quot;) markers4 &lt;- getTopMarkers(stats4[[1]], stats4[[2]], n=10) marker.set &lt;- unique(unlist(c(unlist(markers1), unlist(markers2), unlist(markers3), unlist(markers4)))) length(marker.set) # getting the total number of genes selected in this manner. # Recall that groups for marker detection # are automatically defined from &#39;colLabels()&#39;. markerList &lt;- lapply(rescaled.mbn, function(x){ y &lt;- pairwiseWilcox(x, direction=&quot;up&quot;, BPPARAM=bpp) getTopMarkers(y[[1]], y[[2]], n=10) %&gt;% unlist %&gt;% unlist }) marker.set &lt;- unique(unlist(markerList)) #length(marker.set) # getting the total number of genes selected in this manner. set.seed(1000110) mnn.out2 &lt;- fastMNN( rescaled.mbn[1:4], subset.row=marker.set, BSPARAM=RandomParam(deferred=TRUE), BPPARAM=bpp) The total number of genes selected in this manner is: 1188. set.seed(1000110) mnn.out2 &lt;- fastMNN(rescaled.mbn, subset.row=marker.set, BSPARAM=RandomParam(deferred=TRUE), BPPARAM=bpp) mnn.out2$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions # compute t-SNE: mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) We can also visualize the corrected coordinates using a t-SNE plot: plotTSNE(mnn.out2, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) plotTSNE(mnn.out2, colour_by=&quot;source_name&quot;) + facet_wrap(~colData(mnn.out2)$source_name, ncol=2) plotTSNE(mnn.out2, colour_by=&quot;batch&quot;, shape_by=&quot;source_name&quot;) + facet_wrap(~colData(mnn.out2)$batch, ncol=4) A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context. mnn.out2 &lt;- runTSNE(mnn.out2, dimred=&quot;corrected&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) mnn.out$batch &lt;- factor(mnn.out$batch) batchVec &lt;- levels(mnn.out$batch) # for sample type in batchVec[1] grid.arrange( plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[1]], colour_by=I(colLabels(rescaled.mbn[[1]]))) + ggtitle(batchVec[1]), plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[2]], colour_by=I(colLabels(rescaled.mbn[[2]]))) + ggtitle(batchVec[2]), plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[3]], colour_by=I(colLabels(rescaled.mbn[[3]]))) + ggtitle(batchVec[3]), plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[4]], colour_by=I(colLabels(rescaled.mbn[[4]]))) + ggtitle(batchVec[4]), ncol=2 ) 28.6.3 Using the corrected values it is preferable to perform DE analyses using the uncorrected expression values with blocking on the batch. This strategy is based on the expectation that any genuine DE between clusters should still be present in a within-batch comparison where batch effects are absent. It penalizes genes that exhibit inconsistent DE across batches, thus protecting against misleading conclusions when a population in one batch is aligned to a similar-but-not-identical population in another batch. We demonstrate this approach below using a blocked t-test to detect markers in the PBMC dataset, where the presence of the same pattern across clusters within each batch is reassuring. If integration is performed across multiple conditions, it is even more important to use the uncorrected expression values for downstream analyses - see Section 14.5.2 for a discussion. m.out &lt;- findMarkers( uncorrected, clusters.mnn, block=uncorrected$batch, # TODO batch or type? direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[, c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;), drop=FALSE]) demo &lt;- m.out[[&quot;1&quot;]] as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;)]) #as.data.frame(demo[1:20,c(&quot;external_gene_name&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;)]) Expression level for the top gene, : geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) m.out &lt;- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE], BPPARAM=bpp) #lapply(m.out, function(x){head(x[,2:6])}) tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) geneEnsId &lt;- demo %&gt;% data.frame %&gt;% filter(!str_detect(Symbol, &quot;^RP&quot;)) %&gt;% pull(ensembl_gene_id) %&gt;% head(1) geneSymbol &lt;- rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, FTL on t-SNE plot: Not Encouraging consistency with marker genes p &lt;- plotTSNE(mnn.out, colour_by = geneEnsId, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, geneEnsId, geneSymbol)) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out)$batch) grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) Encouraging consistency with marker genes p &lt;- plotTSNE(mnn.out2, colour_by = geneEnsId, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle( paste(&quot;cluster&quot;, cluToGet, geneEnsId, geneSymbol)) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out2)$batch) grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) We suggest limiting the use of per-gene corrected values to visualization, e.g., when coloring points on a t-SNE plot by per-cell expression. This can be more aesthetically pleasing than uncorrected expression values that may contain large shifts on the colour scale between cells in different batches. Use of the corrected values in any quantitative procedure should be treated with caution, and should be backed up by similar results from an analysis on the uncorrected values. # before we save the mnn.out object in a file, # we should copy some of the cell meta data over, # eg Barcode and lib size. # Mind sets may have been downsampled, eg with nbCells set to 1000. # But that is not in the file name (yet?) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s.Rds&quot;, #fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi2_%s.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(mnn.out, file=fn) #saveRDS(mnn.out2, file=fn) 28.7 Challenge Same but with an ordered merging We will first merge replicates in each sample group separately, then sample groups, starting with the group with the larger number of ‘cell types’. Hint: use the merge.order option in fastMNN ( … maybe with “list( list(1,2,3,4), list(9,10,11), list(5,6), list(7,8) )” ) # Using randomized SVD here, as this is faster than # irlba for file-backed matrices. set.seed(1000101001) rm(mnn.out) mnn.out &lt;- fastMNN(rescaled.mbn, merge.order=list( list(1,2,3,4), list(9,10,11), list(5,6), list(7,8) ), d=50, k=20, subset.row=chosen.hvgs, BSPARAM=RandomParam(deferred=TRUE), BPPARAM=bpp ) mnn.out ## class: SingleCellExperiment ## dim: 12466 47830 ## metadata(2): merge.info pca.info ## assays(1): reconstructed ## rownames(12466): ENSG00000000003 ENSG00000000457 ... ENSG00000285476 ## ENSG00000285492 ## rowData names(1): rotation ## colnames: NULL ## colData names(1): batch ## reducedDimNames(1): corrected ## altExpNames(0): mnn.out$batch &lt;- factor(mnn.out$batch) mnn.out$type &lt;- gsub(&quot;_[1-4]&quot;,&quot;&quot;,mnn.out$batch) mnn.out$type &lt;- factor(mnn.out$type) #class(mnn.out$batch) #head(mnn.out$batch) #dim(reducedDim(mnn.out, &quot;corrected&quot;)) #assay(mnn.out, &quot;reconstructed&quot;) print(dim(assay(mnn.out, &quot;reconstructed&quot;))) ## [1] 12466 47830 print(assay(mnn.out, &quot;reconstructed&quot;)[1:5,1:3]) ## &lt;5 x 3&gt; matrix of class LowRankMatrix and type &quot;double&quot;: ## [,1] [,2] [,3] ## ENSG00000000003 -1.272426e-04 -6.787507e-05 -5.702688e-05 ## ENSG00000000457 -3.356405e-05 4.087098e-04 1.054453e-04 ## ENSG00000000938 -2.351897e-03 -4.617906e-04 -3.513377e-04 ## ENSG00000001167 -6.807745e-05 2.264625e-04 2.274302e-04 ## ENSG00000001461 -2.447150e-04 -4.125638e-05 -2.362878e-04 Diagnostic table and plots: snn.gr &lt;- buildSNNGraph(mnn.out, use.dimred=&quot;corrected&quot;, BPPARAM=bpp) #clusters.mnn &lt;- igraph::cluster_walktrap(snn.gr)$membership clusters.mnn &lt;- igraph::cluster_louvain(snn.gr)$membership mnn.out$clusters.mnn &lt;- sprintf(&quot;c%s&quot;, clusters.mnn) tab.mnn &lt;- table(Cluster=mnn.out$clusters.mnn, Batch=mnn.out$batch) tab.mnn ## Batch ## Cluster ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PBMMC_1 ## c1 756 696 298 279 1142 1804 166 ## c10 8 1 5 8 24 12 93 ## c11 7 11 39 10 9 14 128 ## c12 0 24 3 2 679 128 221 ## c13 0 1 16 11 1 1 403 ## c14 3 3 138 261 1 15 67 ## c15 6 101 458 140 228 37 62 ## c16 1 7 23 42 51 10 194 ## c17 0 21 10 5 2 7 36 ## c2 384 645 109 582 337 560 319 ## c3 101 374 92 85 353 108 22 ## c4 996 803 175 1433 303 392 27 ## c5 13 138 1350 218 192 89 210 ## c6 6 14 187 781 6 19 7 ## c7 11 80 327 107 175 70 79 ## c8 395 519 195 806 406 595 14 ## c9 166 3177 1302 523 642 1576 36 ## Batch ## Cluster PBMMC_2 PBMMC_3 PRE-T_1 PRE-T_2 ## c1 168 207 4 51 ## c10 44 38 1972 1104 ## c11 21 72 181 1057 ## c12 160 439 1 6 ## c13 186 26 2 6 ## c14 617 144 2 68 ## c15 420 459 23 114 ## c16 337 641 6 224 ## c17 67 60 2 28 ## c2 113 319 736 124 ## c3 31 12 849 189 ## c4 27 61 2 0 ## c5 871 884 22 324 ## c6 1066 59 4 44 ## c7 461 361 28 282 ## c8 24 54 5 0 ## c9 45 307 2 7 pheatmap::pheatmap(tab.mnn, border_color = NA, drop_levels = TRUE, #cluster_rows = FALSE, cluster_cols = FALSE ) set.seed(0010101010) mnn.out &lt;- runTSNE(mnn.out, dimred=&quot;corrected&quot;, external_neighbors=TRUE, BNPARAM=AnnoyParam(), BPPARAM=bpp, n_threads=bpnworkers(bpp)) p.batch &lt;- plotTSNE(mnn.out, colour_by=&quot;batch&quot;, point_size=0.3) p.clu &lt;- plotTSNE(mnn.out, colour_by=&quot;clusters.mnn&quot;, point_size=0.3) #grid.arrange(p.clu, p.batch, ncol=2) grid.arrange(p.clu, p.batch+facet_wrap(~mnn.out$type), ncol=2) Write mnn.out object to file colData(mnn.out) &lt;- cbind(colData(uncorrected),colData(mnn.out)[,c(&quot;type&quot;, &quot;clusters.mnn&quot;)]) # Write object to file # fastMnnWholeByList -&gt; Fmwbl tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_Fmwbl.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(mnn.out, tmpFn) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_Fmwbl2.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(list(&quot;chosen.hvgs&quot;=chosen.hvgs, &quot;uncorrected&quot;=uncorrected,&quot;rescaled.mbn&quot;=rescaled.mbn), tmpFn) Proportions of lost variance round(metadata(mnn.out)$merge.info$lost.var,2) ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 PRE-T_1 ## [1,] 0.00 0.00 0.00 0.00 0.00 0.00 0.02 ## [2,] 0.00 0.00 0.00 0.00 0.01 0.03 0.00 ## [3,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [4,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## [5,] 0.02 0.02 0.00 0.00 0.00 0.00 0.00 ## [6,] 0.01 0.01 0.04 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.00 0.01 0.06 0.00 0.00 0.00 ## [8,] 0.04 0.04 0.11 0.16 0.00 0.00 0.00 ## [9,] 0.01 0.02 0.03 0.04 0.07 0.08 0.00 ## [10,] 0.02 0.02 0.03 0.03 0.02 0.02 0.07 ## PRE-T_2 PBMMC_1 PBMMC_2 PBMMC_3 ## [1,] 0.01 0.00 0.00 0.00 ## [2,] 0.00 0.00 0.00 0.00 ## [3,] 0.00 0.04 0.18 0.00 ## [4,] 0.00 0.00 0.00 0.07 ## [5,] 0.00 0.00 0.00 0.00 ## [6,] 0.00 0.00 0.00 0.00 ## [7,] 0.00 0.00 0.00 0.00 ## [8,] 0.00 0.02 0.02 0.02 ## [9,] 0.00 0.02 0.05 0.02 ## [10,] 0.12 0.02 0.02 0.02 tmpData &lt;- metadata(mnn.out)$merge.info$lost.var pheatmap::pheatmap(tmpData, border_color = NA, drop_levels = TRUE, cluster_rows = FALSE, cluster_cols = FALSE ) 28.7.1 Preserving biological heterogeneity 28.7.1.1 Comparison to within-batch clusters # OLD mnn.out$batch &lt;- factor(mnn.out$batch) # somehow need to re-factor batch levels(mnn.out$batch) # For the first batch (adding +10 for a smoother color transition # from zero to non-zero counts for any given matrix entry). batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] length(paste(&quot;after&quot;, clusters.mnn[tmpInd])) rescaled.mbn[[batchPlace]] rescaled.mbn[[batchPlace]] %&gt;% colData %&gt;% head length(paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) #save.image(&quot;dataSetIntegrationWhole.debug.Rdata&quot;) table(paste(&quot;after&quot;, clusters.mnn[tmpInd])) table(paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[tmpInd]), paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) heat1 &lt;- pheatmap( log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison&quot;, splVec[batchPlace]), silent=TRUE) # For the second batch. batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- table(paste(&quot;after&quot;, clusters.mnn[tmpInd]), paste(&quot;before&quot;, colLabels(rescaled.mbn[[batchPlace]]))) heat2 &lt;- pheatmap( log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, main=sprintf(&quot;%s comparison&quot;, splVec[batchPlace]), silent=TRUE) grid.arrange(heat1[[4]], heat2[[4]]) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) treeList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { # heatmap tab &lt;- table( paste(&quot;before&quot;, colLabels(rescaled.mbn[[splIdx]]), sep=&quot;_&quot;), paste(&quot;after&quot;, clusters.mnn[rescaled.rb$batch==splVec[splIdx]], sep=&quot;_&quot;) ) plotList[[splIdx]] &lt;- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE, fontsize=7) # cluster tree: combined &lt;- cbind( cl.1=colLabels(rescaled.mbn[[splIdx]]), cl.2=clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) treeList[[splIdx]] &lt;- clustree(combined, prefix=&quot;cl.&quot;, edge_arrow=FALSE) + ggtitle(splVec[splIdx]) + #theme(legend.background = element_rect(color = &quot;yellow&quot;)) + #theme(legend.position=&#39;bottom&#39;) + #theme(legend.box=&quot;vertical&quot;) + #theme(legend.box=&quot;horizontal&quot;) + theme(legend.margin=margin()) #+ #guides(fill=guide_legend(nrow=2, byrow=FALSE)) #theme(legend.position = &quot;none&quot;) } g_legend&lt;-function(a.gplot){ tmp &lt;- ggplot_gtable(ggplot_build(a.gplot)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == &quot;guide-box&quot;) legend &lt;- tmp$grobs[[leg]] return(legend) } redrawClutree &lt;- function(p){ #p &lt;- treeList[[1]] + theme(legend.position=&#39;bottom&#39;) #p &lt;- p + theme(legend.background = element_rect(color = &quot;yellow&quot;)) p &lt;- p + theme(legend.justification = &quot;left&quot;) #p &lt;- p + theme(legend.justification = c(0,1)) #lemon::gtable_show_names(p) pNoLeg &lt;- p + theme(legend.position = &quot;none&quot;) # edge colour: pEdgeCol &lt;- p + #guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeCol.leg &lt;- g_legend(pEdgeCol) # edge alpha: pEdgeAlpha &lt;- p + guides(edge_colour = FALSE) + #guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) pEdgeAlpha.leg &lt;- g_legend(pEdgeAlpha) # size pSize &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + #guides(size = FALSE) + guides(colour = FALSE) pSize.leg &lt;- g_legend(pSize) # colour pColour &lt;- p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) #+ #guides(colour = FALSE) pColour.leg &lt;- g_legend(pColour) grobx &lt;- arrangeGrob(pNoLeg, pEdgeCol.leg, pEdgeAlpha.leg, #pColour.leg, pSize.leg, nrow=1, ncol=4, layout_matrix=matrix(c(1,2,3,4), ncol=4, byrow=TRUE), widths=c(unit(.64, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;), unit(.12, &quot;npc&quot;)) ) } ##gx &lt;- redrawClutree(treeList[[1]] + theme(legend.position=&#39;bottom&#39;)) ##grid::grid.draw(gx) ## fine # gxList &lt;- lapply(treeList, function(x){redrawClutree(x+theme(legend.position=&#39;bottom&#39;))}) gxList &lt;- lapply(treeList, function(x){redrawClutree(x)}) ##marrangeGrob(gxList, nrow=2, ncol=2) grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3, top = grid::textGrob(&quot;clusterings concordance (number of cells, log10 scale)&quot;, gp=grid::gpar(fontsize=12,font=3)) ) The redistribution of cells from one set of clusters to another, here ‘within-batch before’ and ‘across-batch after’ correction, may also be visualized with a clustering tree clustree. Clusters are represented as filled circles colored by cluster set (‘before’ in pink, ‘after’ in blue) and sized by cell number. A pair of clusters from two sets are linked according to the number of cells they share with a link that informs on the number of cells shared (color) and the ‘incoming node’ proportion for the node it points to (transparency). Although these plots convey more information than heatmaps below, they may not be as easy to read. #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} grid.arrange(grobs = treeList, ncol=1 ) #```{r, fig.height=figSize*length(treeList)/2, fig.width=figSize} #grid.arrange(grobs = treeList, grid.arrange(grobs = gxList[1:4], ncol=1 ) grid.arrange(grobs = gxList[5:6], ncol=1 ) grid.arrange(grobs = gxList[7:8], ncol=1 ) grid.arrange(grobs = gxList[9:11], ncol=1 ) The same plots in more compact form with no legend: treeList &lt;- lapply(treeList, function(p){ p + guides(edge_colour = FALSE) + guides(edge_alpha = FALSE) + guides(size = FALSE) + guides(colour = FALSE) }) grid.arrange(grobs = treeList, ncol=3 ) Co-assignment probabilities # For the first batch. batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd]) heat1 &lt;- pheatmap( tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[batchPlace]), silent=TRUE) # For the second batch. batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] tab &lt;- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd]) heat2 &lt;- pheatmap( tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), main=sprintf(&quot;%s probabilities&quot;, splVec[batchPlace]), silent=TRUE) grid.arrange(heat1[[4]], heat2[[4]]) # coassignProb manual: now deprecated for pairwiseRand. # Note that the coassignment probability is closely related to the Rand index-based ratios broken down by cluster pair in pairwiseRand with mode=&quot;ratio&quot; and adjusted=FALSE. The off-diagonal coassignment probabilities are simply 1 minus the off-diagonal ratio, while the on-diagonal values differ only by the lack of consideration of pairs of the same cell in pairwiseRand. plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tab &lt;- coassignProb(colLabels(rescaled.mbn[[splIdx]]), clusters.mnn[rescaled.rb$batch==splVec[splIdx]]) plotList[[splIdx]] &lt;- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), #main=sprintf(&quot;%s probabilities&quot;, splVec[splIdx]), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3 ) 28.7.1.2 Rand index: # OLD library(fossil) batchPlace &lt;- 1 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] ri1 &lt;- rand.index(as.integer(clusters.mnn[tmpInd]), as.integer(colLabels(rescaled.mbn[[batchPlace]]))) ri1 batchPlace &lt;- 2 tmpInd &lt;- mnn.out$batch==levels(mnn.out$batch)[batchPlace] ri2 &lt;- rand.index(as.integer(clusters.mnn[tmpInd]), as.integer(colLabels(rescaled.mbn[[batchPlace]]))) ri2 # pairwiseRand(), index, adjusted ariVec &lt;- vector(mode = &quot;numeric&quot;, length = length(splVec)) names(ariVec) &lt;- splVec for (splIdx in 1:length(splVec)) { ariVec[splIdx] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled.rb$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled.mbn[[splIdx]])), mode=&quot;index&quot;) } ariVec &lt;- round(ariVec,2) ariVec ## ETV6-RUNX1_1 ETV6-RUNX1_2 ETV6-RUNX1_3 ETV6-RUNX1_4 HHD_1 HHD_2 ## 0.35 0.25 0.72 0.41 0.34 0.54 ## PRE-T_1 PRE-T_2 PBMMC_1 PBMMC_2 PBMMC_3 ## 0.36 0.66 0.75 0.64 0.59 # pairwiseRand(), ratio, adjusted # square numeric matrix is returned with number of rows equal to the number of unique levels in ref. tabList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { tabList[[splIdx]] &lt;- pairwiseRand( ref=as.integer(clusters.mnn[rescaled.rb$batch==splVec[splIdx]]), alt=as.integer(colLabels(rescaled.mbn[[splIdx]])) ) } randVal &lt;- unlist(tabList) ## make breaks from combined range limits &lt;- c( min(randVal, na.rm = TRUE), max(randVal, na.rm = TRUE)) limits &lt;- quantile(randVal, probs=c(0.05, 0.95), na.rm = TRUE) Breaks &lt;- seq(limits[1], limits[2], length = 100) plotList &lt;- vector(mode = &quot;list&quot;, length = length(splVec)) for (splIdx in 1:length(splVec)) { plotList[[splIdx]] &lt;- pheatmap(tabList[[splIdx]], cluster_row=FALSE, cluster_col=FALSE, col=rev(viridis::magma(100)), breaks=Breaks, #main=sprintf(&quot;%s ratio&quot;, splVec[splIdx]), main=sprintf(&quot;%s&quot;, splVec[splIdx]), silent=TRUE) } grobList &lt;- lapply(plotList, function(x){x[[4]]}) grid.arrange(grobs = grobList, ncol=3 ) 28.7.2 Cluster markers: # OLD m.out &lt;- findMarkers( uncorrected, clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, row.data=rowData(uncorrected)[, c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;), drop=FALSE]) #m.out &lt;- findMarkers(uncorrected, m.out &lt;- findMarkers(uncorrected[rownames(mnn.out),], clusters.mnn, block=uncorrected$batch, direction=&quot;up&quot;, lfc=1, #row.data=rowData(uncorrected)[,c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE], row.data=rowData(uncorrected)[rownames(mnn.out),c(&quot;ensembl_gene_id&quot;,&quot;Symbol&quot;),drop=FALSE], BPPARAM=bpp) #lapply(m.out, function(x){head(x[,2:6])}) tl1 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD3D&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.10,2:6]}) # T-cell tl2 &lt;- lapply(m.out, function(x){x[x$Symbol==&quot;CD69&quot; &amp; x$Top &lt;= 50 &amp; x$FDR &lt; 0.20,2:6]}) # activation tb1 &lt;- unlist(lapply(tl1, nrow)) &gt; 0 tb2 &lt;- unlist(lapply(tl2, nrow)) &gt; 0 cluToGet &lt;- unique(c(which(tb1), which(tb2)))[1] # 3 # 19 # 4 demo &lt;- m.out[[cluToGet]] #as.data.frame(demo[1:20,c(&quot;Symbol&quot;, &quot;Top&quot;, &quot;p.value&quot;, &quot;FDR&quot;, &quot;summary.logFC&quot;)]) geneEnsId &lt;- demo %&gt;% data.frame %&gt;% filter(!str_detect(Symbol, &quot;^RP&quot;)) %&gt;% pull(ensembl_gene_id) %&gt;% head(1) geneSymbol &lt;- rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;] Expression level for the top gene in cluster 5, CD3D, (ENSG00000167286): # OLD geneEnsId &lt;- rownames(demo)[1] plotExpression( uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) #geneEnsId &lt;- rownames(demo)[1] plotExpression(uncorrected, x=I(factor(clusters.mnn)), features=geneEnsId, colour_by=&quot;batch&quot;) + facet_wrap(~colour_by) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + ggtitle(sprintf(&quot;%s %s&quot;, geneEnsId, rowData(uncorrected)[geneEnsId,&quot;Symbol&quot;]) ) Expression level for the top gene, CD3D on t-SNE plot: Not Encouraging consistency with marker genes p &lt;- plotTSNE(mnn.out, colour_by = geneEnsId, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle(paste(&quot;cluster&quot;, cluToGet, geneEnsId,geneSymbol)) #print(p) p1 &lt;- p p2 &lt;- p + facet_wrap(~colData(mnn.out)$batch) grid.arrange(p1 + theme(legend.position=&quot;bottom&quot;), p2 + theme(legend.position=&quot;bottom&quot;), ncol=2) 28.8 Identify clusters with PBMMC cells Cluster size and cell contribution by sample type, with clusters sorted by size: mnn.out$source_name &lt;- uncorrected$source_name # cell order is maintained by scran functions tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=mnn.out$source_name) tmpMatTab &lt;- table(tmpMat) sortVecNames &lt;- tmpMatTab %&gt;% rowSums %&gt;% sort(decreasing=TRUE) %&gt;% names tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(tmpMat) tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) #grid.arrange(p1, p2) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) Cluster size and cell contribution by sample type, with clusters sorted by decreasing proportion of PBMMC: tmpMat &lt;- data.frame(&quot;clusters&quot;=clusters.mnn, &quot;batch&quot;=factor(mnn.out$source_name), &quot;Sample.Name&quot;=mnn.out$batch ) sortVecNames &lt;- round(tmpMatTab/rowSums(tmpMatTab),2) %&gt;% as.data.frame() %&gt;% filter(batch==&quot;PBMMC&quot;) %&gt;% arrange(desc(Freq)) %&gt;% pull(clusters) tmpMat$clusters &lt;- factor(tmpMat$clusters, levels=sortVecNames) tmpMatTab &lt;- table(&quot;clusters&quot;=tmpMat$clusters, &quot;batch&quot;=tmpMat$batch) #tmpMatDf &lt;- tmpMatTab[sortVecNames,] %&gt;% data.frame() tmpMatDf &lt;- tmpMatTab[,] %&gt;% data.frame() p1 &lt;- ggplot(data=tmpMatDf, aes(x=clusters,y=Freq, fill=batch)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() p2 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=batch)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + scale_y_continuous(labels = scales::percent) #grid.arrange(p1, p2) p3 &lt;- ggplot(data=tmpMat, aes(x=clusters, fill=Sample.Name)) + geom_bar(position = &quot;fill&quot;) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) p4 &lt;- p3 + scale_y_continuous(labels = scales::percent) p1 &lt;- p1 + theme(legend.text = element_text(size = 5)) p2 &lt;- p2 + theme(legend.text = element_text(size = 5)) p3 &lt;- p3 + theme(legend.text = element_text(size = 5)) + facet_wrap(~tmpMat$batch) p4 &lt;- p4 + theme(legend.text = element_text(size = 5)) #grid.arrange(p1, p2, p3) #grid.arrange(p1, p2, p4, p3, ncol=1) legend &lt;- get_legend(p1) grid.arrange(arrangeGrob(p1 + theme(legend.position=&quot;none&quot;), p2 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) ggplot(data=tmpMat, aes(x=clusters, fill=Sample.Name)) + geom_bar() + facet_wrap(~tmpMat$batch) legend &lt;- get_legend(p3) grid.arrange(arrangeGrob(p4 + theme(legend.position=&quot;none&quot;), p3 + theme(legend.position=&quot;none&quot;), ncol=1), legend, widths=c(5/6, 1/6), ncol=2) #rm(p1, p2, p3, p4) tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=as.character(mnn.out$batch)) #Batch=as.character(mnn.out$source_name)) #tab.mnn &lt;- as.data.frame(tab.mnn, stringsAsFactors=FALSE) ##tab.mnn # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) normNoLog &lt;- normalizeCounts(tab.mnn, pseudo_count=10, log=FALSE) sortVecNames &lt;- rowSums(normNoLog) %&gt;% round(2) %&gt;% sort(decreasing=TRUE) %&gt;% names tab.mnn &lt;- table(Cluster=clusters.mnn, Batch=as.character(mnn.out$source_name)) ##tab.mnn # Using a large pseudo.count to avoid unnecessarily # large variances when the counts are low. #norm &lt;- normalizeCounts(tab.mnn, pseudo_count=10) normNoLog &lt;- normalizeCounts(tab.mnn, pseudo_count=10, log=FALSE) normNoLog &lt;- normNoLog %&gt;% as.data.frame.matrix() # sort by PBMMC proportion: normNoLog &lt;- normNoLog %&gt;% mutate(sum=rowSums(.)) normNoLog &lt;- normNoLog %&gt;% mutate(prop=PBMMC/sum) sortVecNames &lt;- normNoLog %&gt;% tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% arrange(desc(prop)) %&gt;% pull(clusters) Some clusters with a high proportion of PBMMC cells also comprise a large number of cancer cells. To select clusters to keep, we could use the following inclusion criteria: proportion of PBMMC cells in cluster is lower than the threshold for the proportion of PBMMC cells in a cluster, eg 50% proportion of cancer cells in cluster higher than 5% of cells of that sample type The bar plots below show the clusters ordered by decreasing proportion of PBMMC and also split by selection outcome (where ‘TRUE’ means inclusion). normNoLog &lt;- normNoLog %&gt;% tibble::rownames_to_column(&quot;cluster&quot;) normNoLog$cluster &lt;- paste0(&quot;c&quot;, normNoLog$cluster) splSetVec &lt;- colnames(tab.mnn) otherSplType &lt;- setdiff(colnames(tab.mnn), &quot;PBMMC&quot;) # ok for pairs of sample types thdSize &lt;- sum(normNoLog[,otherSplType])*0.02 #thdSize &lt;- sum(normNoLog[,otherSplType])*0.05 thdPropPbmmc &lt;- 0.5 normNoLog &lt;- normNoLog %&gt;% mutate(Non_PBMMC=rowSums(normNoLog[,otherSplType])) otherSplType &lt;- &quot;Non_PBMMC&quot; #propLtDf &lt;- norm2 %&gt;% select(clusters,propLt050) %&gt;% unique() #propLtDf$cluster &lt;- paste0(&quot;c&quot;, propLtDf$clusters) propLtDf &lt;- normNoLog %&gt;% filter(prop &lt; thdPropPbmmc | !!sym(otherSplType) &gt; thdSize) # ok for pairs of sample types normNoLog &lt;- normNoLog %&gt;% mutate(tmpCluBool= ifelse((prop &lt; thdPropPbmmc | !!sym(otherSplType) &gt; thdSize), TRUE, FALSE)) colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% mutate(cluster=clusters.mnn) %&gt;% #select(-tmpCluBool) %&gt;% left_join(normNoLog[,c(&quot;cluster&quot;, &quot;tmpCluBool&quot;)], by=&quot;cluster&quot;) %&gt;% DataFrame() norm2 &lt;- normNoLog %&gt;% data.frame() %&gt;% select(-sum, -prop) %&gt;% select(-c(grep(&quot;propOut&quot;, colnames(normNoLog), value=TRUE))) %&gt;% select(-c(grep(&quot;propLt&quot;, colnames(normNoLog), value=TRUE))) %&gt;% #tibble::rownames_to_column(&quot;clusters&quot;) %&gt;% tidyr::pivot_longer(!c(cluster, grep(&quot;tmpCluBool&quot;, colnames(normNoLog), value=TRUE) ), names_to=&quot;source_name&quot;, values_to=&quot;Freq&quot;) norm2$cluster &lt;- factor(norm2$cluster, levels=paste0(&quot;c&quot;, sortVecNames)) p &lt;- ggplot(data=norm2, aes(x=cluster,y=Freq, fill=source_name)) + theme(axis.text.x=element_text(angle = 90, hjust = 0)) + geom_col() grid.arrange(p, p + facet_wrap(norm2$tmpCluBool)) rm(p) colData(mnn.out) &lt;- colData(mnn.out) %&gt;% data.frame() %&gt;% mutate(cluster=clusters.mnn) %&gt;% #select(-tmpCluBool) %&gt;% left_join(normNoLog[,c(&quot;cluster&quot;, &quot;prop&quot;)], by=&quot;cluster&quot;) %&gt;% DataFrame() # cluster: p &lt;- plotTSNE(mnn.out, colour_by=&quot;prop&quot;, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle(&quot;PBMMC cell proportion&quot;) p1 &lt;- p + facet_wrap(~mnn.out$tmpCluBool) + theme(legend.position=&#39;bottom&#39;) # show #p1 p rm(p, p1) #mnn.out$tmpCluBool &lt;- NULL # cluster: p &lt;- plotTSNE(mnn.out, colour_by=&quot;cluster&quot;, by_exprs_values=&quot;reconstructed&quot;, point_size=0.3) p &lt;- p + ggtitle(&quot;clusters&quot;) p1 &lt;- p + facet_wrap(~mnn.out$tmpCluBool) + theme(legend.position=&#39;bottom&#39;) # show p1 splSetToGet2 &lt;- gsub(&quot;,&quot;, &quot;_&quot;, splSetToGet) # save object? fn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postDeconv%s_dsi_%s_normNoLog.Rds&quot;, projDir, outDirBit, setName, setSuf, splSetToGet2) # &#39;dsi&#39; for data set integration saveRDS(normNoLog, file=fn) 28.9 Session information sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 8 ## ## Matrix products: default ## BLAS: /opt/R/R-4.0.3/lib64/R/lib/libRblas.so ## LAPACK: /opt/R/R-4.0.3/lib64/R/lib/libRlapack.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] gridExtra_2.3 cowplot_1.1.1 ## [3] Cairo_1.5-12.2 clustree_0.4.3 ## [5] ggraph_2.0.5 pheatmap_1.0.12 ## [7] forcats_0.5.1 stringr_1.4.0 ## [9] dplyr_1.0.6 purrr_0.3.4 ## [11] readr_1.4.0 tidyr_1.1.3 ## [13] tibble_3.1.2 tidyverse_1.3.1 ## [15] bluster_1.0.0 batchelor_1.6.3 ## [17] BiocNeighbors_1.8.2 BiocSingular_1.6.0 ## [19] scran_1.18.7 scater_1.18.6 ## [21] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [23] Biobase_2.50.0 GenomicRanges_1.42.0 ## [25] GenomeInfoDb_1.26.7 IRanges_2.24.1 ## [27] S4Vectors_0.28.1 BiocGenerics_0.36.1 ## [29] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [31] ggplot2_3.3.3 BiocParallel_1.24.1 ## [33] knitr_1.33 ## ## loaded via a namespace (and not attached): ## [1] Rtsne_0.15 ggbeeswarm_0.6.0 ## [3] colorspace_2.0-1 ellipsis_0.3.2 ## [5] scuttle_1.0.4 XVector_0.30.0 ## [7] fs_1.5.0 rstudioapi_0.13 ## [9] farver_2.1.0 graphlayouts_0.7.1 ## [11] ggrepel_0.9.1 RSpectra_0.16-0 ## [13] fansi_0.4.2 lubridate_1.7.10 ## [15] xml2_1.3.2 codetools_0.2-18 ## [17] sparseMatrixStats_1.2.1 polyclip_1.10-0 ## [19] jsonlite_1.7.2 ResidualMatrix_1.0.0 ## [21] broom_0.7.6 dbplyr_2.1.1 ## [23] uwot_0.1.10 ggforce_0.3.3 ## [25] compiler_4.0.3 httr_1.4.2 ## [27] dqrng_0.3.0 backports_1.2.1 ## [29] assertthat_0.2.1 Matrix_1.3-3 ## [31] limma_3.46.0 cli_2.5.0 ## [33] tweenr_1.0.2 htmltools_0.5.1.1 ## [35] tools_4.0.3 rsvd_1.0.5 ## [37] igraph_1.2.6 gtable_0.3.0 ## [39] glue_1.4.2 GenomeInfoDbData_1.2.4 ## [41] Rcpp_1.0.6 cellranger_1.1.0 ## [43] jquerylib_0.1.4 vctrs_0.3.8 ## [45] DelayedMatrixStats_1.12.3 xfun_0.23 ## [47] ps_1.6.0 beachmat_2.6.4 ## [49] rvest_1.0.0 lifecycle_1.0.0 ## [51] irlba_2.3.3 statmod_1.4.36 ## [53] edgeR_3.32.1 zlibbioc_1.36.0 ## [55] MASS_7.3-54 scales_1.1.1 ## [57] tidygraph_1.2.0 hms_1.0.0 ## [59] RColorBrewer_1.1-2 yaml_2.2.1 ## [61] sass_0.4.0 stringi_1.6.1 ## [63] highr_0.9 checkmate_2.0.0 ## [65] rlang_0.4.11 pkgconfig_2.0.3 ## [67] bitops_1.0-7 evaluate_0.14 ## [69] lattice_0.20-44 labeling_0.4.2 ## [71] tidyselect_1.1.1 magrittr_2.0.1 ## [73] bookdown_0.22 R6_2.5.0 ## [75] generics_0.1.0 DelayedArray_0.16.3 ## [77] DBI_1.1.1 pillar_1.6.1 ## [79] haven_2.4.1 withr_2.4.2 ## [81] RCurl_1.98-1.3 modelr_0.1.8 ## [83] crayon_1.4.1 utf8_1.2.1 ## [85] rmarkdown_2.8 viridis_0.6.1 ## [87] locfit_1.5-9.4 grid_4.0.3 ## [89] readxl_1.3.1 reprex_2.0.0 ## [91] digest_0.6.27 munsell_0.5.0 ## [93] beeswarm_0.3.1 viridisLite_0.4.0 ## [95] vipor_0.4.5 bslib_0.2.5 "]]
