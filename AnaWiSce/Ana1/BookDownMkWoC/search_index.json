[["QcTopAllCells.html", "Chapter 4 Quality Control 4.1 Introduction 4.2 Load packages 4.3 Sample sheet 4.4 Data representation 4.5 Example 4.6 Mapping QC 4.7 Cell calling for droplet data 4.8 Load filtered matrices 4.9 Properties of scRNA-seq data 4.10 Quality control 4.11 Identification of low-quality cells with adaptive thresholds 4.12 Experimental factors 4.13 Novelty 4.14 QC based on sparsity 4.15 subsample Hca set", " Chapter 4 Quality Control 4.1 Introduction We will use two sets of Bone Marrow Mononuclear Cells (BMMC): ‘CaronBourque2020’: pediatric samples ‘Hca’: HCA Census of Immune Cells for adult BMMCs Fastq files were retrieved from publicly available archive (SRA and HCA). Sequencing quality was assessed and visualised using fastQC and MultiQC. Reads were aligned against GRCh38 and features counted using cellranger (v3.1.0). We will now check the quality of the data further: mapping quality and amplification rate cell counts distribution of keys quality metrics We will then: filter genes with very low expression identify low-quality cells filter and/or mark low quality cells 4.2 Load packages SingleCellExperiment - to store the data Matrix - to deal with sparse and/or large matrices DropletUtils - utilities for the analysis of droplet-based, inc. cell counting scater - QC scran - normalisation igraph - graphs biomaRt - for gene annotation ggplot2 - for plotting irlba - for faster PCA #projDir &lt;- &quot;/home/ubuntu/Course_Materials/scRNAseq&quot; projDir &lt;- params$projDir dirRel &lt;- params$dirRel outDirBit &lt;- params$outDirBit setSuf &lt;- params$setSuf # with merge-knit # params are read once only. # but we need to change one param value: dirRel # 3 solutions: # - unlock bindings to edit the global value # - copy params to edit and use the local copy # - simply set dirRel, based on type of merging if need be. # unlock binding # (but should remember to set back to init value if need be) #bindingIsLocked(&quot;params&quot;, env = .GlobalEnv) #unlockBinding(&quot;params&quot;, env = .GlobalEnv) #params$stuff &lt;- &#39;toto&#39; # OR: # global_params &lt;- params; # if merge-knit # have local copy of params to edit and use here #local_params &lt;- params; # if merge-knit #local_params$stuff &lt;- &#39;toto&#39; # OR: # if merge-knit, edit params. if(params$bookType == &quot;mk&quot;){dirRel &lt;- &quot;..&quot;} # other variables: wrkDir &lt;- sprintf(&quot;%s/CaronBourque2020/grch38300&quot;, projDir) qcPlotDirBit &lt;- &quot;Plots/Qc&quot; poolBool &lt;- TRUE # FALSE # whether to read each sample in and pool them and write object to file, or just load that file. biomartBool &lt;- FALSE # biomaRt sometimes fails, do it once, write to file and use that copy. addQcBool &lt;- TRUE # FALSE runAll &lt;- FALSE # TRUE dir.create(sprintf(&quot;%s/%s/%s&quot;, projDir, outDirBit, qcPlotDirBit), showWarnings = FALSE, recursive = TRUE) sprintf(&quot;dirRel: &#39;%s&#39;&quot;, dirRel) ## [1] &quot;dirRel: &#39;..&#39;&quot; 4.3 Sample sheet We will load both the Caron and Hca data sets. # CaronBourque2020 cb_sampleSheetFn &lt;- file.path(projDir, &quot;Data/CaronBourque2020/SraRunTable.txt&quot;) # Human Cell Atlas hca_sampleSheetFn &lt;- file.path(projDir, &quot;Data/Hca/accList_Hca.txt&quot;) # read sample sheet in: splShtColToKeep &lt;- c(&quot;Run&quot;, &quot;Sample.Name&quot;, &quot;source_name&quot;) cb_sampleSheet &lt;- read.table(cb_sampleSheetFn, header=T, sep=&quot;,&quot;) hca_sampleSheet &lt;- read.table(hca_sampleSheetFn, header=F, sep=&quot;,&quot;) colnames(hca_sampleSheet) &lt;- &quot;Sample.Name&quot; hca_sampleSheet$Run &lt;- hca_sampleSheet$Sample.Name hca_sampleSheet$source_name &lt;- &quot;ABMMC&quot; # adult BMMC sampleSheet &lt;- rbind(cb_sampleSheet[,splShtColToKeep], hca_sampleSheet[,splShtColToKeep]) sampleSheet %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) 4.4 Data representation We will use a SingleCellExperiment object that is described here and stores various data types: the count matrix feature (gene) annotation droplet annotation outcome of downstream analysis such as dimensionality reduction tmpFn &lt;- sprintf(&quot;%s/Images/tenxLibStructureV3.png&quot;, &quot;..&quot;) print(getwd()) ## [1] &quot;/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020/AnaWiSce/Ana1/ScriptsMkWoC&quot; print(tmpFn) ## [1] &quot;../Images/tenxLibStructureV3.png&quot; print(file.exists(tmpFn)) ## [1] TRUE knitr::include_graphics(tmpFn, auto_pdf = TRUE) 4.5 Example We will load the data for the first sample in the sample sheet: SRR9264343. i &lt;- 1 sample.path &lt;- sprintf(&quot;%s/%s/%s/outs/raw_feature_bc_matrix/&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) sce.raw &lt;- read10xCounts(sample.path, col.names=TRUE) sce.raw ## class: SingleCellExperiment ## dim: 33538 737280 ## metadata(1): Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(3): ID Symbol Type ## colnames(737280): AAACCTGAGAAACCAT-1 AAACCTGAGAAACCGC-1 ... ## TTTGTCATCTTTAGTC-1 TTTGTCATCTTTCCTC-1 ## colData names(2): Sample Barcode ## reducedDimNames(0): ## altExpNames(0): We can access these different types of data with various functions. Number of genes and droplets in the count matrix: dim(counts(sce.raw)) ## [1] 33538 737280 Features, with rowData(): head(rowData(sce.raw)) ## DataFrame with 6 rows and 3 columns ## ID Symbol Type ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000243485 ENSG00000243485 MIR1302-2HG Gene Expression ## ENSG00000237613 ENSG00000237613 FAM138A Gene Expression ## ENSG00000186092 ENSG00000186092 OR4F5 Gene Expression ## ENSG00000238009 ENSG00000238009 AL627309.1 Gene Expression ## ENSG00000239945 ENSG00000239945 AL627309.3 Gene Expression ## ENSG00000239906 ENSG00000239906 AL627309.2 Gene Expression Samples, with colData(): head(colData(sce.raw)) ## DataFrame with 6 rows and 2 columns ## Sample Barcode ## &lt;character&gt; &lt;character&gt; ## AAACCTGAGAAACCAT-1 /ssd/personal/baller.. AAACCTGAGAAACCAT-1 ## AAACCTGAGAAACCGC-1 /ssd/personal/baller.. AAACCTGAGAAACCGC-1 ## AAACCTGAGAAACCTA-1 /ssd/personal/baller.. AAACCTGAGAAACCTA-1 ## AAACCTGAGAAACGAG-1 /ssd/personal/baller.. AAACCTGAGAAACGAG-1 ## AAACCTGAGAAACGCC-1 /ssd/personal/baller.. AAACCTGAGAAACGCC-1 ## AAACCTGAGAAAGTGG-1 /ssd/personal/baller.. AAACCTGAGAAAGTGG-1 Single-cell RNA-seq data compared to bulk RNA-seq is sparse, especially with droplet-based methods such as 10X, mostly because: a given cell does not express each gene the library preparation does not capture all transcript the cell does express the sequencing depth per cell is far lower Counts, with counts(). Given the large number of droplets in a sample, count matrices can be large. They are however very sparse and can be stored in a ‘sparse matrix’ that only stores non-zero values, for example a ‘dgCMatrix’ object (‘DelayedArray’ class). counts(sce.raw) &lt;- as(counts(sce.raw), &quot;dgCMatrix&quot;) #class(counts(sce.raw)) counts(sce.raw)[1:10, 1:10] ## 10 x 10 sparse Matrix of class &quot;dgCMatrix&quot; ## ## ENSG00000243485 . . . . . . . . . . ## ENSG00000237613 . . . . . . . . . . ## ENSG00000186092 . . . . . . . . . . ## ENSG00000238009 . . . . . . . . . . ## ENSG00000239945 . . . . . . . . . . ## ENSG00000239906 . . . . . . . . . . ## ENSG00000241599 . . . . . . . . . . ## ENSG00000236601 . . . . . . . . . . ## ENSG00000284733 . . . . . . . . . . ## ENSG00000235146 . . . . . . . . . . 4.6 Mapping QC 4.6.1 Gene body coverage The plot below show the average coverage (y-axis) along the body of genes (x-axis). tmpFn &lt;- sprintf(&quot;%s/Images/1_AAACCTGAGACTTTCG-1.rseqcGeneBodyCovCheck.txt.geneBodyCoverage.curves.png&quot;, &quot;..&quot;) knitr::include_graphics(tmpFn, auto_pdf = TRUE) 4.6.2 Amplification rate We will use the information stored in the ‘molecule info’ file to count the number of UMI and reads for each gene in each cell. ##mol.info.file &lt;- sprintf(&quot;%s/%s/%s/outs/molecule_info.h5&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) ##mol.info &lt;- read10xMolInfo(mol.info.file) # or mol.info object if issue with H5Fopen mol.info.file &lt;- sprintf(&quot;%s/%s/%s/outs/molecule_info_h5.Rds&quot;, wrkDir, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) mol.info &lt;- readRDS(mol.info.file) # slow # &#39;data&#39; slot: mol.info$data ## DataFrame with 18544666 rows and 5 columns ## cell umi gem_group gene reads ## &lt;character&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 1 AAACCTGAGAAACCTA 467082 1 3287 1 ## 2 AAACCTGAGAAACCTA 205888 1 3446 1 ## 3 AAACCTGAGAAACCTA 866252 1 3896 3 ## 4 AAACCTGAGAAACCTA 796027 1 3969 1 ## 5 AAACCTGAGAAACCTA 542561 1 5008 1 ## ... ... ... ... ... ... ## 18544662 TTTGTCATCTTTAGTC 927060 1 23634 1 ## 18544663 TTTGTCATCTTTAGTC 975865 1 27143 1 ## 18544664 TTTGTCATCTTTAGTC 364964 1 27467 4 ## 18544665 TTTGTCATCTTTAGTC 152570 1 30125 7 ## 18544666 TTTGTCATCTTTAGTC 383230 1 30283 5 # &#39;genes&#39; slot head(mol.info$genes) ## [1] &quot;ENSG00000243485&quot; &quot;ENSG00000237613&quot; &quot;ENSG00000186092&quot; &quot;ENSG00000238009&quot; ## [5] &quot;ENSG00000239945&quot; &quot;ENSG00000239906&quot; # for each cell and gene, count UMIs # slow, but needs running, at least once # so write it to file to load later if need be. tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_preProc_ampDf1.Rds&quot;, projDir, outDirBit) if(!file.exists(tmpFn)) { ampDf &lt;- mol.info$data %&gt;% data.frame() %&gt;% mutate(umi = as.character(umi)) %&gt;% group_by(cell, gene) %&gt;% summarise(nUmis = n(), totReads=sum(reads)) %&gt;% data.frame() # Write object to file saveRDS(ampDf, tmpFn) } else { ampDf &lt;- readRDS(tmpFn) } rm(tmpFn) # distribution of nUmis summary(ampDf$totReads) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.00 2.00 6.00 15.23 12.00 79275.00 # distribution of totReads summary(ampDf$nUmis) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 1.000 1.000 2.377 1.000 7137.000 # too slow sp &lt;- ggplot(ampDf, aes(x=nUmis, y=totReads)) + geom_point() + scale_x_continuous(trans=&#39;log2&#39;) + scale_y_continuous(trans=&#39;log2&#39;) sp #ggMarginal(sp) sp2 &lt;- ggplot(ampDf, aes(x=nUmis, y=totReads)) + geom_bin2d(bins = 50) + scale_fill_continuous(type = &quot;viridis&quot;) + scale_x_continuous(trans=&#39;log10&#39;) + scale_y_continuous(trans=&#39;log10&#39;) + ggtitle(&quot;totReads vs nUmis&quot;) + theme_bw() sp2 gc(verbose=FALSE) ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 8607496 459.7 14359685 766.9 10348140 552.7 ## Vcells 106253761 810.7 268468577 2048.3 268431254 2048.0 4.7 Cell calling for droplet data For a given sample, amongst the tens of thousands of droplets used in the assay, some will contain a cell while many others will not. The presence of RNA in a droplet will show with non-zero UMI count. This is however not sufficient to infer that the droplet does contain a cell. Indeed, after sample preparation, some cell debris including RNA will still float in the mix. This ambient RNA is unwillignly captured during library preparation and sequenced. Cellranger generates a count matrix that includes all droplets analysed in the assay. We will now load this ‘raw matrix’ for one sample and draw the distribution of UMI counts. Distribution of UMI counts: libSizeDf &lt;- mol.info$data %&gt;% data.frame() %&gt;% mutate(umi = as.character(umi)) %&gt;% group_by(cell) %&gt;% summarise(nUmis = n(), totReads=sum(reads)) %&gt;% data.frame() rm(mol.info) ggplot(libSizeDf, aes(x=log10(nUmis))) + geom_histogram(bins = 50) Library size varies widely, both amongst empty droplets and droplets carrying cells, mostly due to: variation in droplet size, amplification efficiency, sequencing Most cell counting methods try to identify the library size that best distinguishes empty from cell-carrying droplets. 4.7.1 Mixture model This method by default fits a mixture of two normal distributions to the logged library sizes: one with a small mean for empty droplets the other with a higher mean for cell-carrying droplets set.seed(100) # get package library(&quot;mixtools&quot;) # have library sizes on a log10 scale log10_lib_size &lt;- log10(libSizeDf$nUmis) # fit mixture mix &lt;- normalmixEM(log10_lib_size, mu=c(log10(10), log10(100), log10(10000)), maxrestarts=50, epsilon = 1e-03) ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## One of the variances is going to zero; trying new starting values. ## number of iterations= 64 # plot p1 &lt;- dnorm(log10_lib_size, mean=mix$mu[1], sd=mix$sigma[1]) p2 &lt;- dnorm(log10_lib_size, mean=mix$mu[2], sd=mix$sigma[2]) p3 &lt;- dnorm(log10_lib_size, mean=mix$mu[3], sd=mix$sigma[3]) pList &lt;- list(p1, p2, p3) if (mix$mu[1] &lt; mix$mu[2]) { split &lt;- min(log10_lib_size[p1 &lt; p2]) } else { split &lt;- min(log10_lib_size[p2 &lt; p1]) } # find densities with the higest means: i1 &lt;- which(order(mix$mu)==2) i2 &lt;- which(order(mix$mu)==3) # find intersection: dd0 &lt;- data.frame(log10_lib_size=log10_lib_size, #p1, p2, p3) pA=pList[[i1]], pB=pList[[i2]]) split &lt;- dd0 %&gt;% filter(pA &lt; pB &amp; mix$mu[i1] &lt; log10_lib_size) %&gt;% arrange(log10_lib_size) %&gt;% head(n=1) %&gt;% pull(log10_lib_size) # show split on plot: plot(mix, which=2, xlab2=&quot;log10(mol per cell)&quot;) # get density for each distribution: #log10_lib_size &lt;- log10(libSizeDf$nUmis) abline(v=split, lwd=2) dd &lt;- data.frame(log10_lib_size=log10_lib_size, p1, p2, p3) %&gt;% arrange(log10_lib_size) %&gt;% tidyr::pivot_longer(!log10_lib_size, names_to = &quot;curve&quot;, values_to = &quot;density&quot;) head(dd) ggplot(dd, aes(x=log10_lib_size, y=density, col=curve)) + geom_line() 4.7.2 Barcode rank plot The barcode rank plot shows the library sizes against their rank in decreasing order. barcode_rank &lt;- rank(-libSizeDf$nUmis) plot(barcode_rank, libSizeDf$nUmis, xlim=c(1,10000), ylab=&quot;library size&quot;) Given the exponential shape of the curve above, with library sizes can be shown on the log10 scale: plot(barcode_rank, log10_lib_size, xlim=c(1,10000)) The plot above shows that the majority of droplets have fewer than 100 UMIs, e.g. droplets with rank greater than 4000. We will redraw the plot to focus on droplets with lower ranks, by using the log10 scale for the x-axis. plot(log10(barcode_rank), log10_lib_size, xlim=log10(c(1,10000))) The point on the curve where it drops sharply may be used as the split point. Before that point library sizes are high, because droplets carry a cell. After that point, library sizes are far smaller because droplets do not carry a cell, only ambient RNA (… or do they?). Here, we could ‘visually’ approximate the number of cells to 2500. There are however more robust and convenient methods. 4.7.3 Inflection point We could also compute the inflection point of the curve. o &lt;- order(barcode_rank) log10_lib_size &lt;- log10_lib_size[o] barcode_rank &lt;- barcode_rank[o] rawdiff &lt;- diff(log10_lib_size)/diff(barcode_rank) inflection &lt;- which(rawdiff == min(rawdiff[100:length(rawdiff)], na.rm=TRUE)) plot(x=log10(barcode_rank), y=log10_lib_size, xlim=log10(c(1,10000))) abline(v=log10(inflection), col=&quot;red&quot;, lwd=2) The inflection is at 3279 UMIs (3.5157414 on the log10 scale). 2306 droplets have at least these many UMIs and would thus contain one cell (or more). 4.7.4 Cellranger v1 and v2 Given an expected number of cells, cellranger used to assume a ~10-fold range of library sizes for real cells and estimate this range (cellranger (v1 and v2). The threshold was defined as the 99th quantile of the library size, divided by 10. # approximate number of cells expected: n_cells &lt;- 2500 # CellRanger totals &lt;- sort(libSizeDf$nUmis, decreasing = TRUE) # 99th percentile of top n_cells divided by 10 thresh = totals[round(0.01*n_cells)]/10 plot(x=log10(seq(1,10000)), y=log10(totals)[1:10000] ) abline(h=log10(thresh), col=&quot;red&quot;, lwd=2) The threshold is at 1452 UMIs and 2773 cells are detected. 4.7.5 DropletUtils and EmptyDrops The DropletUtils package offers utilities to analyse droplet-based data, including cell counting using the library size as seen above. These simple approaches may exclude droplets with small or quiet cells with low RNA content. The emptyDrops method calls cells by first computing the expression profile for droplets with RNA content so low they almost certainly do not contain any cell: the ‘background’ or ‘ambient’ profile. The method then tests each non-background droplet for significant difference in expression profile. Let’s first check the knee and inflection methods. my.counts &lt;- counts(sce.raw) br.out &lt;- barcodeRanks(my.counts) plot(br.out$rank, br.out$total, log=&quot;xy&quot;, xlab=&quot;Rank&quot;, ylab=&quot;Total UMI count&quot;) o &lt;- order(br.out$rank) lines(br.out$rank[o], br.out$fitted[o], col=&quot;red&quot;) abline(h=metadata(br.out)$knee, col=&quot;dodgerblue&quot;, lty=2) abline(h=metadata(br.out)$inflection, col=&quot;forestgreen&quot;, lty=2) legend(&quot;bottomleft&quot;, lty=2, col=c(&quot;dodgerblue&quot;, &quot;forestgreen&quot;), legend=c(&quot;knee&quot;, &quot;inflection&quot;)) Testing for empty droplets. We will call cells with a false discovery rate (FDR) of 0.1% so that at most 1 in 1000 droplets called may be empty. # a bit slow # significance is computed by simulation so we set a seed for reproducibility set.seed(100) # run analysis: e.out &lt;- emptyDrops(counts(sce.raw)) e.out ## DataFrame with 737280 rows and 5 columns ## Total LogProb PValue Limited FDR ## &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;logical&gt; &lt;numeric&gt; ## AAACCTGAGAAACCAT-1 0 NA NA NA NA ## AAACCTGAGAAACCGC-1 0 NA NA NA NA ## AAACCTGAGAAACCTA-1 31 NA NA NA NA ## AAACCTGAGAAACGAG-1 0 NA NA NA NA ## AAACCTGAGAAACGCC-1 0 NA NA NA NA ## ... ... ... ... ... ... ## TTTGTCATCTTTACAC-1 0 NA NA NA NA ## TTTGTCATCTTTACGT-1 1 NA NA NA NA ## TTTGTCATCTTTAGGG-1 0 NA NA NA NA ## TTTGTCATCTTTAGTC-1 26 NA NA NA NA ## TTTGTCATCTTTCCTC-1 0 NA NA NA NA NAs are assigned to droplets used to compute the ambient profile. Get numbers of droplets in each class defined by FDR and the cut-off used: summary(e.out$FDR &lt;= 0.001) ## Mode FALSE TRUE NA&#39;s ## logical 487 3075 733718 The test significance is computed by permutation. For each droplet tested, the number of permutations may limit the value of the p-value. This information is available in the ‘Limited’ column. If ‘Limited’ is ‘TRUE’ for any non-significant droplet, the number of permutations was too low, should be increased and the analysis re-run. comment=&quot;emptyDrops() uses Monte Carlo simulations to compute p-values for the multinomial sampling transcripts from the ambient pool. The number of Monte Carlo iterations determines the lower bound for the p-values (Phipson and Smyth 2010). The Limited field in the output indicates whether or not the computed p-value for a particular barcode is bounded by the number of iterations. If any non-significant barcodes are TRUE for Limited, we may need to increase the number of iterations. A larger number of iterations will result in a lower p-value for these barcodes, which may allow them to be detected after correcting for multiple testing.&quot; table(Sig=e.out$FDR &lt;= 0.001, Limited=e.out$Limited) ## Limited ## Sig FALSE TRUE ## FALSE 487 0 ## TRUE 76 2999 Let’s check that the background comprises only empty droplets. If the droplets used to define the background profile are indeed empty, testing them should result in a flat distribution of p-values. Let’s test the ‘ambient’ droplets and draw the p-value distribution. commment=&quot;As mentioned above, emptyDrops() assumes that barcodes with low total UMI counts are empty droplets. Thus, the null hypothesis should be true for all of these barcodes. We can check whether the hypothesis testing procedure holds its size by examining the distribution of p-values for low-total barcodes with test.ambient=TRUE. Ideally, the distribution should be close to uniform (Figure 6.6). Large peaks near zero indicate that barcodes with total counts below lower are not all ambient in origin. This can be resolved by decreasing lower further to ensure that barcodes corresponding to droplets with very small cells are not used to estimate the ambient profile.&quot; set.seed(100) limit &lt;- 100 all.out &lt;- emptyDrops(counts(sce.raw), lower=limit, test.ambient=TRUE) hist(all.out$PValue[all.out$Total &lt;= limit &amp; all.out$Total &gt; 0], xlab=&quot;P-value&quot;, main=&quot;&quot;, col=&quot;grey80&quot;) The distribution of p-values looks uniform with no large peak for small values: no cell in these droplets. To evaluate the outcome of the analysis, we will plot the strength of the evidence against library size. is.cell &lt;- e.out$FDR &lt;= 0.001 Number of cells detected: 3075. The plot plot shows the strength of the evidence against the library size. Each point is a droplet coloured: in black if without cell, in red if with a cell (or more) in green if with a cell (or more) as defined with emptyDrops but not the inflection method. # colour: cellColour &lt;- ifelse(is.cell, &quot;red&quot;, &quot;black&quot;) # rep(&quot;black&quot;, nrow((e.out))) # boolean for presence of cells as defined by the inflection method tmpBoolInflex &lt;- e.out$Total &gt; metadata(br.out)$inflection # boolean for presence of cells as defined by the emptyDrops method tmpBoolSmall &lt;- e.out$FDR &lt;= 0.001 tmpBoolRecov &lt;- !tmpBoolInflex &amp; tmpBoolSmall cellColour[tmpBoolRecov] &lt;- &quot;green&quot; # &#39;recovered&#39; cells # plot strength of significance vs library size plot(log10(e.out$Total), -e.out$LogProb, col=cellColour, xlim=c(2,max(log10(e.out$Total))), xlab=&quot;Total UMI count&quot;, ylab=&quot;-Log Probability&quot;) # add point to show &#39;recovered&#39; cell on top points(log10(e.out$Total)[tmpBoolRecov], -e.out$LogProb[tmpBoolRecov], pch=16, col=&quot;green&quot;) Let’s filter out empty droplets. comment=&quot;Once we are satisfied with the performance of emptyDrops(), we subset our SingleCellExperiment object to retain only the detected cells. Discerning readers will notice the use of which(), which conveniently removes the NAs prior to the subsetting.&quot; sce.ed &lt;- sce.raw[,which(e.out$FDR &lt;= 0.001)] # ed for empty droplet And check the new SCE object: sce.ed ## class: SingleCellExperiment ## dim: 33538 3075 ## metadata(1): Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(3): ID Symbol Type ## colnames(3075): AAACCTGAGACTTTCG-1 AAACCTGGTCTTCAAG-1 ... ## TTTGTCACAGGCTCAC-1 TTTGTCAGTTCGGCAC-1 ## colData names(2): Sample Barcode ## reducedDimNames(0): ## altExpNames(0): Cell calling in cellranger v3 uses a method similar to emptyDrops() and a ‘filtered matrix’ is generated that only keeps droplets deemed to contain a cell. We will load these filtered matrices now. text=&quot;emptyDrops() already removes cells with very low library sizes or (by association) low numbers of expressed genes. Thus, further filtering on these metrics is not strictly necessary. It may still be desirable to filter on both of these metrics to remove non-empty droplets containing cell fragments or stripped nuclei that were not caught by the mitochondrial filter. However, this should be weighed against the risk of losing genuine cell types as discussed in Section 6.3.2.2.&quot; 4.8 Load filtered matrices Each sample was analysed with cellranger separately. We load filtered matrices one sample at a time, showing for each the name and number of features and cells. # a bit slow # load data: sce.list &lt;- vector(&quot;list&quot;, length = nrow(sampleSheet)) for (i in 1:nrow(sampleSheet)) { print(sprintf(&quot;&#39;Run&#39; %s, &#39;Sample.Name&#39; %s&quot;, sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Sample.Name&quot;])) sample.path &lt;- sprintf(&quot;%s/%s/%s/outs/filtered_feature_bc_matrix/&quot;, sprintf(&quot;%s/%s/grch38300&quot;, projDir, ifelse(sampleSheet[i,&quot;source_name&quot;] == &quot;ABMMC&quot;, &quot;Hca&quot;, &quot;CaronBourque2020&quot;)), sampleSheet[i,&quot;Run&quot;], sampleSheet[i,&quot;Run&quot;]) sce.list[[i]] &lt;- read10xCounts(sample.path) print(dim(sce.list[[i]])) } ## [1] &quot;&#39;Run&#39; SRR9264343, &#39;Sample.Name&#39; GSM3872434&quot; ## [1] 33538 3088 ## [1] &quot;&#39;Run&#39; SRR9264344, &#39;Sample.Name&#39; GSM3872435&quot; ## [1] 33538 6678 ## [1] &quot;&#39;Run&#39; SRR9264345, &#39;Sample.Name&#39; GSM3872436&quot; ## [1] 33538 5054 ## [1] &quot;&#39;Run&#39; SRR9264346, &#39;Sample.Name&#39; GSM3872437&quot; ## [1] 33538 6096 ## [1] &quot;&#39;Run&#39; SRR9264347, &#39;Sample.Name&#39; GSM3872438&quot; ## [1] 33538 5442 ## [1] &quot;&#39;Run&#39; SRR9264348, &#39;Sample.Name&#39; GSM3872439&quot; ## [1] 33538 5502 ## [1] &quot;&#39;Run&#39; SRR9264349, &#39;Sample.Name&#39; GSM3872440&quot; ## [1] 33538 4126 ## [1] &quot;&#39;Run&#39; SRR9264350, &#39;Sample.Name&#39; GSM3872441&quot; ## [1] 33538 3741 ## [1] &quot;&#39;Run&#39; SRR9264351, &#39;Sample.Name&#39; GSM3872442&quot; ## [1] 33538 978 ## [1] &quot;&#39;Run&#39; SRR9264352, &#39;Sample.Name&#39; GSM3872442&quot; ## [1] 33538 1150 ## [1] &quot;&#39;Run&#39; SRR9264353, &#39;Sample.Name&#39; GSM3872443&quot; ## [1] 33538 4964 ## [1] &quot;&#39;Run&#39; SRR9264354, &#39;Sample.Name&#39; GSM3872444&quot; ## [1] 33538 4255 ## [1] &quot;&#39;Run&#39; MantonBM1, &#39;Sample.Name&#39; MantonBM1&quot; ## [1] 33538 23283 ## [1] &quot;&#39;Run&#39; MantonBM2, &#39;Sample.Name&#39; MantonBM2&quot; ## [1] 33538 25055 ## [1] &quot;&#39;Run&#39; MantonBM3, &#39;Sample.Name&#39; MantonBM3&quot; ## [1] 33538 24548 ## [1] &quot;&#39;Run&#39; MantonBM4, &#39;Sample.Name&#39; MantonBM4&quot; ## [1] 33538 26478 ## [1] &quot;&#39;Run&#39; MantonBM5, &#39;Sample.Name&#39; MantonBM5&quot; ## [1] 33538 26383 ## [1] &quot;&#39;Run&#39; MantonBM6, &#39;Sample.Name&#39; MantonBM6&quot; ## [1] 33538 22801 ## [1] &quot;&#39;Run&#39; MantonBM7, &#39;Sample.Name&#39; MantonBM7&quot; ## [1] 33538 24372 ## [1] &quot;&#39;Run&#39; MantonBM8, &#39;Sample.Name&#39; MantonBM8&quot; ## [1] 33538 24860 Let’s combine all 20 samples into a single object. We first check the feature lists are identical. # check row names are the same # compare to that for the first sample rowNames1 &lt;- rownames(sce.list[[1]]) for (i in 2:nrow(sampleSheet)) { print(identical(rowNames1, rownames(sce.list[[i]]))) } ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE A cell barcode comprises the actual sequence and a ‘group ID’, e.g. AAACCTGAGAAACCAT-1. The latter helps distinguish cells that share the same sequence but come from different samples. As each sample was analysed separately, the group ID is set to 1 in all data sets. To pool these data sets we first need to change group IDs so cell barcodes are unique across all samples. We will use the position of the sample in the sample sheet. sce &lt;- sce.list[[1]] colData(sce)$Barcode &lt;- gsub(&quot;([0-9])$&quot;, 1, colData(sce)$Barcode) print(head(colData(sce)$Barcode)) ## [1] &quot;AAACCTGAGACTTTCG-1&quot; &quot;AAACCTGGTCTTCAAG-1&quot; &quot;AAACCTGGTGCAACTT-1&quot; ## [4] &quot;AAACCTGGTGTTGAGG-1&quot; &quot;AAACCTGTCCCAAGTA-1&quot; &quot;AAACCTGTCGAATGCT-1&quot; print(tail(colData(sce)$Barcode)) ## [1] &quot;TTTGGTTTCCGAAGAG-1&quot; &quot;TTTGGTTTCTTTAGGG-1&quot; &quot;TTTGTCAAGAAACGAG-1&quot; ## [4] &quot;TTTGTCAAGGACGAAA-1&quot; &quot;TTTGTCACAGGCTCAC-1&quot; &quot;TTTGTCAGTTCGGCAC-1&quot; for (i in 2:nrow(sampleSheet)) { sce.tmp &lt;- sce.list[[i]] colData(sce.tmp)$Barcode &lt;- gsub(&quot;([0-9])$&quot;, i, colData(sce.tmp)$Barcode) sce &lt;- cbind(sce, sce.tmp) #print(head(colData(sce)$Barcode)) print(tail(colData(sce)$Barcode, 2)) } ## [1] &quot;TTTGTCATCTTAACCT-2&quot; &quot;TTTGTCATCTTCTGGC-2&quot; ## [1] &quot;TTTGTCATCCGCGGTA-3&quot; &quot;TTTGTCATCCGGGTGT-3&quot; ## [1] &quot;TTTGTCATCACTCTTA-4&quot; &quot;TTTGTCATCTATCCCG-4&quot; ## [1] &quot;TTTGTCAGTTCCCTTG-5&quot; &quot;TTTGTCATCGACGGAA-5&quot; ## [1] &quot;TTTGTCATCCTTTCGG-6&quot; &quot;TTTGTCATCTATGTGG-6&quot; ## [1] &quot;TTTGTCAGTCATTAGC-7&quot; &quot;TTTGTCAGTTGTGGCC-7&quot; ## [1] &quot;TTTGTCATCTACCAGA-8&quot; &quot;TTTGTCATCTGCAGTA-8&quot; ## [1] &quot;TTTGGTTGTGCATCTA-9&quot; &quot;TTTGTCACAGCTCGAC-9&quot; ## [1] &quot;TTTGTCAGTAAATGTG-10&quot; &quot;TTTGTCAGTACAAGTA-10&quot; ## [1] &quot;TTTGTCATCACCCTCA-11&quot; &quot;TTTGTCATCTTCATGT-11&quot; ## [1] &quot;TTTGTCATCAGTTGAC-12&quot; &quot;TTTGTCATCTCGTTTA-12&quot; ## [1] &quot;TTTGTCATCTTTACAC-13&quot; &quot;TTTGTCATCTTTCCTC-13&quot; ## [1] &quot;TTTGTCATCGACGGAA-14&quot; &quot;TTTGTCATCGCCTGAG-14&quot; ## [1] &quot;TTTGTCATCTTGTACT-15&quot; &quot;TTTGTCATCTTTAGGG-15&quot; ## [1] &quot;TTTGTCATCGGATGGA-16&quot; &quot;TTTGTCATCGTGGACC-16&quot; ## [1] &quot;TTTGTCATCTGCGGCA-17&quot; &quot;TTTGTCATCTGCGTAA-17&quot; ## [1] &quot;TTTGTCATCTAACTGG-18&quot; &quot;TTTGTCATCTGCGGCA-18&quot; ## [1] &quot;TTTGTCATCTGGGCCA-19&quot; &quot;TTTGTCATCTTGTATC-19&quot; ## [1] &quot;TTTGTCATCTTGAGAC-20&quot; &quot;TTTGTCATCTTGTATC-20&quot; We now add the sample sheet information to the object metadata. colDataOrig &lt;- colData(sce) # split path: tmpList &lt;- strsplit(colDataOrig$Sample, split=&quot;/&quot;) # get Run ID, to use to match sample in the meta data and sample sheet objects: tmpVec &lt;- unlist(lapply(tmpList, function(x){x[9]})) colData(sce)$Run &lt;- tmpVec # merge: colData(sce) &lt;- colData(sce) %&gt;% data.frame %&gt;% left_join(sampleSheet[,splShtColToKeep], &quot;Run&quot;) %&gt;% DataFrame Let’s save the object for future reference. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postPool%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postPool%s.Rds&quot;, projDir, outDirBit, setSuf) sce &lt;- readRDS(tmpFn) 4.9 Properties of scRNA-seq data # a bit slow # TODO first remove emtpy droplets the mol.info data mol.info$data head(mol.info$genes) dd &lt;- mol.info$data %&gt;% data.frame() dd$umi &lt;- as.character(dd$umi) tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_preProc_ampDf2.Rds&quot;, projDir, outDirBit) if(FALSE) # slow { ampDf &lt;- dd %&gt;% filter(paste(cell,gem_group, sep=&quot;-&quot;) %in% sce$Barcode) %&gt;% group_by(cell, gene) %&gt;% summarise(nUmis = n(), totReads=sum(reads)) %&gt;% data.frame() # Write object to file saveRDS(ampDf, tmpFn) } else { ampDf &lt;- readRDS(tmpFn) } rm(tmpFn) #summary(ampDf$nUmis) #summary(ampDf$totReads) hist(log2(ampDf$nUmis), n=100) hist(log2(ampDf$totReads), n=100) sp2 &lt;- ggplot(ampDf, aes(x=nUmis, y=totReads)) + geom_bin2d(bins = 50) + scale_fill_continuous(type = &quot;viridis&quot;) + scale_x_continuous(trans=&#39;log2&#39;) + scale_y_continuous(trans=&#39;log2&#39;) + theme_bw() sp2 #rm(mol.info) gc() The number and identity of genes detected in a cell vary across cells: the total number of genes detected across all cells is far larger than the number of genes per cell. Total number of genes detected across cells: # for each gene, compute total number of UMIs across all cells, # then counts genes with at least one UMI: countsRowSums &lt;- rowSums(counts(sce)) sum(countsRowSums &gt; 0) ## [1] 27795 Summary of the distribution of the number of genes detected per cell: # for each cell count number of genes with at least 1 UMI # then compute distribution moments: summary(colSums(counts(sce) &gt; 0)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 26 724 873 1173 1262 8077 Now let’s plot for each gene, the total number of UMIs and the proportion of cells that express it. Lowly expressed genes tend to be detected in a large proportion of cells. The higher the overall expression the lower the proportion of cells. # very slow; many points # skip in DEV, TODO: write plot to file and embed that. # x-axis: total number of UMIs for the gene across all cells # y-axis: fraction of cells expressing the gene tmpFn &lt;- sprintf(&quot;%s/%s/%s/corelLibSizePropCellExpress%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) png(tmpFn) plot( # x-axis: nb UMI per gene across all cells countsRowSums, # y-axis: proportion of cells that do express the cell rowMeans(counts(sce) &gt; 0), log = &quot;x&quot;, xlab=&quot;total number of UMIs&quot;, ylab=&quot;proportion of cells expressing the gene&quot; ) dev.off() dd &lt;- data.frame(&quot;countsRowSums&quot; = countsRowSums, &quot;propCellsExpr&quot; = rowMeans(counts(sce) &gt; 0)) head(dd) ## countsRowSums propCellsExpr ## ENSG00000243485 3 1.205526e-05 ## ENSG00000237613 0 0.000000e+00 ## ENSG00000186092 0 0.000000e+00 ## ENSG00000238009 203 8.157393e-04 ## ENSG00000239945 5 2.009210e-05 ## ENSG00000239906 0 0.000000e+00 sp &lt;- ggplot(dd, aes(x=countsRowSums, y=propCellsExpr)) + geom_point(alpha=0.3) + scale_x_continuous(trans=&#39;log10&#39;) + geom_density_2d() + xlab(&quot;total number of UMIs&quot;) + ylab(&quot;proportion of cells expressing the gene&quot;) #sp #ggExtra::ggMarginal(sp) tmpFn &lt;- sprintf(&quot;%s/%s/%s/corelLibSizePropCellExpress%s_2.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) ggsave(ggExtra::ggMarginal(sp), file=tmpFn) rm(tmpFn) getwd() tmpFn &lt;- sprintf(&quot;%s/%s/corelLibSizePropCellExpress%s_2.png&quot;, dirRel, qcPlotDirBit, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Count genes that are not ‘expressed’ (detected): not.expressed &lt;- rowSums(counts(sce)) == 0 table(not.expressed) ## not.expressed ## FALSE TRUE ## 27795 5743 Plot the percentage of counts per gene and show genes with the highest UMI counts: #Compute the relative expression of each gene per cell # a bit slow rel_expression &lt;- t( t(counts(sce)) / Matrix::colSums(counts(sce))) * 100 rownames(rel_expression) &lt;- rowData(sce)$Symbol most_expressed &lt;- sort(Matrix::rowSums( rel_expression ),T)[20:1] / ncol(sce) boxplot( as.matrix(t(rel_expression[names(most_expressed),])), cex=.1, las=1, xlab=&quot;% total count per cell&quot;, col=scales::hue_pal()(20)[20:1], horizontal=TRUE) Mind that we have combined two data sets here. It may be interesting to count non-expressed genes in each set separately. 4.10 Quality control Cell calling performed above does not inform on the quality of the library in each of the droplets kept. Poor-quality cells, or rather droplets, may be caused by cell damage during dissociation or failed library preparation. They usually have low UMI counts, few genes detected and/or high mitochondrial content. The presence may affect normalisation, assessment of cell population heterogeneity, clustering and trajectory: Normalisation: Contaminating genes, ‘the ambient RNA’, are detected at low levels in all libraires. In low quality libraries with low RNA content, scaling will increase counts for these genes more than for better-quality cells, resulting in their apparent upregulation in these cells and increased variance overall. Cell population heterogeneity: variance estimation and dimensionality reduction with PCA where the first principal component will be correlated with library size, rather than biology. Clustering and trajectory: higher mitochondrial and/or nuclear RNA content may cause low-quality cells to cluster separately or form states or trajectories between distinct cell types. We will now exclude lowly expressed features and identify low-quality cells using the following metrics mostly: library size, i.e. the total number of UMIs per cell number of features detected per cell mitochondrial content, i.e. the proportion of UMIs that map to mitochondrial genes, with higher values consistent with leakage from the cytoplasm of RNA, but not mitochodria We will first annotate genes, to know which lie in the mitochondrial genome, then use scater’s addPerCellQC() to compute various metrics. Annotate genes with biomaRt. # retrieve the feature information gene.info &lt;- rowData(sce) # setup the biomaRt connection to Ensembl using the correct species genome (hsapiens_gene_ensembl) ensembl &lt;- useEnsembl(biomart=&#39;ensembl&#39;, dataset=&#39;hsapiens_gene_ensembl&#39;, #mirror = &quot;www&quot;) #mirror = &quot;useast&quot;) mirror = &quot;uswest&quot;) #mirror = &quot;asia&quot;) ensembl = useMart(biomart=&quot;ENSEMBL_MART_ENSEMBL&quot;, dataset=&quot;hsapiens_gene_ensembl&quot;, host=&quot;uswest.ensembl.org&quot;, ensemblRedirect = FALSE) # retrieve the attributes of interest from biomaRt using the Ensembl gene ID as the key # beware that this will only retrieve information for matching IDs gene_symbol &lt;- getBM(attributes=c(&#39;ensembl_gene_id&#39;, &#39;external_gene_name&#39;, &#39;chromosome_name&#39;, &#39;start_position&#39;, &#39;end_position&#39;, &#39;strand&#39;), filters=&#39;ensembl_gene_id&#39;, mart=ensembl, values=gene.info[, 1]) # create a new data frame of the feature information gene.merge &lt;- merge(gene_symbol, gene.info, by.x=c(&#39;ensembl_gene_id&#39;), by.y=c(&#39;ID&#39;), all.y=TRUE) rownames(gene.merge) &lt;- gene.merge$ensembl_gene_id # set the order for the same as the original gene information gene.merge &lt;- gene.merge[gene.info[, 1], ] # reset the rowdata on the SCE object to contain all of this information rowData(sce) &lt;- gene.merge # slow # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postBiomart%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postBiomart%s.Rds&quot;, projDir, outDirBit, setSuf) sce &lt;- readRDS(tmpFn) table(rowData(sce)$chromosome_name) ## ## 1 10 11 12 13 14 15 ## 3127 1221 1910 1748 662 1380 1121 ## 16 17 18 19 2 20 21 ## 1518 1880 654 1989 2263 889 499 ## 22 3 4 5 6 7 8 ## 831 1704 1345 1646 1616 1526 1303 ## 9 GL000009.2 GL000194.1 GL000195.1 GL000205.2 GL000213.1 GL000218.1 ## 1211 1 2 2 1 1 1 ## GL000219.1 KI270711.1 KI270713.1 KI270721.1 KI270726.1 KI270727.1 KI270728.1 ## 1 1 2 1 2 4 6 ## KI270731.1 KI270734.1 MT X Y ## 1 3 13 1067 97 is.mito &lt;- which(rowData(sce)$chromosome_name==&quot;MT&quot;) Calculate and store QC metrics for genes with addPerFeatureQC() and for cells with addPerCellQC(). # long # for genes sce &lt;- addPerFeatureQC(sce) head(rowData(sce)) %&gt;% as.data.frame() %&gt;% datatable(rownames = FALSE) # ENS ID Three columns of interest for cells: ‘sum’: total UMI count ‘detected’: number of features (genes) detected ‘subsets_Mito_percent’: percentage of reads mapped to mitochondrial transcripts # for cells sce &lt;- addPerCellQC(sce, subsets=list(Mito=is.mito)) head(colData(sce)) %&gt;% as.data.frame() %&gt;% datatable(rownames = FALSE) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postAddQc%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postAddQc%s.Rds&quot;, projDir, outDirBit, setSuf) sce &lt;- readRDS(tmpFn) 4.10.1 QC metric distribution Overall: par(mfrow=c(1, 2)) hist(log10(sce$sum), breaks=20, col=&quot;grey80&quot;, xlab=&quot;Log-total UMI count&quot;, main=&quot;&quot;) hist(sce$subsets_Mito_percent, breaks=20, col=&quot;grey80&quot;, xlab=&quot;Proportion of reads in mitochondrial genes&quot;, main=&quot;&quot;) abline(v=20, lty=2, col=&#39;purple&#39;) Per sample group: sce$source_name &lt;- factor(sce$source_name) sce$block &lt;- sce$source_name sce$setName &lt;- ifelse(grepl(&quot;ABMMC&quot;, sce$source_name), &quot;Hca&quot;, &quot;Caron&quot;) # ok, but little gain in splitting by Caron and Hca, # better set levels to have PBMMC last and use ggplot with colours. tmpFn &lt;- sprintf(&quot;%s/%s/%s/qc_metricDistrib_plotColData2%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) png(tmpFn) # violin plots gridExtra::grid.arrange( plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, other_fields=&quot;setName&quot;) + # facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;), ncol=1 ) dev.off() # eval=FALSE: see chunks below for each of the metrics separately tmpFn &lt;- sprintf(&quot;%s/%s/%s/qc_metricDistrib_plotColData2%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Library size (‘Total count’): plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;) Number of genes (‘detected’): plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) Mitochondrial content (‘subsets_Mito_percent’): plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, other_fields=&quot;setName&quot;) + # facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;) Correlation between the number of genes detected and library size (‘detected’ against ‘sum’): sp &lt;- ggplot(data.frame(colData(sce)), aes(x=sum, y=detected, col=source_name)) + geom_point(alpha=0.3) sp + facet_wrap(~source_name) Correlation between the mitochondrial content and library size (‘subsets_Mito_percent’ against ‘sum’): sp &lt;- ggplot(data.frame(colData(sce)), aes(x=sum, y=detected, col=subsets_Mito_percent)) + geom_point() sp + facet_wrap(~source_name) 4.11 Identification of low-quality cells with adaptive thresholds One can use hard threshold for the library size, number of genes detected and mitochondrial content. These will however vary across runs. It may therefore be preferable to rely on outlier detection to identify cells that markedly differ from most cells. We saw above that the distribution of the QC metrics is close to Normal. Hence, we can detect outlier using the median and the median absolute deviation (MAD) from the median (not the mean and the standard deviation that both are sensitive to outliers). For a given metric, an outlier value is one that lies over some number of MADs away from the median. A cell will be excluded if it is an outlier in the part of the range to avoid, for example low gene counts, or high mitochondrial content. For a normal distribution, a threshold defined with a distance of 3 MADs from the median retains about 99% of values. 4.11.1 Library size For the library size we use the log scale to avoid negative values for lower part of the distribution. qc.lib2 &lt;- isOutlier(sce$sum, log=TRUE, type=&quot;lower&quot;) table(qc.lib2) ## qc.lib2 ## FALSE TRUE ## 245250 3604 Threshold values: attr(qc.lib2, &quot;thresholds&quot;) ## lower higher ## 920.8674 Inf 4.11.2 Number of genes For the number of genes detected we also use the log scale to avoid negative values for lower part of the distribution. qc.nexprs2 &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;) table(qc.nexprs2) ## qc.nexprs2 ## FALSE TRUE ## 246349 2505 Threshold values: attr(qc.nexprs2, &quot;thresholds&quot;) ## lower higher ## 302.3803 Inf 4.11.3 Mitochondrial content qc.mito2 &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;) table(qc.mito2) ## qc.mito2 ## FALSE TRUE ## 237080 11774 Threshold values: attr(qc.mito2, &quot;thresholds&quot;) ## lower higher ## -Inf 7.613065 4.11.4 Summary discard2 &lt;- qc.lib2 | qc.nexprs2 | qc.mito2 # Summarize the number of cells removed for each reason. DataFrame(LibSize=sum(qc.lib2), NExprs=sum(qc.nexprs2), MitoProp=sum(qc.mito2), Total=sum(discard2)) ## DataFrame with 1 row and 4 columns ## LibSize NExprs MitoProp Total ## &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; &lt;integer&gt; ## 1 3604 2505 11774 15386 4.11.5 All steps at once The steps above may be run at once with quickPerCellQC(): reasons &lt;- quickPerCellQC(colData(sce), percent_subsets=c(&quot;subsets_Mito_percent&quot;)) colSums(as.matrix(reasons)) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) 4.11.6 Assumptions Data quality depends on the tissue analysed, some being difficult to dissociate, e.g. brain, so that one level of QC stringency will not fit all data sets. Filtering based on QC metrics as done here assumes that these QC metrics are not correlated with biology. This may not necessarily be true in highly heterogenous data sets where some cell types represented by good-quality cells may have low RNA content or high mitochondrial content. 4.12 Experimental factors The two data sets analysed here may have been obtained in experiments with different settings, such as cell preparation or sequencing depth. Such differences between these two batches would affect the adaptive thresholds discussed above. We will now perform QC in each batch separately. We will use the quickPerCellQC() ‘batch’ option. batch.reasons &lt;- quickPerCellQC(colData(sce), percent_subsets=c(&quot;subsets_Mito_percent&quot;), batch=sce$setName) colSums(as.matrix(batch.reasons)) ## low_lib_size low_n_features high_subsets_Mito_percent ## 0 1034 11046 ## discard ## 12014 sce$discard &lt;- batch.reasons$discard Fewer cells are discarded, in particular because of small library size and low gene number. But the differences are deeper as the two sets only partially overlap: table(reasons$discard, batch.reasons$discard) ## ## FALSE TRUE ## FALSE 231781 1687 ## TRUE 5059 10327 # see chunks below for each of the metric separately tmpFn &lt;- sprintf(&quot;%s/%s/%s/qc_metricDistrib_plotColDataBatch%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) png(tmpFn) gridExtra::grid.arrange( plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;), plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;), ncol=1 ) dev.off() # eval=FALSE; see chunks below for each of the metric separately tmpFn &lt;- sprintf(&quot;%s/%s/qc_metricDistrib_plotColDataBatch%s.png&quot;, dirRel, qcPlotDirBit, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) Library size: plotColData(sce, x=&quot;block&quot;, y=&quot;sum&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Total count&quot;) Number of genes detected: plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) plotColData(sce, x=&quot;block&quot;, y=&quot;detected&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + facet_wrap(~colour_by) + scale_y_log10() + ggtitle(&quot;Detected features&quot;) Mitochondrial content: plotColData(sce, x=&quot;block&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;, other_fields=&quot;setName&quot;) + #facet_wrap(~setName) + ggtitle(&quot;Mito percent&quot;) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=detected, y=subsets_Mito_percent, col=discard)) + geom_point(size = 0.05, alpha = 0.2) + geom_density_2d(size = 0.5, colour = &quot;blue&quot;) + guides(colour = guide_legend(override.aes = list(size=1, alpha=1))) + theme(legend.position=&quot;bottom&quot;) #sp ggExtra::ggMarginal(sp) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=detected, y=subsets_Mito_percent, col=discard)) + geom_point(size = 0.05, alpha = 0.2) sp + facet_wrap(~source_name) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=detected, y=subsets_Mito_percent)) + geom_point(size = 0.05, alpha = 0.0) sp + #geom_density_2d_filled(alpha = 0.5) + geom_density_2d(size = 0.5, colour = &quot;black&quot;) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=detected, y=subsets_Mito_percent)) + geom_point(size = 0.05, alpha = 0.2) + geom_density_2d(size = 0.5, colour = &quot;blue&quot;) ggExtra::ggMarginal(sp) 4.12.1 Identify poor-quality batches We will now consider the ‘sample’ batch to illustrate how to identify batches with overall low quality or different from other batches. Let’s compare thresholds across sample groups. 4.12.1.1 Number of genes detected # compute discard.nexprs &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;, batch=sce$Sample.Name) nexprs.thresholds &lt;- attr(discard.nexprs, &quot;thresholds&quot;)[&quot;lower&quot;,] nexprs.thresholds ## GSM3872434 GSM3872435 GSM3872436 GSM3872437 GSM3872438 GSM3872439 GSM3872440 ## 607.01358 335.54504 328.38324 141.03857 156.68225 571.77950 196.22460 ## GSM3872441 GSM3872442 GSM3872443 GSM3872444 MantonBM1 MantonBM2 MantonBM3 ## 264.00781 71.29113 131.73259 236.52629 435.19204 411.90586 393.54345 ## MantonBM4 MantonBM5 MantonBM6 MantonBM7 MantonBM8 ## 314.04514 238.93994 465.76038 371.40723 341.75957 Without block: # plots - without blocking discard.nexprs.woBlock &lt;- isOutlier(sce$detected, log=TRUE, type=&quot;lower&quot;) without.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;detected&quot;, colour_by=I(discard.nexprs.woBlock)) without.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) With block: # plots - with blocking with.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;detected&quot;, colour_by=I(discard.nexprs)) with.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) 4.12.1.1.1 Mitochondrial content discard.mito &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;, batch=sce$Sample.Name) mito.thresholds &lt;- attr(discard.mito, &quot;thresholds&quot;)[&quot;higher&quot;,] mito.thresholds %&gt;% round(0) %&gt;% as.data.frame() %&gt;% datatable(rownames = TRUE) Without block: # plots - without blocking discard.mito.woBlock &lt;- isOutlier(sce$subsets_Mito_percent, type=&quot;higher&quot;) without.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=I(discard.mito.woBlock)) without.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) With block: # plots - with blocking with.blocking &lt;- plotColData(sce, x=&quot;Sample.Name&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=I(discard.mito)) with.blocking + theme(axis.text.x = element_text(angle = 90, hjust = 1)) 4.12.1.2 Samples to check Names of samples with a ‘low’ threshold for the number of genes detected: # names names(nexprs.thresholds)[isOutlier(nexprs.thresholds, type=&quot;lower&quot;)] ## character(0) Names of samples with a ‘high’ threshold for mitocondrial content: # names names(mito.thresholds)[isOutlier(mito.thresholds, type=&quot;higher&quot;)] ## [1] &quot;GSM3872434&quot; &quot;GSM3872437&quot; &quot;GSM3872438&quot; &quot;GSM3872443&quot; 4.12.2 QC metrics space A similar approach exists to identify outliers using a set of metrics together. We will the same QC metrics as above: # slow stats &lt;- cbind(log10(sce$sum), log10(sce$detected), sce$subsets_Mito_percent) library(robustbase) outlying &lt;- adjOutlyingness(stats, only.outlyingness = TRUE) multi.outlier &lt;- isOutlier(outlying, type = &quot;higher&quot;) summary(multi.outlier) ## Mode FALSE TRUE ## logical 232401 16453 Compare with previous filtering: table(sce$discard, multi.outlier) ## multi.outlier ## FALSE TRUE ## FALSE 226413 10427 ## TRUE 5988 6026 4.12.3 QC PCA One can also perform a principal components analysis (PCA) on cells, based on the column metadata in a SingleCellExperiment object. Here we will only use the library size, the number of genes detected (which is correlated with library size) and the mitochondrial content. sce &lt;- runColDataPCA(sce, variables=list( &quot;sum&quot;, &quot;detected&quot;, &quot;subsets_Mito_percent&quot;), outliers=TRUE) #reducedDimNames(sce) #head(reducedDim(sce)) #head(colData(sce)) #p &lt;- plotReducedDim(sce, dimred=&quot;PCA_coldata&quot;, colour_by = &quot;Sample.Name&quot;) p &lt;- plotReducedDim(sce, dimred=&quot;PCA_coldata&quot;, colour_by = &quot;outlier&quot;) p + facet_wrap(~sce$discard) Compare with previous filtering: discard and runColDataPCA’s outlier table(sce$discard, sce$outlier) ## ## FALSE TRUE ## FALSE 227999 8841 ## TRUE 5611 6403 adjOutlyingness’ multi.outlier and runColDataPCA’s outlier table(multi.outlier, sce$outlier) ## ## multi.outlier FALSE TRUE ## FALSE 226248 6153 ## TRUE 7362 9091 4.12.4 Other diagnostic plots Mitochondrial content against library size: plotColData(sce, x=&quot;sum&quot;, y=&quot;subsets_Mito_percent&quot;, colour_by=&quot;discard&quot;) sp &lt;- ggplot(data.frame(colData(sce)), aes(x=sum, y=subsets_Mito_percent, col=discard)) + geom_point(size = 0.05, alpha = 0.7) + geom_density_2d(size = 0.5, colour = &quot;blue&quot;) + guides(colour = guide_legend(override.aes = list(size=1, alpha=1))) + theme(legend.position=&quot;bottom&quot;) #sp ggExtra::ggMarginal(sp) Mind distributions: sp + facet_wrap(~source_name) 4.12.5 Filter low-quality cells out We will now exclude poor-quality cells. scePreQc &lt;- sce sce &lt;- scePreQc[,!scePreQc$discard] sce ## class: SingleCellExperiment ## dim: 33538 236840 ## metadata(20): Samples Samples ... Samples Samples ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(10): ensembl_gene_id external_gene_name ... mean detected ## colnames: NULL ## colData names(15): Sample Barcode ... discard outlier ## reducedDimNames(1): PCA_coldata ## altExpNames(0): We also write the R object to file to use later if need be. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postQc%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_postQc%s.Rds&quot;, projDir, outDirBit, setSuf) sce &lt;- readRDS(tmpFn) 4.13 Novelty The number of genes per UMI for each cell informs on the level of sequencing saturation achieved ( hbctraining). For a given cell, as sequencing depth increases each extra UMI is less likely to correspnf to a gene not already detected in that cell. Cells with small library size tend to have higher overall ‘novelty’ i.e. they have not reached saturation for any given gene. Outlier cell may have a library with low complexity. This may suggest the some cell types, e.g. red blood cells. The expected novelty is about 0.8. Here we see that some PBMMCs have low novelty, ie overall fewer genes were detected for an equivalent number of UMIs in these cells than in others. p &lt;- colData(sce) %&gt;% data.frame() %&gt;% ggplot(aes(x=sum, y=detected, color=subsets_Mito_percent)) + geom_point() + stat_smooth(method=lm) + scale_x_log10() + scale_y_log10() + geom_vline(xintercept = 800) + facet_wrap(~source_name) p # write plot to file tmpFn &lt;- sprintf(&quot;%s/%s/%s/novelty_scat%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) ggsave(plot=p, file=tmpFn) # Novelty # the number of genes per UMI for each cell, # https://hbctraining.github.io/In-depth-NGS-Data-Analysis-Course/sessionIV/lessons/SC_quality_control_analysis.html # Add number of UMIs per gene for each cell to metadata colData(sce)$log10GenesPerUMI &lt;- log10(colData(sce)$detected) / log10(colData(sce)$sum) # Visualize the overall novelty of the gene expression by visualizing the genes detected per UMI p &lt;- colData(sce) %&gt;% data.frame() %&gt;% ggplot(aes(x=log10GenesPerUMI, color = source_name, fill = source_name)) + geom_density() p tmpFn &lt;- sprintf(&quot;%s/%s/%s/novelty_dens%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) ggsave(plot=p, file=tmpFn) 4.14 QC based on sparsity The approach above identified poor-quality using thresholds on the number of genes detected and mitochondrial content. We will here specifically look at the sparsity of the data, both at the gene and cell levels. 4.14.1 Remove genes that are not expressed at all Genes that are not expressed at all are not informative, so we remove them not.expressed &lt;- rowSums(counts(scePreQc)) == 0 # store the cell-wise information cols.meta &lt;- colData(scePreQc) rows.meta &lt;- rowData(scePreQc) nz.counts &lt;- counts(scePreQc)[!not.expressed, ] sce.nz &lt;- SingleCellExperiment(list(counts=nz.counts)) # reset the column data on the new object colData(sce.nz) &lt;- cols.meta rowData(sce.nz) &lt;- rows.meta[!not.expressed, ] sce.nz # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce.nz, tmpFn) # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz%s.Rds&quot;, projDir, outDirBit, setSuf) sce.nz &lt;- readRDS(tmpFn) Number of genes 27795. Number of cells 248854. 4.14.2 Sparsity plots We will compute: the cell sparsity: for each cell, the proportion of genes that are not detected the gene sparsity: for each gene, the proportion of cells in which it is not detected # compute - SLOW cell_sparsity &lt;- apply(counts(sce.nz) == 0, 2, sum)/nrow(counts(sce.nz)) gene_sparsity &lt;- apply(counts(sce.nz) == 0, 1, sum)/ncol(counts(sce.nz)) colData(sce.nz)$cell_sparsity &lt;- cell_sparsity rowData(sce.nz)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(list(&quot;colData&quot; = colData(sce.nz), &quot;rowData&quot; = rowData(sce.nz)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setSuf) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity We now plot the distribution of these two metrics. The cell sparsity plot shows that cells have between 85% and 99% 0’s, which is typical. The gene sparsity plot shows that a large number of genes are almost never detected, which is alo regularly observed. #```{r sparsity_plot_allCells, eval=runAll} # plot tmpFn &lt;- sprintf(&quot;%s/%s/%s/sparsity%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setSuf) png(tmpFn) par(mfrow=c(1, 2)) hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) abline(v=40, lty=2, col=&#39;purple&#39;) dev.off() ## png ## 2 tmpFn &lt;- sprintf(&quot;%s/%s/sparsity%s.png&quot;, dirRel, qcPlotDirBit, setSuf) knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) 4.14.3 Filters We also remove cells with sparsity higher than 0.99, and/or mitochondrial content higher than 20%. Genes detected in a few cells only are unlikely to be informative and would hinder normalisation. We will remove genes that are expressed in fewer than 20 cells. # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.nz$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells Number of genes removed: table(sparse.genes) ## sparse.genes ## FALSE TRUE ## 21579 6216 Number of cells removed: table(sparse.cells, mito.cells) ## mito.cells ## sparse.cells FALSE TRUE ## FALSE 244996 1785 ## TRUE 1859 214 # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.nz) rows.meta &lt;- rowData(sce.nz) counts.nz &lt;- counts(sce.nz)[!sparse.genes, !(sparse.cells | mito.cells)] sce.nz &lt;- SingleCellExperiment(assays=list(counts=counts.nz)) colData(sce.nz) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.nz) &lt;- rows.meta[!sparse.genes, ] sce.nz # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setSuf) saveRDS(sce.nz, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setSuf) sce.nz &lt;- readRDS(tmpFn) Compare with filter above (mind that the comparison is not fair because we used a less stringent, hard filtering on mitochondrial content): table(scePreQc$discard, (sparse.cells | mito.cells)) ## ## FALSE TRUE ## FALSE 235832 1008 ## TRUE 9164 2850 4.14.4 Separate Caron and Hca batches We will now check sparsity for each batch separately. sce.nz.caron &lt;- sce.nz[,sce.nz$setName==&quot;Caron&quot;] sce.nz.hca &lt;- sce.nz[,sce.nz$setName==&quot;Hca&quot;] 4.14.5 Caron only setName &lt;- &quot;caron&quot; sce.x &lt;- sce.nz.caron # compute - SLOW cell_sparsity &lt;- apply(counts(sce.x) == 0, 2, sum)/nrow(counts(sce.x)) gene_sparsity &lt;- apply(counts(sce.x) == 0, 1, sum)/ncol(counts(sce.x)) colData(sce.x)$cell_sparsity &lt;- cell_sparsity rowData(sce.x)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(list(&quot;colData&quot; = colData(sce.x), &quot;rowData&quot; = rowData(sce.x)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setName, setSuf) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity # plot tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sparsity%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf) png(tmpFn) par(mfrow=c(1, 2)) hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) abline(v=40, lty=2, col=&#39;purple&#39;) dev.off() tmpFn &lt;- sprintf(&quot;%s/%s/%s_sparsity%s.png&quot;, dirRel, qcPlotDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;../Plots/Qc/caron_sparsity_allCells.png&quot; print(file.exists(tmpFn)) ## [1] TRUE knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.x$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.x) rows.meta &lt;- rowData(sce.x) counts.x &lt;- counts(sce.x)[!sparse.genes, !(sparse.cells | mito.cells)] sce.x &lt;- SingleCellExperiment(assays=list(counts=counts.x)) colData(sce.x) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.x) &lt;- rows.meta[!sparse.genes, ] sce.x We write the R object to caron_sce_nz_postQc_allCells.Rds. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce.x, tmpFn) rm(sce.x) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce.nz.caron &lt;- readRDS(tmpFn) 4.14.6 Hca only setName &lt;- &quot;hca&quot; sce.x &lt;- sce.nz.hca # compute - SLOW cell_sparsity &lt;- apply(counts(sce.x) == 0, 2, sum)/nrow(counts(sce.x)) gene_sparsity &lt;- apply(counts(sce.x) == 0, 1, sum)/ncol(counts(sce.x)) colData(sce.x)$cell_sparsity &lt;- cell_sparsity rowData(sce.x)$gene_sparsity &lt;- gene_sparsity # write outcome to file for later use tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(list(&quot;colData&quot; = colData(sce.x), &quot;rowData&quot; = rowData(sce.x)), tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_sparsityCellGene%s.Rds&quot;, projDir, outDirBit, setName, setSuf) tmpList &lt;- readRDS(tmpFn) cell_sparsity &lt;- tmpList$colData$cell_sparsity gene_sparsity &lt;- tmpList$rowData$gene_sparsity #```{r Hca_sparsity_plot_allCells, eval=runAll} # plot tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sparsity%s.png&quot;, projDir, outDirBit, qcPlotDirBit, setName, setSuf) png(tmpFn) par(mfrow=c(1, 2)) hist(cell_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Cell sparsity&quot;, main=&quot;&quot;) hist(gene_sparsity, breaks=50, col=&quot;grey80&quot;, xlab=&quot;Gene sparsity&quot;, main=&quot;&quot;) abline(v=40, lty=2, col=&#39;purple&#39;) dev.off() ## png ## 2 #tmpFn &lt;- sprintf(&quot;%s/%s/%s/%s_sparsity.png&quot;, projDir, outDirBit, qcPlotDirBit, setName) tmpFn &lt;- sprintf(&quot;%s/%s/%s_sparsity%s.png&quot;, dirRel, qcPlotDirBit, setName, setSuf) print(tmpFn) ## [1] &quot;../Plots/Qc/hca_sparsity_allCells.png&quot; print(file.exists(tmpFn)) ## [1] TRUE knitr::include_graphics(tmpFn, auto_pdf = TRUE) rm(tmpFn) # filter sparse.cells &lt;- cell_sparsity &gt; 0.99 mito.cells &lt;- sce.x$subsets_Mito_percent &gt; 20 min.cells &lt;- 1 - (20/length(cell_sparsity)) sparse.genes &lt;- gene_sparsity &gt; min.cells # remove cells from the SCE object that are poor quality # remove the sparse genes, then re-set the counts and row data accordingly cols.meta &lt;- colData(sce.x) rows.meta &lt;- rowData(sce.x) counts.x &lt;- counts(sce.x)[!sparse.genes, !(sparse.cells | mito.cells)] sce.x &lt;- SingleCellExperiment(assays=list(counts=counts.x)) colData(sce.x) &lt;- cols.meta[!(sparse.cells | mito.cells),] rowData(sce.x) &lt;- rows.meta[!sparse.genes, ] sce.x We write the R object to hca_sce_nz_postQc_allCells.Rds. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) saveRDS(sce.x, tmpFn) # Read object in: tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc%s.Rds&quot;, projDir, outDirBit, setName, setSuf) sce.nz.hca &lt;- readRDS(tmpFn) 4.15 subsample Hca set The HCA data comprises about 25,000 cells per samples, compared to 5,000 for the Caron study. We will randomly subsample the HCA samples down to 5000 cells. sce.nz.hca # have new list of cell barcodes for each sample sce.nz.hca.5k.bc &lt;- colData(sce.nz.hca) %&gt;% data.frame() %&gt;% group_by(Sample.Name) %&gt;% sample_n(5000) %&gt;% pull(Barcode) table(colData(sce.nz.hca)$Barcode %in% sce.nz.hca.5k.bc) tmpInd &lt;- which(colData(sce.nz.hca)$Barcode %in% sce.nz.hca.5k.bc) sce.nz.hca.5k &lt;- sce.nz.hca[,tmpInd] # mind that genes were filtered using all cells, not just those sampled here. We write the R object to ‘hca_sce_nz_postQc_5kCellPerSpl.Rds’. # Write object to file tmpFn &lt;- sprintf(&quot;%s/%s/Robjects/%s_sce_nz_postQc_5kCellPerSpl.Rds&quot;, projDir, outDirBit, setName) saveRDS(sce.nz.hca.5k, tmpFn) "]]
