---
title: "CRUK CI Summer School 2020 - introduction to single-cell RNA-seq analysis"
subtitle: 'Data integration'

author: "Stephane Ballereau, Zeynep Kalender Atak, Katarzyna Kania"
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_float: yes
    number_sections: true
  html_document:
    df_print: paged
    toc: yes
    number_sections: true
    code_folding: hide
  html_book:
    code_folding: hide
params:
  projDir: "/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020"
  dirRel: ".."
  inpDirBit: "AnaWiSce/Ana1"
  outDirBit: "AnaWiSce/Ana1"
  bookType: "mk"
  cacheBool: FALSE  
  splSetToGet: "PBMMC,ETV6-RUNX1"
  setName: "caron"
  setSuf: "_allCells"
  dsiSuf: '_dsi'
---

<!--
  setSuf: "_5hCellPerSpl"
-->
  
# Data integration - all Caron sample types {#dataSetIntegration_allSetsTop}

**CODE NEEDS UPDATING**
**as were other daya set integration chapters with fewr sample types** 

```{r, eval=FALSE}
projDir <- "/mnt/scratcha/bioinformatics/baller01/20200511_FernandesM_ME_crukBiSs2020"
outDirBit <- "AnaWiSce/Attempt1"
nbPcToComp <- 50
```

```{r}
projDir <- params$projDir
dirRel <- params$dirRel
outDirBit <- params$outDirBit
cacheBool <- params$cacheBool
splSetToGet <- params$splSetToGet
setName <- params$setName
setSuf <- params$setSuf
dsiSuf <- params$dsiSuf # 'dsi' for data set integration

if(params$bookType == "mk"){
	setName <- "caron"
	splSetToGet <- "dummy"
	setSuf <- "_allCells"
}

splSetVec <- unlist(strsplit(splSetToGet, ",")) # params may not be read in if knitting book.
splSetToGet2 <- gsub(",", "_", splSetToGet)
nbPcToComp <- 50
figSize <- 7

library(BiocParallel)
bpp <- MulticoreParam(8)
```

```{r dataSetIntegration_allSets_setup, include=FALSE, echo=FALSE, dev="CairoPNG"}
# First, set some variables:
require(knitr)
opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE, cache=cacheBool)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = TRUE) 
options(stringsAsFactors = FALSE)
opts_chunk$set(fig.width=7, fig.height=7)
#opts_chunk$set(dev = c("png"))
options(bitmapType='cairo')
knitr::opts_chunk$set(dev="CairoPNG")
set.seed(123) # for reproducibility
```

```{r library_dataSetIntegration_allSets, include=FALSE}
library(ggplot2)
library(scater)
library(scran)
library(dplyr)
library(BiocNeighbors)
library(bluster)
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
```

Source: [Integrating Datasets](https://osca.bioconductor.org/integrating-datasets.html) of the OSCA book and the [fastMNN manual](https://rdrr.io/github/LTLA/batchelor/man/fastMNN.html).

## Motivation

Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results.

Computational correction of these effects is critical for eliminating batch-to-batch variation, allowing data across multiple batches to be combined for common downstream analysis. However, existing methods based on linear models (Ritchie et al. 2015; Leek et al. 2012) assume that the composition of cell populations are either known or the same across batches. To overcome these limitations, bespoke methods have been developed for batch correction of single-cell data (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019) that do not require a priori knowledge about the composition of the population. This allows them to be used in workflows for exploratory analyses of scRNA-seq data where such knowledge is usually unavailable.

## Load data

We will load the R file keeping the SCE object with the normalised counts.

```{r}
#setName <- "caron"
# Read object in:
#setSuf <- ""
tmpFn <- sprintf("%s/%s/Robjects/%s_sce_nz_postDeconv%s.Rds", projDir, outDirBit, setName, setSuf)
print(tmpFn)
if(!file.exists(tmpFn))
{
	knitr::knit_exit()
}
sce <- readRDS(tmpFn)
sce
colnames(rowData(sce))[colnames(rowData(sce)) == "strand"] <- "strandNum" # to avoid error later

#head(rowData(sce))
#head(colData(sce))
table(colData(sce)$block)
#assayNames(sce)
#reducedDimNames(sce)
```

Read in the sample sheet:

```{r}
# CaronBourque2020
cb_sampleSheetFn <- file.path(projDir, "Data/CaronBourque2020/SraRunTable.txt")
cb_sampleSheet <- read.table(cb_sampleSheetFn, header=T, sep=",")
cb_sampleSheet <-  cb_sampleSheet %>% filter(!Run == "SRR9264351")
cb_sampleSheet
```

Have sample names:

```{r}
cb_sampleSheet$Sample.Name2 <- "NA"
typeVec <- unique(cb_sampleSheet$source_name)
for (tx in typeVec)
{
	tmpInd <- which(cb_sampleSheet$source_name == tx)
	for (i in 1:length(tmpInd))
	{
		cb_sampleSheet$Sample.Name2[tmpInd[i]] <- sprintf("%s_%s", tx, i)
	}
}

colData(sce)$Sample.Name2 <- colData(sce) %>%
	data.frame() %>%
	left_join( cb_sampleSheet, by="Sample.Name") %>%
	pull(Sample.Name2)

splVec <- cb_sampleSheet %>%
	#filter(source_name == "ETV6-RUNX1") %>%
	pull(Sample.Name2)
splVec
```

<!--
Subset cells (e.g 500 or 1000 per sample for a faster analysis):
-->

```{r}
# mind we now have a downsampled set to use all along
# so avoid doing it again
# also, changes setsuf to shorter form eg _5hCps, which we could use from the start TODO

all.sce <- list()

if(setSuf == "_allCells" | setSuf == "_5hCellPerSpl")
{
  for(spx in splVec)
  {
  	vec.bc <- colData(sce) %>%
  		data.frame() %>%
  		filter(Sample.Name2 == spx) %>%
  		pull(Barcode)
  	tmpInd <- which(colData(sce)$Barcode %in% vec.bc)
  	all.sce[[spx]] <- sce[,tmpInd]
  }
} else {  
  nbCells <- 500
  setSuf <- "_5hCps" # "_5hCellPerSpl"

  #nbCells <- 1000
  #setSuf <- "_1kCps" # "_1kCellPerSpl"

  for(spx in splVec)
  {
  	vec.bc <- colData(sce) %>%
  		data.frame() %>%
  		filter(Sample.Name2 == spx) %>%
  		slice_sample(n=nbCells) %>%
  		pull(Barcode)
  	tmpInd <- which(colData(sce)$Barcode %in% vec.bc)
  	all.sce[[spx]] <- sce[,tmpInd]
  }
}

# show size of sets:
lapply(all.sce, dim)
# sizeFactors(all.sce[[1]])
```

We will analyse each sample separately, namely:

* normalise counts
* model gene expression variance
* identify highly variable genes
* perform dimensionality reduction
* cluster cells

```{r}
#--- normalization ---#
all.sce <- lapply(all.sce, logNormCounts)

#--- variance-modelling ---#
library(scran)
all.dec <- lapply(all.sce, modelGeneVar)
all.hvgs <- lapply(all.dec, getTopHVGs, prop=0.1)

#--- dimensionality-reduction ---#
library(BiocSingular)
set.seed(10000)
all.sce <- mapply(FUN=runPCA, x=all.sce, subset_row=all.hvgs, 
    MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), 
    SIMPLIFY=FALSE)

# TSNE
#set.seed(100000)
#all.sce <- lapply(all.sce, runTSNE, dimred="PCA")

# UMAP
#set.seed(1000000)
#all.sce <- lapply(all.sce, runUMAP, dimred="PCA")

#--- clustering ---#
for (n in names(all.sce)) {
    g <- buildSNNGraph(all.sce[[n]], k=10, use.dimred='PCA')
    clust <- igraph::cluster_walktrap(g)$membership
    colLabels(all.sce[[n]])  <- factor(clust)
}
```

To prepare for the batch correction, we need to:

* subset all batches to the common “universe” of features
* rescale each batch to adjust for differences in sequencing depth between batches
* perform feature selection by averaging the variance components across all batches  

We subset all batches to the common “universe” of features. In this case, it is straightforward as batches use Ensembl gene annotation.

```{r}
allNames <- unlist(lapply(all.sce, function(x){rownames(x)}))
allNamesNb <- table(allNames)
universe <- names(allNamesNb)[allNamesNb==length(splVec)] 
length(universe)
```

```{r}
# Subsetting the SingleCellExperiment object.
uni.sce <- lapply(all.sce, function(x){x[universe,]})
# Also subsetting the variance modelling results, for convenience.
uni.dec <- lapply(all.dec, function(x){x[universe,]})
```

We rescale each batch to adjust for differences in sequencing depth between batches. The multiBatchNorm() function recomputes log-normalized expression values after adjusting the size factors for systematic differences in coverage between SingleCellExperiment objects. (Size factors only remove biases between cells within a single batch.) This improves the quality of the correction by removing one aspect of the technical differences between batches.

```{r}
library(batchelor)
rescaled.mbn <- multiBatchNorm(uni.sce, batch = "Sample.Name2")
```

We perform feature selection by averaging the variance components across all batches with the combineVar() function. We compute the average as it is responsive to batch-specific HVGs while still preserving the within-batch ranking of genes. This allows us to use the same strategies described in Section 8.3 to select genes of interest. In contrast, approaches based on taking the intersection or union of HVGs across batches become increasingly conservative or liberal, respectively, with an increasing number of batches.

```{r}
library(scran)
combined.dec <- combineVar(
  uni.dec[[1]], uni.dec[[2]], uni.dec[[3]], uni.dec[[4]],
  uni.dec[[5]], uni.dec[[6]],
  uni.dec[[7]], uni.dec[[8]],
  uni.dec[[9]], uni.dec[[10]], uni.dec[[11]]
  )
chosen.hvgs <- combined.dec$bio > 0
sum(chosen.hvgs)
```

When integrating datasets of variable composition, it is generally safer to err on the side of including more genes than are used in a single dataset analysis, to ensure that markers are retained for any dataset-specific subpopulations that might be present. For a top X selection, this means using a larger X (say, ~5000), or in this case, we simply take all genes above the trend. That said, many of the signal-to-noise considerations described in Section 8.3 still apply here, so some experimentation may be necessary for best results.

Alternatively, a more forceful approach to feature selection can be used based on marker genes from within-batch comparisons.

## Diagnosing batch effects

Before we actually perform any correction, it is worth examining whether there is any batch effect in this dataset. We combine the SingleCellExperiments and perform a PCA on the log-expression values for all genes with positive (average) biological components.

```{r}
# Synchronizing the metadata for cbind()ing.
#identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[2]]))
#identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[3]]))
#identical(rowData(rescaled.mbn[[1]]), rowData(rescaled.mbn[[4]]))

rescaled2 <- lapply(rescaled.mbn, function(x){x$batch <- x$Sample.Name2; x})
rescaled.mbn <- rescaled2
rm(rescaled2)

uncorrected <- do.call(cbind, rescaled.mbn)

# Using RandomParam() as it is more efficient for file-backed matrices.
library(scater)
set.seed(0010101010)
uncorrected <- runPCA(
  uncorrected,
  subset_row=chosen.hvgs,
  BSPARAM=BiocSingular::RandomParam())
```

We use graph-based clustering on the components to obtain a summary of the population structure. As our each sample group is represented by at least two replicates, each cluster should ideally consist of cells from several batches. This is the case for some but not all clusters. Some clusters comprise of cells from a single sample. This may indicate that cells of the same type are artificially separated due to technical differences between batches. They may also be cancer cell population private to samples. 

```{r diagBatch_cluster_dataSetIntegration_allSets, eval=FALSE}
# 30+ min run
nSteps <- 4 # walktrap default
if(ncol(uncorrected) > 10000){
	nSteps <- 20 # or else get 63 clusters with caron allCells
}

library(scran)
snn.gr <- buildSNNGraph(uncorrected, use.dimred="PCA")
clusters <- igraph::cluster_walktrap(snn.gr, steps=nSteps)$membership
tab <- table(Cluster=clusters, Batch=uncorrected$batch)
tab
```

```{r diagBatch_heatmap_dataSetIntegration_allSets, eval=FALSE}
pheatmap::pheatmap(tab,
           border_color      = NA,
           drop_levels       = TRUE,
           cluster_cols      = FALSE
           )
```

```{r diagBatch_blustercluster_dataSetIntegration_allSets}
# NNGraphParam k?
# k is for makeSNNGraph: nearest neighbors to consider during graph construction

set.seed(1000)
nSteps <- 4 # walktrap default
clusters <- clusterRows(reducedDim(uncorrected, "PCA"),
				      TwoStepParam(KmeansParam(centers=2000,iter.max=30),
						   NNGraphParam(
								shared = TRUE,
								k=5,
								cluster.fun = "walktrap",
								cluster.args = list(steps=nSteps)
								)))

tab2 <- table(Cluster=clusters, Batch=uncorrected$batch)
tab2
```

```{r diagBatch_blusterHeatmap_dataSetIntegration_allSets}
pheatmap::pheatmap(tab2,
           border_color      = NA,
           drop_levels       = TRUE,
           cluster_cols      = FALSE
           )
```

We can also visualize the corrected coordinates using a t-SNE plot. The strong separation between cells from different batches is consistent with the clustering results.

```{r}
set.seed(1111001)
#uncorrected <- runTSNE(uncorrected, dimred="PCA")
uncorrected <- runTSNE(uncorrected, dimred="PCA",
    external_neighbors=TRUE, 
    BNPARAM=AnnoyParam(),
    BPPARAM=bpp,
    n_threads=bpnworkers(bpp))

plotTSNE(uncorrected, colour_by="batch")
```

```{r}
set.seed(1111001)
#uncorrected <- runUMAP(uncorrected, dimred="PCA")
uncorrected <- runUMAP(uncorrected, dimred="PCA",
    external_neighbors=TRUE, 
    BNPARAM=AnnoyParam(),
    BPPARAM=bpp,
    n_threads=bpnworkers(bpp))
plotUMAP(uncorrected, colour_by="batch")
```

Of course, the other explanation for batch-specific clusters is that there are cell types that are unique to each batch. The degree of intermingling of cells from different batches is not an effective diagnostic when the batches involved might actually contain unique cell subpopulations. If a cluster only contains cells from a single batch, one can always debate whether that is caused by a failure of the correction method or if there is truly a batch-specific subpopulation. For example, do batch-specific metabolic or differentiation states represent distinct subpopulations? Or should they be merged together? We will not attempt to answer this here, only noting that each batch correction algorithm will make different (and possibly inappropriate) decisions on what constitutes “shared” and “unique” populations.

## Linear regression

Batch effects in bulk RNA sequencing studies are commonly removed with linear regression. This involves fitting a linear model to each gene’s expression profile, setting the undesirable batch term to zero and recomputing the observations sans the batch effect, yielding a set of corrected expression values for downstream analyses. Linear modelling is the basis of the removeBatchEffect() function from the limma package (Ritchie et al. 2015) as well the comBat() function from the sva package (Leek et al. 2012).

To use this approach in a scRNA-seq context, we assume that the composition of cell subpopulations is the same across batches. We also assume that the batch effect is additive, i.e., any batch-induced fold-change in expression is the same across different cell subpopulations for any given gene. These are strong assumptions as batches derived from different individuals will naturally exhibit variation in cell type abundances and expression. Nonetheless, they may be acceptable when dealing with batches that are technical replicates generated from the same population of cells. (In fact, when its assumptions hold, linear regression is the most statistically efficient as it uses information from all cells to compute the common batch vector.) Linear modelling can also accommodate situations where the composition is known a priori by including the cell type as a factor in the linear model, but this situation is even less common.

We use the rescaleBatches() function from the batchelor package to remove the batch effect. This is roughly equivalent to applying a linear regression to the log-expression values per gene, with some adjustments to improve performance and efficiency. For each gene, the mean expression in each batch is scaled down until it is equal to the lowest mean across all batches. We deliberately choose to scale all expression values down as this mitigates differences in variance when batches lie at different positions on the mean-variance trend. (Specifically, the shrinkage effect of the pseudo-count is greater for smaller counts, suppressing any differences in variance across batches.) An additional feature of rescaleBatches() is that it will preserve sparsity in the input matrix for greater efficiency, whereas other methods like removeBatchEffect() will always return a dense matrix.

```{r}
library(batchelor)
rescaled.rb <- rescaleBatches(rescaled.mbn)
rescaled.rb
```

After clustering, we observe fewer clusters and these consist of mixtures of cells from the several replicates, consistent with the removal of the batch effect. This conclusion is supported by the apparent mixing of cells from different batches on the TSNE plot below. However, at least one batch-specific cluster is still present, indicating that the correction is not entirely complete. This is attributable to violation of one of the aforementioned assumptions, even in this simple case involving replicated batches.

```{r}
set.seed(1010101010) # To ensure reproducibility of IRLBA.
rescaled.rb <- runPCA(rescaled.rb, subset_row=chosen.hvgs, exprs_values="corrected")

snn.gr <- buildSNNGraph(rescaled.rb, use.dimred="PCA")
clusters.resc <- igraph::cluster_walktrap(snn.gr)$membership
rescaled.rb$clusters.resc <- clusters.resc
tab.resc <- table(Cluster=clusters.resc, Batch=rescaled.rb$batch)
tab.resc
```

```{r}
pheatmap::pheatmap(tab.resc,
           border_color      = NA,
           drop_levels       = TRUE,
           cluster_cols      = FALSE
           )
```

<!-- and/or barplots -->

```{r, fig.height=0.5*figSize, fig.width=1.2*figSize}
rescaled.rb <- runTSNE(rescaled.rb, dimred="PCA",
    external_neighbors=TRUE, 
    BNPARAM=AnnoyParam(),
    BPPARAM=bpp,
    n_threads=bpnworkers(bpp))
rescaled.rb$batch <- factor(rescaled.rb$batch)
p.batch <- plotTSNE(rescaled.rb, colour_by="batch")
p.clu <- plotTSNE(rescaled.rb, colour_by="clusters.resc")
gridExtra::grid.arrange(p.clu, p.batch, ncol=2)
```

## Performing MNN correction

### Algorithm overview

Consider a cell a in batch A, and identify the cells in batch B that are nearest neighbors to a in the expression space defined by the selected features. Repeat this for a cell b in batch B, identifying its nearest neighbors in A. Mutual nearest neighbors (MNNs) are pairs of cells from different batches that belong in each other’s set of nearest neighbors. The reasoning is that MNN pairs represent cells from the same biological state prior to the application of a batch effect - see Haghverdi et al. (2018) for full theoretical details. Thus, the difference between cells in MNN pairs can be used as an estimate of the batch effect, the subtraction of which yields batch-corrected values.

Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand. This is because it learns the shared population structure via identification of MNN pairs and uses this information to obtain an appropriate estimate of the batch effect. Instead, the key assumption of MNN-based approaches is that the batch effect is orthogonal to the biology in high-dimensional expression space. Violations reduce the effectiveness and accuracy of the correction, with the most common case arising from variations in the direction of the batch effect between clusters. Nonetheless, the assumption is usually reasonable as a random vector is very likely to be orthogonal in high-dimensional space.

### Application to the data

The batchelor package provides an implementation of the MNN approach via the fastMNN() function. Unlike the MNN method originally described by Haghverdi et al. (2018), the fastMNN() function performs PCA to reduce the dimensions beforehand and speed up the downstream neighbor detection steps.

We apply it to our two PBMC batches to remove the batch effect across the highly variable genes in chosen.hvgs. To reduce computational work and technical noise, all cells in all batches are projected into the low-dimensional space defined by the top d principal components. Identification of MNNs and calculation of correction vectors are then performed in this low-dimensional space.

```{r}
# Using randomized SVD here, as this is faster than 
# irlba for file-backed matrices.
set.seed(1000101001)
mnn.out <- fastMNN(
  rescaled.mbn,
  auto.merge=TRUE,
  d=50,
  k=20,
  subset.row=chosen.hvgs,
  BSPARAM=BiocSingular::RandomParam(deferred=TRUE)
  )
mnn.out
mnn.out$batch <- factor(mnn.out$batch)
mnn.out$type <- gsub("_[1-4]","",mnn.out$batch)
```

The function returns a SingleCellExperiment object containing corrected values for downstream analyses like clustering or visualization. Each column of mnn.out corresponds to a cell in one of the batches, while each row corresponds to an input gene in chosen.hvgs. The batch field in the column metadata contains a vector specifying the batch of origin of each cell.

```{r}
head(mnn.out$batch) 
```

The corrected matrix in the reducedDims() contains the low-dimensional corrected coordinates for all cells, which we will use in place of the PCs in our downstream analyses.

```{r}
dim(reducedDim(mnn.out, "corrected"))
```

A reconstructed matrix in the assays() contains the corrected expression values for each gene in each cell, obtained by projecting the low-dimensional coordinates in corrected back into gene expression space. We do not recommend using this for anything other than visualization.

```{r}
dim(assay(mnn.out, "reconstructed"))
print(assay(mnn.out, "reconstructed")[1:5,1:3])
```

The most relevant parameter for tuning fastMNN() is k, which specifies the number of nearest neighbors to consider when defining MNN pairs. This can be interpreted as the minimum anticipated frequency of any shared cell type or state in each batch. Increasing k will generally result in more aggressive merging as the algorithm is more generous in matching subpopulations across batches. It can occasionally be desirable to increase k if one clearly sees that the same cell types are not being adequately merged across batches.

<!--
See Chapter 32 for an example of a more complex fastMNN() merge involving several human pancreas datasets generated by different authors on different patients with different technologies.
-->


### Correction diagnostics

We cluster on the low-dimensional corrected coordinates to obtain a partitioning of the cells that serves as a proxy for the population structure. If the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches. We see that all clusters contain contributions from each batch after correction, consistent with our expectation that the two batches are replicates of each other.

```{r}
library(scran)
snn.gr <- buildSNNGraph(mnn.out, use.dimred="corrected")
clusters.mnn <- igraph::cluster_walktrap(snn.gr)$membership
mnn.out$clusters.mnn <- clusters.mnn
tab.mnn <- table(Cluster=clusters.mnn, Batch=mnn.out$batch)
tab.mnn
```

```{r}
pheatmap::pheatmap(tab.mnn,
           border_color      = NA,
           drop_levels       = TRUE,
           cluster_cols      = FALSE
           )
```

We can also visualize the corrected coordinates using a t-SNE plot. The presence of visual clusters containing cells from batches provides a comforting illusion that the correction was successful.

```{r, fig.height=0.5*figSize, fig.width=1.2*figSize}
library(scater)
set.seed(0010101010)
mnn.out <- runTSNE(mnn.out, dimred="corrected",
    external_neighbors=TRUE, 
    BNPARAM=AnnoyParam(),
    BPPARAM=bpp,
    n_threads=bpnworkers(bpp))
plotTSNE(mnn.out, colour_by="batch")
p.batch <- plotTSNE(mnn.out, colour_by="batch")
p.clu <- plotTSNE(mnn.out, colour_by="clusters.mnn")
#gridExtra::grid.arrange(p.clu, p.batch, ncol=2)
gridExtra::grid.arrange(p.clu, p.batch+facet_wrap(~mnn.out$type), ncol=2)
```

For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row).

```{r}
metadata(mnn.out)$merge.info$lost.var
```

```{r}
tmpData <- metadata(mnn.out)$merge.info$lost.var

pheatmap::pheatmap(tmpData,
           border_color      = NA,
           drop_levels       = TRUE,
           cluster_rows      = FALSE,
           cluster_cols      = FALSE
           )
```


Large proportions of lost variance (>10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is small, indicating that non-orthogonality is not a major concern.

## Preserving biological heterogeneity

### Comparison to within-batch clusters

Another useful diagnostic check is to compare the clustering within each batch to the clustering of the merged data. Accurate data integration should preserve variance within each batch as there should be nothing to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against cases where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest.

Ideally, we should see a many-to-1 mapping where the across-batch clustering is nested inside the within-batch clusterings. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. In practice, more discrepancies can be expected even when the correction is perfect, due to the existence of closely related clusters that were arbitrarily separated in the within-batch clustering. As a general rule, we can be satisfied with the correction if the vast majority of entries in Figure 13.4 are zero, though this may depend on whether specific clusters of interest are gained or lost.

One heatmap is generated for each of the PBMC 3K and 4K datasets, where each entry is colored according to the number of cells with each pair of labels (before and after correction). 

```{r}
library(pheatmap)

# For the first batch (adding +10 for a smoother color transition
# from zero to non-zero counts for any given matrix entry).
batchPlace <- 1
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
tab <- table(paste("after", clusters.mnn[tmpInd]),
             paste("before", colLabels(rescaled.mbn[[batchPlace]])))
heat1 <- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE,
    main=sprintf("%s comparison", splVec[batchPlace]), silent=TRUE)

# For the second batch.
batchPlace <- 2
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
tab <- table(paste("after", clusters.mnn[tmpInd]),
    paste("before", colLabels(rescaled.mbn[[batchPlace]])))
heat2 <- pheatmap(log10(tab+10), cluster_row=FALSE, cluster_col=FALSE,
    main=sprintf("%s comparison", splVec[batchPlace]), silent=TRUE)

gridExtra::grid.arrange(heat1[[4]], heat2[[4]])
```

Another evaluation approach is to compute the coassignment probabilities (Section 10.6), i.e., the probability that cells from two within-batch clusters are clustered together in the across-batch clustering. High probabilities off the diagonal in Figure 13.5 indicate that within-batch clusters are merged in the across-batch analysis. We would generally expect low off-diagonal probabilities for most pairs of clusters, though this may not be reasonably possible if the within-batch clusters were poorly separated in the first place.

Coassignment probabilities for the within-batch clusters, based on coassignment of cells in the across-batch clusters obtained after MNN correction. One heatmap is generated for each of the GSM3872434 and GSM3872435, where each entry is colored according to the coassignment probability between each pair of within-batch clusters:

```{r}
# For the first batch.
batchPlace <- 1
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
tab <- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd])
heat1 <- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE,
    col=rev(viridis::magma(100)), main=sprintf("%s probabilities", splVec[batchPlace]), silent=TRUE)

# For the second batch.
batchPlace <- 2
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
tab <- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd])
heat2 <- pheatmap(tab, cluster_row=FALSE, cluster_col=FALSE,
    col=rev(viridis::magma(100)), main=sprintf("%s probabilities", splVec[batchPlace]), silent=TRUE)

gridExtra::grid.arrange(heat1[[4]], heat2[[4]])
```

Finally, we can summarize the agreement between clusterings by computing the Rand index. This provides a simple metric that we can use to assess the preservation of variation by different correction methods. Larger rand indices (i.e., closer to 1) are more desirable, though this must be balanced against the ability of each method to actually remove the batch effect.

```{r}
suppressMessages(library(fossil))
batchPlace <- 1
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
ri1 <- rand.index(as.integer(clusters.mnn[tmpInd]),
    as.integer(colLabels(rescaled.mbn[[batchPlace]])))
ri1

batchPlace <- 2
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
ri2 <- rand.index(as.integer(clusters.mnn[tmpInd]),
    as.integer(colLabels(rescaled.mbn[[batchPlace]])))
ri2
```

### Encouraging consistency with marker genes

In some situations, we will already have performed within-batch analyses to characterize salient aspects of population heterogeneity. This is not uncommon when merging datasets from different sources where each dataset has already been analyzed, annotated and interpreted separately. It is subsequently desirable for the integration procedure to retain these “known interesting” aspects of each dataset in the merged dataset. We can encourage this outcome by using the marker genes within each dataset as our selected feature set for fastMNN() and related methods. This focuses on the relevant heterogeneity and represents a semi-supervised approach that is a natural extension of the strategy presented in th feature selection section.

<!-- To illustrate, we apply this strategy to our PBMC datasets. --> We identify the top marker genes from pairwise Wilcoxon ranked sum tests between every pair of clusters within each batch, analogous to the method used by SingleR (Chapter 12). In this case, we use the top 10 marker genes but any value can be used depending on the acceptable trade-off between signal and noise (and speed). We then take the union across all comparisons in all batches and use that in place of our HVG set in fastMNN().

```{r}
# Recall that groups for marker detection
# are automatically defined from 'colLabels()'. 
stats1 <- pairwiseWilcox(rescaled.mbn[[1]], direction="up")
markers1 <- getTopMarkers(stats1[[1]], stats1[[2]], n=10)

stats2 <- pairwiseWilcox(rescaled.mbn[[2]], direction="up")
markers2 <- getTopMarkers(stats2[[1]], stats2[[2]], n=10)

stats3 <- pairwiseWilcox(rescaled.mbn[[3]], direction="up")
markers3 <- getTopMarkers(stats3[[1]], stats3[[2]], n=10)

stats4 <- pairwiseWilcox(rescaled.mbn[[4]], direction="up")
markers4 <- getTopMarkers(stats4[[1]], stats4[[2]], n=10)

marker.set <- unique(unlist(c(unlist(markers1), unlist(markers2), unlist(markers3), unlist(markers4))))
length(marker.set) # getting the total number of genes selected in this manner.
```

<!-- MIND marker.set is from thr RUN etc and used for all 11 samples -->

```{r}
set.seed(1000110)
mnn.out2 <- fastMNN(
  rescaled.mbn[1:4],
  subset.row=marker.set,
  BSPARAM=BiocSingular::RandomParam(deferred=TRUE))
```

A quick inspection indicates that the original within-batch structure is indeed preserved in the corrected data. This highlights the utility of a marker-based feature set for integrating datasets that have already been characterized separately in a manner that preserves existing interpretations of each dataset. We note that some within-batch clusters have merged, most likely due to the lack of robust separation in the first place, though this may also be treated as a diagnostic on the appropriateness of the integration depending on the context.

```{r}
mnn.out2 <- runTSNE(mnn.out2, dimred="corrected",
    external_neighbors=TRUE, 
    BNPARAM=AnnoyParam(),
    BPPARAM=bpp,
    n_threads=bpnworkers(bpp))
batchVec <- levels(mnn.out$batch)
gridExtra::grid.arrange(
    plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[1]], colour_by=I(colLabels(rescaled.mbn[[1]]))) + ggtitle(batchVec[1]),
    plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[2]], colour_by=I(colLabels(rescaled.mbn[[2]]))) + ggtitle(batchVec[2]),
    plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[3]], colour_by=I(colLabels(rescaled.mbn[[3]]))) + ggtitle(batchVec[3]),
    plotTSNE(mnn.out2[,mnn.out2$batch==batchVec[4]], colour_by=I(colLabels(rescaled.mbn[[4]]))) + ggtitle(batchVec[4]),
    ncol=2
)
```

### Using the corrected values

it is preferable to perform DE analyses using the uncorrected expression values with blocking on the batch. This strategy is based on the expectation that any genuine DE between clusters should still be present in a within-batch comparison where batch effects are absent. It penalizes genes that exhibit inconsistent DE across batches, thus protecting against misleading conclusions when a population in one batch is aligned to a similar-but-not-identical population in another batch. We demonstrate this approach below using a blocked t-test to detect markers in the PBMC dataset, where the presence of the same pattern across clusters within each batch is reassuring. If integration is performed across multiple conditions, it is even more important to use the uncorrected expression values for downstream analyses - see Section 14.5.2 for a discussion.

```{r}
m.out <- findMarkers(
  uncorrected,
  clusters.mnn,
  block=uncorrected$batch, # TODO batch or type?
  direction="up",
  lfc=1,
  row.data=rowData(uncorrected)[,
                                c("ensembl_gene_id","Symbol"),
                                drop=FALSE])
```

```{r}
demo <- m.out[["1"]]
as.data.frame(demo[1:20,c("Symbol", "Top", "p.value", "FDR")]) 
#as.data.frame(demo[1:20,c("external_gene_name", "Top", "p.value", "FDR")]) 
```

Expression level for the top gene, `r rownames(demo)[1]`:

```{r}
geneEnsId <- rownames(demo)[1]
plotExpression(uncorrected, x=I(factor(clusters.mnn)), 
    features=geneEnsId, colour_by="batch") + facet_wrap(~colour_by)
```

## **Challenge** Same but with an ordered merging

We will first merge replicates in each sample group separately, then sample groups, starting with the group with the larger number of 'cell types'.

Hint: use the merge.order option in fastMNN ( ... maybe with "list( list(1,2,3,4), list(9,10,11), list(5,6), list(7,8) )" )

```{r}
# Using randomized SVD here, as this is faster than 
# irlba for file-backed matrices.
set.seed(1000101001)
rm(mnn.out)
mnn.out <- fastMNN(rescaled.mbn,
		   merge.order=list( list(1,2,3,4), list(9,10,11), list(5,6), list(7,8) ),
		   d=50, k=20, subset.row=chosen.hvgs,
    BSPARAM=BiocSingular::RandomParam(deferred=TRUE))
mnn.out
mnn.out$batch <- factor(mnn.out$batch)
mnn.out$type <- gsub("_[1-4]","",mnn.out$batch)
mnn.out$type <- factor(mnn.out$type)
```

```{r}
#class(mnn.out$batch)
#head(mnn.out$batch)
#dim(reducedDim(mnn.out, "corrected"))
#assay(mnn.out, "reconstructed")
print(dim(assay(mnn.out, "reconstructed")))
print(assay(mnn.out, "reconstructed")[1:5,1:3])
```

Diagnostic table and plots:

```{r}
library(scran)
snn.gr <- buildSNNGraph(mnn.out, use.dimred="corrected")
clusters.mnn <- igraph::cluster_walktrap(snn.gr)$membership
mnn.out$clusters.mnn <- sprintf("c%s", clusters.mnn)
tab.mnn <- table(Cluster=mnn.out$clusters.mnn, Batch=mnn.out$batch)
tab.mnn
```

```{r}
pheatmap::pheatmap(tab.mnn,
           border_color      = NA,
           drop_levels       = TRUE,
           #cluster_rows      = FALSE,
           cluster_cols      = FALSE
           )
```

```{r, fig.height=0.5*figSize, fig.width=1.2*figSize}
library(scater)
set.seed(0010101010)
mnn.out <- runTSNE(mnn.out, dimred="corrected",
    external_neighbors=TRUE, 
    BNPARAM=AnnoyParam(),
    BPPARAM=bpp,
    n_threads=bpnworkers(bpp))

p.batch <- plotTSNE(mnn.out, colour_by="batch")
p.clu <- plotTSNE(mnn.out, colour_by="clusters.mnn")
#gridExtra::grid.arrange(p.clu, p.batch, ncol=2)
gridExtra::grid.arrange(p.clu, p.batch+facet_wrap(~mnn.out$type), ncol=2)
```

Write mnn.out object to file

```{r fastMnnWholeByList_writeRds}
colData(mnn.out) <- cbind(colData(uncorrected),colData(mnn.out)[,c("type", "clusters.mnn")])
# Write object to file
# fastMnnWholeByList -> Fmwbl
tmpFn <- sprintf("%s/%s/Robjects/%s_sce_nz_postDeconv%s_Fmwbl.Rds", projDir, outDirBit, setName, setSuf)
saveRDS(mnn.out, tmpFn)

tmpFn <- sprintf("%s/%s/Robjects/%s_sce_nz_postDeconv%s_Fmwbl2.Rds", projDir, outDirBit, setName, setSuf)
saveRDS(list("chosen.hvgs"=chosen.hvgs, "uncorrected"=uncorrected,"rescaled.mbn"=rescaled.mbn), tmpFn)
```

Proportions of lost variance

```{r}
metadata(mnn.out)$merge.info$lost.var
```

```{r}
tmpData <- metadata(mnn.out)$merge.info$lost.var

pheatmap::pheatmap(tmpData,
           border_color      = NA,
           drop_levels       = TRUE,
           cluster_rows      = FALSE,
           cluster_cols      = FALSE
           )
```


Comparison to within-batch clusters

```{r}
library(pheatmap)
mnn.out$batch <- factor(mnn.out$batch) # somehow need to re-factor batch
levels(mnn.out$batch)

# For the first batch (adding +10 for a smoother color transition
# from zero to non-zero counts for any given matrix entry).
batchPlace <- 1
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
length(paste("after", clusters.mnn[tmpInd]))
rescaled.mbn[[batchPlace]]
rescaled.mbn[[batchPlace]] %>% colData %>% head

length(paste("before", colLabels(rescaled.mbn[[batchPlace]])))
#save.image("dataSetIntegrationWhole.debug.Rdata")

table(paste("after", clusters.mnn[tmpInd]))
table(paste("before", colLabels(rescaled.mbn[[batchPlace]])))
```

`r #knitr::knit_exit()`


```{r}
tab <- table(paste("after", clusters.mnn[tmpInd]),
             paste("before", colLabels(rescaled.mbn[[batchPlace]])))
heat1 <- pheatmap(
  log10(tab+10),
  cluster_row=FALSE,
  cluster_col=FALSE,
  main=sprintf("%s comparison", splVec[batchPlace]),
  silent=TRUE)

# For the second batch.
batchPlace <- 2
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
tab <- table(paste("after", clusters.mnn[tmpInd]),
    paste("before", colLabels(rescaled.mbn[[batchPlace]])))
heat2 <- pheatmap(
  log10(tab+10),
  cluster_row=FALSE,
  cluster_col=FALSE,
  main=sprintf("%s comparison", splVec[batchPlace]),
  silent=TRUE)

gridExtra::grid.arrange(heat1[[4]], heat2[[4]])
```

Co-assignment probabilities

```{r}
# For the first batch.
batchPlace <- 1
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
tab <- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd])
heat1 <- pheatmap(
  tab,
  cluster_row=FALSE,
  cluster_col=FALSE,
  col=rev(viridis::magma(100)),
  main=sprintf("%s probabilities", splVec[batchPlace]),
  silent=TRUE)

# For the second batch.
batchPlace <- 2
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
tab <- coassignProb(colLabels(rescaled.mbn[[batchPlace]]), clusters.mnn[tmpInd])
heat2 <- pheatmap(
  tab,
  cluster_row=FALSE,
  cluster_col=FALSE,
  col=rev(viridis::magma(100)),
  main=sprintf("%s probabilities", splVec[batchPlace]),
  silent=TRUE)

gridExtra::grid.arrange(heat1[[4]], heat2[[4]])
```

Rand index:

```{r}
library(fossil)
batchPlace <- 1
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
ri1 <- rand.index(as.integer(clusters.mnn[tmpInd]),
    as.integer(colLabels(rescaled.mbn[[batchPlace]])))
ri1

batchPlace <- 2
tmpInd <- mnn.out$batch==levels(mnn.out$batch)[batchPlace]
ri2 <- rand.index(as.integer(clusters.mnn[tmpInd]),
    as.integer(colLabels(rescaled.mbn[[batchPlace]])))
ri2
```

Cluster markers:

```{r}
m.out <- findMarkers(
  uncorrected,
  clusters.mnn,
  block=uncorrected$batch,
  direction="up",
  lfc=1,
  row.data=rowData(uncorrected)[,
                                c("ensembl_gene_id","Symbol"),
                                drop=FALSE])
```

```{r}
demo <- m.out[["1"]]
as.data.frame(demo[1:20,c("Symbol", "Top", "p.value", "FDR")]) 
```

Expression level fot the top gene, `r demo$Symbol[1]`, (`r rownames(demo)[1]`):

```{r}
geneEnsId <- rownames(demo)[1]

plotExpression(
  uncorrected,
  x=I(factor(clusters.mnn)),
  features=geneEnsId,
  colour_by="batch") +
  facet_wrap(~colour_by)
```

## Session information

```{r}
sessionInfo()
```
